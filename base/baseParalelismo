PA UNIVERSIDADE DE SÃO PAULO
   INSTITUTO DE FÍSICA DE SÃO CARLOS
   PARALELISMO EM VISÃO NATURAL E
   ARTIFICIAL
   Odemir Martinez Bruno
   Tese apresentada ao Instituto de Física de São
   Carlos, da Universidade de São Paulo, para a
   obtenção do título de Doutor em Ciências: Física
   Aplicada (Física Computacional).
   Orientador: Prof. Dr. Luciano da Fontoura Costa
   DEPARTAMENTO DE FÍSICA E INFORMÁTICA
   São Carlos
   2000
   Bruno, Odemir Martinez
   Paralelismo em Visão Natural e Artificial / Odemir
   Martinez Bruno. São Carlos, 200.
   391 p.
   Tese (Doutorado) - Instituto de Física de São Carlos,
   2000.
   Orientador: Prof. Dr. Luciano da Fontoura Costa
   1. Visão Cibernética. 2. Computação Paralela.
   I. Título
   À minha esposa Adriana e aos meus
   pais Orlando e Maria Candida.
   AGRADECIMENTOS
   À minha esposa Adriana e aos meus pais Orlando e Maria Candida, pelo
   incentivo, colaboração, carinho e apoio.
   Ao Prof. Luciano, pela orientação científica, amizade e pelas valiosas
   oportunidades de aprendizado.
   Aos meus amigos, colegas e colaboradores Alan Salvany Felinto e Jander
   Moreira, pela cooperação nos trabalhos referentes ao sistema Cyvis-1 e pelo
   auxílio na validação e testes do CVMP, além da convivência pessoal.
   A Luís Augusto Consularo, pelo trabalho em conjunto, pelo auxílio nos
   testes do CVMP e pela amizade.
   A Roberto César Marcondes Junior, pelo trabalho em conjunto no projeto
   ynergos e convivência pessoal.
   À Cristina Algodoal Martins, pelas valiosas sugestões em botânica e pela
   amizade.
   Ao Prof. Hilton Thadeu Zarate do Couto da ESALQ-USP, pelas indicações e
   informações referentes aos herbários.
   À Estação Ecológica de Moji-Guaçu do Instituto Florestal do Estado de S.
   Paulo, pelo fornecimento de amostras de plantas arbóreas utilizadas neste
   trabalho. Em especial a Eduardo Amaral Batista, pesquisador chefe da unidade e
   José Carlos de Lima, auxiliar de apoio à pesquisa.
   À Wladerez A. G. Caiado, por sua competência e constante bom humor,
   nos auxiliando ao longo desses anos nas questões burocráticas.
   Ao pessoal da biblioteca do Instituto de Física de São Carlos, pela
   competência e presteza.
   A todos os colegas do Grupo de Pesquisa em Visão Cibernética pela
   amizade, fraternidade, cooperação e pelas produtivas discussões.
PA Aos técnicos do Grupo, Marcos Roberto Gonçalves e Alexandre Rodrigues
   da Silva, pelo auxílio e suporte.
   A todos os professores e pesquisadores com quem pude aprender e
   debater nesses anos.
   A todos que, direta ou indiretamente, prestaram seu apoio e/ou sua
   colaboração na realização deste trabalho.
   Ao CNPq pelo suporte financeiro.
   E finalmente quero deixar meus profundos agradecimentos ao Instituto de
   Física de São Carlos da Universidade de São Paulo, pela infra-estrutura e
   excelente ambiente para a pesquisa científica, onde tive a honra de estudar,
   pesquisar, trabalhar e conhecer grandes amigos.
   RESUMO
   Nesta tese são abordados, de maneira integrada, aspectos de paralelismo
   em visão natural e artificial, com discussões críticas das diversas áreas
   relacionadas. O paralelismo é discutido no sistema visual dos primatas, assim como
   suas principais contribuições e motivações incentivando a incorporação de
   paralelismo em sistemas de visão artificial. Um dos objetivos principais é fornecer
   as bases de paralelismo para o desenvolvimento do projeto Cyvis-1, uma proposta
   do Grupo de Pesquisa em Visão Cibernética (IFSC-USP) para visão versátil, com
   forte motivação biológica e baseada no córtex visual dos primatas. Para tanto, foi
   introduzida e implementada a proposta CVMP (Cybernetic Vision Message
   Passage), um conjunto de ferramentas para o desenvolvimento de aplicações
   paralelas em visão, tanto para sistemas distribuídos como para máquinas
   multiprocessadores. Baseada em programação orientada a objetos, interação
   homem-máquina, engenharia de software e programação visual, a proposta prima
   pelo desenvolvimento de forma simples e amigável. O CVMP é testado, avaliado e
   validado quanto a aspectos de funcionalidade e utilização, através da
   implementação paralela de diversos algoritmos de visão computacional e de
   processamento de imagens (operadores locais, transformada de Hough e
   transformada de Fourier, entre outros) os quais, além de ilustrar a utilização da
   ferramenta, são discutidos em termos de arquitetura e balanceamento de carga.
   São apresentadas três aplicações reais de sistemas paralelos de visão
   computacional, implementadas através do CVMP, demonstrando a eficiência da
   ferramenta, na implementação paralela, na utilização e cooperação de trabalho.
   Duas destas aplicações (integração de atributos visuais no projeto Cyvis-1 e um
   modelo de complexidade com base na percepção humana), foram desenvolvidas
   em conjunto com outros pesquisadores do Grupo de Pesquisa em Visão
   Cibernética. A terceira aplicação apresenta uma proposta do autor para um sistema
   automático de reconhecimento de plantas arbóreas (Botânica).
   i
   ii
   ABSTRACT
   This thesis addresses, in an integrated way, the concept and usage of
   parallelism in natural and artificial vision. It starts by revising the primate visual
   system, and discussing how its principles and solutions can be extended to
   computational systems. One of the main objectives is to supply the parallelism
   backbone for the development of the Cyvis-1 System, which is a proposal of the
   Cybernetic Vision Research Group (IFSC-USP) for versatile vision, presenting a
   strong biological motivation, especially regarding the primate visual cortex. In order
   to achieve these objectives, the CVMP – Cybernetic Vision Message Passage – had
PA to be developed, representing a set of simple and friendly paral el tools for computer
   vision applications in distributed and paral el (multiprocessor) systems, which is
   based on object oriented programming, human-machine interaction, software
   engineering and visual programming. The CVMP is tested, evaluated and validated
   with respect to functionality and utilization through the parallel implementation of
   several algorithms in computer vision and image processing (local operators, Hough
   transform, Fourier transform, etc.) which, in addition to il ustrating the tools, are also
   discussed as far as their architecture and load balancing is concerned. Three
   applications of parallel computer vision systems to real situations are presented and
   implemented by using CVMP, corroborating the effectiveness of the tools in the
   paral el implementation, usage, and researcher integration. Two such applications
   (visual attributes integration in Cyvis-1 and a human complexity model) have been
   developed in collaboration with other researchers at the Cybernetic Vision Research
   Group. The third application presents the author’s proposal for an automated
   system for arboreal plants recognition (Botany).
   iii
 
  CAPÍTULO 1 – INTRODUÇÃO
   1.1 – O PARALELISMO NATURAL
   Desconhecemos a exata razão da natureza ao evoluir os diversos seres
   vivos, mas sabemos entretanto, que como resultado, eles se tornam mais
   adaptados ao meio e consequentemente mais complexos. Devemos lembrar que a
   adaptação não compreende apenas a modelagem do indivíduo ao meio físico, mas
   também seu relacionamento com outros seres e muitas vezes a competição entre
   as espécies e indivíduos. Embora vários fatores sejam relevantes na adaptação de
   um ser ao meio, tais como: locomoção, mecanismos de alimentação e dispositivos
   de ataque (predadores) e defesa (presa), sem dúvida o mais importante é a
   informação, uma vez que é através dela que o indivíduo vai poder se locomover,
   alimentar, defender ou atacar, enfim realizar sua integração ao meio.
   No decorrer de bilhões de anos, inúmeros mecanismos foram desenvolvidos
   pela natureza a fim de que os seres vivos pudessem extrair informações do meio.
   Esses mecanismos são denominados sentidos, estando presentes no ser humano
   em cinco diferentes modalidades: audição, visão, olfato, paladar e tato. O que
   determina a eficácia de um sentido é a quantidade e a qualidade das informações
   através dele percebidas. Foi através da percepção das ondas eletromagnéticas que
   a natureza desenvolveu uma das suas obras mais incríveis, o mecanismo mais
   poderoso e sofisticado para a aquisição de informação: a visão.
   Mais do que apenas uma maneira de obter informações sobre o meio, a
   visão é um complexo sistema de processamento de sinais, no qual as imagens são
   convertidas em informações compreensíveis para o indivíduo. É razoável que um
   sistema de processamento tão intrincado e sofisticado tenha um elevado custo. De
   fato, nos animais que possuem a visão mais evoluída, como é o caso dos primatas,
   cerca de 60% dos neurônios corticais estão envolvidos com este processo.
   Entretanto, num mundo onde a competição é sinônimo de sobrevivência, não basta
   obter informação abundante e de qualidade sobre o meio, é necessário também
   que ela seja adquirida em tempo real, uma vez que essa condição na maioria das
   vezes pode significar a diferença entre a vida ou morte para grande parte dos seres
PA vivos.
   3
   CAPÍTULO 1
   Sem dúvida, o principal mecanismo encontrado na natureza para agilizar o
   processamento das informações é o paralelismo. A maior prova disso é a natureza
   paralela e distribuída do sistema de visão dos primatas, os animais mais evoluídos.
   Contudo, não é apenas para a velocidade de resposta que o paralelismo contribui.
   Na verdade, o sistema de visão dos primatas tem no paralelismo sua base de
   estruturação em todos os seus níveis. Como propõem Zeki e Shipp [Zeki & Shipp,
   1988], o paralelismo permite não somente a integração dos atributos visuais, mas
   também de cada um dos submódulos que os compõe.
   O paralelismo foi uma escolha realizada pela natureza ao longo da
   evolução, o qual iniciou com o aparecimento dos seres pluricelulares. Se
   pensarmos em cada célula como um elemento individual de processamento da
   vida, todo ser vivo pluricelular é composto por uma estrutura de processamento
   paralelo. Nesse contexto, o paralelismo vai se intensificando à medida que os seres
   se tornam mais complexos e começam a surgir os tecidos e órgãos, culminando no
   sistema nervoso central, a máquina de processamento paralelo mais poderosa que
   conhecemos. Em visão, assim como no sistema nervoso, a base estrutural do
   processamento está fundada no paralelismo.
   Podemos considerar que o paralelismo na visão se inicia nos dois órgãos
   responsáveis pela captação da luz, os olhos, que possuem autonomia e
   independência, operando em concorrência. O paralelismo dos olhos se acentua
   quando consideramos suas retinas. Além de possuírem hemisférios de percepção
   autônomos (campo visual direito e esquerdo), as retinas possuem dois conjuntos de
   fotorreceptores (cones e bastonetes) que constituem o início de sistemas
   independentes que captam informações distintas (caminho parvo celular e magno
   celular). A informação proveniente da retina é replicada e distribuída para diversas
   regiões do córtex visual, caracterizando um sistema massivamente paralelo com
   arquitetura distribuída constituído por módulos independentes responsáveis pelo
   processamento de informações específicas. Cada um dos módulos que constituem
   o sistema visual é ainda subdividido em estruturas hierárquicas que realizam
   processamento paralelo. Deste modo, o paralelismo apresenta-se no sistema visual
   em multiníveis, mostrando-se como uma das bases de sua arquitetura.
   É dentro do fascinante universo da visão que reside o objeto de estudo
   desta tese multidisciplinar: o estudo do paralelismo no sistema de visão dos
   primatas e sua inspiração para que possamos desenvolver sistemas paralelos de
   visão artificial mais eficientes.
   4
   INTRODUÇÃO
   1.2 - PARALELISMO EM VISÃO ARTIFICIAL
   Embora seja de conhecimento da neurociência que os sistemas biológicos
   de visão estejam fundamentados em estruturas distribuídas e paralelas de
   processamento, não encontramos, como era de se esperar, na visão artificial (visão
   computacional) a mesma concepção. De fato, observando a literatura da área, esse
   assunto, embora de extrema importância, tem sido pouco explorado. Se tomarmos
   algumas das bases bibliográficas mais importantes, poderemos constatar que o
   paralelismo não é nem ao menos citado, na sua grande maioria. Como exemplo
   podemos sugerir o famoso livro "Vision" de David Marr, o qual é consagrado por ser
   uma das bíblias da área. Marr não faz nem ao menos uma citação em sua obra
PA sobre a importância do paralelismo em visão.
   Ainda que a visão artificial seja uma área cuja inspiração biológica é
   amplamente incentivada, não sabemos qual é o motivo da lacuna que incide sobre
   o tema do paralelismo. Podemos supor alguns fatores responsáveis pela exclusão
   do paralelismo nas bases da visão artificial. Uma das possibilidades seria o
   processamento seqüencial historicamente utilizado pela ciência da computação
   para resolver seus problemas, que pode ter contribuído para que o paralelismo
   tenha sido abandonado em visão artificial.
   Uma diferença entre os elementos de processamento natural e biológico é a
   velocidade de processamento. Sendo os neurônios lentos, se comparados com a
   freqüência de operação dos microprocessadores atuais, existe uma necessidade
   intrínseca de paralelismo para realizar processamento em tempo real. Talvez este
   fator tenha levado a uma crença onde, ao contrário da visão natural, o estudo de
   visão artificial não tivesse a necessidade de se preocupar com os assuntos de
   paralelismo, uma vez que num futuro próximo, os sistemas computacionais
   poderiam chegar a possuir poder computacional suficiente para efetuar os métodos
   e técnicas de visão computacional e processamento de imagens em tempo real.
   Entretanto, devemos lembrar que na visão natural o paralelismo não possui apenas
   esse caráter.
   Outra possibilidade seria a dificuldade no desenvolvimento de aplicações
   paralelas, devido à impopularidade da computação paralela levando a uma falta de
   ambientes de desenvolvimento amigáveis, a necessidade de um profundo
   conhecimento em computação paralela exigida para sua programação e sistemas
   de computação complexos e pouco amigáveis entre outras. Esses fatores têm
   5
   CAPÍTULO 1
   mantido a computação paralela restrita aos especialistas da área. Sendo visão um
   assunto multidisciplinar envolvendo além de cientistas da computação,
   engenheiros, matemáticos, físicos, biólogos, neurocientistas e outros, o alto custo
   com o aprendizado e utilização das técnicas de computação paralela estariam
   assim conduzindo à opção seqüencial.
   Seja qual for a possibilidade, podemos concluir que a principal barreira que
   impõe uma abordagem paralela em visão artificial é a dificuldade de implementação
   paralela e o direcionamento de suas ferramentas para o restrito grupo dos
   especialista da área. Observando a história da computação, vemos a grande
   importância da interação usuário/máquina e de sua simplificação. Deste modo,
   tornar as tecnologias mais fáceis de utilizar, além de auxiliar os usuários
   inexperientes, também beneficia os expertos, uma vez que [Hayes, 1990] [Baber et
   al., 1993]. Bons exemplos desta linha de raciocínio são: a tecnologia GUI ( Grafical
   User Interface), a programação visual e a programação orientada a objetos, cujo
   principal objetivo é simplificar o relacionamento entre o homem e a máquina.
   Deste forma, acreditamos que a principal solução para a ausência de
   paralelismo em visão artificial seria eliminar a barreira da dificuldade de utilização
   da tecnologia de computação paralela, através de metodologias e ferramentas que
   possibilitassem uma simplificação da implementação de aplicativos, permitindo
   assim que toda a gama de pesquisadores relacionados com visão pudessem
   facilmente incorporar paralelismo em seus projetos.
   Assim sendo, o problema do paralelismo em visão artificial se transforma
   numa questão inserida no seio da ciência da computação: a adoção do paralelismo
   com uma filosofia de interação homem-máquina, objetivando o acesso fácil e
PA amigável aos recursos da computação paralela.
   1.3 - AS DUAS COLUNAS
   O paralelismo é inerente à visão natural, possibilitando além de grande
   performance (processamento em tempo real), as bases para a integração entre os
   diferentes atributos visuais e seus respectivos módulos [Zeki & Shipp, 1988]
   [Livingstone & Hubel, 1988] [Zeki, 1993] [Hubel, 1995] [Levine & Shefner, 1991].
   Seguindo as lições da natureza, o estudo do paralelismo em visão artificial, é vital
   para o desenvolvimento de modelos mais realísticos de visão auxiliando na
   elaboração de sistemas mais complexos, que permitam a integração de atributos
   6
   INTRODUÇÃO
   visuais (cor, estéreo, textura, forma, etc.) e diferentes técnicas de visão, assim
   como sua execução em tempo real, uma vez que a performance está condicionada
   à filosofia paralela.
   Além de melhorias nos sistemas de visão artificial, a adoção de modelos
   mais realísticos do ponto de vista biológico permite uma melhor compreensão dos
   sistemas de visão natural, e consequentemente do funcionamento do cérebro como
   um todo. Essa realimentação de conhecimento constitui uma das bases da Visão
   Cibernética, que caracteriza o estudo da visão como um assunto multidisciplinar
   correlacionado.
   Esta tese está fundada em duas colunas: (i) o estudo do paralelismo em
   visão natural e artificial e (i ) a proposta de uma ferramenta de desenvolvimento
   paralelo, baseada na interação entre usuário e máquina, que facilite a
   implementação de algoritmos paralelos de visão.
   Na primeira parte que compõe este trabalho realizamos uma revisão,
   discussão e análise do paralelismo em visão natural e artificial. São abordadas as
   bases do paralelismo na visão natural, enfocando o sistema de visão dos primatas.
   Em visão artificial são tratados os possíveis benefícios do paralelismo, através de
   sistemas paralelos de visão, concentrando o assunto sobre o projeto Cyvis-1
   ( Cybernetic Vision 1), sistema de visão versátil em desenvolvimento no nosso
   grupo. O Cyvis-1 é baseado no modelo de especialização funcional proposto por
   Zeki & Shipp [Zeki & Shipp, 1988], apresentando deste modo, assim como os
   sistemas de visão natural, uma arquitetura que possui paralelismo inerente.
   Conforme discutimos na seção anterior, acreditamos que a principal razão
   que impele a utilização de paralelismo em massa em visão computacional é a
   dificuldade de utilização, de implementação e o longo treinamento requerido para a
   implementação paralela. Na tentativa de solucionar esse problema, sobretudo
   dentro do nosso grupo de pesquisa, a segunda parte desta tese introduz uma nova
   metodologia de implementação paralela, baseada na simplicidade de utilização e
   programação e na reutilização de código.
   1.4 - OBJETIVOS DA TESE
   Nesta seção vamos apresentar ao leitor uma síntese dos principais objetivos
   deste trabalho, permitindo uma perspectiva sobre os assuntos discutidos e
   abordados ao longo da tese.
   7
   CAPÍTULO 1
   Como primeiro passo, este trabalho pretende realizar um levantamento
   crítico e abrangente das diversas áreas relacionadas ao paralelismo em visão
   natural e artificial. Uma vez que o paralelismo em visão artificial está vinculado à
   computação paralela, intencionamos realizar uma substancial revisão à
PA computação paralela, de modo a fornecer ao leitor as bases para as discussões do
   assunto sob o ponto de vista da visão. Em visão natural, o objetivo é realizar uma
   revisão sobre o assunto, culminando em uma discussão do paralelismo no sistema
   visual dos primatas. A integração entre as duas modalidades de visão ocorre
   através de uma análise crítica de sistemas de visão artificial com motivação
   biológica.
   Um dos objetivos principais deste trabalho é fornecer as bases de
   paralelismo e integração entre pesquisadores para o desenvolvimento do projeto
   Cyvis-1, uma proposta de visão versátil, que vem sendo desenvolvida pelo nosso
   grupo. Com forte motivação biológica, o Cyvis-1, é baseado na especialização
   funcional do córtex visual dos primatas proposta por Zeki & Shipp [Zeki & Shipp,
   1988], possuindo como principais características a integração dos atributos visuais,
   o paralelismo em visão e o trabalho cooperativo entre os diversos pesquisadores
   envolvidos no projeto.
   De forma a viabilizar o item anterior e na tentativa de preencher a lacuna do
   paralelismo em visão artificial, pretendemos desenvolver um conjunto de
   ferramentas para o desenvolvimento, de forma simples e amigável, de aplicações
   paralelas em visão que, auxilie tanto os programadores sem conhecimentos em
   paralelismo como os expertos. Deste modo, permitirá a qualquer pesquisador de
   visão com o mínimo conhecimento de programação, a utilização de recursos de
   paralelismo em seus projetos, e aos especialistas, o desenvolvimento mais ágil.
   Denominado CVMP ( Cybernetic Vision Message Passage), o conjunto de
   ferramentas em questão é voltado para a plataforma Windows NT/9X e para o
   ambiente de desenvolvimento Delphi, que constituem uma das bases de
   desenvolvimento computacional do nosso grupo.
   Uma vez implementado, é necessário realizar a avaliação e validação do
   CVMP, tanto nos aspectos de funcionalidade quanto em utilização. Assim, um dos
   objetivos do trabalho foi a implementação de versões paralelas de diversos
   algoritmos de visão computacional e de processamento de imagens. Dentre os
   algoritmos, serão abordados casos clássicos em visão e processamento de
   imagens, tais como os operados locais, transformada de Hough [Hough, 1959] e
   8
   INTRODUÇÃO
   transformada de Fourier [Brigham, 1988], amplamente discutidos na literatura,
   algumas vezes até mesmo sob o ponto de vista do paralelismo, além de uma
   técnica de segmentação inédita baseada em campos aleatórios de Markov [Bruno &
   Costa, 2000]. Os algoritmos foram analisados através dos módulos de estatística do
   CVMP, o qual permitiu um estudo sobre seu comportamento, eficiência e
   performance.
   Outro objetivo é o desenvolvimento de situações reais em visão artificial que
   utilizem os recursos da computação paralela, através do CVMP. Para tanto serão
   apresentadas 3 aplicações inéditas desenvolvidas nesse trabalho: (i) estruturas de
   paralelismo da integração dos atributos cor e estéreo do projeto Cyvis-1, (ii) um
   experimento para um modelo de complexidade baseado na percepção humana
   (projeto ynergos) e (i i) uma proposta para um herbário digital e automático
   (proposta TreeVis). As duas primeiras aplicações fazem parte de projetos em
   desenvolvimento no nosso grupo (Grupo de Pesquisa em Visão Cibernética), nos
   quais além do autor participam outros integrantes do grupo, possibilitando a
   validação do CVMP tanto na simplicidade de utilização (manuseio amigável), como
   na reutilização de código e integração entre pesquisadores. A outra aplicação
PA apresenta um protótipo de uma proposta do autor para um sistema de
   reconhecimento automático de plantas arbóreas, com o intuito de fornecer aos
   botânicos uma ferramenta complementar aos tradicionais herbários.
   1.5 - ORGANIZAÇÃO DA TESE
   Esta tese prossegue com uma revisão dos conceitos básicos de
   computação paralela, permitindo ao leitor familiarizar-se com o assunto. No
   Capítulo 2 são apresentados alguns aspectos teóricos de arquiteturas paralelas e,
   no Capítulo 3, o tema continua com uma abordagem em software.
   No Capítulo 4 é realizada uma revisão de visão natural, com enfoque no
   sistema de visão dos primatas. O capítulo é complementado por uma discussão do
   assunto sob o prisma do paralelismo. No Capítulo 5 são apresentados os sistemas
   de visão artificial Cyvis-1 e ynergos, em desenvolvimento no Grupo de Visão
   Cibernética deste instituto. Dentre eles devemos destacar o Cyvis-1, sistema
   fortemente motivado pela inspiração biológica, que possui como coluna dorsal o
   paralelismo, sendo uma das bases de estudo deste trabalho. Ainda nesse capítulo
   será realizada uma análise comparativa entre o sistema Cyvis-1 e outros sistemas
   9
   CAPÍTULO 1
   artificiais encontrados na literatura.
   Esta tese introduz um conjunto de ferramentas visuais, que simplificam a
   implementação de aplicações paralelas, denominado CVMP. Embora o CVMP
   tenha sido idealizado para a visão computacional, sua utilização é genérica,
   permitindo virtualmente que qualquer programador Delphi desenvolva uma
   aplicação paralela, bastando para isto um conhecimento rudimentar de paralelismo.
   O conjunto de ferramentas CVMP é apresentado e discutido no Capítulo 6.
   O Capítulo 7 apresenta diversas técnicas e métodos paralelos de visão
   computacional e processamento de imagens, desenvolvidos através de CVMP.
   Cada caso é discutido, abordando as questões teóricas do assunto, assim como os
   resultados da implementação paralela e ainda sua comparação com as versões
   seqüenciais. Dentre as técnicas apresentadas salientamos a implementação
   paralela do algoritmo de segmentação de imagens, baseado em campos aleatórios
   de Markov, cuja metodologia foi desenvolvida neste trabalho.
   No Capítulo 8 são apresentadas três inéditas aplicações paralelas em visão
   artificial, implementadas através de CVMP. A primeira delas é um protótipo do
   sistema de visão Cyvis-1, na qual é realizada a integração dos atributos de cor e
   estéreo, a partir do paralelismo. Na seguinte, é discutido um experimento de
   psicofísica realizado a partir do projeto ynergos, visando a obtenção de um
   modelo de medida de complexidade, baseado na percepção humana. Na última
   aplicação temos um sistema paralelo de visão para auxiliar no levantamento e
   estudo das plantas arbóreas de florestas tropicais, que funciona como um herbário
   digital, cuja proposta e implementação foi introduzida nesta tese.
   Finalmente esta tese é concluída no Capítulo 9, onde são discutidas as
   contribuições deste trabalho e as possíveis pesquisas científicas que podem ser
   realizadas na sua continuação.
   10
   CAPÍTULO
   2
   COMPUTAÇÃO PARALELA –
   HARDWARE
   ... toda ciência é melhor conhecida a partir de sua história, do mesmo modo que as
PA maiores edificações apresentam as bases mais sólidas ...
   11
   CAPÍTULO 2
   12
   COMPUTAÇÃO PARALELA - HARDWARE
   CAPÍTULO 2 – COMPUTAÇÃO PARALELA -
   HARDWARE
   2.1 – INTRODUÇÃO
   Partindo da premissa de que toda ciência é melhor conhecida a partir de sua
   história, do mesmo modo que as maiores edificações apresentam as bases mais
   sólidas, iniciamos esse capítulo com uma breve revisão da história da computação
   paralela, a fim de que possamos, a partir da base, traçar as perspectivas para os
   avanços de uma das áreas mais importantes da Ciência da Computação. Seguindo
   esse princípio, discorreremos sobre a evolução da computação seqüencial e a
   seguir apresentaremos a evolução da computação paralela abordando alguns
   elementos clássicos, de modo a gerar as bases para sua melhor compreensão.
   Como podemos deduzir através do título desse capítulo, estaremos
   discutindo a computação paralela sob o ponto de vista do hardware. Após a
   abordagem histórica da computação paralela, apresentada na Seção 2.2, na
   seguinte, iremos tratar da evolução da eletrônica, e apresentar o perfil tecnológico
   da evolução do hardware. Continuando, trataremos na Seção 2.4 da evolução da
   computação seqüencial, demonstrando as tendências de paralelismo nos
   computadores seqüenciais. Na Seção 2.5 apresentaremos a evolução da
   computação paralela através de uma jornada evolutiva sobre as principais
   arquiteturas não convencionais, e finalmente concluímos o capítulo apresentando
   alguns métodos para a taxionomia de computadores.
   2.2 – PRINCÍPIOS HISTÓRICOS DA COMPUTAÇÃO
   PARALELA
   A história da computação paralela é tão antiga quanto a história do
   computador moderno. O próprio John von Neumann, criador da arquitetura von
   Neumann, arquitetura fundamental para a maioria dos computadores desenvolvidos
   13
   CAPÍTULO 2
   até hoje, desenvolveu trabalhos na década de 40 que discutiam a possibilidade de
   algoritmos paralelos para a solução de equações diferenciais [Breton, 1991]. Com
   isso podemos concluir que a história da computação paralela vem transcorrendo
   em paralelo com a própria história da computação moderna, e como poderemos
   observar, aparenta ser uma evolução natural à computação.
   Sem desmerecer as contribuições de importantes nomes da história da
   computação, como Blaise Pascal [Goldstine, 1993], Gottfried Wilhelm von Leibniz
   [Breton, 1991], Charles Babbage [Spufford & Uglow, 1997] e Al an Turing [Hodges,
   1992], assim como toda a era pré-moderna da história da computação, podemos
   dizer que a computação moderna, teve seu início com o projeto ENIAC (Electronic
   Numerical Integrator and Computer) [Goldstine, 1993] [Breton, 1991], iniciado na
   década de 40. O projeto ENIAC iniciou-se na era das grandes calculadoras.
   Embora seus coordenadores Eckert e Mauchly estivessem dispostos a inovar, em
   seu projeto inicial, o ENIAC não passava de uma calculadora, e a teoria utilizada
   ainda era muito semelhante à máquina de Babbage e mesmo à Pascalina. Em
   agosto de 1944, com a incorporação de John von Neumann no projeto do ENIAC, o
   rumo da história mudaria. Infelizmente o ENIAC já estava em fase bem adiantada e
PA não apresentaria muitas das propostas revolucionárias de von Neumann, mas ainda
   assim o ENIAC seria o primeiro computador eletrônico de uso geral. Mesmo sendo
   um precursor dos computadores modernos, o ENIAC já possuía caráter paralelo,
   uma vez que era disposto em vários módulos independentes, descentralizados e
   que poderiam realizar operações simultaneamente.
   John von Neumann propôs uma nova forma de organizar os sistemas de
   computação, que deu origem à arquitetura von Neumann e marcou o início da
   computação moderna. Um dos principais conceitos apresentados por von Neumann
   foi a memória e a idéia de programa armazenado. A partir da influência direta das
   idéias de von Neumann nasceram os primeiros cinco computadores modernos
   (sistema de memória) da história, que foram o EDVAC (o primeiro projeto de
   computador moderno), a máquina IAS, o BINAC, o EDSAC e o Manchester MARK I
   (o primeiro computador a funcionar na história). Esses computadores foram de
   caráter acadêmico ou militar, porém seus sucessos fizeram com que logo
   começassem a ser produzidos computadores comerciais.
   Um fato bastante curioso nessa história, e que nos liga novamente à história
   da computação paralela, é que uma das características que inviabilizavam o ENIAC
   era o seu aspecto paralelo, onde diversas partes de sua arquitetura funcionavam
   14
   COMPUTAÇÃO PARALELA - HARDWARE
   independentes e em paralelo. Com o paralelismo era necessária a supervisão
   humana, já que a máquina não possuía uma unidade central autômata. [Breton,
   1991].
   Com os princípios de memória e programa armazenado, von Neumann
   implementava a máquina de Turing universal, e com isso, o computador assumia
   agora um papel genérico, todo e qualquer (salvo limitações) problema computável
   possuía um programa capaz de resolvê-lo; porém essa nova organização possuía
   um controle centralizado e tarefas seqüenciais. A partir da definição de computador
   moderno, a história dos computadores pode ser dividida em três partes, que vão
   caminhando simultaneamente. Primeiramente temos a revolução tecnológica, à
   medida que a eletrônica se desenvolvia, computadores mais poderosos e velozes
   surgiam. Ao mesmo tempo que avançava a eletrônica, que está intimamente ligada
   à história da computação, ocorriam também progressos na própria computação, em
   termos de arquitetura, “hardware” e “software”. Na computação ocorreram dois
   caminhos simultâneos: por um lado temos os computadores de uso geral ou
   comerciais, que adotaram a tradicional máquina de von Neumann como arquitetura
   básica, por outro lado temos os denominados supercomputadores.
   A necessidade de velocidade é inerente à computação, e a solução natural
   para essa questão é a paralelização. Portanto, os supercomputadores são projetos
   que tentam alternativas à arquitetura seqüencial de von Neumann, e buscam
   aumentar a performance da máquina através do paralelismo. Em geral essas
   máquinas são de uso específico, voltadas a problemas determinados, e de caráter
   científico.
   2.3 – EVOLUÇÃO ELETRÔNICA
   Do ponto de vista da eletrônica, a história pode ser dividida em cinco partes
   ou gerações. À medida que a tecnologia eletrônica evoluía, novos computadores
   mais velozes e poderosos surgiam, baseados na nova tecnologia. Por um lado a
   velocidade de comutação dos dispositivos aumentava a cada geração e por outro
   as tecnologias de miniaturização e de integração evoluíam e proporcionavam
   computadores menores em tamanho, porém com um número cada vez maior de
PA dispositivos de processamento (transistores) e memória. A Figura 2.1 apresenta um
   diagrama sobre as gerações e seus respectivos períodos.
   A primeira geração de computadores (1938-1953), iniciou-se com os primeiros
   15
   CAPÍTULO 2
   computadores pré-modernos (máquinas de calcular), que utilizavam dispositivos
   eletromecânicos (Reles) e estendeu-se até que surgiram os primeiros
   computadores eletrônicos, sendo essa fase o período áureo da primeira geração: a
   utilização de válvulas para o desenvolvimento de computadores eletrônicos. Neste
   período os computadores possuíam arquitetura bit-by-bit, onde não existia o
   conceito de palavra (byte) e o processador utilizava um intervalo de relógio para
   processar cada bit.
   Quinta
   Quarta
   Terceira
   Gerações
   Segunda
   Primeira
   1940
   1950
   1960
   1970
   1980
   1990
   Fig. - 2.1 – Gerações de Computadores.
   Os transistores foram inventados em 1948, e com eles surge uma nova
   evolução na eletrônica. A confecção de computadores utilizando transistores marca
   a segunda geração de computadores (1952-1963). O primeiro computador a utilizar
   essa nova tecnologia foi o TRADIC, construído pela Bel Laboratories em 1954. O
   TRADIC utilizava 800 transistores. Nesse período surge o circuito impresso e a
   memória magnética.
   Ainda nessa época começam a surgir as primeiras linguagens de alto-nível,
   como o Fortran (do inglês, formula translation) em 1956, o Algol (do inglês,
   algorithmic language) em 1960 e o COBOL (do inglês COmmon Business Oriented
   Language) em 1959, e começam também a aparecer processadores específicos
   para processamento de entrada e saída de dados.
   A terceira geração de computadores (1962-1975) surge com o aparecimento
   dos circuitos integrados SSI (pequena escala) e MSI (média escala). Nessa época
   surge a memória de estado sólido. Nesse período as linguagens de alto-nível são
   16
   COMPUTAÇÃO PARALELA - HARDWARE
   favorecidas com compiladores inteligentes. Começam a ser empregadas as
   tecnologias de multiprogramação e memória virtual.
   Nessa geração surge o microprocessador, através de um projeto de
   calculadora, Ted Hoff da Intel, projeta um circuito integrado para uso geral em
   calculadoras e então nasce o microprocessador. O microprocessador é uma
   unidade central de processamento construída em um único circuito integrado. Esse
   foi um importante passo na história, surge então o microcomputador e somente a
   partir daqui os computadores podem ser difundidos e construídos em larga escala.
   Inicia-se a popularização da informática.
PA A partir de 1972, utilizando a nova tecnologia de circuitos integrados LSI,
   surge a quarta geração de computadores (1972 a 1985). Nessa fase os
   computadores utilizam os novos circuitos integrados em seções de processamento
   e memória. Surgem os supercomputadores escalar e vetoriais, assim como as
   extensões de linguagens tradicionais como o Fortran para utilizarem seus novos
   recursos de paralelismo. A maioria dos sistemas operacionais desta geração
   utilizam compartilhamento de tempo (“time-sharing”) e memória virtual. No final
   desta geração surge uma corrida por paralelismo, concentrando esforços tanto das
   porções acadêmicas quanto comerciais.
   A atual geração de computadores (quinta geração – 1985 até hoje) iniciou-
   se com o aparecimento da tecnologia de integração VLSI. Esta época marca a
   continuidade da corrida por paralelismo. Surgem sistemas de computação
   massivamente paralelos com mais de 64000 unidades de processamento. Este
   período marca também a fase áurea do Transputer, um microprocessador
   desenvolvido especificamente para projetos em computação paralela.
   Surgem também as estações de trabalho, e com elas a tecnologia RISC e a
   adoção de paralelismo nos computadores tradicionalmente seqüenciais.
   Atualmente, a maioria dos microprocessadores convencionais tradicionais incorpora
   alguns mecanismos de paralelismo. Populariza-se o conceito de rede de
   computadores e com ele surge um novo sistema de paralelização – computação
   distribuída, que é o enfoque deste trabalho.
   2.4 – EVOLUÇÃO DA COMPUTAÇÃO SEQÜENCIAL
   Entre os anos 50 até meados dos anos 60, a computação passa por uma
   fase confusa, onde os padrões ainda não estão estabelecidos, e os fabricantes e
   17
   CAPÍTULO 2
   pesquisadores iniciam diversos projetos distintos, em geral o computador fica uma
   máquina de uso muito específico, destinado a poucos problemas [Bruno, 1995]. A
   partir dos anos 60, os computadores começam a proliferar e a generalizar o seu
   uso. A partir desse ponto, a história da computação pode ser dividida em duas
   partes: por um lado temos os computadores comerciais (na maioria) de uso geral e
   por outro lado temos os denominados supercomputadores, que eram destinados
   normalmente a problemas específicos e voltados mais à área científica ou militar,
   esses em usualmente tinham como requerimento básico a velocidade.
   Quanto aos computadores seqüenciais (de uso geral), um consenso adotou
   a arquitetura de von Neumann como padrão, e isso não se alterou. Até meados da
   década de sessenta, a arquitetura dos processadores não foi muito alterada. Um
   dos primeiros passos rumo ao paralelismo foi o conceito de palavra (byte).
   Anteriormente o processador possuía uma arquitetura bit-by-bit, onde deveria
   processar um bit por vez (a cada passo do relógio). Com o conceito de palavra,
   uma única instrução possibilitava ao processador carregar uma palavra de oito bits
   a um único passo (clock).
   Juntamente com os avanços de arquitetura, o software também evoluía. Um
   dos primeiros passos foi o aparecimento das linguagens de alto nível, tornando a
   programação mais simples, deste modo aumentando mais a quantidade de
   programas e do mesmo modo as aplicações e o uso.
   A partir da terceira geração, observou-se que a unidade de processamento
   ficava ociosa com o acesso a dispositivos de entrada e saída de dados, e pouco a
   pouco foram sendo acrescentadas novas unidades de processamento nos
   dispositivos de entrada e saída de dados. O aumento de desempenho
PA proporcionado por essa abordagem aumentou a motivação para essa estratégia e
   cada vez mais dispositivos do sistema (excluindo UCP – Unidade Central de
   Processamento) foram ganhando unidades de processamento independentes,
   autômatas e capazes de trabalhar simultaneamente à UCP. Essa abordagem deu
   origem ao conceito de interrupção e se difundiu, chegando aos sistemas de
   computação atuais, que mesmo sendo seqüenciais apresentam várias unidades de
   processamento (microcontroladores). Podemos citar como exemplos atuais desta
   abordagem os controladores de Vídeo, interfaces de controle de disco e demais
   dispositivos de armazenamento de dados, portas seriais (mouse) e paralelas
   (impressora), controlador DMA (acesso direto a memória), assim como uma série
   de outros dispositivos incorporados nos atuais sistemas de computação.
   18
   COMPUTAÇÃO PARALELA - HARDWARE
   Ainda na segunda e terceira gerações, muitas melhorias beneficiaram o
   desempenho dos computadores. Enquanto a eletrônica inovou com circuitos mais
   rápidos e potentes, a computação desenvolve sistemas e melhorias na arquitetura,
   a fim de deixar o computador mais poderoso e veloz. Surgem então, entre outras
   melhorias, a memória cache (disco e RAM), a multitarefa, a multiprogramação e a
   memória virtual.
   A partir da terceira e quarta gerações de computadores utiliza-se o circuito
   integrado. Como resultado, a redução do custo faz com que o microcomputador
   popularize-se e comece a proliferar. Até o final da década de 70 o microcomputador
   estaria consolidado como bem de consumo. Na década de 80, o microcomputador
   atinge o ápice. Com o lançamento do microcomputador da IBM PC, o
   microcomputador começa sua escalada, e rapidamente ocorre o chamado
   “downsizing”, fenômeno onde o microcomputador ocupa os lugares dos
   computadores de grande porte, e faz com que estes tornem-se obsoletos.
   No início da informática, os computadores eram programados através da
   conexão de cabos. Um contato mais íntimo entre o homem e a máquina tornaria
   sem dúvida o computador mais fácil de ser utilizado pelo homem. Muitas
   descobertas e invenções contribuíram para a evolução das interfaces. O primeiro
   passo seria os cartões perfurados, logo a seguir teríamos as “teletypewrites”
   (dispositivos que se assemelhavam a máquinas de escrever). A primeira grande
   inovação nesse contexto viria no final da década de 60, com o uso do terminal de
   vídeo, que adotava a interface CLI (do inglês command line interface); bons
   exemplos são o UNIX, o VAX-VMS, o AppleDOS e o próprio MS-DOS [Hayes,
   1990].
   Durante toda a década de 70, um importante consórcio coordenou os rumos
   da computação para a próxima década. Não poderíamos narrar a história da
   computação atual sem considerar as importantes contribuições da XEROX e de seu
   centro de pesquisas PARC (Palo Alto Research Center). Desde o início da década
   de 70 o PARC iniciou pesquisas para tornar o relacionamento entre o homem e a
   máquina mais íntimo. Durante uma década de pesquisas, o PARC chegou a um
   sistema muito próximo ao que denominamos atualmente de GUI (do inglês
   graphical user interface) [Peddie, 1992]. Através dessa pesquisa foi descoberto o
   mouse (dispositivo apontador), o paradoxo de orientação a mensagens e a eventos
   e adotado o conceito de orientação a objeto, que viria a marcar definitivamente os
   rumos da computação no final da década de 80 e na década de 90 [Bruno, 1995].
   19
   CAPÍTULO 2
PA A partir da utilização das interfaces gráficas (GUI) e suas novas tecnologias,
   surgem as estações de trabalho, e com elas se popularizam as redes de
   computadores. Embora as redes de computadores tenham também uma longa
   história, foi apenas nos anos 80 através das estações de trabalho que ocorreu sua
   popularização na computação.
   A nível de hardware, as estações de trabalho trouxeram o paralelismo para
   os microprocessadores seqüenciais. Isto ocorreu inicialmente com o conceito de
   arquitetura RISC (do Inglês Reduce Instruction Set Computer). A nova geração de
   microprocessadores RISC incorporava a arquitetura pipeline [Gimarc & Milutinovic,
   1987]. A Figura 2.2 apresenta um exemplo de pipeline de instruções em
   microprocessadores RISC. [Gimarc & Milutinovic, 1987] [Ryan, 1992]
   Tempo
   Busca
   Decodificação
   Execução
   Escrita
   Instrução 1
   Ciclo 0
   Instrução 2
   Instrução 1
   Ciclo 1
   Instrução 3
   Instrução 2
   Instrução 1
   Ciclo 2
   Instrução 4
   Instrução 3
   Instrução 2
   Instrução 1
   Ciclo 3
   Instrução 4
   Instrução 3
   Instrução 2
   Ciclo 4
   Instrução 4
   Instrução 3
   Ciclo 5
   Instrução 4
   Ciclo 6
   Fluxo das instruções
   Fig. 2.2 – Típica pipeline de instruções de arquitetura RISC.
   A velocidade e o poder de processamento alcançados por esse novo
   conceito proporcionaram uma corrida dos desenvolvedores de microprocessadores
   para o mundo do paralelismo (a nível de instrução). Atualmente vivemos uma forte
   tendência onde as pesquisas de arquiteturas paralelas estão sendo aproveitadas
   para o desenvolvimento dos novos microprocessadores “seqüenciais”, que se
   tornam mais paralelos a cada geração. Um bom exemplo dessa perspectiva é o
   microprocessador Intel Pentium, que como podemos observar pela Figura 2.3
   superou a expectativa tecnológica de desempenho graças à utilização de conceitos
   de computação paralela. Atualmente a grande maioria dos microprocessadores
PA comerciais incorporam pipeline e outros mecanismos de paralelismo em seus
   microprocessadores convencionais [Ryan, 1992].
   20
   COMPUTAÇÃO PARALELA - HARDWARE
   Desnsidade / MIPS
   100M/1000
   P5 - Desempenho
   Benefício do
   10M/100
   paralelismo
   Desempenho
   1M/10
   esperado
   P5 - Densidade
   100K/1
   10K/0,1
   1K/0,01
   1971 73 75 77 79 81 83 85 87 89 91 93
   Desempenho/ MIPS
   Densidade – Número de transistores
   Milhões de Instruções por segundo
   Fig. 2.3 – Benefício proporcionado pelo paralelismo na arquitetura do
   Pentium.
   2.5 – EVOLUÇÃO DO PARALELISMO
   Até a década de 60, os computadores eram projetados para resolver
   problemas específicos, isto porém apresentava um obstáculo para a evolução da
   computação. À medida que a computação evoluía e o universo de aplicações que
   poderiam utilizar computadores crescia, os computadores começaram a ser úteis
   para uma gama cada vez maior de problemas. Tornava-se bem claro o rumo dos
   fabricantes de computadores: desenvolver computadores de uso genérico, que
   possam ser utilizados nas mais diversas formas de aplicações [Bruno, 1995]. Para
   esse fim ficou consagrada a arquitetura de von Neumann e com ela os
   computadores seqüenciais.
   A demanda por velocidade é inerente à computação. Assim, nem todos os
   usuários ficaram satisfeitos com a generalização. Muitos problemas, a grande
   maioria de caráter científico ou científico-militar, exigiam um desempenho
   computacional maior que o fornecido pelas máquinas de uso genérico. A resposta
   21
   CAPÍTULO 2
   para aumentar o desempenho dos computadores estava muito clara: paralelismo. O
   paralelismo porém acarretaria um custo muito maior em diversos aspectos, tais
   como: desenvolvimento de hardware específico, multiplicação de recursos
   (multiplicação de custos consequentemente), desenvolvimento de software
   específico, desenvolvimento personalizado (sem utilizar as vantagens da produção
   em massa). Mesmo sendo o paralelismo o resultado de projetos onerosos, existia
   um nicho disposto a pagar seu preço. Deste modo surge a computação paralela ou
   supercomputação [Hockney & Jesshope, 1988].
   Embora presente desde o ENIAC na história da computação moderna,
   somente a partir da década de sessenta a computação paralela assume o seu
   papel. Devido ao desempenho e aplicações das máquinas paralelas, a computação
PA paralela passa a ser denominada de supercomputação. A partir dessa demanda
   surgiram diversos projetos de arquiteturas paralelas, apresentando cada vez mais
   alternativas de paralelização.
   2.5.1 – ARQUITETURA ESCALAR
   Uma das primeiras arquiteturas paralelas que surgiram foi a arquitetura
   escalar, que deu origem aos denominados computadores escalares rápidos. A
   longa história do desenvolvimento dos computadores escalares inicia-se na década
   de 60 e seu desenvolvimento prolonga-se por toda a década de 70. A evolução dos
   computadores escalares é basicamente semelhante à própria história da
   computação paralela, onde o paralelismo vem surgindo e evoluindo pouco a pouco,
   baseado em máquinas convencionais.
   Os computadores escalares, também denominados de computadores
   pipeline [Hwang et al., 1984] são máquinas que apresentam elementos de
   processamento duplicados. A grande diferença em termos de instrução entre os
   computadores escalares e os computadores vetoriais (que trataremos mais tarde) é
   o tratamento dos dados. As instruções dos computadores escalares trabalham com
   dados individuais, enquanto que os computadores vetoriais trabalham com grande
   quantidade de dados ordenados (vetores) por instrução. Um dos primeiros
   computadores escalares que surgiram foi o IBM 7090.
   Um computador que influenciou a história tanto em arquitetura quanto em
   software foi o ATLAS. Embora seu projeto tenha-se iniciado na Universidade de
   Manchester por volta de 1956, a primeira produção dessa máquina ocorreu apenas
   22
   COMPUTAÇÃO PARALELA - HARDWARE
   em 1963, pela Ferranti. Em termos de software, o ATLAS foi o pioneiro na utilização
   de sistema operacional multiprogramado. Com aproximadamente 80000
   transistores, o ATLAS dispunha de vários dispositivos de I/O com processamento
   independente, que solicitava o processador apenas quando necessário. Além do
   pioneirismo em termos de organização, o ATLAS incorporava paralelismo para
   aumentar seu desempenho computacional.
   O ATLAS utilizava quatro bancos independentes de memória, que permitiam
   acesso simultâneo (em um único clock). Utilizando esses blocos, o ATLAS possuía
   uma arquitetura funcional com duas unidades aritméticas, de modo que em
   combinação com seu arranjo de memória, ele poderia (em casos muito favoráveis)
   executar duas instruções aritméticas em um único clock. Além da arquitetura
   funcional, o ATLAS também possuía um arranjo pipeline entre as seguintes fases
   da execução de instruções: busca de instrução, cálculo de endereçamento, busca
   de operando e execução aritmética.
   Para fazer melhor uso de suas características paralelas (múltiplas unidades
   aritméticas, registradores e memória) e de seus recursos computacionais, seria
   necessário um sistema que previsse as futuras instruções e determinasse quais
   instruções poderiam ser executadas concorrentemente sem alterar a lógica do
   programa. Embora o ATLAS não possuísse nenhum mecanismo de previsão, dois
   aspectos foram considerados posteriormente por Kel er (1976) e Kuck (1978) e
   incluídos nos computadores escalares CDC6600 e IBM 360/91.
   A introdução gradual do paralelismo funcional e pipeline nos computadores
   seriais pode ser bem observada através dos computadores da Control Data
   (empresa sob influência direta de Seymour Cray). O seu computador CDC 6600,
   lançado em 1964, foi o primeiro computador escalar a utilizar o paralelismo
   funcional como sua característica mais importante de projeto. O modelo seguinte da
PA Control Data, que tomaria o lugar do CDC 6600, viria a ser o CDC 7600, lançado
   posteriormente em 69. Estas duas máquinas estão entre os supercomputadores de
   maior sucesso da história, possuindo um parque em sua época com mais de 70
   máquinas instaladas. O sucesso comercial bem como o computacional foram tão
   grandes, que a IBM não conseguia superar sua concorrente. A IBM lançou sua
   corrida aos supercomputadores através do projeto STRETCH, do laboratório de
   computação científica de Los Alamos, que pretendia projetar um computador 100
   vezes mais rápido que o IBM 704. A versão comercial do STRETCH sairia mais
   tarde através do IBM 7030, porém não obteve sucesso comercial. Os
   23
   CAPÍTULO 2
   supercomputadores da série CDC eram imbatíveis. Em 1964 a IBM anuncia a série
   de supercomputadores IBM 360, que segundo a IBM teria performance comparável
   ao CDC 6600.
   A IBM perdia a cada dia o parque de computação científica para sua rival.
   Em resposta a essa situação, em 1967 a IBM lançou o IBM 360/91, que possuía
   uma performance cerca de duas vezes maior que o CDC 6600. Essa máquina
   possuía unidades de execução separadas para operações com números reais e
   cálculo de endereçamento de memória (inteiro), as instruções eram executadas em
   paralelo através de arquitetura pipeline.
   A corrida continuaria e em 1969 a Control Data lançava a série CDC 7600,
   com um desempenho cerca de duas vezes maior que o IBM 360/91. A disputa
   comercial trouxe muitos benefícios para a arquitetura de computadores. Em 1970 a
   IBM utilizaria o conceito de memória caché [Zuffo, 1978] [Tabak, 1990], que já teria
   sido utilizado desde o vagaroso ATLAS, e lança o IBM 360/195, superando mais
   uma vez a Control Data.
   Ainda nas arquiteturas escalares, não poderíamos deixar de citar as
   máquinas da Amdahl corporation. Essa companhia foi fundada por Gene Amdahl,
   chefe da equipe de arquitetura da séria IBM 360. Amdahl desenvolveu
   computadores baseados na arquitetura IBM 360. Com isso, suas máquinas além de
   serem compatíveis com os periféricos IBM, também poderiam utilizar software e
   sistema operacional desenvolvidos para as máquinas IBM. Isso foi muito
   importante, pois nesse período os fabricantes tomavam as interfaces com
   dispositivos de entrada e saída como segredos industriais. Empresas como a
   Amdahl, quebraram esses segredos e contribuíram muito com a história da
   portabilidade [Bruno, 1995]. Um outro fator muito importante foi a utilização da nova
   tecnologia de integração LSI. Com isso a máquina AMDAHL 470V/6 era cerca de
   um terço do tamanho de sua equivalente a IBM 360/168.
   2.5.2 – ARQUITETURA PIPELINE VETORIAL
   Em 1972, Seymour Cray deixou a Control Data com o propósito de fundar
   sua própria empresa, a Cray Research. A principal meta dessa empresa era
   desenvolver o supercomputador mais rápido do mundo. Em apenas quatro anos a
   Cray estaria não apenas lançando o computador mais rápido do mundo, o CRAY-1
   (1976), como também revolucionando a arquitetura dos supercomputadores e
   24
   COMPUTAÇÃO PARALELA - HARDWARE
   virando uma nova página na história da computação paralela. O CRAY-1 marcava
   um estágio evolucionário aos projetos CDC 6600 e CDC 7600 e através dele surgia
   um novo conceito em arquitetura, a arquitetura vetorial.
   Em geral, os problemas científicos mais freqüentes, com grande demanda
PA computacional, realizam de algum modo operações com matrizes ou vetores. A
   estratégia de paralelismo da arquitetura vetorial parte exatamente desse princípio.
   Na arquitetura vetorial, diversos elementos de processamento são replicados e
   arranjados de modo a favorecer o processamento de estruturas de dados vetoriais.
   Esses elementos são controlados por uma única unidade de controle, e muitas
   vezes com uma única instrução podem ser feitas operações em vetores inteiros.
   A Figura 2.4 apresenta um esquema genérico de uma arquitetura vetorial.
   Neste modelo, é apresentada uma arquitetura vetorial real, onde os elementos são
   realmente replicados. Na prática, a idéia da arquitetura vetorial verdadeira é
   transposta para pipeline. Com o pipeline os elementos não são replicados
   realmente, ocorrendo então paralelismo temporal ao invés de espacial [Almasi &
   Gottlieb, 1994].
   UCP
   ULA
   ULA
   ULA
   M
   M
   M
   UCP – Unidade Central de Processamento e de Controle
   M – Memória
   ULA – Unidade de Lógica e Aritmética
   Fig. - 2.4 – Arquitetura Vetorial.
   Em relação ao software, o programador pode perceber diretamente o
   potencial da arquitetura vetorial através das instruções. A arquitetura vetorial
   permite que ocorram instruções voltadas para vetores, que possam operar
   diretamente através desses sem a necessidade de indexadores.
   A Figura 2.5 apresenta uma comparação entre dois códigos para
   multiplicação de matrizes com 100 elementos, escritos em Fortran. No código para
   máquinas seriais, podemos observar a multiplicação realizada a partir de uma
   25
   CAPÍTULO 2
   estrutura de laço (loop), que incrementa o indexador dos vetores. Através de uma
   máquina vetorial, em uma única instrução pode ser realizada essa operação, como
   podemos observar no código paralelo, escrito em Fortran 90 [Almasi & Gottlieb,
   1994].
   Código em Fortran seqüencial
   Código em Fortran 90, otimizado
   para máquinas vetoriais
   DO 10 I=1,100
   A(1:100)=B(1:100) * C(1:100)
   10 A( I ) = B( I ) * C( I )
   Fig. - 2.5 – Comparação entre códigos Fortran.
   Embora o CRAY-1 tenha marcado a era das máquinas vetoriais, existiram
   outras duas máquinas anteriores ao CRAY-1, o CDC STAR 100 e o TIASC (Texas
   Instruments Advanced Scientific Computer).
   O projeto da STAR 100 iniciou-se em 1967, porém apenas em 1973, após
   um processo de gestação de seis anos, foi desenvolvida uma STAR 100
   operacional. Embora utilizasse uma arrojada arquitetura pipeline voltada para
   cálculos vetoriais, a STAR 100 foi implementada utilizando memória de núcleo
PA magnético, uma tecnologia anterior às memórias de semicondutores. Devido ao
   atraso tecnológico, o acesso à memória era demasiadamente lento comparado com
   as memórias semicondutoras, o que fazia com que o seu desempenho se
   equiparasse ao das máquinas seqüenciais de uso geral contemporâneas. Apenas
   em vetores muito longos, da ordem de centenas a milhares de elementos, e com o
   código muito bem elaborado, o STAR era mais rápido que seus contemporâneos de
   uso geral. Com isso, seu projeto foi um completo fracasso, não ocorrendo nenhuma
   venda comercial da máquina (apenas foram vendidas quatro máquinas que haviam
   previamente sido encomendadas pelo governo americano).
   Fato semelhante aconteceu com o TIASC. Seu projeto iniciou-se em 1966,
   porém apenas em 1973 estava operacional. Por ter sido projetado com uma
   tecnologia obsoleta, não possuía um bom desempenho e tornou-se um fracasso
   comercial. A Texas Instruments não deu continuidade ao projeto de máquinas
   vetoriais e deste modo não houve prosseguimento ao TIASC.
   No entanto, o projeto STAR foi completamente reconstruído em tecnologia
   LSI e entrou em 1979 novamente no mercado com o nome de CYBER203E, que
   após pequenas alterações ficou conhecido como CYBER205 (Figura 2.6). Essa
   26
   COMPUTAÇÃO PARALELA - HARDWARE
   máquina tornou-se competitiva com o CRAY-1, embora tenha sido lançada três
   anos após o lançamento daquele.
   Embora o CYBER205 seja uma máquina vetorial, sua arquitetura possui
   uma estratégia para adaptação de recursos de máquina genérica. Enquanto o
   CRAY-1 possuía registradores vetoriais e também uma arquitetura totalmente
   otimizada para o cálculo vetorial, o CYBER 205 processava os vetores diretamente
   da memória, e sua estrutura pipeline podia ter características de uso geral.
   Tanto o CRAY-1 quanto o CYBER 205 deram continuidade a sua
   revolucionária arquitetura vetorial, e seguiram caminhos semelhantes de evolução,
   através da replicação de processadores. O CYBER 205 foi base para o
   supercomputador ETA-10, lançado em 1986. O ETA-10 foi a máquina mais rápida
   de sua época, possuía uma performance de pico de 10 Gflop/s (flop/s – operações
   com ponto flutuante por segundo).
   Buffer de
   Comunicação
   IOP 0
   CPU 0
   add
   add
   add
   add
   IOP 1
   mult
   mult
   mult
   mult
   CPU 1
   div
   div
   div
   div
PA sqrt
   sqrt
   sqrt
   sqrt
   ória
   tilhada
   IOP 2
   CPU 2
   m
   par
   Me
   m
   Co
   IOP 3
   CPU 3
   Unidade Vetorial
   CPU 4
   IOP 16
   CPU 5
   Memória Central
   IOP 17
   CPU 6
   CPU 7
   Unidade de
   Serviço
   ETA-10 – Com sua configuração máxima:
   CYBER 205 – quatro unidades
   8 CPUs – Unidades de Processamento
   pipeline de ponto flutuante de
   18 IOP – Portos de Entrada e Saída de dados
   uso geral idênticas.
   Fig. - 2.6 – Diagramas das arquiteturas dos computadores Cyber205 e ETA-10.
   A Figura 2.6 apresenta um diagrama da arquitetura do ETA-10. O ETA-10
   podia possuir 2, 4, 6 ou 8 unidades de processamento, onde cada um desses
   processadores possuía a mesma arquitetura do Cyber-205, cuja arquitetura
   também é apresentada na Figura 2.6. O ETA-10 podia possuir também de 2 a 18
   portos de entrada e saída, através dos quais era possível a comunicação com
   27
   CAPÍTULO 2
   periféricos padrão, como discos, tapes e rede, e uma memória compartilhada de 64,
   128, 192 ou 256 Mwords (64-bits).
   Fig. - 2.7 – Diagrama de arquitetura do computador CRAY - 1.
   O CRAY-1 foi a base para a evolução da família de computadores CRAY. A
   Figura 2.7 apresenta um diagrama da arquitetura do CRAY – 1, onde podemos
   observar os registradores específicos para vetores, e as pipelines assim como toda
   sua estrutura vetorial. Os primeiros modelos baseados no CRAY-1 foram o CRAY
   X-MP e o CRAY-2. Ambos, do mesmo modo que o ETA-10, seguiram o passo de
   28
   COMPUTAÇÃO PARALELA - HARDWARE
   multiprocessamento, e multiplicaram seu poder replicando os processadores. O
PA CRAY X-MP foi lançado com dois processadores em 1982 e a versão com quatro
   processadores em 1984.
   A Figura 2.8 apresenta o arranjo esquemático de um CRAY X-MP, com sua
   versão de 2 processadores. Como podemos observar, o CRAY X-MP nada mais é
   do que a duplicação de recursos computacionais do CRAY-1, uma vez que esse
   possui dois processadores CRAY-1. É importante observar que os computadores
   Cray X-MP, Cray 2 e Eta-10 são exemplos de arquitetura MIMD, e foram aqui
   apresentados apenas para elucidar a evolução de sua família. Porém os núcleos
   desses permanecem como bons exemplos de arquitetura SIMD (arquitetura
   vetorial).
   UCP-1
   Intercom
   UCP-2
   Unidade de
   Controle
   Clock
   sincronizador
   Buffer de
   Instrução
   Memória
   word
   64bits
   -1
   dor
   -1
   dor
   Y
   Y
   A
   cessa
   A
   2Mword
   cessa
   CR
   ou
   CR
   Pro
   Pro
   4Mword
   E/S
   SSD
   Discos,
   2 a 4
   64Mbyte
   Tapes,
   Portos
   128Mbyte
   1 a 3
   ou
   entradas
PA 256Mbyte
   Fig. - 2.8 – Diagrama de arquitetura do computador CRAY X-MP/2.
   O CRAY-2 também seguiu a mesma linha evolutiva do CRAY X-MP, porém
   foi seu caráter tecnológico que recebeu maior destaque em seu projeto (em
   comparação ao CRAY X-MP). A compactação e a utilização de processadores com
   alta freqüência foram suas principais características. Devido a esses fatores, o
   CRAY-2 gerava 195 kW, que era aproximadamente a mesma quantia gerada pelo
   CRAY X-MP, porém sua dimensão reduzida restringia a dissipação de toda essa
   energia. Para solucionar esse problema, um sofisticado sistema de refrigeração foi
   adotado, onde todos os circuitos dos processadores, memória e fontes ficavam
   imersos num líquido inerte e dielétrico de fluorcarbono. A Figura 2.9 apresenta o
   29
   CAPÍTULO 2
   computador CRAY-2. Seu extravagante sistema de refrigeração proporcionava um
   aspecto inédito ao computador. Seus circuitos podiam ser observados imersos em
   líquido borbulhante através do vidro, dando um ar fictício ao computador.
   Fig. - 2.9 – CRAY 2.
   Atualmente a CRAY Research faz parte da Silicon Graphics, dando uma
   ênfase maior à visualização científica e computação gráfica na utilização das
   máquinas científicas CRAY.
   2.5.3 – ARQUITETURA MATRICIAL
   Diferentemente da arquitetura vetorial, que apresentava apenas uma
   evolução lógica dos computadores seqüenciais voltada para o cálculo vetorial, a
   arquitetura matricial marcou uma mudança radical na concepção da computação
   paralela. A arquitetura matricial nasceu basicamente a partir de um único artigo de
   1962 [Hockney & Jesshope, 1988], intitulado “The SOLOMON Computer”, cujo
   nome SOLOMON é um acrônimo derivado de “Simultaneous Operation Linked
   Ordinal Modular Network”. O trabalho descreve uma matriz bidimensional de 32 x
   32 elementos de processamento, onde cada um desses elementos contém uma
   memória de 128 posições de 32 bits e uma unidade aritmética. Toda essa estrutura
   está sob o controle de uma única unidade de controle e fluxo de instrução. Embora
   SOLOMON tenha sido a origem das arquiteturas matriciais, houve ainda um artigo
   anterior no qual foi inspirado, o computador espacial, publicado por Unger em 1958
   30
   COMPUTAÇÃO PARALELA - HARDWARE
   [Unger, 1958].
   [80-100]
   [104]
   ILLIAC IV
   Phoenix
   (1972)
   (?)
   [100]
   [50]
   [103]
   PEPE
   BSP
   NASF
   (1973)
   (1979)
PA (?)
   [200-600]
   Unger
   SOLOMON
   Staran
   MPP
   (1958)
   (1962)
   (1970)
   (1983)
   Clip
   (1976)
   [10-30]
   DAP
   (1978)
   Fig. - 2.10 – Família dos computadores de arquitetura matricial. Os números
   em conchetes são as performances máximas estimadas em mflops.
   Embora o conceito SOLOMON tenha sido uma revolução em arquitetura de
   computadores, seu projeto nunca foi construído exatamente como descrito no artigo
   de 1962. Porém deu origem aos clássicos computadores ILLIAC IV, Burroughs
   PEPE, Goodyear Aerospace STARAN e ICL DAP entre outros (ver Figura 2.10).
   Em 1966, a Universidade de Illinois, contratada pelo departamento de
   defesa americano (ARPA), iniciou o projeto de um computador baseado no
   SOLOMON. Nascia então o clássico ILLIAC IV (Figura 2.11 e 2.12), que possuía
   quatro quadrantes com uma unidade de controle e interpretação de instruções para
   os 64 elementos de processamento de ponto flutuante. Cada um dos elementos de
   processamento tinha uma memória com 2000 posições de 64 bits. Cada elemento
   de processamento e memória, em cada quadrante, eram conectados por uma
   matriz de 8 x 8, e os quadrantes eram conectados por um barramento paralelo, o
   qual era também responsável pela interface de uma unidade de disco, que era a
   unidade secundária do sistema. Embora o projeto inicial possuísse quatro
   quadrantes, o ILLIAC IV foi construído utilizando apenas um, pela Burroughs
   Corporation 1969-73, conforme apresenta a Figura 2.11.
   31
   CAPÍTULO 2
   Entrada/Saída
   Barramento de dados
   Dados e Intruções
   MUC
   UC
   Barramento de controle
   EP0
   EP1
   EP63
   MEP0
   MEP1
   MEP63
   Rede de interconexão
   UC
   Unidade de Controle
PA MUC
   Memória da Unidade de Controle
   EP
   Elemento de Processamento
   MEP
   Memória do Elemento de Processamento
   Fig. - 2.11 – Diagrama de arquitetura do computador ILLIAC IV.
   EP56
   EP57
   EP58
   EP63
   EP63
   0
   1
   2
   7
   EP8
   EP7
   8
   9
   10
   15
   EP16
   EP15
   16
   17
   18
   23
   EP24
   EP55
   56
   57
   58
   63
   EP0
   EP0
   EP1
   EP2
   EP7
   Fig. - 2.12 – Configuração da rede de elementos de processamento (EP).
   Pela primeira vez despontava a problemática do software paralelo. Um
   amplo investimento em software fez com que o ILLIAC IV possuísse seu próprio
   sistema operacional, assim como quatro linguagens de programação específicas (
   TRANQUIL e GLYPNIR – derivadas do ALGOL, ACTUS – derivada do PASCAL e
   CFD FORTRAN).
   O projeto ILLIAC IV foi seguido pelo PEPE, computador encomendado à
   Burroughs com finalidades militares, e ao computador científico comercial BSP, e
   ainda ao Phoenix, projeto da NASA para substituir o ILLIAC IV. Classificado como
   múltiplo-SIMD, o Phoenix possuía basicamente 16 máquinas ILLIAC IV, onde cada
   uma executava seu próprio fluxo de instruções, sob o controle de uma única
PA 32
   COMPUTAÇÃO PARALELA - HARDWARE
   unidade de controle.
   A arquitetura matricial marcou era na computação paralela, tornando
   possível a incorporação de muitas unidades de processamento em máquinas
   (milhares). Contribuiu também para a pesquisa em software paralelo, que talvez
   venha a ser o maior desafio da computação paralela.
   2.5.4 – ARQUITETURA MIMD
   O termo MIMD, derivado do inglês “Multiple Instructions Multiple Data”, é
   proveniente do clássico artigo de taxonomia de computadores, proposto por Flynn
   [Flynn, 1966]. Nas arquiteturas anteriores à MIMD, somente algumas partes da
   UCP são replicadas, ou ainda, são replicados pseudo-processadores, (ex:
   elementos de processamento da arquitetura matricial), onde existe um controle
   único externo, que em geral é ainda responsável pelo fluxo de instruções. Na
   arquitetura MIMD no entanto, UCPs (unidade central de processamento) são
   inteiramente replicadas, e em certos casos computadores inteiros. Deste modo a
   arquitetura MIMD é verdadeiramente uma coleção de computadores formando uma
   única máquina paralela.
   A arquitetura MIMD despontou no início da década de 80, devido à queda de
   preço dos microprocessadores, assim como ao aumento da performance desses a
   partir da tecnologia VLSI. A arquitetura MIMD demonstrou ser a tecnologia
   integradora e evolutiva das arquiteturas SIMD. A maioria do prosseguimento de
   projeto das tecnologias vetoriais e matriciais acabaram por se tornar arquiteturas
   MIMD replicadoras de SIMD. Como exemplos, temos as arquiteturas Phoenix, Cray
   2, Cray X-MP e Eta 10, descritas anteriormente como SIMD (modo didaticamente
   evolutivo), mas que na verdade são máquinas MIMD paralelizando SIMD. A
   arquitetura MIMD amadureceu, chegando até os dias de hoje, onde é a mais
   utilizada tanto em pesquisa quanto comercialmente.
   O maior desafio para os projetos de arquiteturas MIMD está exatamente na
   comunicação entre os computadores. Na maior parte dos casos, os processadores
   utilizados são comerciais de larga difusão e de uso genérico, porém a consolidação
   da tendência MIMD fez com que surgissem processadores específicos para
   projetos de máquinas MIMD. Entre eles podemos citar a linha Transputer da Inmos
   e os processadores de processamento de sinais da Texas Instruments.
   A partir da comunicação ou integração dos processadores, podemos
   33
   CAPÍTULO 2
   classificar a arquitetura MIMD basicamente em memória compartilhada e memória
   distribuída, conforme apresenta a Figura 2.13. A diferença básica entre os dois
   modelos é que enquanto os sistemas de memória compartilhada utilizam uma única
   memória acessível a todos os processadores, e a utilizam para trocar informações,
   nos sistemas de memória distribuída, por outro lado, cada um dos processadores
   possui sua própria memória, inacessível para os demais, e utilizam troca de
   mensagens via rede ou barramento para efetuar a comunicação.
   rede ou barramento
   P
   P
   P
   P
   P
PA P
   Memória
   M
   M
   M
   Memória compartilhada
   Memória distribuída
   Fig. - 2.13 – Memória compartilhada versus memória distribuída.
   UCP 0
   Seção 0
   Porto A
   Registradores
   a
   da UCP
   Sub-seções
   Porto B
   a de
   16 bancos
   rot
   móri
   lecionador
   Registr. de
   de
   Me
   Porto D
   Se
   Instrução
   da
   ída
   rtilha
   Sa
   pa
   e
   om
   ção de
   da
   Se
   UCP 7
   tra
   ia C
   En
   ór
   em
   Porto A
   Registradores
   M
   a
   da UCP
   Porto B
   a de
PA rot
   móri
   Seção 7
   lecionador
   Registr. de
   de
   Me
   Porto D
   Se
   Instrução
   Sub-seções
   16 bancos
   Fig. - 2.14 – Organização da memória do Cray - J90.
   Entre as máquinas MIMD de memória compartilhada atuais podemos citar:
   as séries J90 e T90 da Cray, a AlphaServer da Digital, a série Hitachi S3800, o
   NEC SX-4, a Starfire E10000 da Sun, Connection Machine CM-5, etc. A Figura 2.14
   34
   COMPUTAÇÃO PARALELA - HARDWARE
   apresenta um diagrama da arquitetura da máquina Cray – J90 uma típica MIMD de
   memória compartilhada.
   Unidade de Ponto Flutuante
   VCC
   GND
   CapPlus
   CapM inus
   Processador
   Reset
   Analyse
   Serviços do
   32 bit
   ErrorIn
   Sistema
   Error
   BootFromROM
   ClockIn
   Serviços de
   LinkSpecial
   ProcSpeed
   Link0Special
   Select0-2
   Link
   Link123Special
   LINK 0 Entrada
   Timers
   Interface - Link
   LINK 0 S aída
   LINK 1 Entrada
   Interface - Link
   RAM
   LINK 1 S aída
PA 4 Kbytes
   Interface - Link
   LINK 2 Entrada
   LINK 2 S aída
   ProcClockOut
   LINK 3 Entrada
   NotMemS0-4
   Interface - Link
   LINK 3 S aída
   NotM emWrB0-3
   Interface
   NotMemRd
   NotMemRf
   Memória
   MemWait
   Externa
   MemConfig
   Memória
   MemReq
   MemGranted
   Fig. - 2.15 – Diagrama em blocos do processador Transputer IMS T800.
   As máquinas MIMD de memória distribuída, obtiveram uma atenção maior a
   partir da metade da década de 80. A arquitetura MIMD de memória distribuída,
   praticamente começou com um projeto Cosmic Cube da Caltech. Esse projeto
   introduziu toda a pesquisa em torno de redes de conexão de processadores
   (hipercubos) [Almasi & Gottlieb, 1994]. O Cosmic Cube foi uma máquina baseada
   no processador 8086 e seu coprocessador de ponto flutuante 8087 (famosos devido
   aos microcomputadores pessoais), que integrava 64 pares de processadores (8086
   e 8087), conectados com arquitetura de hipercubo [Hockney & Jesshope, 1988]. A
   partir de 1985, com o lançamento do Transputer (Inmos), um processador
   destinado ao desenvolvimento de arquiteturas paralelas, houve uma grande difusão
   da pesquisa e utilização de arquitetura MIMD. Devido ao fato de ser
   especificamente voltado ao desenvolvimento de sistemas paralelos, o Transputer
   tornava os projetos paralelos simples e com custos competitivos. Além de contar
   com uma série de ferramentas e linguagens que realizavam o suporte de
   programação. A Figura 2.15 apresenta o diagrama do processador Transputer
   35
   CAPÍTULO 2
   [Inmos, 1988].
   Dentre o universo das máquinas MIMD distribuídas podemos citar:
   Intel iPSC, Intel Paragon, Cray T3E, Avalon A12, nCUBE 2S, As máquinas
   baseadas em Transputer (ex: IBM – Victor), IBM 9076 SP2, etc.
   2.5.5 – COMPUTAÇÃO DISTRIBUÍDA
   No final da década de 80, devido ao desenvolvimento e proliferação da
   tecnologia de redes de computadores e do mesmo modo à diminuição do custo dos
   microcomputadores, surgiu uma nova arquitetura paralela denominada de
   Computação Distribuída. Ao invés de desenvolver hardware específico, o conceito
   de Computação Distribuída utiliza computadores padrão (ou não) conectados por
   rede de computadores (ethernet ou outra), ficando todo o mecanismo de
   paralelização sob a responsabilidade das camadas de software [Tanenbaum, 1990],
PA sendo essa em nível de sistema operacional, através de sistemas operacionais
   distribuídos [Tanenbaum, 1995], ou ainda através de ferramentas de troca de
   mensagens tais como PVM [Geist et al., 1996], MPI [Pacheco, 1997] ou ainda
   CVMP apresentada nesta tese.
   Embora a velocidade de comunicação das redes de computadores seja
   muito mais lenta do que através dos mecanismos desenvolvidos em hardware, a
   simplicidade e baixo custo fizeram com que os Sistemas Distribuídos viessem a se
   tornar a mais difundida utilização de arquiteturas paralelas, somando a utilização
   comercial e científica [Almasi & Gottlieb, 1994].
   Segundo a classificação de Flynn [Flynn. 1972], a Computação Distribuída é
   considerada MIMD de memória distribuída [Almasi & Gottlieb, 1994], seguindo a
   mesma heurística de arquitetura e software. Assim como ocorrem em algumas
   máquinas de arquitetura MIMD, que podem ser compostas por elementos de
   processamento com arquiteturas paralelas diferentes, como por exemplo o CRAY –
   J90 (MIMD com processadores SIMD), os sistemas distribuídos podem integrar um
   único sistema e possuir diversas arquiteturas paralelas diferentes, trabalhando
   juntas. Além de possuir tal característica heterogênea, os Sistemas Distribuídos
   ainda podem possuir um número de unidades de processamento variáveis,
   caracterizando sua utilização em sistemas tolerantes a falha. Para caracterizar um
   aglomerado de estações como Sistema Distribuído (Computação Distribuída), basta
   que exista um mecanismo de integração das máquinas e que através desse
   36
   COMPUTAÇÃO PARALELA - HARDWARE
   mecanismo de troca de mensagens sejam capazes de realizar uma mesma tarefa
   (ou diferentes partes de uma mesma tarefa). O número de máquinas (elementos de
   processamento) de um Sistema Distribuído varia muito, indo desde 2 a mesmo
   milhares de máquinas. A Figura 2.16 apresenta um diagrama de um Sistema
   Distribuído heterogêneo, onde juntos podem operar estações de trabalho de
   diversas plataformas diferentes (PCs, estações de trabalho RISC) assim como
   supercomputadores MIMD e ou SIMD, conectados por rede.
   Fig. - 2.16 – Sistema Distribuído Heterogêneo.
   2.6 – TAXONOMIA DE COMPUTADORES
   Anteriormente, descrevemos uma série de tecnologias apresentadas com
   sua evolução no tempo. Obviamente, não abordamos todo o universo das
   arquiteturas paralelas, apenas traçamos um breve perfil da evolução da
   computação paralela, com o intuito de formar bases para as noções de arquitetura
   de computadores requeridas nesta tese.
   As inúmeras possibilidades de organização dos computadores, assim como
   a diversidade de processadores, geram a necessidade da classificação dos
   computadores, a fim de encontrarmos famílias as quais podem ser agrupadas,
   melhor estudadas e comparadas. Existem inúmeras propostas encontradas na
   literatura para classificar as diferentes arquiteturas e organização dos
   37
   CAPÍTULO 2
   computadores, podemos citar entre elas: Flynn [Flynn, 1966], Feng [Hwang et al.,
   1984], Händler [Hwang et al., 1984], Gajski [Amorin et al.,1988], Shore [Hockney &
   Jesshope, 1988], Estrutural [Hockney & Jesshope, 1988], Kuck [Almasi & Gottlieb,
   1994], Treleaven [Almasi & Gottlieb, 1994], Duncan [Duncan, 1990], etc. Nesta
   seção vamos apresentar três delas: classificação de Flynn, taxonomia estrutural de
   Hockney e classificação de Duncam.
PA A classificação de Flynn é a mais divulgada pela literatura, embora seja
   bastante antiga, originária a partir de um artigo de 1966. A tradição e a
   popularização tornaram-na a mais importante taxonomia de computadores,
   permanecendo a mais utilizada atualmente, mesmo com suas falhas e dúvidas
   [Bogni & Marrone, 1991]. Devido à sua importância, trataremos esta classificação
   com maiores detalhes que as demais.
   Na tentativa de realizar uma classificação bastante abrangente, foi proposta
   a taxonomia estrutural de Hockney. Esta classifica tanto os computadores
   (históricos) seqüenciais, quanto os paralelos (até os atuais). A maior característica
   da taxonomia estrutural é a sua diversidade de classes. Embora seja bastante
   abrangente, essa classificação é pouco conhecida e utilizada. Apresentaremos
   sucintamente a taxonomia estrutural na Seção 2.6.2.
   Com o surgimento de novas tecnologias e com o decorrer de décadas de
   pesquisa houve uma diversificação das arquiteturas de computadores paralelos,
   muitas das quais não poderiam ser classificadas através da taxonomia clássica.
   Tendo em vista esse problema, Duncan propôs uma classificação extensiva à
   classificação de Flynn, através do artigo “A Survey of Parallel Computer
   Architectures” [Duncan, 1990]. Finalizaremos a seção Taxonomia de Computadores
   apresentando sucintamente a proposta de Duncan, na Seção 2.6.3.
   2.6.1 – CLASSIFICAÇÃO DE FLYNN
   O primeiro método de classificação de computadores foi inicialmente
   proposto por Flynn, em seu célebre artigo de 1966, intitulado “Very High Speed
   Computing Systems” [Flynn, 1966], mais tarde apresentado com maior formalidade,
   em 1972 [Flynn, 1972]. O método consiste nas possibilidades de combinação entre
   uma ou mais seqüências de instruções atuando sobre uma ou mais seqüências de
   dados.
   O princípio básico do funcionamento de um processador é a busca de
   38
   COMPUTAÇÃO PARALELA - HARDWARE
   operandos na memória principal, seguindo da execução das instruções compostas
   por esses operandos e finalmente no armazenamento dos resultados obtidos na
   memória. Assim sendo, as etapas distintas associadas ao processamento de uma
   instrução constituem o ciclo de instruções. Deste modo um ciclo de instrução é
   composto por:
   Encontrar o endereço da instrução
   Buscar a instrução
   Decodificar a instrução
   Gerar os endereços referentes aos operandos
   Executar a instrução
   Armazenar os resultados
   A visualização da seqüência da execução das instruções pode ser
   comparada a um fluxo ou corrente. O fluxo de instruções dirigi-se da memória para
   o processador. A partir da execução das instruções, são solicitados dados,
   armazenados na memória, cuja visualização pode igualmente ser comparada a um
   fluxo ou corrente (fluxo de dados). O fluxo de dados por sua vez, possui uma dupla
   corrente, indo e vindo da memória para o processador e do processador para a
   memória.
   Número de Fluxo de Dados
   Simples
   Múltiplos
PA Número de
   Simples
   SISD
   SIMD
   Fluxo de
   Instruções
   Múltiplos
   MISD
   MIMD
   Fig. - 2.17 – Classificação de Flynn.
   Baseado no fluxo de instruções e no fluxo de dados, Michael J. Flynn
   realizou uma classificação de computadores, sugerindo combinações de classes de
   fluxos de dados versus fluxo de instruções. A partir dessas combinações, Flynn
   sugeriu quatro classes de computadores: Um fluxo de instrução e um fluxo de
   dados – SISD (do inglês “Single Instruction stream Single Data stream”), um fluxo
   39
   CAPÍTULO 2
   de instrução e múltiplos fluxos de dados – SIMD (do inglês “Single Instruction
   stream Multiple Data stream”), múltiplos fluxos de instrução e um fluxo de dados –
   MISD (do inglês “Multiple Instruction stream Single Data stream”) e múltiplos fluxos
   de instrução e múltiplos fluxos de dados – SISD (do inglês “Multiple Instruction
   stream Multiple Data stream”). (ver Figura 2.17).
   Apresentaremos cada um dos casos a seguir, e um diagrama
   correspondente à arquitetura classificada. Em cada um dos diagramas mostrados
   serão apresentadas apenas três espécies de componentes de sistema: Unidade de
   Controle (UC), Unidade de Processamento (UP) e Memória (M) (Figuras 2.18, 2.19,
   2.20 e 2.21).
   Unidade de Controle (UC) – Responsável pela decodificação das instruções
   e pelo envio das instruções decodificadas ao processador.
   Unidade de Processamento (UP) – Executa as instruções e armazena os
   resultados na memória.
   Memória (M) – Armazena os dados.
   Além dos componentes do sistema também serão apresentados os fluxos
   de dados (FD) e os fluxos de instruções (FI). Observando as Figuras 2.18, 2.19,
   2.20 e 2.21, devemos notar que cada fluxo de instruções é gerado por uma unidade
   de controle independente.
   2.6.1.1 – SISD - UM FLUXO DE INSTRUÇÃO E UM FLUXO DE
   DADOS
   A classe SISD classifica as arquiteturas convencionais, ou de von
   Neumman, ou seja os computadores seqüenciais, que compõem a maioria do
   nosso parque atualmente. Embora a maioria dos microprocessadores atuais SISD
   possuam mais do que uma unidade funcional e pipeline de instrução [Gimarc &
   Milutinovic, 1987], todas as suas unidades funcionais estão sob a supervisão de
   uma única unidade de controle, classificando-os deste modo como SISD (Figura
   2.18).
   40
   COMPUTAÇÃO PARALELA - HARDWARE
   FI
   UC
   FI
PA UP
   FD
   M
   Fig. - 2.18 – Diagrama da arquitetura SISD.
   2.6.1.2 – MISD - MÚLTIPLOS FLUXOS DE INSTRUÇÃO E UM
   FLUXO DE DADOS
   A Figura 2.19 apresenta um diagrama conceptual da arquitetura
   MISD. Não existe nenhuma implementação real desse tipo de arquitetura,
   ocorrendo então uma falha de classificação do modelo de Flynn [Almasi & Gottlieb,
   1994] [Duncan, 1990].
   FD
   UC
   FI1
   1
   UP1
   FI2
   UC1
   UP2
   M1
   M2
   Mn
   FIn
   UC1
   UPn
   FI1
   FD
   FIn
   FI2
   Fig. - 2.19 – Diagrama da arqui t etura MISD.
   41
   CAPÍTULO 2
   2.6.1.3 – SIMD – UM FLUXO DE INSTRUÇÃO E MÚLTIPLOS
   FLUXOS DE DADOS
   UP
   FD
   1
   1
   M1
   UP
   FD2
   M
   UC
   2
   FI
   2
   UP
   FDn
   n
   Mn
   FI
PA Fig. - 2.20 – Diagrama da arquitetura SIMD.
   A classe SIMD corresponde aos computadores matriciais e vetoriais.
   Conforme podemos observar na Figura 2.20, existem muitos elementos de
   processamento sendo supervisionados por uma única unidade de controle. Todos
   os elementos de processamento recebem a mesma instrução, transmitida pela
   unidade de controle, porém operam as instruções sobre distintos fluxos de dados.
   Na prática, a classificação SIMD levanta algumas dúvidas e polêmicas. Na
   literatura podemos encontrar alguns autores que classificam máquinas vetoriais
   pipeline (ex: Cray-1, Cyber-205) como SIMD [Almasi & Gottlieb, 1994] [Hockney &
   Jesshope, 1988], enquanto outros autores as classificam como SISD [Hwang et al.,
   1984] [Bogni & Marrone, 1991].
   42
   COMPUTAÇÃO PARALELA - HARDWARE
   2.6.1.4 – MIMD – MÚLTIPLOS FLUXOS DE INSTRUÇÃO E
   MÚLTIPLOS FLUXOS DE DADOS
   FI1
   FD1
   UC1
   UP1
   M1
   FI1
   FI1
   FI
   FI
   2
   FD2
   UC
   2
   1
   UP2
   M2
   FI2
   FIn
   FIn
   FDn
   UC1
   UPn
   Mn
   FIn
   Fig. - 2.21 – Diagrama da arquitetura MIMD.
   A Figura 2.21 apresenta um diagrama conceptual da arquitetura MIMD. A
   maioria dos sistemas paralelos atuais podem ser classificados nessa categoria,
   gerando deste modo uma sobrecarga a esta classe, que abrange tanto as
   máquinas multiprocessadores (memória compartilhada) quanto os sistemas
   multicomputadores (memória distribuída). Deste modo, segundo a organização da
   memória, a classe MIMD é diretamente dividida em MIMD memória compartilhada e
   MIMD memória distribuída (Figura 2.13).
   43
   CAPÍTULO 2
   2.6.2 – TAXONOMIA ESTRUTURAL
PA Computadores
   Único fluxo de Instrução
   Múltiplo fluxo de Instrução
   Única unidade
   de execução
   Aritmética de
   Aritmética de
   MIMD
   inteiro
   ponto flutuante
   (figura 2.24)
   serial 1-bit
   Paralelo n-bit
   Computadores
   Computadores
   Computadores
   seqüenciais de
   seqüenciais de
   seqüenciais de
   bit serial
   bit paralelo
   ponto flutuante
   EDSAC1
   IBM 701
   IBM 7090
   Múltiplas unidades
   UNIVAC1
   de execução
   Pipelined
   Sem pipeline
   Computadores
   matriciais
   (figura 2.23)
   Somente instruções
   Instruções
   escalares
   vetoriais
   Computadores
   com múltiplas
   unidades
   escalares
   Controle
   Issue-When-
   Pipeline
   Pipeline
   Horizontal
   ready
   Uso específico
   Uso Geral
   CDC 6600
PA Computadores
   Computadores
   Computadores
   Computadores
   com pipeline
   com pipeline
   com pipeline
   com pipeline
   escalar
   escalar
   escalar
   escalar
   horizontal
   horizontal
   CDC 7600
   CYBER 205
   FPS AP-120B
   CRAY - 1
   Fig. - 2.22 – Diagrama da classificação estrutural.
   A taxonomia estrutural proposta por [Hockney & Jesshope, 1988] é uma
   classificação bastante abrangente tanto para os computadores seqüenciais quanto
   para os paralelos. As Figuras 2.22, 2.23 e 2.24 apresentam o diagrama da
   classificação, que correspondem respectivamente à classificação geral, máquinas
   matriciais e MIMD.
   A primeira estratégia utilizada para a classificação é a divisão dos
   computadores em dois grandes grupos: computadores com um único fluxo de
   instrução e computadores com diversos fluxos de instrução. Através dessa primeira
   etapa, é separado o universo dos computadores MIMD (diversos fluxos de
   instrução) dos demais (único fluxo de instrução – seriais e SIMD). A classe dos
   44
   COMPUTAÇÃO PARALELA - HARDWARE
   computadores com único fluxo de instruções é então dividida em: única unidade de
   execução e múltiplas unidades de execução. A primeira classe agrupa os
   computadores seqüenciais clássicos. A classe de computadores com múltiplas
   unidades de execução é dividida em pipeline, máquinas matriciais e múltiplas
   unidades de execução sem pipeline. A partir dessa divisão podemos notar a grande
   abrangência da taxonomia estrutural, observando a classificação da classe pipeline
   e matricial. O diagrama da classificação das máquinas matriciais é apresentado na
   Figura 2.23.
   As máquinas matriciais são divididas em duas classes: máquinas com
   unidades de execução de ponto flutuante e máquinas com unidades de execução
   com poucos bits (computadores ortogonais e associativos).
   Processador
   matricial
   Unidade de
   Unidade de
   execução de
   execução com
   ponto flutuante
   poucos bits
PA Desconectado
   Conectado
   Conectado X
   Desconectado
   Conectado
   Memória ortogonal
   Conjunto de
   Matriz de
   Matriz de proc.
   Computador
   Matriz de
   Co mputador
   Processadores
   processadores
   de p. flutuante
   Associativo
   processadores
   ortogonal de
   de ponto
   de ponto
   conectados em
   de poucos bits
   poucos bits
   flutuante
   flutuante
   X
   STARAN
   ICL DA P
   OMEN
   PEPE
   ILLIAC IV
   BSP
   Fig. - 2.23 – Arquiteturas matriciais.
   Como comentamos anteriormente, a primeira divisão da taxonomia
   estrutural separa os computadores MIMD dos demais. As classes de computadores
   MIMD são apresentadas no diagrama 2.24, que é uma continuação da Figura 2.22.
   Diferentemente da divisão: memória distribuída e memória compartilhada;
   denotação essa largamente utilizada na literatura, a taxonomia estrutural de
   Hockney divide as máquinas MIMD primeiramente entre máquinas com
   comutadores e máquinas com redes. As máquinas MIMD de memória
   compartilhada tornam-se então uma subclasse das máquinas com comutadores.
   45
   CAPÍTULO 2
   Devemos observar novamente a divergência da classificação, onde temos grupos
   para cada topologia, no caso de redes, assim como diferentes classes para as
   diferentes estruturas de comutadores, para as classes de máquinas com
   comutadores.
   MIMD
   Macro pipeline
   Comutado
PA Rede
   CHiP
   CRAY X-MP
   CRAY 2 e 3
   Crossbar
   Midas
   Reconfigurável
   ETA10
   Memória
   Multi-estágio
   ULTRA
   compartilhada
   Anel
   barramento
   C
   C
   C
   malha
   MINERVA
   Multidimensional
   ELXSI
   FPS5000
   M
   M
   M
   FLEX/32
   Cosmic
   Intel iPSC
   hipercubo
   N-CUBE
   Cubo
   Crossbar
   EMPRESS
   Conectado
   Memória
   Multi-estágio
   ciclicamente
   PASM
   distribuída
   barramento
   PRINGLE
   NC-TREE
   Árvore
   Hierárquica
   C
   C
   C
   X-TREE
   M
   M
PA M
   EGPA
   Pirâmide
   M
   Memória
   Aglomerado
   C
   Computador
   Fig. - 2.24 – Classificação estrutural para MIMD.
   2.6.3 – CLASSIFICAÇÃO DE DUNCAN
   Segundo Duncan [Duncan, 1990], a década de 1980 foi marcante para a
   computação paralela devido a sua proliferação e popularização. As recentes
   descobertas e a proliferação da tecnologia de processamento paralelo introduziram
   novas arquiteturas ao contexto da computação paralela. Deste modo tornou-se
   difícil a compreensão e a classificação das arquiteturas paralelas baseadas na
   taxonomia clássica (Flynn).
   Tentando resolver o problema da classificação de máquinas paralelas
   46
   COMPUTAÇÃO PARALELA - HARDWARE
   Duncan, propôs sua taxinomia baseado no seguinte conjunto de imperativos:
   Excluir as arquiteturas que utilizem somente mecanismos de paralelismo de baixo-
   nível (comuns nos microcomputadores atuais: Pentium, RISC, etc...).
   Continuar adotando os elementos baseados em fluxo de dado e instruções da
   classificação de Flynn.
   Incluir processadores vetoriais (pipeline), e outras arquiteturas que intuitivamente
   deveriam receber o mérito de pertencer às classes de computadores paralelos.
   Conforme vimos anteriomente na classificação de Flynn, essas arquiteturas são
   classificadas como SISD e não como SIMD por alguns autores.
   A Figura 2.25 apresenta um diagrama da classificação sugerida por Duncan.
   As arquiteturas são divididas em três classes: Síncronas, Assíncronas ou MIMD e
   não convencionais. A classe Síncrona contém uma extensão da classe SIMD de
   Flynn. A esta classe, além de pertencer as arquiteturas SIMD, foram formalmente
   inseridas as arquiteturas vetoriais assim como arquiteturas sistólicas [Duncan,
   1990], devido a sua característica síncrona. A subclasse SIMD foi ainda dividida em
   processadores matriciais e memória associativa.
   Não
   Síncronas
   Convencionais
   MIMD
   Vetorial
   SIMD
   Sistólica
   Memória
   Memória
   Compartilhada
   Distribuída
   Processadores
   Memória
   Matriciais
   Associativa
PA MIMD/SIMD
   Dataflow
   Redução
   Frente de Onda
   Fig. - 2.25 – Classificação de Duncan.
   A classe de arquitetura MIMD (assíncrona) permaneceu com as mesmas
   47
   CAPÍTULO 2
   subdivisões clássicas: Memória Compartilhada e Distribuída. Duncan porém
   apresenta uma nova classe, para atender as arquiteturas mais modernas. A classe
   de arquiteturas não convencionais classifica os novos paradigmas introduzidos à
   arquitetura paralela. Embora sejam todas derivadas da arquitetura MIMD, as
   arquiteturas híbridas MIMD/SIMD (exemplo: DADO e o Non-von [Almasi & Gottlieb,
   1994]), máquinas de redução (Newcastle Reduction Machine, Utah Applicative
   Multiprocessing System [Duncan, 1990]), matrizes de frente de onda
   (implementações assíncronas de arranjos sistólicos [Kung et al., 1987]) e fluxo de
   dados (MDM - Manchester Dataflow Machine [Almasi & Gottlieb, 1994] e MIT
   Tagged Token Dataflow [Duncan, 1990]) são difíceis de enquadrar em uma
   classificação convencional.
   48
   CAPÍTULO
   3
   COMPUTAÇÃO PARALELA –
   SOFTWARE
   À medida que paralelizamos nossos algoritmos, multiplicamos nossos problemas.
   (pensamento do autor)
   49
   CAPÍTULO 3
   50
   A COMPUTAÇÃO PARALELA - SOFTWARE
   CAPÍTULO 3 – COMPUTAÇÃO PARALELA -
   SOFTWARE
   3.1 – INTRODUÇÃO
   No capítulo anterior abordamos a computação paralela e os sistemas
   distribuídos sob o prisma do hardware. Iremos agora discorrer sobre o mesmo
   assunto através do ponto de vista do software. O software é um importante conceito
   abstrato, responsável por toda a base da ciência da computação. Somente a partir
   do conceito de programa armazenado (software), proposto por John von Neumann
   em meados de 1950, o computador moderno passou a existir, fechando
   definitivamente o capítulo das super calculadoras da história da ciência da
   computação.
   O conceito abstrato de software ou programa permitiu o aparecimento dos
   computadores de uso genérico. As primeiras máquinas parecidas com o que hoje
   denominamos "computador", eram construídas para fins específicos. A partir da
   teoria da computabilidade [Penrose, 1989], surgiu o conceito de programa. Assim,
   os computadores passaram a resolver todo e qualquer problema, desde que fosse
   ele computável, bastando para isso apenas alterar o conteúdo de sua memória de
   programa. Embora pareça trivial, esse conceito solidificou as bases da computação
   moderna, construindo toda a sua história.
   Na computação paralela, um dos maiores desafios é o desenvolvimento de
PA software paralelo. Atualmente, grande parte da pesquisa da computação paralela
   encontra-se destinada a esse aspecto. Embora em muitos casos o paralelismo seja
   realizado unicamente pelo hardware, ficando transparente às camadas de software
   (ex: pipeline), em outros, como por exemplo os sistemas distribuídos, toda a
   abstração das máquinas virtuais, assim como seus mecanismos de paralelismo,
   são inteiramente realizados pelo software.
   Trataremos neste capítulo do conceito de software em linhas gerais, em
   todos os níveis da máquina (Figura 3.1), enfocando principalmente a exploração do
   paralelismo em cada um desses níveis.
   Iniciaremos a discussão com o conceito de software e logo depois
   51
   CAPÍTULO 3
   apresentaremos o modelo em camadas do computador moderno. Para cada uma
   dessas camadas discutiremos a atuação do software, assim como a exploração de
   paralelismo através deste. Finalmente, concluiremos o capítulo apresentando
   alguns conceitos e ferramentas voltados para o desenvolvimento e utilização de
   software.
   3.2 – SOFTWARE
   Aproveitando a característica multidisciplinar desta tese, vamos apresentar
   uma parábola para ilustrar melhor a distinção entre software e hardware nos
   computadores, comparando-os com os sistemas nervosos biológicos, mais
   especificamente com o cérebro humano. Através desse paralelo entre homem e
   máquina, podemos denominar de hardware, todas as características físico-químicas
   dos neurônios, que são as células nervosas que compõem o sistema nervoso;
   seguindo a mesma linha de raciocínio, o software, seria todo o sistema de
   aprendizado. Como sabemos, o aprendizado é vital para o funcionamento do
   cérebro, ele é responsável pela definição da forma e modo de processamento
   realizado por cada uma das diferentes regiões cerebrais (hardware). Deste modo,
   podemos dizer que é o software que determina a forma e o modo de manipulação
   do hardware, e ainda podemos concluir que sem o aprendizado (software) a parte
   física do cérebro (hardware) seria apenas um aglomerado de células, e você caro
   leitor, jamais estaria lendo esta tese.
   Vamos continuar essa discussão no próximo capítulo, entretanto, a
   finalidade dessa simples comparação foi ilustrar a importância do software. Embora
   extremamente dependente das bases do hardware, a sofisticação evolutiva
   (instinto, decisão, razão, sentimento, etc.) fica sob a responsabilidade do software.
   O mesmo ocorre nos computadores. Embora necessite de um meio físico
   (hardware) para concretizar-se, o software é o elemento responsável pelo
   comportamento da máquina. É através dele que os computadores modernos são
   capazes de executar suas funções.
   Agora que já observamos sua importância, vamos à sua definição: Software
   pode ser definido como uma abstração compreendida por algoritmos, instruções,
   dados e informações responsáveis pelo controle, supervisão e manipulação do
   hardware.
   Como podemos observar através do modelo de camadas apresentado na
   52
   A COMPUTAÇÃO PARALELA - SOFTWARE
   Figura 3.1, muitas vezes o limiar entre software e hardware é bastante sutil, de
   modo que a sua diferenciação sob determinados níveis de máquina é bastante
   complexa. No entanto, em termos gerais, podemos definir o hardware como a parte
PA física do computador e o software como a abstração responsável por sua
   manipulação.
   3.3 – MODELO DE CAMADAS
   Um importante conceito que devemos levar em conta na organização dos
   computadores é a vinculação das camadas de software ao hardware. A partir do
   modelo de camadas [Tanenbaum, 1990], os computadores são definidos como
   composições de hardware e software. Levando em conta o hardware e o software
   ao definirmos os computadores, estamos acrescentando o conceito de plataforma.
   Deste modo, uma mesma máquina pode, em função das camadas de software
   (principalmente Sistema Operacional), pertencer a diferentes plataformas. Um bom
   exemplo dessa abordagem são os computadores pessoais PC. Embora o hardware
   seja o mesmo, a máquina pode pertencer a diferentes plataformas, e deste modo
   modificar seu comportamento, bastando para isso alterar seu sistema operacional
   (ex: UNIX, Windows, Windows NT, DOS e OS/2). A partir desse conceito o software
   passa a constituir parte da arquitetura dos computadores.
   Linguagem de Alto Nível
   Tradução (compilador)
   Linguagem Assembly
   Tradução (assembler)
   re
   wa
   Sistema Operacional
   ft
   Interpretação Parcial
   So
   (Sistema Operacional)
   Convencional
   Interpretação (Microprograma)
   are
   Microprogramação
   dw
   Execução dos microprogramas
   Har
   diretamente no hardware
   Hardware
   Fig. - 3.1– Organização genérica em camadas dos computadores.
   53
   CAPÍTULO 3
   A Figura 3.1 ilustra a clássica divisão em camadas na organização dos
   computadores proposta por Tanenbaum [Tanenbaum, 1990]. Esse modelo pode
   variar muito de computador para computador, tanto em número de camadas quanto
   em sua diferença. Nesta figura, representa-se um típico computador CISC (do
   inglês Complex Instruction Set Computer) [Gimarc & Milutinovic, 1987]. Devemos
   observar também que o desempenho de cada camada é afetado diretamente pelas
   camadas inferiores.
   A primeira camada do modelo apresentado pela Figura 3.1 representa
   hardware. Nesta seção não abordaremos o paralelismo contido nessa camada,
   uma vez que já foi bastante discutido no capítulo anterior. A segunda camada é
   constituída pela micromáquina ou microprogramação. Em computadores CISC,
   compete à micromáquina controlar os recursos do hardware. Deste modo, cada
PA instrução do nível convencional, ao ser processada, é interpretada e dividida pela
   unidade de controle em microinstruções. A micromáquina apresenta uma memória
   especial denominada de memória de controle (tabela de controle), onde são
   armazenados os sinais de controle. As microinstruções são convertidas em sinais,
   através dessa tabela, que controlam diretamente o hardware. Embora essa camada
   possua o conceito de programa, geralmente não a classificamos como software,
   uma vez que é transparente ao programador. Discutiremos sucintamente na Seção
   3.4 algumas abordagens paralelas utilizadas nessa camada.
   A terceira camada é composta pelo nível convencional, também conhecida
   por linguagem de máquina. No nível convencional é realizada a primeira interface
   entre o software e o hardware. Esta camada é constituída pelo conjunto de
   instruções do processador, registradores, dispositivos funcionais (ALUs,
   deslocadores, etc.), do espaço de endereçamento e de outros recursos de
   hardware “visíveis” ao programador. Através da interpretação das instruções e sua
   execução (microprogramação), é realizado o processamento da memória,
   interrupções e os processos de entrada e saída para periféricos. Apresentaremos o
   paralelismo a nível convencional na Seção 3.5.
   As camadas seguintes: sistema operacional, linguagem assembly e
   linguagens de alto nível constituem as camadas de software “puro”. Iremos tratar
   desses assuntos nas Seções 3.6 e 3.7.
   Finalizaremos a discussão do modelo de camadas com as bibliotecas de
   troca de mensagens, assunto da Seção 3.8 onde apresentaremos algumas das
   principais ferramentas disponíveis atualmente e também introduziremos a
   54
   A COMPUTAÇÃO PARALELA - SOFTWARE
   ferramenta CVMP, no decorrer desta tese.
   3.4 – PARALELISMO DE MICRO-MÁQUINA
   Compete à micromáquina controlar os recursos do hardware através dos
   sinais que são enviados aos pontos de controle. Para isso, a micromáquina
   interpreta cada instrução executada pelo nível convencional e as transforma em
   microinstruções. A micromáquina apresenta uma memória especial denominada de
   memória de controle, onde são armazenados os sinais de controle, para isso, as
   microinstruções são organizadas em campos de um ou mais bits, chamados de
   microordens, onde cada uma destas especifica o sinal a ser produzido a fim de
   executar o hardware.
   Mesmo apresentando o conceito de programa, não podemos caracterizar a
   micromáquina como uma camada de software, pois sua programação não pode ser
   alterada (hardware) e ela é completamente transparente ao usuário. Deste modo, a
   programação da micromáquina é realizada pelo fabricante do hardware. Como
   estamos tratando de paralelismo de software, nesta seção não entraremos em
   detalhes sobre a implementação paralelas da microprogramação.
   1
   2
   Micro-ordens
   1 A:=5
   3
   2 B:=12
   3 C:=A*B
   4 A:=1
   4
PA 5
   5 C:=2
   6 D:=13+C
   6
   (a) trecho de micro-ordens
   (b) Grafo de dependência de dados
   Fig. - 3.2 – Grafo de Dependência de Dados.
   As máquinas com microinstruções verticais [Hwang et al., 1984] [Amorin et
   al.,1988] são capazes de executar diversas microinstruções simultaneamente. A
   55
   CAPÍTULO 3
   heurística da exploração de seu paralelismo consiste basicamente na verificação da
   dependência de dados. Desta forma, seu algoritmo deverá percorrer as
   microinstruções e verificar quais poderão ser executadas em paralelo, gerando um
   grafo de execução. A Figura 3.2 apresenta um exemplo mostrando um grupo de
   microinstruções e seu respectivo grafo. Observa-se que, devido à dependência de
   dados, a microinstrução 3 foi executada seqüencialmente.
   3.5 – PARALELISMO NO NÍVEL CONVENCIONAL
   A camada de nível convencional também conhecida por linguagem de
   máquina (embora essa denominação seja incorreta [Tanenbaum, 1990]) é a
   camada onde se realiza a primeira interface entre o software e o hardware. Ela é
   caracterizada pelo conjunto de instruções do processador, registradores,
   dispositivos funcionais (ALUs, deslocadores, etc.), do espaço de endereçamento e
   de outros recursos de hardware “visíveis” ao programador.
   Embora possamos discutir o paralelismo no nível convencional sob o ponto
   de vista dos registradores, dispositivos funcionais, espaço de endereçamento e etc.,
   vamos enfocar a discussão no conjunto de instruções que compõe a linguagem de
   máquina.
   A exploração do paralelismo das camadas inferiores ao nível convencional
   ocorre completamente transparente ao programador. Um bom exemplo disso são
   as máquinas com pipeline de instrução. Do ponto de vista do programador, as
   instruções de linguagem de máquina são executadas seqüencialmente, porém a
   unidade de controle realiza o paralelismo do hardware através do pipeline, fazendo
   com que diversas instruções possam estar sendo executadas simultaneamente,
   independentemente do conhecimento ou controle do programador.
   Existe ainda um determinado tipo de máquina onde essa forma de
   paralelismo não é transparente ao programador do nível convencional. É o caso
   das máquinas com múltiplas unidade funcionais (como por exemplo as máquinas
   escalares CDC 6600, CDC 7600 e IBM 360 [Hwang et al., 1984]). Nesse caso, o
   paralelismo de hardware somente pode ser explorado quando não ocorre
   dependência de dados entre as instruções (ver Figura 3.2), ficando sob a
   responsabilidade do programador (ou mesmo do compilador) a tarefa de gerar o
   código de linguagem de máquina otimizado.
   A principal estratégia de paralelismo dentro do nível convencional é
   56
   A COMPUTAÇÃO PARALELA - SOFTWARE
   encontrada nas arquiteturas VLIW (do inglês “Very Long Instruction Word”) [Amorin
   et al.,1988]. Esse tipo de máquina possui instruções com palavras muito longas, e
   exploram o paralelismo de hardware através da replicação dos recursos da UCP
   (unidade central de processamento).
PA As arquiteturas VLIW são constituídas de uma única unidade central de
   processamento e foram projetadas para executar as instruções seqüencialmente,
   do mesmo modo como ocorre na tradicional máquina de von Neumann. O
   paralelismo nessas máquinas, porém, está contido dentro de cada instrução, que
   contém informação suficiente para explorar todo o potencial paralelo de suas
   unidades funcionais replicadas. Devido à sua complexidade, as instruções possuem
   a capacidade de especificar as unidades funcionais que irão executar seus
   respectivos operandos.
   3.6 – PARALELISMO A NÍVEL DE SISTEMA
   OPERACIONAL
   O sistema operacional é a primeira das camadas que compõem um
   computador, sendo constituído inteiramente por software. É responsável pela
   interface entre os aplicativos (programas) e o computador. Compete ao sistema
   operacional controlar e supervisionar os dispositivos de entrada e saída de dados,
   organizar e gerenciar a memória, interpretar parcialmente os programas ao serem
   executados, etc. [Tanenbaum, 1992].
   Em sistemas operacionais o processo é um importante conceito de
   exploração do paralelismo, sendo constituído por todas as partes necessárias de
   um programa em execução, ou seja: código objeto, o valor das variáveis do
   programa (“stream”) e conteúdo dos registradores e indicadores. Através dele, o
   sistema operacional é capaz de isolar os programas em execução. Através deste
   princípio, o sistema operacional é capaz de executar diversas atividades em
   concorrência, ainda que utilizando um único processador, técnica que recebe a
   denominação multitarefa (“multitasking”). O conceito de processo exige um
   sofisticado gerenciamento de memória, interrupções e de controle total sobre a
   camada convencional.
   57
   CAPÍTULO 3
   Processo 1
   Processo 2
   Kernel
   Processo 3
   Processo n
   Fig. - 3.3 – Escalonamento de tarefas.
   Multitarefa é um mecanismo do sistema operacional, que, utilizando o
   conceito de processo, alterna os processos (ou tarefas), permitindo a execução de
   programas simultaneamente (em concorrência). A Figura 3.3 ilustra o
   escalonamento das tarefas. Neste exemplo, "n" processos estão sendo executados
   de forma alternada no tempo, sob supervisão do kernel (camada do sistema
   operacional responsável pelo controle da multitarefa). Assim, o kernel habilita a
   execução do processo A por um breve período de tempo, a seguir interrompe a
   execução e começa a executar o próximo processo. Ao final da lista de processos,
   o kernel volta a executar o primeiro processo e assim sucessivamente até que
   todos sejam terminados. Esse procedimento gera a ilusão ao usuário de que
   diversos programas estão sendo executados ao mesmo tempo.
   Essa técnica auxilia a programação concorrente, uma vez que permite ao
   programador executar seus programas em concorrência. Mesmo sendo esse
   contexto adotado em computadores seqüenciais, sua noção de paralelismo permite
   ao programador desenvolver sistemas que emulem paralelismo. Do ponto de vista
   da utilização, a multitarefa somente faz sentido efetivo quando é empregada em
PA sistemas operacionais com interface gráfica com o usuário (GUI).
   Durante toda a década de 70, uma série de pesquisas em ciência da
   computação viria a mudar o conceito de sistema operacional, através do paradigma
   das interfaces gráficas com o usuário - GUI (do inglês “graphical user interface”)
   [Bruno, 1995]. Podemos atribuir quase que inteiramente ao Xerox PARC (Palo Alto
   Research Center) todo o desenvolvimento do conceito de GUI. A camada GUI não
   é apenas uma simples contribuição ao método de realizar a interface entre o
   computador e o usuário, mas sim um novo conceito inserido ao sistema operacional
   [Bruno, 1995], que contribuiu com o desenvolvimento da ciência da computação.
   58
   A COMPUTAÇÃO PARALELA - SOFTWARE
   Entre os benefícios acrescidos pelo conceito podemos citar: a programação
   orientada a objetos [Cox, 1986] e a programação orientada a eventos [Bruno, 1995].
   A Figura 3.4 apresenta como exemplo um diagrama das camadas entre as
   aplicações e o sistema operacional UNIX com e sem GUI. Com a popularização e
   proliferação do conceito GUI, atualmente a maioria dos sistemas operacionais
   disponíveis possuem essa camada embutida.
   Aplicativos
   user shell (sh, ch, ksh)
   UNIX sem GUI
   UNIX
   Desktop
   Aplicativos
   API/toolkit
   Looking Glass, IXI
   GUI
   Motif, Open Look
   UNIX com GUI
   Sistema de Janelas
   X Window System
   Sistema Operacional
   UNIX
   Fig. - 3.4 – Comparação entre o sistema operacional UNIX com e sem a
   camada GUI.
   Além da multitarefa, que possibilita a concorrência de processos, os
   sistemas operacionais genéricos atuais (UNIX, Windows NT/9X, Mac OS e etc.)
   apresentam também um outro conceito muito útil para o desenvolvimento de
   programas concorrentes, denominado Thread. O conceito de Thread é bastante
   parecido com a multitarefa. Porém agora, ao invés de processos, temos parte de
   programas (podendo ser de um mesmo programa ou não) sendo executados em
   concorrência.
   Um outro conceito muito importante para a computação paralela é a adoção
   do sistema de arquivo para redes de computadores [Tanenbaum, 1992]. Essa nova
   camada permite que o sistema de arquivos do sistema operacional seja expandido
   aos dispositivos de armazenamento conectados pela rede. Somente a partir dessa
   camada foi possível a implementação de sistemas operacionais distribuídos.
   As estratégias até aqui comentadas, embora relacionadas ao paralelismo,
   são diretamente associadas aos computadores seqüenciais. Discutiremos a seguir
   59
   CAPÍTULO 3
PA de forma abreviada, os sistemas operacionais desenvolvidos especificamente para
   computação paralela.
   O objetivo principal dos sistemas operacionais consiste na interface entre o
   usuário (programador) e a aplicação (computador). Deste modo, o sistema
   operacional cria uma camada de software que simplifica toda a complexidade do
   hardware da máquina, possibilitando sua operação e disponibilizando a base para o
   desenvolvimento e execução das aplicações (programas). Seguindo esse princípio,
   o sistema operacional funciona como uma máquina virtual [Tanenbaum, 1992],
   simples de utilizar, compreender e programar, tornando todo o complexo conjunto
   de dispositivos que constituem o computador (memória, relógios, terminais,
   controladores de discos rígidos, controladores de discos flexíveis, interfaces de
   rede, dispositivos de entrada e saída, processador, etc.) transparentes ao usuário.
   Sendo o sistema operacional definido como uma máquina virtual, conforme
   comentamos anteriormente, torna-se bastante natural a transposição desse
   conceito para as máquinas paralelas. Deste modo, os sistemas operacionais
   paralelos procuram tornar as características paralelas igualmente transparentes.
   Assim, foram desenvolvidos os sistemas operacionais distribuídos [Tanenbaum,
   1995].
   Segundo Tanenbaum [Tanenbaum, 1995], um sistema operacional
   distribuído consiste de uma camada de software capaz de fazer com que uma
   coleção de computadores independentes aparentem para o usuário como um único
   computador. Entretanto, essa definição é apenas teórica. Embora existam diversos
   sistemas operacionais distribuídos, o atual estado da arte da ciência da
   computação ainda não permite a implementação efetiva desse conceito. Mais uma
   vez, o software é a grande barreira do paralelismo. Não sabemos como projetar,
   implementar ou usar software distribuído de modo a desenvolver um sistema
   operacional que com eficácia distribua uma aplicação em diversas unidades de
   processamento.
   O atual estado da arte em sistemas operacionais distribuídos ainda não
   permite paralelizar automaticamente os programas e aplicações, o que seria de se
   esperar de um sistema operacional distribuído ideal. No entanto, esses sistemas
   são capazes de deixar transparente e automática a exploração dos recursos
   paralelos, através da distribuição de processos e threads pelos processadores
   espalhados na rede. O usuário, ao utilizar um sistema operacional distribuído (ex:
   Amoeba [Tanenbaum, 1995]), tem a idéia de estar utilizando um sistema
   60
   A COMPUTAÇÃO PARALELA - SOFTWARE
   operacional multitarefa convencional ao invés de um conjunto de máquinas
   integradas pelo sistema operacional distribuído. Deste modo, quando o usuário
   executa diversas aplicações, o sistema operacional distribui estas para máquinas
   distintas, de modo transparente ao usuário, que tem a impressão de estar utilizando
   um sistema operacional convencional multitarefa com alta performance
   computacional.
   Basicamente existem três possibilidades de implementar um sistema
   operacional distribuído:
   Desenvolvimento completo - Consiste em desenvolver um sistema operacional
   distribuído específico, partindo do ponto zero, ou seja sem utilizar nenhum outro
   sistema operacional existente como base de desenvolvimento.
   Modificando um sistema operacional convencional – Resume em utilizar as
   bases de um sistema operacional convencional (normalmente UNIX),
PA alterando-o e incrementando-o até transformá-lo em um novo sistema
   operacional com características de sistema operacional distribuído.
   Utilizando um sistema operacional convencional – Consiste no desenvolvimento
   de uma camada de software adicional sobre um sistema operacional já
   existente, ficando entre o usuário / aplicações e o sistema operacional, de modo
   que a partir dessa nova camada o conjunto todo se comporte como um novo
   sistema operacional distribuído.
   É importante comentar que, embora o conceito de sistemas operacionais
   distribuídos seja bastante interessante, e que existam mesmo algumas
   implementações, esse tipo de abordagem não se popularizou. A grande maioria das
   implementações desses sistemas são de caráter acadêmico e os exemplos que se
   tornaram comerciais são bastante raros; entre eles podemos citar o Chorus,
   sistema operacional distribuído desenvolvido a partir do UNIX, no INRIA (Instituto
   Francês de Pesquisas) e posteriormente comercializado pela Chorus Sistèmes
   [Tanenbaum, 1995].
   A Figura 3.5 apresenta um arranjo da arquitetura do sistema operacional
   distribuído AMOEBA [Mullender et al., 1990] [Tanenbaum, 1995]. Seguindo a
   estratégia de desenvolvimento completo, o Amoeba foi desenvolvido totalmente
   sem utilizar nenhuma base (sistema operacional) previamente implementada.
   Originado na Vrije Universiteit, Amsterdã, sua primeira versão ficou operante em
   61
   CAPÍTULO 3
   1984. O sistema possui dois objetivos básicos: constituir um sistema operacional
   distribuído totalmente transparente ao usuário e fornecer as bases para
   desenvolvimento de programação paralela e distribuída.
   Quanto ao primeiro objetivo, o Amoeba tem o propósito de fazer com que as
   características paralelas sejam transparentes ao usuário. Um interessante conceito
   do sistema está na opção de não existir máquina-mãe para processos ou usuários.
   Deste modo, quando um usuário entra no sistema, está entrando no sistema como
   um todo e não em uma determinada máquina que compõe o sistema. Assim,
   quando é apresentado a interface (shel ) para o usuário entrar no sistema, ela é
   executada em um processador arbitrário.
   O outro objetivo, é fazer com que o Amoeba forneça as bases para
   pesquisas em programação paralela e distribuída. Se operado por um usuário sem
   intenções de desenvolver aplicações paralelas, devido à sua transparência,
   aparenta ser um sistema operacional multitarefa (multitasking) executado em um
   supercomputador seqüencial. Porém, o Amoeba também possui ferramentas,
   linguagens e aplicações específicas para a exploração do paralelismo, como a
   linguagem Orca, voltada exclusivamente para o desenvolvimento de aplicações
   paralelas [Tanenbaum, 1995].
   Grupo de processadores
   Terminais X
   Servidor de Arquivos
   Servidor de impressão
   Fig. - 3.5 – Arquitetura do sistema operacional distribuído Amoeba.
   Conforme podemos observar através da Figura 3.5, o Amoeba é composto
   basicamente por três partes: grupos de processadores, terminais X-Windows e
   servidores. Os grupos de processadores possuem um substancial número de
   UCPs, as quais possuem sua própria memória local e conexões de rede. O sistema
   62
PA A COMPUTAÇÃO PARALELA - SOFTWARE
   permite também processadores utilizando memória compartilhada. Neste caso, a
   troca de mensagens é otimizada através da comunicação memória para memória
   ao invés de trocar mensagens pela rede. As UCPs de um grupo podem pertencer a
   diferentes arquiteturas, como por exemplo uma mistura entre 680x0, família Intel,
   ou máquinas SPARC. As máquinas pertencentes ao grupo de processadores
   podem ser máquinas completas (com teclado, mouse e monitor) ou simplesmente a
   placa de processamento com a conexão de rede e memória. As máquinas
   completas no entanto possuem o inconveniente de serem sub-utilizadas, uma vez
   que não podem ser utilizadas como terminais.
   A outra parte que compõe o sistema Amoeba são os terminais X-Windows.
   Além destes, podem ser utilizados computadores pessoais ou estações de trabalho
   como terminais, que no entanto serão sub-utilizados, uma vez que não poderão
   participar do processamento. A terceira parte do sistema consiste dos servidores,
   máquinas que executam tarefas específicas (Ex: servidores de arquivos e de
   impressão).
   Aplicações Distribuídas
   Serviço de Arquivos
   Serviço de segurança
   Serviço de tempo
   Serviço de diretório
   DCE -Chamadas a procedimentos remotos e autentificações
   Threads DCE
   Sistema Operacional Convencional
   Hardware
   Fig. - 3.6 – Camadas do sistema DCE.
   Como exemplo da terceira abordagem de implementação de sistemas
   operacionais distribuídos, podemos citar o DCE (do inglês Distributed Computing
   Environment) [Rosenberry et al., 1992]. Utilizando máquinas com sistemas
   operacionais convencionais e adicionando uma aplicação, que funciona como uma
   camada de software adicional, o DCE, transforma um conjunto de máquinas em
   sistema operacional distribuído. A Figura 3.6 apresenta o modelo de camadas do
   DCE. Inicialmente desenvolvido para rodar em plataforma UNIX, o DCE foi portado
   para as plataformas VMS, Windows e OS/2. Uma outra característica que chama a
   atenção é seu caráter comercial, que constitui a base de seu projeto desde a
   origem.
   63
   CAPÍTULO 3
   3.7 – PARALELISMO A NÍVEL DE LINGUAGENS DE
   PROGRAMAÇÃO
   Antes de discutirmos sobre o paralelismo a nível de linguagens de
   programação, é interessante definirmos o que vem a ser uma linguagem de
   programação. A linguagem de programação de alto nível consiste em um método
   desenvolvido pela ciência da computação para transformar o modo de programar
   deixando-o mais abstrato e menos dependente da máquina. Através de um
   compilador ou interpretador, os programas escritos em linguagens de alto nível são
   convertidos em linguagem de máquina, e deste modo, transformam-se em novas
   aplicações (ver Figura 3.1).
   O conceito de linguagem de programação de alto nível auxiliou o
   desenvolvimento da ciência da computação em dois níveis: simplicidade no
PA desenvolvimento de programas e portabilidade. A simplicidade de desenvolvimento
   de programas é uma das questões mais importantes da computação. A informática
   somente conseguiu atingir seu estado de popularização através da crescente
   variedade de aplicações. Se os programas fossem desenvolvidos em linguagem de
   máquina, a complexidade e o tempo de trabalho fariam com que o software tivesse
   um custo tão elevado que impossibilitaria a generalização do uso do computador. A
   portabilidade é uma questão extremamente importante na história da computação
   [Bruno, 1995]. Com o conceito de linguagem de programação de alto nível, os
   programas puderam ser portáteis. Deste modo, os programadores podem
   desenvolver um programa e transpô-lo para qualquer máquina, sem se preocupar
   com o conjunto de instruções ou com a sua linguagem de máquina ou assembly,
   bastando que a nova máquina (com arquitetura diferente) possua um compilador
   para a linguagem em que foi escrito o programa. Em [Bruno, 1995] são encontrados
   detalhes sobre a história da computação sob os aspectos da portabilidade.
   3.7.1 - LINGUAGENS DE PROGRAMAÇÃO DE ALTO
   NÍVEL
   Sendo o objetivo das linguagens de alto nível a abstração técnica e a
   representação dos problemas de modo mais facilitado para os programadores,
   como seria de se esperar, a linguagem de alto nível é desenvolvida com base na
   64
   A COMPUTAÇÃO PARALELA - SOFTWARE
   classe de problemas que procura atender. Verificando o universo das linguagens de
   programação de alto nível, podemos constatar seu caráter de orientação ao
   problema. A seguir vamos apresentar algumas das linguagens mais populares de
   programação com suas respectivas especificações. Apresentamos também na
   Figura 3.7 um diagrama da genealogia de algumas dessas linguagens.
   Fortran – ( FORmula TRANslation) Projetada para aplicações técnicas e
   científicas, mais especificamente para cálculos matemáticos, pode ser considerada
   como origem de todas as linguagens de programação de alto nível. Embora não
   possua muita abstração e seja mais voltada para simplificar o trabalho de
   compilação do que o de programação, o Fortran é uma das linguagens que mais
   evoluiu, possuindo novas versões a cada década. É amplamente utilizado até os
   dias de hoje, principalmente em super computação. Existem muitas ferramentas e
   extensões para exploração de paralelismo em Fortran.
   Algol – (ALGOrithmic Language) O Algol foi a primeira linguagem de alto
   nível realmente preocupada com a abstração (mais voltada ao programador que à
   estrutura da máquina). Designado para uso geral, introduziu, entre outros, os
   conceitos de estrutura de blocos, procedimentos e variáveis locais (declaradas
   dentro dos procedimentos). O Algol influenciou teoricamente a grande maioria das
   linguagens.
   COBOL – (COmercial Business Oriented Language). Primeira linguagem de
   computadores designada especificamente para uso comercial, o Cobol é ainda hoje
   uma das linguagens mais utilizadas em todo o mundo. A principal atividade de suas
   aplicações é a manipulação de arquivos.
   Lisp – (LISt Processing language). Foi a primeira linguagem declarativa.
   Projetada para problemas em inteligência artificial, assim como em outras áreas
   com estruturas de dados irregulares que são melhor representadas através de
   listas, introduziu o conceito de recursividade que não era permitido pelo Fortran.
   Atualmente, existem algumas extensões e implementações do Lisp para a
   exploração de paralelismo.
PA BASIC – (Beginner's Al -purpose Symbolic Instruction Code). Linguagem de
   uso geral, utilizada por iniciantes em linguagens de programação. Popularizou-se a
   partir de meados da década de 70, por se tornar padrão como linguagem de alto
   nível para os primeiros microcomputadores. Atualmente o Visual Basic constitui
   uma evolução da linguagem BASIC, adicionando características de programação
   65
   CAPÍTULO 3
   visual ao BASIC, tornando-se a linguagem que mais desenvolveu aplicativos para a
   plataforma Windows.
   Pascal – Possui essa denominação em homenagem ao matemático e
   filósofo Blaise Pascal. Caracterizado como um estágio evolutivo da linguagem
   Algol, foi inicialmente projetado para o ensino de linguagens de programação em
   nível superior. Devido a sua modularidade e estruturação, assim como sua
   simplicidade, popularizou-se o Pascal, que se tornou uma das principais linguagens
   dos computadores de terceira geração. Tendo sido projetado para uso geral, muitos
   compiladores e sistemas operacionais forma escritos em Pascal. Atualmente o
   Pascal possui diversas extensões paralelas. A atual ferramenta de desenvolvimento
   Delphi [Calvert, 1999], estimulou a utilização do Pascal, adicionando características
   de orientação a objetos [Cox, 1986] e visuais.
   C – É uma linguagem de alto nível de uso geral, cuja principal característica
   é a habilidade de acessar o hardware, comportando-se como linguagem de baixo
   nível. Embora possua tais características, os programas escritos em C possuem
   alta portabilidade podendo ser recompilados em diversas plataformas. Essas
   condições fazem com que a linguagem C seja voltada ao desenvolvimento de
   sistemas operacionais (UNIX é escrito em C). Com a popularidade do UNIX em
   sistemas paralelos, consequentemente a linguagem C ganhou diversas extensões
   paralelas.
   Smalltalk – O Smal talk é uma linguagem de programação visual, que
   inspirou tanto a programação visual quanto o emprego da tecnologia de orientação
   a objetos. Desenvolvida para suportar os paradigmas dos projetos PARC [Bruno,
   1995], motivou diversas outras linguagens por seus conceitos inovadores.
   Modula 2 – A linguagem Modula 2, também foi inspirada pelas novas
   concepções do projeto PARC da Xerox [Bruno, 1995]. baseada em Pascal, foi
   designada para ser a linguagem de alto nível base para as novas estações de
   trabalho.
   C++ - Devido à popularização do conceito de programação orientada a
   objetos, foi desenvolvido o C++, que é uma extensão da linguagem C. O C++
   acrescenta o conceito de orientação a objetos ao C. As características OO
   (orientação a objetos) trouxeram a estrutura de classes ao C++ e todas as suas
   vantagens de reutilização de código e facilidades para projetos extensos.
   Prolog – ( PROgramming LOGic). O Prolog é uma linguagem de alto nível
   de abstração. Projetado para ser utilizado em inteligência artificial e sistemas
   66
   A COMPUTAÇÃO PARALELA - SOFTWARE
   inteligentes, é uma linguagem declarativa, baseada em predicados lógicos.
   Ada – Denominação para homenagear a primeira programadora de
   computadores Augusta Ada Lovelace, aluna de Charles Babbage [Spufford &
   Uglow, 1997]. A linguagem de programação ADA é uma linguagem de alto nível,
   muito parecida com o Pascal, foi encomendada pelo departamento de defesa
   americano e desenvolvida para computação numérica, programação de sistemas,
PA aplicações em tempo real e programação concorrente. ADA é uma linguagem
   robusta com bibliotecas nativas para diferentes especificações, incluindo a
   exploração de paralelismo.
   JAVA – Criada pela Sun Microsystens, a linguagem Java foi criada para
   atender as necessidades da Internet, possuindo caraterísticas que facilitam a
   utilização de suas aplicações em diversas plataformas de computação diferentes
   assim como sua integração com as metodologias de navegação da Internet. É uma
   linguagem de uso geral com estruturas muito parecidas ao C++.
   Linguagens Visuais – O conceito de linguagem visual foi introduzido
   primeiramente pelo Smalltalk. Na plataforma Windows, esse conceito foi introduzido
   pela linguagem Visual Basic, que consiste num ambiente de programação que,
   através de ferramentas CASE [Bruno, 1995], é capaz de gerar código através de
   interação visual entre o programador e o sistema, facilitando o desenvolvimento e
   diminuindo o tempo de programação. O Visual Basic popularizou-se rapidamente,
   tornando-se a linguagem mais utilizada e que possui o maior número de aplicações
   para plataforma Windows. Atualmente, existe uma forte tendência na utilização do
   conceito de linguagem visual, gerando inúmeras extensões visuais das linguagens
   tradicionais, como por exemplo: Delphi (Pascal), C++Builder e Visual C++ (C++),
   Jbuilder e Visual J++ (Java), Visual Fortran (Fortran) e etc.
   67
   CAPÍTULO 3
   1955
   1965
   1975
   1985
   1995
   COBOL
   Java
   PROLOG
   FORTRAN
   PL/1
   SMALLTALK
   HTML
   Java Visual
   Eiffel
   SIMULA
   C++
   C++ Builder
   ALGOL
   C
   MODULA 2
   Oberon
   Visual C++
   PASCAL
   Delphi
   ADA
   SMALLTALK
   LISP
   BASIC
   Visual Basic
PA Fig. - 3.7 – Genealogia das Linguagens de Programação.
   Podemos dividir as linguagens de programação em duas classes principais:
   DECLARATIVAS e IMPERATIVAS [Hudak, 1989] [Gregory, 1987]. A semântica
   para programas imperativos consiste em uma série de comandos obedecidos de
   forma seqüencial, que embora possuam abstração, ainda são baseados na
   estrutura dos computadores. Alguns exemplos são o BASIC, o Pascal, Algol,
   COBOL, C, C++, ADA, Fortran, etc. As linguagens imperativas possuem natureza
   inerente ao modelo de computação de von Neumann e uma história de evolução e
   desenvolvimento de 40 anos. Não é de estranhar que essa classe seja a mais
   difundida e utilizada pela grande maioria dos programadores de todos os níveis. O
   advento da computação paralela trouxe uma série de extensões paralelas para as
   linguagens imperativas, a fim de que estas pudessem explorar o paralelismo, e
   compiladores paralelos, que tentam extrair o paralelismo das linguagens
   imperativas seqüenciais.
   As linguagens declarativas constituem-se de uma série de funções ou
   predicados lógicos. Como exemplos podemos citar o Prolog, o Lisp, Sisal e etc.
   Embora considerada por alguns autores [Hockney & Jesshope, 1988] como menos
   eficiente que o estilo imperativo de programação, por não ser fundada na estrutura
   von Neumann, é também considerada de natureza mais paralela, e
   consequentemente apresenta soluções paralelas mais naturais [Almasi & Gottlieb,
   1994]. Uma outra característica que deve ser atribuída às linguagens declarativas é
   o seu rigoroso formalismo matemático, que pode auxiliar na temática da
   complexidade dos programas atuais.
   A discussão sobre as vantagens e desvantagens das duas classes ou
   estilos de linguagem de programação atinge patamares filosóficos, e não podemos
   68
   A COMPUTAÇÃO PARALELA - SOFTWARE
   com certeza designar uma ou outra como a melhor solução para programas
   complexos ou não, lineares ou paralelos. Embora as linguagens declarativas
   clamem sua superioridade pelo seu formalismo, elas encontram uma barreira
   constituída por 40 anos de evolução.
   3.7.2 – ALTERNATIVAS DE PARALELISMO
   Discutiremos a seguir algumas abordagens para explorar o paralelismo
   através das linguagens de programação (ver Figura 3.1).
   Quando um programador tenciona desenvolver um aplicativo paralelo, ele
   possui quatro possibilidades básicas: paralelismo automático, extensões paralelas
   para linguagens imperativas, bibliotecas de paralelismo e linguagens não
   imperativas paralelas.
   O paralelismo automático consiste no desenvolvimento de compiladores
   capazes de analisar o código seqüencial de um programa e paralelizá-lo. Esse tipo
   de compilador é tipicamente voltado aos programas escritos em Fortran [Almasi &
   Gottlieb, 1994]. Embora essa abordagem seja a mais cômoda para o usuário, que
   não precisa alterar seu código fonte, aprender ferramentas e extensões de
   linguagens ou ainda aprender linguagens diferentes ou técnicas e estratégias de
   desenvolvimento de programas paralelos, a performance obtida pelos
   compiladores, na maioria dos casos, não é satisfatória. A semântica de
   paralelização demonstra não ser trivial, uma vez que a natureza dos algoritmos
   para a exploração de paralelismo possui lógica, estrutura e estratégias muito
   complexas e depende das condições de paralelismo das camadas inferiores.
   Assim, encontrar um compilador capaz de transformar um programa seqüencial em
PA paralelo com eficiência é um desafio que se algum dia for atingido, exigirá a
   dedicação de muitas mentes brilhantes. Sem dúvida, essa linha de pesquisa é a
   mais cobiçada pelos pesquisadores e pela sociedade da computação paralela como
   um todo, vindo a ser a pedra filosofal do paralelismo.
   Uma outra estratégia utilizada para o desenvolvimento de programas
   paralelos consiste na utilização de extensões paralelas em linguagens imperativas
   convencionais. Embora essa abordagem requeira maior esforço do programador,
   que deverá aprender sobre computação paralela e sobre o funcionamento das
   ferramentas adicionais, por outro lado não será necessário aprender outra
   linguagem, podendo reutilizar muitas de suas bibliotecas e programas. Deste modo,
   69
   CAPÍTULO 3
   o programador pode utilizar a linguagem com a qual está familiarizado e através do
   acréscimo de comandos e estruturas específicas para funções paralelas será capaz
   de explorar o paralelismo. Ainda que esta estratégia seja muito criticada, por manter
   vínculos com a programação von Neumann, é a mais utilizada atualmente. Através
   desse tipo de abordagem, pode-se conseguir excelentes performances,
   dependendo da estratégia de paralelismo adotada pelo programador, que deverá
   conhecer muito bem a semântica de paralelismo, assim como a estrutura da
   plataforma paralela utilizada.
   Ainda uma alternativa é a utilização de bibliotecas de funções e
   procedimentos voltadas ao desenvolvimento paralelo. Neste caso, as bibliotecas
   são utilizadas em linguagens de programação seqüencial permitindo o
   desenvolvimento de aplicações paralelas.
   A última opção que apresentamos é a utilização de uma linguagem não
   imperativa, com nenhum ou quase nenhum vestígio da estrutura von Neumann.
   Embora muitos acreditem ser essa a resposta mais pródiga, é também a mais
   custosa para o programador, que deverá aprender uma nova linguagem, com uma
   heurística diferente da qual ele está familiarizado, e ainda reescrever todo o seu
   código para essa nova linguagem.
   Podemos considerar dois tipos de linguagens que não apresentam vestígios
   da arquitetura von Neumann: as linguagens baseadas em predicados lógicos como
   o Prolog e as linguagens funcionais como o Sisal e outras linguagens voltadas para
   arquiteturas DataFlow [Duncan, 1990]. Embora existam situações em que a
   performance do Sisal sobressai ao Fortran, na maioria das vezes a melhor
   performance obtida é através da utilização de extensões paralelas em linguagens
   imperativas, entretanto esta é uma área com uma crescente força de pesquisa
   [Almasi & Gottlieb, 1994].
   Existem linguagens desenvolvidas exclusivamente para a exploração de
   paralelismo, mas que apresentam estruturas e comandos baseados em linguagens
   imperativas (Occam [Inmos, 1988]). Este tipo de linguagem é classificada como
   extensão de linguagens imperativas.
   70
   A COMPUTAÇÃO PARALELA - SOFTWARE
   3.7.3 – MECANISMOS DE EXPLORAÇÃO DE
   PARALELISMO
   Dentre as quatro estratégias de paralelismo que apresentamos na seção
   anterior, estaremos preocupados principalmente em apresentar técnicas voltadas
   às extensões paralelas das linguagens convencionais e as bibliotecas de
   paralelismo.
PA Antes de começarmos a discutir as técnicas básicas de paralelismo,
   devemos discutir a definição de máquina paralela. Segundo a definição de Almasi e
   Gottlieb [Almasi & Gottlieb, 1994], uma máquina paralela é um conjunto de
   elementos de processamento, capaz de comunicar e cooperar para resolver
   problemas mais rapidamente. Utilizando-se dessa definição e observando o modelo
   de camadas do computador moderno apresentado na Figura 3.1, devemos nos
   lembrar da grande complexidade envolvida na exploração do paralelismo. Abaixo
   da camada de linguagem de alto nível existem diversas outras camadas que
   podem, cada uma ao seu modo, executar a exploração do paralelismo. Desse
   modo, devemos concluir que não existe uma regra ou modelo único capaz de
   descrever as bases da exploração de paralelismo. Para cada uma das possíveis
   combinações de exploração de paralelismo, em cada uma das camadas, existem
   técnicas e estratégias de programação mais adequadas que outras. Desse modo, o
   conjunto das técnicas de programação é tão vasto quanto o conjunto das
   combinações de paralelismo das camadas inferiores à sua. Assim, estaremos
   limitando a discussão deste item às máquinas MIMD genéricas. Devemos lembrar
   que o universo das máquinas MIMD é bastante abrangente, ocorrendo diversas
   situações (ex: máquinas MIMD formadas a partir de SIMD – Cray J-90 [Hockney &
   Jesshope, 1988]) em que as bases de exploração de paralelismo são um pouco
   adversas.
   Segundo Pratt [Pratt, 1984], em sua forma mais simples, um programa para
   computador von Neumann é composto por um conjunto de linhas contendo cada
   uma um único comando, sendo executadas uma após a outra. Existe, no entanto,
   uma série de procedimentos que nos auxiliam a eliminar essa visão estritamente
   seqüencial e construir programas mais interessantes. Esses conceitos estão
   presentes na grande maioria das linguagens atuais de programação e são
   conhecidas como estruturas de programação. As estruturas de programação
   permitem que as linhas de programação sejam integradas em estruturas. Dentre
   71
   CAPÍTULO 3
   elas, podemos citar as estruturas de condicionamento (ex: if then else; case), as
   estruturas de repetições (ex: for; while; repeat), assim como o agrupamento de
   estruturas ou linhas em blocos ou sub-programas (ex: procedimentos e funções). A
   diferença entre os comandos e as estruturas de programação são responsáveis
   pela caracterização das linguagens de programação.
   Embora os conceitos de programação estruturada e a aglomeração de
   linhas em blocos e sub-rotinas sejam bastante conhecidos e importantes na
   computação seqüencial, são eles também que constituem as bases para a
   elaboração de programas paralelos. Sem tais conceitos, praticamente seria
   impossível o desenvolvimento de aplicações paralelas, pois não haveria como
   realizar a caracterização formal das tarefas a paralelizar.
   Os algoritmos correspondentes a um problema geralmente são
   implementados através das estruturas de programação de forma seqüencial,
   testados e somente então são paralelizados. Isso ocorre devido à dificuldade de
   implementação e depuração de programas paralelos. Em termos gerais, as bases
   para a paralelização de um algoritmo seqüencial obedecem às seguintes tarefas:
   Definir quais conjuntos de sub-tarefas podem ser executados em paralelo
   (dependência de dados).
   Quando e como iniciar e finalizar sua execução.
   Coordenar e especificar sua interação enquanto estão executando.
PA A dependência de dados ocorre quando um comando ou operação depende
   do resultado de outro. Em geral, a sua a análise gera um grafo no estilo do
   apresentado pela Figura 3.2. Após verificar a dependência de dados, deve-se então
   decidir quando e como iniciar e finalizar as tarefas paralelas. Existem algumas
   primitivas básicas comuns, tanto em bibliotecas de extensão paralelas como em
   linguagens de programação paralelas. São elas: fork/join, parbegin/parend e doall.
   A Figura 3.8 apresenta um exemplo de comparação entre a estratégia
   parbegin/parend e fork/join.
   Tanto o fork/join quanto o parbegin/parend, possuem o mesmo objetivo:
   controlar a execução paralela. Na Figura 3.8 podemos observar a diferença entre
   as duas abordagens. Se por um lado a alternativa parbegin/parend oferece um
   código mais elegante e simples, sua exploração de paralelismo não é tão flexível
   quanto fork/join. Outra primitiva bastante comum, que apresenta uma estratégia um
   72
   A COMPUTAÇÃO PARALELA - SOFTWARE
   pouco diferenciada, é a primitiva doall e similares ( foral , pardo, etc.), que são
   voltadas às repetições com exploração de paralelismo. Por serem principalmente
   empregadas no cálculo de vetores e matrizes, são comuns em linguagens
   científicas como algumas extensões paralelas do FORTRAN. Embora a abordagem
   doall seja bastante útil e poderosa, existe um grande número de problemas
   envolvendo operações com matrizes e vetores, nos quais ocorrem dependência de
   dados, inviabilizando, deste modo, sua paralelização através desta abordagem.
   parbegin/parend
   fork/join
   A
   m=2
   A
   fork C
   parbegin
   B
   C
   n=3
   A
   A
   begin
   fork E
   B
   B
   B
   fork F
   D
   C
   D
   E
   F
   parbegin
   C
   D
   E
   F
PA join m,g; quit
   D
   g:G
   G
   E
   G
   join n,h; quit
   F
   h:H
   H
   parend
   H
   quit
   end
   c:C
   parend
   join m,g; quit
   H
   e:E
   join n,h; quit
   f:F
   join n,h; quit
   Fig. - 3.8 – Comparação entre parbegin/parend e fork/join, duas alternativas
   diferentes para controlar a execução paralela [Almasi & Gottlieb, 1994].
   Um conceito igualmente poderoso, que além de ser utilizado em linguagens
   paralelas ou com extensões paralelas pode ser utilizado em linguagens
   convencionais, com mecanismos de troca de mensagens (como no caso do CVMP
   apresentado nesse trabalho), é o conceito de sub-programas paralelos ou sub-
   rotinas paralelas. Nesse caso, um programa é capaz de ativar um ou mais sub-
   programas de modo a gerar execução paralela ou concorrente. Em geral, esses
   mecanismos utilizam o conceito de processos e "threads" providos pelo sistema
   operacional, comentados na Seção 3.6. A Figura 3.9 apresenta uma árvore de
   execução paralela, ilustrando este conceito. Nela podemos observar os processos
   representados por retângulos. O processo principal executa diversos outros sub-
   73
   CAPÍTULO 3
   processos. Este exemplo foi implementado utilizando a concepção de chamada de
   processos da linguagem PL/1. PL/1 foi uma das primeiras linguagens que
   possibilitou a execução de processos concorrentes, porém ela não viabilizava
   nenhuma espécie de controle, sincronismo ou coordenação dos processos, o que
   inviabilizava o desenvolvimento de aplicações paralelas. Atualmente a linguagem
   PL/1 não é mais utilizada, apresentando apenas interesse histórico e didático.
   Principal
   call A, task
   A
   call B, task
   call A1, task
   A1
   B
   call B1, task
PA call A11, task
   B1
   A11
   call A2, task
   call C, task
   A2
   C
   Fig. - 3.9 – Árvore de Execução Paralela. Exemplo de disparos de processos
   realizados a partir da linguagem PL/1.
   A necessidade de sincronismo ou coordenação dos processos paralelos
   surge devido à necessidade de uma melhor exploração do paralelismo e
   principalmente pela dependência de dados entre os processos. Além da
   coordenação dos processos, um outro fator muito importante na exploração do
   paralelismo é a comunicação entre processos, permitindo a estes trocar
   informações referentes à dependência dos dados durante sua execução.
   Existem diversas estratégias de coordenação de processos e tarefas.
   Discutiremos sucintamente algumas estratégias utilizadas para a comunicação e
   sincronismo em máquinas MIMD com memória distribuída e MIMD com memória
   compartilhada. Caso o leitor deseje entrar em detalhes, encontrará uma ampla
   abordagem em: [Almasi & Gottlieb, 1994] [Amorin et al.,1988] [Brawer, 1989]
   [Codenoti & Leoncini, 1994] [Foster, 1995] [Krishnamurthy, 1989] [Quinn, 1987].
   As técnicas utilizadas para comunicação são, na grande maioria das vezes,
   74
   A COMPUTAÇÃO PARALELA - SOFTWARE
   utilizadas para o sincronismo, variando de acordo com as camadas de hardware.
   Em máquinas de memória compartilhada, o meio mais usual de comunicação
   consiste nas variáveis compartilhadas. As variáveis compartilhadas são variáveis de
   processos diferentes, declaradas no mesmo endereço de memória, que permitem,
   aos diferentes processos ou tarefas (em diferentes processadores ou não) trocar
   informações. Devido à sua arquitetura, os processadores das máquinas de
   memória compartilhada podem ter acesso aos mesmos endereços de memória, e
   graças a esta possibilidade é viabilizado o mecanismo de comunicação via variável
   compartilhada.
   As máquinas que possuem memória distribuída, devido à sua arquitetura,
   não permitem que diferentes processadores acessem o mesmo endereço de
   memória, e portanto não permitem variáveis compartilhadas. Entretanto, a
   comunicação nas máquinas de memória distribuída é realizada através de uma
   técnica denominada de passagem de mensagens. A passagem de mensagens
   consiste na transferência de informações através da rede (ou memória, no casos de
   sua utilização em sistemas de memória compartilhada) que faz a conexão entre os
   processadores (ou computadores). Os processos são capazes de efetuar a
   comunicação via passagem de mensagens na rede através das primitivas SEND e
   RECEIVE. É importante observar que algumas linguagens possuem suporte para
   uma única abordagem (ex: Occam [Inmos, 1988b]) ou ainda para as duas
   abordagens, como é o caso da técnica Rendezvous da linguagem Ada [Naiditch,
   1995].
   Através dos mecanismos de comunicação são realizados o sincronismo e a
   coordenação dos processos paralelos. Em termos gerais, a coordenação de
   processos é realizada através da sincronização. Segundo Andrews e Schneider
   [Andrews & Schneider, 1983], o sincronismo entre processos concorrentes pode ser
PA visto como um paradigma de ação e reação. Em outras palavras, o sincronismo
   ocorre quando um processo envia uma mensagem (memória distribuída) ou atribui
   determinado valor a uma variável compartilhada (memória compartilhada) e um
   outro processo executa uma determinada ação mediante a detecção dessa ordem
   (alteração do valor de uma variável ou mensagem). Através dessa concepção
   podemos conceber os mecanismos de sincronização de processos como um
   mecanismo de espera na execução dos processos, que são disparados mediante
   eventos.
   Existem uma série de estratégias de sincronismo de processos, entre elas:
   75
   CAPÍTULO 3
   testa e continua, semáforos, barreiras, RPC, monitores e etc. Não iremos abordá-
   las aqui, porém essas estratégias podem ser melhor estudas em [Almasi & Gottlieb,
   1994] [Amorin et al.,1988] [Brawer, 1989] [Codenoti & Leoncini, 1994] [Foster, 1995]
   [Krishnamurthy, 1989] [Quinn, 1987]. O princípio básico dessas estratégias é a
   atualização e a verificação de variáveis, que indicam a condição ou ordem de outro
   ou outros processos, sendo possível implementá-las utilizando técnicas de
   passagem de mensagem ou memória compartilhada.
   A Figura 3.10 apresenta um exemplo genérico de aplicação paralela que
   utiliza o conceito de processos paralelos coordenados. Neste exemplo temos uma
   máquina composta por três processadores. Os processos são representados pelas
   caixas cinzas, e a comunicação e sincronismo entre os processos pelas setas. É
   importante observar a dependência de dados entre os processos.
   Processador 1
   Processador 2
   Processador 3
   LER DADOS
   CALCULA
   B
   CALCULA
   C
   CALCULA
   A
   CALCULA
   CALCULA
   D = função(C)
   E = B * C
   CALCULA
   F = A + E + D
   IMPRIME F
   Fig. - 3.10 – Exemplo genérico de uma aplicação paralela com coordenação de
   processos e dependência de dados.
   3.8 – FERRAMENTAS DE PASSAGEM DE MENSAGEM
   EM SISTEMAS DISTRIBUÍDOS
   Conforme comentamos na Seção 2.5.5, sistemas distribuídos são conjuntos
   de computadores conectados por rede, que podem executar um trabalho
   cooperativo explorando o paralelismo. Para implementar uma aplicação distribuída,
   76
   A COMPUTAÇÃO PARALELA - SOFTWARE
   ou seja, uma aplicação que aproveitará o recurso computacional do sistema
PA distribuído, é necessário utilizar ferramentas que realizem a comunicação através
   da rede. Denominadas ferramentas de passagem de mensagem, são de modo
   geral, extensões ou bibliotecas, que permitem ao programador utilizar linguagens
   de programação convencionais e efetuar a troca de mensagens entre as máquinas.
   Existem diversas ferramentas de troca de mensagens, dentre as quais podemos
   citar: P4, PVM, MPI, Express, e PARMACS [Geist et al., 1996] [Foster, 1995]
   [Pacheco, 1997] [Almasi & Gottlieb, 1994], além do CVMP, introduzido nesta tese.
   Vamos discutir sucintamente as ferramentas mais populares: PVM e MPI. Depois
   faremos uma pequena introdução ao CVMP.
   3.8.1 – O PACOTE PVM
   O PVM, cujo nome provem do inglês “Paral el Virtual Machine”, foi
   inicialmente desenvolvido em 1989 no Oak Ridge National Laboratory (ORNL).
   Trata-se de um pacote de software que permite utilizar uma coleção heterogênea
   de computadores conectados em rede como se fossem uma única máquina
   paralela (sistema distribuído) [Geist et al., 1996]. Uma das principais propostas de
   sistema heterogêneo formulada pelo PVM é a integração de máquinas seqüenciais,
   paralelas e vetoriais formando uma única enorme máquina de memória distribuída.
   O pacote PVM é dividido em duas partes: um controlador de processos
   denominado de daemon (ou simplesmente pvmd) e uma biblioteca de rotinas. O
   pvmd é uma aplicação que deve rodar em todas as máquinas, a fim de implementar
   a integração destas. Funciona basicamente como um servidor de recursos
   residente em cada uma das máquinas, e é através dele que as rotinas PVM são
   capazes de se comunicar. Deste modo, a principal função do módulo pvmd é
   implementar o conceito de máquina virtual paralela. A biblioteca de rotinas PVM
   consiste de um conjunto de primitivas para a comunicação, coordenação de
   processos e conversão de dados. Ela funciona como uma biblioteca de extensão
   para uma linguagem de programação convencional, de modo que as chamadas
   para rotinas PVM são usadas em conjunto com o código fonte original. A biblioteca
   PVM possui dezenas de funções, constituindo um complexo de comunicação de
   processos.
   Embora o pacote PVM tenha sido originalmente desenvolvido para rodar em
   máquinas com sistema operacional UNIX, atualmente existem pacotes para o
   77
   CAPÍTULO 3
   sistema operacional Windows NT/9X, além de encontrar-se em desenvolvimento
   uma versão baseada em Java [PVM]. Em relação à sua biblioteca de rotinas, o
   PVM não pode ser utilizado por qualquer linguagem de programação, possuindo
   atualmente versões para as linguagens C, C++ e Fortran.
   O modelo computacional do PVM é baseado na noção de que uma
   aplicação consiste em muitas tarefas e cada tarefa é responsável por uma parte do
   trabalho computacional da aplicação. O paralelismo ocorre na execução em
   concorrência dessas tarefas, através de diferentes processos sendo executados em
   diferentes máquinas num ambiente de troca de mensagens. Deste modo, o PVM foi
   projetado para promover um ambiente de troca de mensagens, onde diversos
   processos podem se comunicar (granularidade preferivelmente grande). Uma
   característica das aplicações PVM é a sua preferência pelo modelo SPMD (do
   inglês “Single Program Multiple Data”). Dentro dessa abordagem, em cada
   processador o mesmo programa é executado, porém processando dados
   diferentes.
   3.8.2 – A BIBLIOTECA MPI
PA O MPI [Pacheco, 1997] [Foster, 1995], cujo nome é derivado do inglês
   “Message Passing Interface”, é o resultado de uma tentativa de implantar um
   padrão nas interfaces de passagem de mensagem. O MPI foi criado a partir de um
   consórcio envolvendo cerca de quarenta organizações da comunidade de
   processamento paralelo mundial (sendo a grande maioria dos Estados Unidos e da
   Europa), contando com representantes de diversas áreas: indústria, comércio e
   universidade. Em 1992 iniciou-se o desenvolvimento do MPI, surgindo sua primeira
   versão funcional em 1994. O MPI é similar ao PVM, trata-se de uma ferramenta
   voltada a comunicar máquinas heterogêneas em plataforma UNIX conectadas via
   rede, gerando um ambiente de troca de mensagens. A principal diferenciação entre
   as duas ferramentas é que o MPI é composto apenas por uma biblioteca de rotinas,
   não possuindo nenhum outro componente.
   A biblioteca MPI é um conjunto complexo de 129 funções, das quais muitas
   apresentam numerosos parâmetros e variantes, que caracterizam seu poder e sua
   complexidade. Do mesmo modo que o PVM, o MPI possui variantes para apenas
   três linguagens de programação, sendo elas a linguagem C, C++ e Fortran.
   No modelo de programação MPI, a computação compreende em um ou
   78
   A COMPUTAÇÃO PARALELA - SOFTWARE
   mais processos que se comunicam através de chamadas à biblioteca de rotinas
   (MPI). Essas rotinas são utilizadas para enviar e receber mensagens para outros
   processos. Na maioria da implementações MPI, um número fixo de processos é
   criado no início do programa, onde cada processo pertence a um determinado
   processador ou máquina.
   Os sistemas MPI apresentam um número fixo de processos. Existem
   diferentes abordagens para a comunicação entre os processos, podendo haver
   comunicação individual e coletiva. Na comunicação individual, ou ponto a ponto, os
   processos enviam mensagens para outros determinados processos através da
   comunicação individual. Na comunicação coletiva, um único processo ou um grupo
   de processos enviam mensagem para um grupo de processos. Além dessas
   características de comunicação, uma interessante abordagem adotada pelo MPI é o
   conceito de modularidade. Esse conceito é bastante importante, principalmente sob
   o ponto de vista da engenharia de software. Um mecanismo denominado de
   comunicador permite que o programador MPI possa definir módulos que
   incorporem estruturas internas de comunicação.
   3.8.3 – O PACOTE CVMP
   Nesta seção vamos fazer uma breve apresentação do pacote CVMP, que
   será abordado ao longo desta tese.
   O nome CVMP é derivado do inglês “Cybernetic Vision Message Passage”,
   tratando-se de um pacote de exploração de paralelismo similar ao MPI e ao PVM,
   onde são fornecidas ferramentas de programação para auxiliar o desenvolvimento
   de aplicações paralelas. O CVMP foi desenvolvido ao longo de nosso trabalho no
   Grupo de Pesquisa em Visão Cibernética do IFSC/USP com o intuito de auxiliar no
   desenvolvimento dos projetos que necessitem da exploração de paralelismo. No
   decorrer da pesquisa de nosso grupo, observou-se a necessidade de
   desenvolvimento de sistemas e aplicações paralelas, devido à grande demanda de
   poder computacional exigida pelos experimentos nas áreas de Visão
   Computacional e Processamento de Imagens. Embora existam diversos pacotes de
   exploração de paralelismo, nossa pesquisa constatou a necessidade da elaboração
   de um pacote de simples utilização, adequado ao parque de computadores
PA pessoais e à plataforma Windows, e que fosse nativo a uma linguagem de
   programação visual, para facilitar ao máximo a sua programação, além de conter
   79
   CAPÍTULO 3
   ferramentas específicas para a pesquisa em Visão Computacional e
   Processamento de Imagens.
   Procurando atender a essas premissas, as quais não foram encontradas
   integralmente em nenhum pacote de exploração de paralelismo atual, decidimos
   implementar o CVMP. Deste modo, o CVMP é um pacote de exploração de
   paralelismo baseado em troca de mensagens, de simples utilização, capaz de
   efetivar a comunicação, controle e sincronismo em: (i) ambientes distribuídos
   constituídos por computadores pessoais em plataforma Windows 95/NT conectados
   via rede e (i ) máquinas multiprocessadas. A proposta CVMP busca a simplicidade
   de desenvolvimento de aplicações paralelas, sendo os principais objetivos do
   projeto:
   Simples utilização – prover a possibilidade de implementação paralela a
   programadores sem experiência ou especialidade em computação paralela
   e sistemas distribuídos, mas que necessitem desenvolver aplicações
   paralelas (característica da maioria dos pesquisadores em visão e
   processamento de sinais);
   Ser nativo para a plataforma Windows NT/9X – Utilizada pela grande maioria
   dos usuários;
   Operacionalidade em ambientes de programação visual – Os ambientes de
   programação visual (Delphi, Visual Basic e etc.) proporcionam ferramentas
   para facilitar o desenvolvimento de aplicações, facilitando o processo de
   programação. Deste modo possuem a importante característica de
   proporcionar uma boa ferramenta de programação para todo o universo de
   programadores (inexperiente / experiente );
   Prover mecanismos para facilitar o desenvolvimento de algoritmos de Visão
   Computacional e processamento de sinais em paralelo.
   Com base nesses objetivos e nas necessidades dos projetos do grupo,
   desenvolvemos o pacote CVMP, através do qual, o usuário é capaz de implementar
   uma aplicação paralela, realizar análise de performance e localizar gargalos.
   A comunicação dos processos através do CVMP está baseada no conceito
   de Canal Virtual. O Canal Virtual, é um conceito de canal de comunicação,
   inspirado nos processadores Transputer [Inmos, 1988] [Inmos, 1989]. Através dos
   Canais Virtuais, os objetos CVMP podem trocar mensagens e deste modo
   80
   A COMPUTAÇÃO PARALELA - SOFTWARE
   possibilitar a comunicação entre os processos. Os Canais Virtuais são
   estabelecidos a partir de um par de objetos CVMP, onde um componente é mestre
   e o outro é escravo. Uma vez estabelecido, o Canal Virtual não poderá mais ser
   alterado. Essa característica simplifica bastante o controle e a programação do
   ponto de vista do usuário [Bruno & Costa, 2000] [Bruno & Costa, 1996] [Bruno &
   Costa, 1997].
   Os componentes ou objetos CVMP são VCLs (Visual Component Library)
   [Konopka, 1997] compatíveis com os ambientes de programação Borland Delphi
   [Calvert, 1999] e C++ Builder [Calvert, 1997]. Possuem características de
   programação orientada a objetos, podendo ser programados visualmente e deste
   modo ser simples de usar. Funcionam em computadores com plataforma Windows
PA NT/9X, conectados via rede (ethernet, fast-ethernet ou ATM) através dos protocolos
   de rede TCP/IP [Bennett, 1997] e IPX/SX [Chappell, 1998], assim como em
   máquinas multiprocessadas, através de variáveis compartilhadas.
   Diferentemente do PVM e MPI, o CVMP possui caráter homogêneo. Do
   ponto de vista da plataforma, todos os micros deverão estar executando Windows
   9X/NT. A sua principal característica é a simples utilização do pacote, permitindo a
   pesquisadores e programadores de diversas áreas a exploração de paralelismo em
   seus algoritmos. Essa característica se acentua para algoritmos voltados para
   Visão Computacional e Processamento de Sinais.
   3.9 – DESENVOLVIMENTO DE SOFTWARE
   Nesta seção iremos abordar brevemente algumas técnicas, conceitos e
   ferramentas, que auxiliam no desenvolvimento de software. De um modo geral, os
   conceitos genéricos de desenvolvimento de software paralelo são similares aos de
   software seqüencial. Iniciaremos a discussão através de uma breve apresentação
   da engenharia de software, que constitui de uma série de ferramentas, métodos e
   procedimentos para formalizar o desenvolvimento de software. Em seguida
   comentaremos um pouco sobre a avaliação e teste de software, apresentando o
   revolucionário conceito de programação orientada a objetos, e passando para
   interfaces gráficas com o usuário e programação visual. Finalmente terminaremos
   esta seção discutindo técnicas de análise de desempenho de programas paralelos
   e a engenharia da utilização.
   81
   CAPÍTULO 3
   3.9.1 – ENGENHARIA DE SOFTWARE
   As primeiras décadas da história da computação marcaram o domínio do
   hardware, quando este era considerado o maior desafio da Ciência da
   Computação, deixando o software em segundo plano. O conjunto de normas,
   organização, ferramentas e metodologias utilizadas no desenvolvimento de
   hardware foi denominado de Engenharia de Hardware, que na realidade tratava-se
   de mais uma especialização da Engenharia Elétrica. Através da Engenharia de
   Hardware, o custo e o tempo de desenvolvimento de um novo sistema podia ser
   objetivamente calculado e estimado.
   De um modo geral, não havia a comercialização e industrialização do
   software, como conseqüência, este era desenvolvido dentro das empresas, pelas
   mesmas pessoas que iriam utilizá-los e em caso de erros corrigi-los. Esse tipo de
   abordagem permitia que o desenvolvimento de software fosse realizado sem
   qualquer tipo de formalismo, métodos, normas e documentação. Dentro desse
   ambiente, o mundo do software estava completamente indisciplinado, acarretando
   na crise do software (final da década de 1970), responsável pela improdutividade,
   alto custo, insatisfação dos consumidores, longo período de desenvolvimento, baixa
   qualidade, difícil manutenção, etc. [Pressman, 1988]
   Na tentativa de ordenar a criação, implementação e manutenção de
   software, surgiu a Engenharia de Software, que compreende uma série de
   metodologias, critérios, conceitos, ferramentas, que possibilitaram a formalização
   do software.
   Segundo Pressman [Pressman, 1988], o software pode ser definido como:
   Instruções (programas de computadores) que quando executadas fazem com que o
   hardware proceda de acordo com a sua programação.
   Estrutura de dados que permitem aos programas manipular adequadamente
   informações.
PA A documentação que descreve a operação e a utilização dos programas.
   Dentro da filosofia da engenharia de software, os projetos são desenvolvidos
   em ciclos. Esta abordagem é denominada de Paradigma de Engenharia de
   Software [Pressman, 1988]. Cada projeto possui um paradigma apropriado, sendo
   escolhido de acordo com sua natureza e de sua aplicação. Embora existam
   82
   A COMPUTAÇÃO PARALELA - SOFTWARE
   diversos paradigmas diferentes, apresentamos na Figura 3.11 um modelo clássico
   de ciclo de vida de um software.
   Engenharia de
   Sistema
   Análise
   Projeto
   Código
   Testes
   Manutenção
   Fig. - 3.11 – Ciclo de vida clássico de um software.
   O projeto de software é dividido em três fases: definição, desenvolvimento e
   manutenção. Cada uma destas fases possuem diversas metodologias,
   procedimentos, análises e ferramentas. Segundo a Engenharia de Software tem
   demonstrado, a forte formalização dos processos de criação, produção e
   manutenção do software, faz com que o projeto de software apresente uma
   previsão de tempo, custo e qualidade previamente determinados, assim como nas
   demais áreas da engenharia.
   A engenharia de software tem também como objetivo o desenvolvimento de
   ferramentas de auxílio à modelagem e desenvolvimento de software. Dentre estas,
   devemos comentar o CASE (do inglês “Computer Aided Software Engineering”).
   Através de ferramentas CASE, algumas tarefas repetitivas de programação podem
   ser substituídas pela geração automática de código. Dentre as ferramentas CASE,
   destacam-se as voltadas ao desenvolvimento de software que utilizam base de
   dados e também as ferramentas de geração automática de interfaces para
   aplicações direcionadas para ambientes GUI [Bruno, 1995]. As ferramentas CASE
   voltadas para base de dados possibilitam a geração de código a partir da
   diagramação de metodologias de análise de dados (DFD) [Pressman, 1988].
   As ferramentas CASE voltadas à interfaces, embora possuam versões
   voltadas a ambientes CLI [Hayes, 1990] são especialmente úteis em ambientes GUI
   (veja Seção 9.4). Conforme é apresentado por [Bruno, 1995], as aplicações
   83
   CAPÍTULO 3
   voltadas para ambientes GUI por mais simples que sejam envolvem uma complexa
   programação de sua interface, uma vez que se preocupam muito mais com o
   usuário. A complexidade do tratamento da interface faz com que muitas linhas de
   código sejam necessárias para implementar uma simples aplicação GUI, tornando
   as ferramentas CASE vitais, uma vez que geram o código da camada de interface
   automaticamente, poupando o programador dessa tarefa maçante e muitas vezes
   repetitiva.
   Através de ferramentas CASE para GUI originou-se o conceito de
   programação visual, que é tratado na Seção 3.9.5.
   3.9.2 – AVALIAÇÃO E TESTES
   A avaliação e testes de um software é uma das etapas que mais tomam
PA tempo no projeto (cerca de 40% do tempo total [Pressman, 1988]). Em alguns
   casos extremos, como controle de vôo ou reatores nucleares, a fase de teste pode
   custar três a quatro vezes mais que todas as outras etapas juntas. Os principais
   objetivos para a realização dos testes nos projetos de software é a qualidade e o
   funcionamento correto do software
   Conforme podemos observar na Figura 3.11, a etapa de avaliação e testes
   de um software é uma das últimas a ser realizada num projeto de engenharia de
   software. Na fase de testes são localizados os erros cometidos nas fases anteriores
   do projeto. Uma vez localizados, deve-se voltar à fase onde estes ocorreram,
   alterá-los e repetir os testes novamente, fazendo com que a depuração desenvolva
   um ciclo.
   Existem duas alternativas para a realização da fase de testes: manual e
   automática. Enquanto na manual o software é analisado por usuários, a automática
   consiste de um outro software, capaz de efetuar a análise de forma automática.
   Devido à complexidade de implementação do software de análise, também
   conhecido como CASE de teste ou depuração, a grande maioria dos testes é
   realizado manualmente.
   Quando um erro é detectado indicando alguma falha de programação, pode
   ser facilmente localizado ou não através do código fonte. Quando os erros não são
   facilmente detectados a partir da análise do código, o programador utiliza algumas
   ferramentas de auxílio à programação, tais como o "debbuger" e o "trace",
   disponíveis na grande maioria dos ambientes de programação.
   84
   A COMPUTAÇÃO PARALELA - SOFTWARE
   Em computação paralela, o teste do software é uma tarefa ainda mais
   trabalhosa, uma vez que as situações de análise não estão mais dispostas de modo
   seqüencial. Cada código distribuído entre os processadores do sistema deve ser
   analisado em conjunto, e em algumas situações as falhas não são claramente
   detectadas independentemente. Atualmente, a maioria dos sistemas de
   computação paralela, especialmente os de computação distribuída, não possuem
   ferramentas específicas para a depuração de erros, utilizando versões como as dos
   sistemas seqüenciais, tornando a análise e teste de software paralelo bastante
   complexa.
   3.9.3 – PROGRAMAÇÃO ORIENTADA A OBJETOS
   A programação orientada a objetos ou OOP (abreviação do inglês “Object-
   Oriented Programming”), embora tenha sido iniciada com o Simula, despontou
   juntamente com os projetos do PARC (Palo Alto Research Center) da Xerox. O
   PARC percorreu toda a década de 70 pesquisando e obteve em meados da década
   de 80 um novo conceito de interface entre homem-máquina, a interface gráfica com
   o usuário, também denominada de GUI (abreviação do inglês “Graphical User
   Interface”). Embora intimamente ligada, ao conceito de GUI, a programação
   orientada a objeto não depende necessariamente desse conceito, uma vez que é
   um paradigma ligado ao modo de programação.
   O principio básico da OOP é abstrair o software e modelá-lo a partir do
   conceito de objetos, existente no mundo real [Cox, 1986] [Pressman, 1988]. A
   Figura 3.12 apresenta o paradigma OOP segundo o Smalltalk [Hurson et al., 1993].
   Vamos a seguir apresentar alguns conceitos básicos sobre OOP. Um objeto é,
   basicamente, um pacote de informações (dados) e as descrições de suas formas
   de manipulação (métodos). Uma das principais características dos objetos é a
   encapsulação, ou seja, os dados de um objeto são protegidos do mundo exterior,
PA sendo inacessíveis. O único meio de obter acesso a esses dados é através do
   envio de mensagens aos seus métodos, onde a mensagem é definida como uma
   especificação para um método do objeto. O método é uma entidade (como um
   procedimento) que descreve uma seqüência de ações a serem realizadas. Algumas
   mensagens possuem a característica de requerer um retorno, nesses casos, após a
   execução do método, a informação solicitada é retornada. Os objetos são definidos
   e agrupados através de classes [Bruno, 1995], as quais são constituídas por
   85
   CAPÍTULO 3
   declarações formais.
   Fig. - 3.12 - Concepção de Objeto.
   A OOP possui diversas características tais como: organização hierárquica,
   herança, polimorfismo, facilidade de agrupamento ordenado, abstração de dados,
   reutilização de código, encapsulação, entre outras.
   A OOP possibilita um grande auxilio à engenharia de software, através da
   abstração de dados, encapsulação e reutilização de código. Essas características
   tornam o paradigma OOP muito vantajoso para grandes projetos, facilitando a
   independência entre os programadores e a integração de trabalho no
   desenvolvimento do software e proporcionando também a reabilitação e reciclagem
   de software.
   Uma outra característica muito relevante da OOP, especialmente para o
   assunto deste capítulo, é sua abordagem paralela. Devido à arquitetura
   encapsulada e orientada às mensagens, o paradigma OOP é caracterizado por
   apresentar uma abordagem natural ao paralelismo. Se observarmos os modelos de
   arquitetura MIMD distribuídos (ver Seção 2.5.5) poderemos constatar que são muito
   semelhantes ao modelo OOP, especialmente no que se refere ao encapsulamento
   dos dados e a comunicação entre objetos por troca de mensagens.
   Outra característica do paradigma que beneficia a implementação de
   aplicações paralelas, é a facilidade e a versatilidade para modelar situações
   complexas, uma vez que as aplicações paralelas envolvem algoritmos complexos.
   Este fato deve ser bastante considerado, já que um dos maiores obstáculos para o
   86
   A COMPUTAÇÃO PARALELA - SOFTWARE
   desenvolvimento de programas paralelos está exatamente na sua complexidade e
   dificuldade de implementação.
   3.9.4 – INTERFACE GRÁFICA COM O USUÁRIO (GUI)
   Nesta seção vamos abordar a revolucionária interface gráfica com o usuário
   (GUI). Durante toda a década de 70 e início da década de 80 este novo conceito de
   interface entre homem-máquina foi pesquisado pelo PARC (Palo Alto Research
   Center) da Xerox. Atualmente utilizado em larga escala na maioria das plataformas
   dos computadores, a GUI tem a sua principal característica no conceito de
   utilização do dispositivo de exibição de forma virtual, possibilitando que o usuário
   interaja virtualmente com a máquina arrastando ícones, clicando botões e
   manipulando dispositivos de controle diretamente na tela.
   3.9.4.1 - DEFINIÇÃO DE GUI
   O primeiro dispositivo que forneceu uma interface interativa homem -
   máquina, largamente utilizado nos primórdios da computação (décadas de 50 e 60),
   foram as “teletypewriters” (TTYs), terminais baseados em caracteres, onde cada
   caracter digitado era impresso em papel. Com o aprimoramento tecnológico,
   tornaram-se disponíveis os terminais de vídeo (baseados em caracteres). Pela
PA incontestável superioridade de interação sobre os TTYs, os terminais de vídeo
   rapidamente tornaram-se uma norma na computação [Hayes, 1990]. Nestes
   sistemas baseados em caracteres, a interface com o usuário adotada era a
   interface de linhas de comando (CLI do inglês “command-line interface”), que vem
   sendo utilizada até os dias de hoje.
   Os sistemas operacionais com interface CLI, como o DOS ou o UNIX, vêm
   sendo criticados ao longo do tempo pela complexidade de suas interfaces com o
   usuário. Desenvolvido para ser utilizado em minicomputadores, o UNIX foi criado
   como um conjunto de aplicações compartilháveis, que dispunham de uma interface
   orientada a linha (CLI). Esta interface foi revolucionária em seu tempo, por sua
   simplicidade e poder. O UNIX introduziu o conceito de “shel ”, um interpretador de
   comandos, que lê e executa as linhas de comando provenientes do teclado [Peddie,
   1992]. O DOS foi implementado mediante este conceito muitos anos depois.
   Os pesquisadores do Xerox PARC, contudo, estavam trabalhando com uma
   idéia diferente. Pesquisavam uma interface que substituísse as linhas de comando
   87
   CAPÍTULO 3
   e as telas de caracteres, por telas gráficas com grandes mapas de bits, através das
   quais os comandos seriam exibidos graficamente (na forma icônica). Assim a
   interface com o computador seria de forma “visual” [Peddie, 1992] [Petzold & Yao,
   1996].
   Para isso, os pesquisadores do PARC precisaram revolucionar o conceito
   de monitor de vídeo. Antigamente, o monitor de vídeo, era utilizado somente para
   reproduzir o texto que o usuário digitava no teclado. Com a nova concepção o
   monitor, através de um apontador (no caso o “mouse”, também criado na Xerox
   PARC), transformava-se numa verdadeira fonte de entrada de dados [Petzold &
   Yao, 1996]. A tela do monitor de vídeo passa agora a exibir objetos gráficos na
   forma de ícones e janelas com dispositivos que são verdadeiros comandos
   “virtuais”, como botões, barras de rolagem, menus, etc. Esses são manipulados
   virtualmente pelo usuário, através do apontador e também do teclado. A Figura 3.13
   apresenta o aspecto visual de uma interface gráfica com o usuário (GUI).
   Os gráficos fazem uma utilização melhor da tela, transmitindo informações
   de maneira visual mais rica. E a combinação da exibição rica com a manipulação
   virtual dos gráficos fez das GUIs uma nova etapa evolutiva da interface homem-
   máquina. Deste modo com evolução de CLIs para GUIs, trabalhamos com um
   computador menos abstrato e mais “real” [Peddie, 1992] [Petzold & Yao, 1996].
   Durante décadas, pesquisas tem sido realizadas com o intuito de
   desenvolver arquiteturas que aproveitem melhor o “software”. Nestas pesquisas
   apareceram questões em relação a prioridades; as interfaces devem ser projetadas
   a fim de que os usuários experientes tirem, ao máximo, o proveito das máquinas,
   ou a fim de otimizar a curva de aprendizado dos iniciantes ? [Hayes, 1990].
   As interfaces gráficas com o usuário demostraram ser uma resposta efetiva
   para as questões de prioridade, na interface homem - máquina [Hayes, 1990]. Com
   esta nova tecnologia, a utilização da máquina satisfaz todos os níveis de usuários:
   [Peddie, 1992]
   usuário iniciante, através da simplicidade de utilização, interação e conceitos
   intuitivos, imediatamente torna-se hábil para utilizar alguns recursos da máquina.
   O treinamento torna-se então rápido e eficaz, não necessitando de leitura de
   manuais extensos, e o aprendiz rapidamente está hábil a ser “mestre”.
   usuário casual, que executa várias diferentes aplicações diariamente, encontra a
PA consistência do padrão entre as diferentes aplicações.
   E o usuário experiente (“power user”), também é beneficiado por executar suas
   88
   A COMPUTAÇÃO PARALELA - SOFTWARE
   tarefas com maior interação. Ele se beneficia do maior número de recursos
   providos com o novo sistema (ex: multitarefa).
   Fig. - 3.13 - Aspecto visual de uma GUI.
   3.9.4.3- MODELO DE CAMADAS
   Atualmente existe uma grande variedade de GUIs, diferindo em várias
   características. Além das diferenças em relação à interface, podem variar também
   quanto ao seu nível de integração com o sistema operacional. Certas GUIs são
   fortemente agregadas ao sistema operacional (Macintosh), enquanto que outras
   são visivelmente colocadas sobre o sistema operacional (Windows, e das GUIs
   para o UNIX).
   A definição do que faz parte ou não de uma GUI varia de um fabricante para
   outro. Apresentaremos um modelo genérico das camadas de uma GUI que tem
   como objetivo mostrar seus componentes (Figura 3.14). O modelo apresentado
   nesta figura ilustra uma GUI que é colocada sobre o sistema operacional, entretanto
   existem casos em que o sistema operacional é parte integrante da GUI [Peddie,
   1992].
   O modelo de GUI da Figura 3.14 é composto por cinco camadas, as quais
   serão comentadas a seguir:
   89
   CAPÍTULO 3
   Modelo de objetos: O caminho pelo qual as aplicações reagem entre si
   freqüentemente, envolve o uso de um modelo de objetos. O modelo “Object Link &
   Embedding (OLE)” é um exemplo desta camada. Existem algumas GUI que não
   possuem um modelo de objetos.
   API: A Abreviação é oriunda do inglês “Application Program Interface”. Esta
   camada é um conjunto de funções que são utilizadas pelos programas para se
   comunicarem com a GUI. O programador precisa especificar quais funções (ex:
   janelas, menus, barras de rolagem, ícones e etc.) são utilizadas e quando.
   GUI: Como mencionado outrora, o que faz parte ou não de uma GUI varia
   de fabricante para fabricante. A camada GUI é onde as ações e elementos da tela
   residem.
   Sistema de janelas: Esta camada é tão difícil de definir quanto a camada
   GUI. Por exemplo, o X-Window é apenas um sistema de janelas, ao passo que o
   Windows é um sistema de janelas e uma GUI construídos juntamente.
   Modelo de imagem: Enquanto o sistema X-Window não tem um modelo de
   imagem, algumas GUI suportam mais de um modelo de imagem. É o caso do
   NeWS da Sun Microsystem, que suporta um modelo similar ao modelo de imagem
   Display PostScript (DPS); porém, diferente do DPS, ele pode também trabalhar com
   um modelamento complexo como o PHIGS ou GKS para controle de programas de
   CAD (“Computer Aided Design”).
   Fig. - 3.14 - Modelo em Camadas de uma GUI.
   É bastante difícil obter um modelo genérico de representação para todas as
   GUIs, que diferem muito. Na Figura 3.14 foi apresentado um modelo que tenta ser o
   mais genérico possível.
   Na Figura 3.15 são apresentadas algumas GUIs diferentes, possibilitando a
   comparação de uma para outra. Não obstante, nem todas as GUIs possuem as
PA 90
   A COMPUTAÇÃO PARALELA - SOFTWARE
   camadas descritas no modelo genérico. Existem algumas que apresentam
   camadas externas, como o caso do NeXTstep, que não é fundamentado numa
   plataforma orientada ao objeto. Neste caso, o modelo de objeto, quando usado
   nesse sistema, é externo.
   Fig. - 3.15 - Diagrama comparativo de camadas de GUI.
   3.9.4.4- FUNDAMENTOS DE PROGRAMAÇÃO EM GUI
   Com o conceito GUI, várias novas tecnologias de programação foram
   91
   CAPÍTULO 3
   adotadas ou criadas para dar consistência à nova interface homem-máquina.
   Ao contrário da filosofia CLI, a plataforma GUI é voltada para o usuário, e
   não para o programador. Com isto, a tarefa de programar (utilizando um compilador
   tradicional) para um ambiente GUI, não é tão simples como num ambiente CLI, cuja
   filosofia facilita ao programador. Nos primórdios do ambiente GUI, a programação
   de aplicativos era uma tarefa extremamente difícil e trabalhosa, pois embora o
   sistema gerenciasse as janelas e facilitasse sua criação, uma boa parte do trabalho
   era destinado ao programador. Atualmente, essa tarefa é realizada
   automaticamente através de CASE ou da programação visual, liberando o tempo e
   esforço do programador para outras atividades importantes [Bruno,1995].
   3.9.5 – PROGRAMAÇÃO VISUAL
   A idéia de programação visual surgiu com o famoso projeto Vivarium, no
   qual crianças utilizavam o Smal talk para desenvolver um ambiente e então o
   povoavam com animais virtuais. Se crianças podem gerar um “mundo”
   simplesmente movimentando objetos, não poderíamos utilizar a mesma abordagem
   para desenvolver aplicativos ? [Bonner, 1995].
   A idéia básica da programação visual seria desenvolver uma ferramenta na
   qual fosse possível gerar um aplicativo sem escrever nenhuma linha de código.
   Porém, o que ocorre é que na programação visual os elementos da interface com o
   usuário, suas características e controle são gerados visualmente (através do
   apontador) e a estes elementos é ligado o código que implementa a ação
   (“software”) que provoca o elemento. Este código não é implementado visualmente,
   ficando como tarefa das linguagens convencionais (ou não) de programação.
   Atualmente, parece predominar a tendência de ferramentas de programação
   visual. Fortemente ligada aos conceitos GUI e OOP, a larga difusão dessas duas
   tendências tem arrastado consigo a programação visual, a qual tem influenciado
   muitos ambientes de linguagens de programação convencionais.
   O conceito de programação visual tem base na inversão da ênfase da
   programação. Nas interfaces baseadas em caracteres (CLI), e nos compiladores
   tradicionais de linguagens procedimentais, a ênfase da programação residia no
   projeto das estruturas de dados e na tradução lógica de uma atividade para o
   código do programa. O projeto da interface com o usuário ficava normalmente em
   segundo plano. As ferramentas de programação visual invertem esta equação: o
   92
   A COMPUTAÇÃO PARALELA - SOFTWARE
   processo de programação começa com a interface com o usuário, e permanece
   centralizado nela [Bonner, 1995].
   Com isso surge uma nova filosofia de codificação, onde o código do
   programa fica ligado diretamente aos objetos da interface com o usuário. Isto só é
PA possível em ambiente onde o compilador e o CASE estejam integrados.
   Dentre as ferramentas de programação visual para ambiente Windows
   disponíveis atualmente, podemos citar como exemplos de compiladores que
   possuem ferramentas de programação visual o Borland Delphi e o C++ Builder
   assim como o Microsoft Visual Basic. Estes compiladores possuem um parque
   estabelecido de usuários, tornando um forte padrão para a programação em
   ambiente Windows. As suas principais vantagens estão na simplicidade de
   elaboração de protótipos e construção automática de interfaces, além da utilização
   de componentes visuais, que tornam facilmente acessíveis, através de objetos
   (OOP), poderosos recursos de programação.
   3.9.6 – ANÁLISE ESTATÍSTICA, GARGALOS E
   DESEMPENHO DE PROGRAMAS PARALELOS
   Conforme comentamos anteriormente, a principal motivação para a
   exploração de paralelismo nas máquinas, seja via hardware ou software, é o
   aumento da performance. A grande questão é avaliar a performance de um
   software. Mesmo nos softwares seqüenciais, avaliação de performance é muito
   complexa, chegando a ser subjetiva, uma vez que interação entre as camadas
   inferiores (ver Figura 3.1) exerce papel fundamental no desempenho em questão.
   Normalmente, a avaliação de performance é feita através da comparação de
   desempenho entre as aplicações. Esse método é conhecido como benchmark
   [benchmark].
   No entanto a confiabilidade nas medidas de benchmark são questionáveis,
   uma vez que a comparação entre os algoritmos e sua performance pode dar
   resultados completamente diversos dependendo da arquitetura na qual a aplicação
   está sendo executada. Como exemplo, se compararmos dois algoritmos que
   utilizam estratégias adversas para solucionarem o mesmo tipo de problema, e
   utilizarmos duas plataformas diferentes, é bastante freqüente ocorrer que um
   algoritmo possua uma performance superior a seu concorrente em uma plataforma,
   e esse resultado se inverta completamente na outra plataforma. Isso ocorre devido
   93
   CAPÍTULO 3
   à interação entre as camadas inferiores à aplicação.
   A complexidade da avaliação de desempenho de um software aumenta
   muito quando tratamos de computação paralela, especialmente no caso dos
   sistemas baseados em computação distribuída, que ainda podem ser compostos
   por plataforma heterogêneas. Em computação paralela, além de avaliar o
   desempenho como um todo, é essencial que seja analisado o desempenho de cada
   uma das etapas de execução dos programas, da comunicação entre processos,
   acesso a disco, etc. Somente através da análise de performance e tempo
   despendido em cada uma das etapas é que podemos localizar os gargalos, ou seja
   regiões responsáveis pelo comprometimento da performance.
   (A)
   (B)
   (C)
   Fig. - 3.16 – Comparação entre a vazão de fluxo em um sistema de
   encanamento e o desempenho do conjunto hardware/software.
   O conceito de gargalo em software é similar ao gargalo em fluxo de fluídos.
   Podemos comparar o fluxo de execução do software à vazão de fluídos em um
   sistema de encanamento. A Figura 3.16 apresenta um exemplo que ilustra a
   comparação entre a execução de software paralelo e vazão em sistema de
PA encanamento. Devemos observar que o término de execução ou vazão ocorre
   quando não há mais fluido em nenhum ducto. Na representação devemos observar
   que cada ducto corresponde a um conjunto hardware/software e o fluído ao fluxo de
   processamento. Devemos observar ainda que o diâmetro do ducto corresponde ao
   desempenho computacional de cada conjunto hardware/software, com isso, quanto
   maior o diâmetro do ducto, maior será a sua vazão ou desempenho. Porém de,
   modo similar ao que ocorre nos fluídos, existem regiões, onde o estreitamento do
   ducto compromete sua vazão. Essas regiões são denominadas de gargalos. O
   gargalo limita a vazão do ducto como um todo, não importando seu diâmetro
   94
   A COMPUTAÇÃO PARALELA - SOFTWARE
   anterior, do mesmo modo, no conjunto hardware/software, não importa o poder
   computacional anterior ao gargalo, dependendo de quão estreito seja o gargalo,
   todo o desempenho do conjunto será comprometido.
   Desse modo, observamos que embora o ducto (B) tenha um poder de vazão
   maior que os ductos (A) e (C), devido ao gargalo que possui, sua vazão é muito
   menor que a vazão de (A) ou de (C). Em termos do conjunto hardware/software, o
   ducto (B) poderia ser comparado a um sistema com um processador mais
   poderoso, porém em algum ponto de seu programa existe um intensivo acesso a
   um dispositivo de hardware lento (acesso a disco ou rede) ou ainda algum tipo de
   processamento dispendioso. Podemos observar também, que simultaneamente ao
   momento em que ocorre o gargalo no ducto(B), o ducto (C) aumenta seu diâmetro.
   Isso seria equivalente a uma sub-utilização de seus recursos computacionais num
   dado momento. A partir da análise de gargalo, o programador pode rever a
   estratégia de paralelização de modo a balancear a carga de processamento da
   etapa crítica (gargalo) de (B) com a fase de sub-utilização de (C), eliminando o
   gargalo e consequentemente, aumentando o desempenho do sistema como um
   todo.
   Como vimos, a localização e a eliminação dos gargalos é vital para o
   desempenho do software (o mesmo se aplica ao hardware). Embora na
   computação seqüencial a análise e localização de gargalos sejam importantes, elas
   são cruciais na computação paralela, que deve sua existência principalmente à
   velocidade. Sem a localização e a eliminação de estreitos gargalos, um sistema
   paralelo com diversos processadores pode possuir a mesma velocidade, ou ainda
   pior, ser mais lento que seu equivalente seqüencial, tornando-se completamente
   ineficiente e sem sentido.
   Basicamente, a técnica utilizada para localizar os gargalos de um software
   consiste no mapeamento de todas as suas etapas, registrando a performance
   individual de cada uma. Embora existam algumas ferramentas para auxiliar a
   medida de cada uma das etapas (Engenharia de Software), na maioria dos casos
   essa tarefa é realizada pelo programador, que deve fazer uma análise estatística do
   tempo de execução de cada uma delas. No caso do CVMP, implementamos
   ferramentas específicas para a localização de gargalos e análise de desempenho
   de software, que serão comentadas no Capítulo 6.
   A partir do mapa de desempenho, pode-se localizar com precisão os
   gargalos dos sistemas paralelos e deste modo auxiliar sua eliminação. Uma outra
   95
   CAPÍTULO 3
   estratégia seria analisar diferentes etapas de algoritmos lineares, e após localizar
   as etapas mais custosas, traçar uma estratégia de paralelização mais eficiente
PA antes mesmo da implementação da versão paralela. Como exemplo dessa
   abordagem, a Figura 3.17 mostra um diagrama que representa uma análise de
   desempenho em uma aplicação seqüencial e posteriormente sua versão paralela.
   Algoritmo Seqüencial
   Proc. 1
   Algoritmo Paralelo
   Proc. 1
   Leitura de dados
   Proc. 2
   Processamento parte 1
   Processamento parte 2
   Proc. 3
   Gravação de dados
   Proc. 4
   Transmissão de dados
   Tempo de duração da execução seqüencial versus paralela
   Seqüencial
   Paralela
   Fig. - 3.17 – Mapa de desempenho das diferentes etapas de um programa e a
   eliminação de um gargalo através de sua paralelização.
   Como podemos observar, neste exemplo a aplicação foi dividida em quatro
   etapas: leitura de dados, processamento parte 1, processamento parte 2 e escrita
   de dados. Segundo constatamos ao observar o diagrama, a etapa processamento
   parte 1 é onde se localiza o gargalo do programa e supondo que essa etapa não
   possua uma grande dependência de dados e seja simples de paralelizar, podemos
   dividi-la em quatro partes, através da paralelização. Embora essa divisão
   acrescente mais etapas, responsáveis pela transferência de dados entre os
   processadores ou máquinas, o principal gargalo do sistema é eliminado e
   96
   A COMPUTAÇÃO PARALELA - SOFTWARE
   consequentemente ocorre um ganho no desempenho. No caso do exemplo, para
   quatro processadores, o tempo de execução do programa paralelo é da ordem de
   2,5 vezes menor.
   Devemos observar, entretanto, que quando concentramos esforços ou
   recursos computacionais apenas em um único ponto do problema, ocorre que o
   gargalo é transferido para uma outra etapa. Na Ciência da Computação esse
   paradoxo é conhecido como lei de Amdahl [Hockney & Jesshope, 1988]. Tomando
   o nosso exemplo, se aumentarmos o recurso computacional, ou seja, se
   aumentarmos o número de processadores na versão paralela, a um determinado
   momento, o gargalo será deslocado para outras etapas do programa, e a partir
   desse momento não faria mais sentido aumentar os recursos computacionais para
   essa fase, havendo então necessidade de eliminar os outros gargalos para
   aumentar o desempenho de forma efetiva.
   Ainda quanto à análise, é possível medir objetivamente a performance e
   desempenho de um software paralelo em relação a seu equivalente seqüencial.
   Essa medida, denominada de “speed-up” ( Sp), é dada pela razão entre o tempo de
   execução do programa seqüencial ( ts) pelo tempo de execução do programa
   paralelo ( tp) (Equação 3.1). Ainda em termos de desempenho, é importante
   também saber a eficiência da paralelização, ou seja, se foi realizado um
   balanceamento de cargas efetivo, e consequentemente sem gargalos. A eficiência
PA é dada pela razão entre o tempo em que o programa utiliza os recursos
   computacionais ( tu – tempo de processador em uso) e o tempo total de execução
   ( tt) (Equação 3.2). Embora existam outras formas de mensurar o desempenho de
   software paralelo, o “speed-up” e a eficiência são as mais genéricas [Costa &
   Slaets, 1991] [Faber et al., 1987].
   ts
   Sp( N ) =
   (3.1)
   tp( N )
   tu
   E =
   (3.2)
   tt
   97
   CAPÍTULO 3
   3.9.7 – ENGENHARIA DA UTILIZAÇÃO
   O projeto PARC (Palo Alto Research Center) da Xerox, influenciou a ciência
   da computação em diversos aspectos diferentes, dentre os quais podemos citar: a
   interface gráfica com o usuário (GUI), a descoberta do apontador (mouse), a
   virtualidade do monitor (através de eventos e botões GUI), a programação visual, a
   programação orientada a objetos, a estação de trabalho, etc. Observando a
   computação atual, e a importância desses conceitos podemos concluir que grande
   parte da história da computação moderna foi escrita no PARC [Bruno, 1995]. Dentre
   as novas idéias apresentadas pelo PARC, uma das mais importantes foi a
   consagração do computador e do software como uma ferramenta de trabalho.
   Embora esse conceito não tenha sido diretamente ditado pelo PARC, foram suas
   novas idéias que impulsionaram o surgimento dessa tendência.
   A tendência de assumir o computador como uma ferramenta de trabalho
   surgiu através da revolução da micro-informática. Com a queda dos computadores
   de grande porte ( mainframes) e o aparecimento dos microcomputadores, esses
   começaram a proliferar e a informática iniciou sua jornada de influência em todas as
   áreas de nossa sociedade. A partir desse momento, a concepção da utilização dos
   computadores começou a mudar. Inicialmente, os computadores existiam em
   número reduzido, eram caríssimos e as poucas corporações que desfrutavam
   dessas máquinas possuíam uma equipe de profissionais altamente treinados para
   operá-los. Neste contexto, não havia a necessidade de se preocupar com a
   dificuldade de manipular ou programar os computadores, uma vez que estes eram
   operados e programados apenas por profissionais altamente especializados e
   treinados. A complexidade dessas tarefas não era um problema, era apenas uma
   característica do perfil das profissões ligadas à computação, uma vez que tais
   profissionais eram os únicos usuários dos computadores.
   Com o surgimento da micro-informática e com a proliferação dos
   microcomputadores, o perfil dos usuários mudou drasticamente. Ao invés de
   especialistas altamente treinados, os usuários passaram a ser pessoas comuns,
   dispostas a utilizar os computadores para auxiliar de alguma forma suas tarefas.
   Dentro desse novo contexto não há lugar para a complexidade e a sobrevivência de
   um produto (computador ou software) passou a depender também de sua
   simplicidade e objetividade para o usuário.
   É claro que essa transição não foi imediata. Nenhuma evolução ou
   98
PA A COMPUTAÇÃO PARALELA - SOFTWARE
   revolução envolvendo o caráter humano ocorre do dia para noite. O período de
   transição entre o complexo e o simples na história da informática vem ocorrendo
   desde o final da década de 70, e ainda continuamos vivenciando esse processo.
   Através da simplificação da manipulação dos computadores surgiu o conceito de
   ferramenta de trabalho, onde o computador e a informática são vistos como uma
   ferramenta para auxiliar o trabalho humano.
   Esse novo conceito não é apenas uma tendência, mas sim um novo
   postulado na Ciência da Computação. Atualmente contamos com novas áreas tais
   como Interação Homem – Máquina e Engenharia da Utilização que basicamente
   estão preocupadas com essas questões.
   Comentamos anteriormente, as novas concepções apresentadas pelo PARC
   (Palo Alto Research Center) da Xerox foram essenciais para formar as bases da
   concepção de ferramenta de trabalho. O conceito de interface gráfica com o usuário
   (GUI) fez com que o método de utilização do computador se tornasse simples ao
   usuário inexperiente e ágil ao usuário experto, como podemos constatar pela
   análise feita por Hayes [Hayes, 1990].
   No dia-a-dia, podemos observar que a questão da utilização é importante
   não apenas para a informática mas também para todas as demais áreas. Se
   tivermos que escolher entre dois abridores de latas automáticos, que executam a
   mesma função com a mesma qualidade e eficiência, sendo que um deles possui
   apenas um botão, bastando pressioná-lo para abrir a lata e o outro apresenta uma
   interface com o usuário bem mais complicada, com dezenas de ajustes, botões e
   alavancas, qual dos dois abridores seria a ferramenta mais útil ?
   Como conseqüência da tendência de simplificar a manipulação dos
   computadores, descobrimos que não apenas as aplicações voltadas ao usuário
   final apresentam-se com mais vantagens quando analisadas e pensadas sob o
   ponto de vista da engenharia da utilização, mas também as ferramentas, ambientes
   e linguagens de desenvolvimento. A razão para isso é bastante simples, quando
   utilizamos ferramentas complicadas, normalmente temos que perder tempo em
   treinamentos desnecessários ou ainda executarmos um número demasiado de
   procedimentos para realizar apenas uma tarefa. Ao passo que utilizando
   ferramentas simples, a situação é completamente diferente, poucos procedimentos
   são necessários para realizar as tarefas assim como o tempo desperdiçado com
   treinamentos é menor.
   Alguns conceitos foram essenciais para o desenvolvimento de ferramentas,
   99
   CAPÍTULO 3
   ambientes e linguagens de desenvolvimento de software mais adequados sob o
   ponto de vista da engenharia de utilização [Preece et al., 1994]. Através da
   programação orientada a objetos, interface gráfica com o usuário e programação
   visual (PARC), assim como de conceitos extraídos da engenharia de software, tais
   como ferramentas CASE e reutilização de código, temos hoje uma série de
   linguagens visuais, sistemas operacionais com GUI e ferramentas de
   desenvolvimento, que obedecem às regras da engenharia da utilização e são
   simples e eficazes para os programadores.
   A engenharia da utilização é uma área da Ciência da Computação
   responsável pelo estudo da maneira mais adequada de se utilizar e desenvolver
   interfaces entre o homem e a máquina. Através de análise estatística sobre o
   comportamento humano ao utilizar um determinado software, é possível encontrar o
PA modo mais adequado para que o software em questão torne-se uma ferramenta
   simples, intuitiva e eficaz [Preece et al., 1994].
   À medida que aumenta a sofisticação das aplicações, dos programas e dos
   sistemas fica cada vez mais óbvio a necessidade de ferramentas de
   desenvolvimento que utilizem os conceitos de engenharia da utilização e se tornem
   mais simples, intuitivas e eficazes. Isso fica claro especialmente para o
   desenvolvimento de aplicativos em GUI. O autor apresentou em sua dissertação de
   mestrado [Bruno, 1995] um exemplo entre um ambiente visual e um compilador
   tradicional. Observando o código fonte e a diferença entre procedimentos, podemos
   constatar a importância de utilizar uma ferramenta adequada, que simplifica o
   trabalho, sem perder a eficiência e qualidade. Enquanto no compilador tradicional o
   programador deveria escrever o código para todo o sistema de interface, ao invés
   de concentrar seu esforço na implementação do algoritmo principal, através do
   ambiente visual, o programador simplesmente desenha a interface, e através de
   ferramenta CASE é gerado o código, economizando assim seu tempo. É muito mais
   vantajoso o programador concentrar o tempo de programação em seu algoritmo
   principal do que programando a interface.
   O exemplo do ambiente de programação visual é apenas uma
   demonstração do emprego da filosofia da engenharia da utilização sob o aspecto
   macro (sistema como todo), no entanto a engenharia da utilização preocupa-se
   também com os detalhes, ou seja, interfaces, gráficos, ícones e nomes de funções
   e modo de utilização de bibliotecas de funções, visando tornar as ferramentas mais
   intuitivas e fáceis de utilizar.
   100
   A COMPUTAÇÃO PARALELA - SOFTWARE
   Pelo que observamos ao longo de nossa pesquisa, normalmente as
   ferramentas voltadas para a computação paralela não se preocupam com as
   questões da engenharia de utilização, sendo na maioria dos casos complexas,
   exigindo treinamento amplo e geralmente necessitando ser manipuladas por
   especialistas da área. A história nos mostra a importância da engenharia de
   utilização e do mesmo modo a importância de ferramentas simples e eficientes.
   Não estamos questionando a eficiência das ferramentas de desenvolvimento
   paralelo, mas sim sua simplicidade e sua preocupação com a utilização (ser
   amigável com o usuário). Temos observado que existe uma latência na computação
   paralela para a adoção dos princípios da engenharia da utilização. Conforme
   comentamos anteriormente, um dos grandes problemas da computação paralela é
   o desenvolvimento e manutenção de software. Existem muitos fatores responsáveis
   pela complexidade desses itens, porém acreditamos que um deles é a falta da
   adoção dos princípios da engenharia da utilização e consequentemente com a falta
   de preocupação com o usuário, que embora normalmente seja um especialista da
   área, poderia ser favorecido com tais conceitos.
   Visando esses fatores, um dos principais objetivos desta tese é o
   desenvolvimento de uma ferramenta intuitiva e simples de utilizar, voltada para a
   computação paralela, a qual, através de sua simplicidade, pode ser utilizada
   mesmo por programadores com o mínimo de conhecimento em computação
   paralela. Portanto, uma das principais bases do pacote CVMP que será
   apresentado no Capítulo 6 é a sua abordagem sob o ponto de vista da engenharia
   de utilização. De acordo com a evolução natural da computação é vital a existência
   de uma ferramenta para desenvolvimento de aplicações paralelas que obedeça aos
   requisitos da engenharia da utilização, sendo desse modo intuitiva, fácil de usar,
PA simples e eficiente.
   101
   CAPÍTULO 3
   102
   CAPÍTULO
   4
   OS CAMINHOS PARALELOS
   DA VISÃO
   Paralelism is therefore of profund significance for understanding the workings of the
   cerebral cortex, and increases by several orders of magnitude the enormity of the
   task needed to understand the workings of the brain.
   Semir Zeki
   103
   CAPÍTULO 4
   104
   OS CAMINHOS PARALELOS DA VISÃO
   CAPÍTULO 4 – OS CAMINHOS
   PARALELOS DA VISÃO
   4.1 – INTRODUÇÃO
   Neste capítulo estaremos abordando a visão biológica, o mais eficiente
   sistema de aquisição de informação criado pela natureza, com enfoque em seu
   paralelismo. Iniciaremos nossa discussão abordando a evolução em função da
   informação e do paralelismo, correlacionando esses tópicos. A seguir,
   discorreremos um pouco sobre as técnicas de estudo de visão e apresentaremos
   uma breve introdução à neurociência e finalmente discutiremos o sistema de visão
   natural dos primatas, apresentando o percurso da informação visual dentro do
   maquinário neural enfocando o paralelismo.
   4.2 – INFORMAÇÃO, EVOLUÇÃO, VISÃO
   Quando lemos um livro, estamos alimentando nossa memória com
   informações e, deste modo, aprendendo. Normalmente, atribuímos esse
   aprendizado à nossa inteligência e nos esquecemos da importância da aquisição de
   informações nesse processo. Para salientá-la, podemos fazer as seguintes
   perguntas:
   Existe inteligência sem a informação ?
   Um indivíduo que não possui nenhum sentido, ou seja, cujo cérebro não
   possui conexão alguma com o meio exterior possui inteligência ?
   Se refletirmos um pouco sobre essas questões, logo podemos chegar à
   conclusão de que tanto a razão quanto a inteligência não existem sem a
   informação, e ainda mais, podem ser definidas simplesmente como a interpretação,
   aprendizado e compreensão da informação. A palavra inteligência tem sua origem
   do latim intelligentia, e sua definição, segundo o tradicional dicionário Aurélio da
   língua portuguesa, é a faculdade de aprender, apreender ou compreender;
   105
   CAPÍTULO 4
   percepção, capacidade de compreender e adaptar-se facilmente e ainda maneira
   de interpretar ou entender. Devemos observar que não podemos aprender,
   compreender ou perceber sem a informação, e, deste modo, podemos concluir que
   não existe inteligência sem informação.
   A importância da informação é tamanha que, durante bilhões de anos, a
   natureza vem aprimorando os sentidos dos seres vivos, para que possam de
PA maneira mais eficiente se adaptar ao meio e, deste modo, sobreviver. Em algum
   ponto da história da vida neste planeta, começou a competição entre as espécies, e
   a informação passou a desempenhar um papel importante, senão vital, para a
   sobrevivência. Vamos imaginar as primeiras espécies deste planeta a procura de
   alimento, ou seja, garantindo sua sobrevivência. No início, essas criaturas primitivas
   não possuíam sistemas sofisticados de aquisição de informação (sentidos),
   portanto seus métodos de procura por alimentos eram bastante ineficientes. Muitas
   vezes essas criaturas estavam próximas ao alimento e, devido à falta de
   informação, não localizavam-no e deste modo desperdiçavam as oportunidades.
   Vamos supor que algumas espécies, através da evolução [Darwin, 1859],
   tivessem desenvolvido algum tipo de sistema de aquisição de informação, através
   do qual pudessem encontrar alimento de maneira mais eficaz que as demais. No
   primeiro momento em que houvesse escassez de alimento no "habitat" no qual
   concorriam, as espécies que possuíssem o sistema de aquisição mais eficiente,
   certamente sobreviveriam, ao passo que as outras sucumbiriam.
   A informação passa a ser ainda mais vital quando, além da competição por
   alimento, estão envolvidas também as atividades predatórias. A vitória da luta entre
   presa e predador é dada, praticamente, pela informação. Para o predador, é
   fundamental um sistema de aquisição de informação que localize a presa, enquanto
   que para a presa é vital a informação sobre o predador. A natureza desenvolveu
   dispositivos tanto para a presa quanto para o predador com o intuito de obter
   informações (sentidos) ou ocultá-las (camuflagem).
   Neste ciclo de adaptação, luta e sobrevivência, basicamente girando em
   torno da informação, a natureza desenvolveu, ao longo de bilhões de anos de
   evolução, um sistema poderoso para obter informação: a visão.
   Dentre todos os sentidos que a natureza desenvolveu, a visão consegue
   absorver a maior quantidade de informação. A visão pode ser definida como a
   capacidade fisiológica de ver e perceber o mundo. Através de órgãos
   especializados, os olhos, as ondas eletromagnéticas são captadas e direcionadas
   106
   OS CAMINHOS PARALELOS DA VISÃO
   para sensores capazes de senti-las, ou seja, converter a informação proveniente
   em sinais neurológicos. Além disso, a visão também consiste no processamento e
   interpretação desses sinais, e foram exatamente nesses processos que a natureza
   encontrou seus maiores desafios e, atualmente, nossa ciência também: como
   funciona a visão ?
   4.3 – EVOLUÇÃO, PARALELISMO E VISÃO
   Nesta seção vamos discorrer sobre a evolução, o paralelismo e a visão.
   Embora essa combinação possa inicialmente parecer muito estranha e sem razão,
   veremos que seu sentido surge a partir dos paradoxos da evolução.
   De acordo com a teoria da evolução de Darwin, a vida na terra começou a
   partir de uma forma de vida primitiva. Não podemos provar com certeza como era a
   sua consistência e composição exata, porém teoricamente supomos que essa
   forma primordial de vida era constituída por uma única célula, ou seja estamos
   falando de um ser unicelular. Não sabemos por que, nem qual é o objetivo último da
   evolução, mas é claro o seu anseio por formas de vida mais adaptadas e muitas
   vezes, em conseqüência disso, complexas.
   Na busca da adaptação, e consequentemente da complexidade, em algum
   momento da evolução surgiu um indivíduo cujo organismo era formado por mais de
   uma célula, surgiram assim os indivíduos pluricelulares. Podemos observar aqui a
PA primeira escolha da natureza pelo paralelismo, se nesse caso considerarmos a
   célula como uma unidade de processamento biológico. Mas por que teria a
   evolução optado em criar seres vivos compostos por diferentes unidades celulares?
   Por que a evolução não optou por desenvolver os seres unicelulares e deixá-los
   cada vez mais complexos e adaptados, porém permanecendo unicelulares?
   Pensando nessas respostas, verificamos que a evolução optou realmente
   pelo paralelismo, e o quanto ela favoreceu os indivíduos unicelulares. Se
   observarmos os seres mais evoluídos, podemos constatar que todos são
   pluricelulares. Mas poderíamos conjecturar que o fato dos seres terem mais de uma
   célula não significa nada em termos de paralelismo, ou ainda que correlação teria o
   paralelismo com isso. Se pensarmos em termos de microorganismos, o conceito de
   paralelismo não é tão óbvio, mas e se pensarmos num mamífero ?
   No caso de um mamífero qualquer, cada uma dos bilhões de células possui
   o mesmo programa genético e funções independentes, sem falar ainda nos
   107
   CAPÍTULO 4
   processos fisiológicos tais como respiração, reprodução, excreção, etc. Se
   pensarmos agora em termos de órgãos, o paralelismo fica ainda mais óbvio.
   Qualquer mamífero possui uma série de órgãos, responsáveis por uma
   determinada tarefa essencial à vida. Estes, por sua vez, são compostos por células
   operando em paralelo, e ainda exercem suas funções paralelamente em relação
   aos outros demais órgãos. Como exemplo, podemos pensar no coração, pulmão,
   órgãos do sistema digestivo e sensorial, todos executando suas tarefas no mais
   absoluto paralelismo. Podemos concluir que os seres pluricelulares são sistemas de
   vida paralelos, e que quanto maior o seu grau de evolução, maior a escala de
   paralelismo envolvida.
   Agora que concordamos com o paralelismo envolvendo os seres
   pluricelulares, voltamos a perguntar: Se os seres unicelulares satisfazem a
   condição básica de vida, por que razão a evolução optou pelo desenvolvimento de
   seres paralelos (pluricelulares) ? Por que não existem seres unicelulares com alto
   grau de evolução ? A resposta parece ser um conjunto de fatores, envolvendo a
   natureza química e física da vida. Infelizmente nosso conhecimento ainda é muito
   limitado, e não sabemos como se comportaria a vida em condições adversas à
   nossa. Não sabemos nem ao menos se existe vida evoluída fora da terra. Não
   sabemos responder se existe apenas um universo, se as leis da física regem nosso
   universo como um todo ou ainda se existe outro ou outros universos. Agora,
   hipoteticamente falando, se houver outro universo, a probabilidade das leis físicas
   serem exatamente iguais as nossas é remota. Poderia em situações adversas, a
   natureza desenvolver vida com alto grau de evolução sem a multiplicação de
   unidades básicas de vida ? Ou seja poderia a natureza escolher como caminho de
   evolução seres unicelulares?
   As respostas a essas perguntas e conjecturas parecem estar longe do
   nosso alcance. No entanto, na natureza nada é por acaso, bilhões de anos de
   evolução não foram em vão e, como a natureza optou pelo paralelismo em massa,
   o melhor a fazer é compreender e estudar suas vantagens.
   Compreendemos que a natureza encontrou no paralelismo celular um ótimo
   mecanismo na busca da complexidade, adaptação e evolução, mas aonde entraria
   a visão nesse contexto ? Por que estaria a natureza preocupada com sistemas de
   visão paralelos ?
   Como comentamos anteriormente a visão está ligada à necessidade dos
PA seres vivos de obter informações do meio. Quando indivíduos competem no mesmo
   108
   OS CAMINHOS PARALELOS DA VISÃO
   habitat, e concorrem pela alimentação, qualquer informação a esse respeito é vital
   para a sobrevivência, e aquele que obtiver mais informação será favorecido na luta
   da sobrevivência. Até este ponto apenas a qualidade da informação foi levada em
   conta, no entanto a situação é um pouco diferente: além da qualidade, um outro
   fator crucial nessa questão é a velocidade, pois além de saber onde está e como
   chegar até o alimento, é necessário também que o indivíduo obtenha essa
   informação antes dos demais. Vamos imaginar duas espécies concorrentes,
   disputando o mesmo alimento escasso. Supondo que a principal fonte de
   informação de ambas seja a visão, e ainda que uma das espécies possua um
   sistema de visão lento e a outra um sistema de visão veloz. Se a diferença básica
   entre as duas espécies fosse essa qual sobreviveria ? Parece-nos bastante óbvio
   que a espécie que obtivesse a informação de modo lento pereceria, uma vez que
   os concorrentes chegariam ao alimento antes.
   A necessidade de velocidade na percepção visual se torna ainda mais crítica
   quando levamos em conta a disputa entre predador e presa. Neste caso, é
   fundamental para ambos, presa e predador, obter informações a respeito de seu
   oponente. Embora a visão não seja a única fonte de informação numa tal disputa,
   que conta com outros estímulos (olfato, audição, etc.), podemos dizer que a
   informação pela visão ainda assim tem uma relevância fundamental, e até mesmo
   primordial em algumas espécies. É claro que a natureza ao longo desses anos tem
   encontrado diversos mecanismos para contornar e iludir o sistema de informação
   do oponente, como a camuflagem, mas a velocidade do reconhecimento e
   localização da presa ou do predador é fundamental para a sobrevivência.
   Como vimos nos capítulos anteriores, a história da computação demonstra
   que a resposta para o desempenho de sistemas de informação artificiais é o
   paralelismo. Desde sua opção pelo paralelismo, no desenvolvimento de seres
   pluricelulares, a natureza se tornou mestra na arte de paralelizar, não seria de se
   espantar que ela usasse essa mesma arte para aprimorar os sistemas de visão
   biológicos, e é exatamente isso que o estudo da visão tem constatado. Neste
   capítulo apresentaremos uma revisão sobre os sistemas de visão biológicos, com
   enfoque nos primatas, e finalizaremos apresentando alguns estudos que
   demonstram a adoção do paralelismo já nas primeiras fases do processo visual.
   Visão artificial é hoje um tema de pesquisa de ponta, e tentamos a todo
   custo desenvolver sistemas artificiais de visão. No entanto, por maior esforço que
   realizemos e por maior o número de áreas científicas envolvidas, não conseguimos
   109
   CAPÍTULO 4
   sequer igualar a eficiência de nossos sistemas com o sistema de visão dos seres
   mais primitivos. Tendo a natureza encontrado no paralelismo uma escolha ao longo
   de bilhões de anos, por que nós, que possuímos um conhecimento tão limitado
   (funcionamento cortical), iríamos discordar?
   4.4 – O ESTUDO DO CÉREBRO E DA VISÃO
   Embora a ciência tenha se esforçado arduamente durante todo este século,
   o cérebro ainda permanece uma caixa preta. Se considerarmos o estudo do
   cérebro como um livro, nosso conhecimento científico atual corresponderia apenas
   às primeiras páginas. Devemos observar a grande complexidade envolvida nesta
   questão. A uma primeira instância o estudo do cérebro pode parecer pertencer a
PA algumas poucas áreas científicas, mais especificamente a áreas fundamentadas
   em biologia. No entanto, uma tendência científica atual vem unindo diversas áreas
   na construção do imenso quebra-cabeça no qual se relacionam este estudo. Assim
   sendo, o estudo do cérebro está reunindo, concentrando e integrando diversas
   áreas científicas, possuidoras de caminhos históricos bastante diferentes. Nenhum
   outro tema científico reuniu áreas tão distintas, e talvez, graças ao desafio de
   desvendar nosso próprio cérebro, nossa ciência altere seu curso separatista na
   história.
   4.4.1 – AS ESPECIALIZAÇÕES FUNCIONAIS CORTICAIS
   Até o século passado o cérebro era visto como uma caixa preta, dividida
   apenas em duas partes: áreas de projeção e áreas de associação [Machado, 1993].
   Na metade do século passado o neurologista francês Pierre Paul Broca, iniciou um
   estudo que expandiria a divisão dualista do cérebro [Broca, 1861]. Através de um
   caso clínico de um paciente que perdeu a capacidade de falar e, realizando
   autopsia após seu óbito, Broca constatou que uma área específica do cérebro era
   responsável pelo caso clínico, mas foi duramente criticado pelo meio científico de
   sua época. Porém seu trabalho introduziu a noção de que o córtex cerebral era
   composto de áreas distintas diferenciadas por sua especialização. No entanto, a
   crença na dualidade cerebral perduraria, especialmente pela dificuldade de localizar
   regiões anatomicamente distintas no córtex, assim como a questão da plasticidade
   cerebral.
   110
   OS CAMINHOS PARALELOS DA VISÃO
   Uma grande diversidade de trabalhos científicos viriam a consolidar a
   divisão do córtex em áreas distintas classificadas mediante a função, entre eles
   devemos destacar os trabalhos de Fritsch e Hitzig [Fritsch & Hitzig, 1870], que
   conseguiram provocar movimentos em determinadas partes do corpo através de
   estímulos elétricos em áreas específicas no córtex do cão.
   A divisão do córtex em áreas funcionais possibilitou que a clássica
   estratégia de dividir e conquistar fosse aplicada à neurociência, permitindo a
   canalização de diferentes estudos relativos a função de suas áreas determinadas.
   Com isso, ao estudarmos uma determinada função específica do córtex, podemos
   concentrar esforços na sua região cortical correspondente.
   4.4.2 – ANÁLISE MULTI-ESCALA
   Uma questão muito importante no estudo cortical é a sua complexidade
   multi-escalar. O córtex deve ser explorado sob diferentes prismas relativos a
   escala. Deste modo, do ponto de vista multi-escala, podemos dividir a análise
   cortical em três partes [Costa, 1996]:
   Microscópica: Dentro dessa abordagem o córtex é estudado em nível
   celular. São estudadas as células que o compõe: neurônios, fibras e glias. Além do
   comportamento do estudo histológico dos componentes de cada célula, nessa
   escala são ainda estudadas as ramificações dendríticas e axonais. As técnicas de
   estudo nessa escala são histológicas / anatômicas (empregam corantes,
   dissecações e são feitas in vitro).
   Intermediária: Nesta classe são estudados grupos de células e suas
   conexões. O comportamento das árvores dendríticas e como são compostas as
   redes neurais. São ainda exploradas as conexões neurais dentro de uma região
   cortical. Um exemplo do estudo cortical nessa escala são as visualizações de redes
   neurais e de seu comportamento nas regiões V1 e V2 do córtex visual. Através das
   técnicas de citoarquiteturas, citochromo oxidase e mieloarquiteturas é possível a
PA visualização das sub-regiões de cataventos em V1 (blobs e inter-blobs) e das sub-
   regiões em forma de faixas em V2 ("thin stripe", "inter stripe" e "thick stripe") [Zeki, 1993] [Hubel, 1995].
   Macroscópica: A esta categoria pertence o estudo de regiões inteiras do
   córtex. Embora essa escala possa ser explorada do ponto de vista anatômico, o
   maior interesse reside na sua pesquisa fisiológica. A principal característica da
   111
   CAPÍTULO 4
   exploração fisiológica é que esta envolve aspectos funcionais da parte estudada e
   são executadas in vivo. Assim, temos como exemplo da escala macroscópica os
   estudos cirúrgicos (como o de Broca), tomografia por ressonância magnética e
   PET (Positron-Emition Tomography).
   Devemos lembrar que não existe uma divisão distinta entre as escalas.
   Ninguém sabe exatamente onde uma escala começa ou termina. Essa
   classificação tem como único objetivo apresentar as características multi-escala do
   estudo do córtex.
   4.4.3 – VISUALIZANDO O CÉREBRO ATRAVÉS DA VISÃO
   Como vimos anteriormente, o cérebro sempre foi visto como uma caixa
   preta (em especial o córtex). Do ponto de vista anatômico tradicional, quando
   analisamos o córtex, este se apresenta como uma estrutura uniforme,
   diferenciando-se apenas pelas depressões, intituladas sulcos, que delimitam os
   giros e lobos. Entretanto, a existência dos sulcos não dizem nada em termos da
   funcionalidade do córtex, eles são apenas uma estratégia utilizada pela natureza
   que permite aumento da superfície sem grande aumento do volume (no homem,
   cerca de dois terços do córtex está “escondido” pelos sulcos) [Machado, 1993].
   Desta forma, o córtex apresenta-se singular: uma única matéria uniforme enrugada
   (sulcos e giros). Devido a essa característica uniforme, Semir Zeki [Zeki, 1993]
   sugere que, embora o córtex seja diferenciado pela funcionalidade de cada região,
   deva existir uma estratégia única ou geral para o seu funcionamento. Deste modo,
   se explorarmos e desvendarmos o funcionamento de uma região cortical, teremos
   conhecimentos suficientes para desvendar as demais regiões.
   Nessas últimas décadas, a visão recebeu uma atenção especial. Nenhum
   outro sentido ou região cerebral foi mais explorado do que a visão. Embora tenha
   sido alvo da pesquisa científica, tem revelado muito pouco sobre o seu
   funcionamento.
   Assim, o estudo da visão está trazendo evidências de como funciona o
   cérebro como um todo, e aproveitando o trocadilho proposto pelo título do livro A
   Vision of the Brain, de Semir Zeki [Zeki, 1993], fornecendo uma poderosa
   ferramenta de visualização do funcionamento do cérebro.
   Embora esta subseção seja destinada ao estudo do cérebro, vamos a partir
   daqui enfocar a visão: o sentido e a região mais explorados do córtex.
   112
   OS CAMINHOS PARALELOS DA VISÃO
   4.4.4 – VISÃO – UMA ÁREA MULTIDISCIPLINAR
   Dentre as áreas do conhecimento cientifico, talvez a que envolva a maior
   diversidade de disciplinas seja a visão. É fácil verificar esta suspeita. O estudo da
   visão pode ser dividido em visão natural e artificial. Em visão natural, os objetos de
   estudos são os sistemas biológicos de visão, ao passo que no segundo caso,
   temos as ciências exatas tentando reproduzir artificialmente o processo de
   interpretação visual do mundo realizado pelos sistemas biológicos. O verdadeiro
   fascínio dessa ciência ocorre na integração de suas duas partes: visão natural e
PA artificial, integrando as ciências exatas com as ciências biológicas. Se por um lado
   a biologia tenta desvendar a arquitetura e funcionamento do cérebro, a cibernética
   desenvolve modelos baseados nos sistemas biológicos e experimentam sistemas
   artificiais. Embora aparentemente estejam percorrendo caminhos diversos, a
   integração ocorre na realimentação do conhecimento científico.
   No entanto, a visão é muito mais complexa e contém um número maior de
   áreas de conhecimento envolvidas do que a versão dualista anteriormente
   apresentada. Para explorar algumas dessas áreas envolvidas, vamos considerar a
   definição de visão utilizada por David Marr. Segundo Marr [Marr, 1982], visão é o
   processo de descobrir através de imagens o que está presente em nosso mundo e
   suas respectivas posições. Seguindo essa abordagem, o primeiro estágio da visão
   é a aquisição de imagens. Assim, os olhos captam energia eletromagnética na
   forma de luz e a converte em impulsos nervosos através de células fotorreceptoras.
   A visão é um mecanismo neurológico, baseado em estímulos do universo físico,
   necessitando deste modo, para sua compreensão de conhecimentos em ambos
   universos científicos (compreensão física e neurológica).
   Nesse patamar a complexidade da questão fica bastante evidente, assim
   como a diversidade de áreas científicas envolvidas. Num primeiro plano temos as
   neurociências, através das quais são estudados os mecanismos neurais. O
   entendimento dos processos de percepção, compete à psicologia, assim como
   entramos em questões de interesse filosófico quando levantamos a questão da
   consciência envolvida em todo o processo. Se ponderarmos sobre a questão do
   comportamento do sistema visual em resposta ao ambiente, assim como do
   processo evolutivo que levou ao desenvolvimento do sistema de visão natural,
   devemos considerar a ecologia e o darwinismo. Encerrando o processo do estudo
   da visão temos a matemática e a física desenvolvendo os modelos formais das
   113
   CAPÍTULO 4
   interpretações encontradas para o processo visual e finalmente a computação
   auxiliando no desenvolvimento de experimentos, fazendo análises abstratas ou não
   das simulações e modelagens, e desenvolvendo sistemas artificiais
   correspondentes (Figura 4.1).
   Visão
   Matemática
   Ecologia
   -
   Física
   Neurociência
   Ciência da
   Filosofia
   Computação
   Psicologia
   Fig. - 4.1 – Visão, uma ciência formada pela integração de muitas outras.
   4.5 – INTRODUÇÃO À NEUROCIÊNCIA
   Nesta seção iremos discutir sucintamente as bases da neurociência, para
   que possamos no contexto desse capítulo discorrer sobre o funcionamento do
   córtex visual. O sistema nervoso é constituído basicamente por dois tipos de
   células: células neurais ou neurônios e glias ou neuróglias. Enquanto os neurônios
   são células especializadas na condução e processamento de sinais eletroquímicos,
   as glias tem como finalidade o revestimento ou isolamento, modulação da atividade
PA neural e defesa [Machado, 1993]. Nesta seção iremos enfocar nossa discussão nos
   neurônios, uma vez que estamos nos limitando ao perfil de processamento de
   informações.
   4.5.1 – SISTEMA NERVOSO
   Em termos evolutivos, a complexidade do sistema nervoso dos seres vivos
   determina sua escala hierárquica. Assim, quanto mais primitivo, mais rudimentar é
   o seu sistema nervoso, se comparado com o sistema nervoso dos vertebrados e
   114
   OS CAMINHOS PARALELOS DA VISÃO
   mais ainda se compararmos com os representantes do ápice da pirâmide evolutiva,
   os primatas. No entanto, todos eles possuem uma unidade fundamental, as células
   neurais ou neurônios [Kovács, 1997]. Os sistemas nervosos são constituídos por
   aglomerados dessas células (gânglios, núcleos e córtices). Através de seus
   sistemas nervosos, os seres vivos são capazes de agir e reagir a eventos no
   ambiente, e muitas vezes até mesmo a modelá-lo.
   O sistema nervoso dos vertebrados costuma ser dividido em duas porções
   com características distintas: o sistema nervoso central, localizado dentro do
   esqueleto axial (cavidade craniana e canal vertebral) e o sistema nervoso periférico
   localizado fora do esqueleto axial. O sistema nervoso central é formado pelo
   cérebro, medula espinhal e retina do sistema visual, ao passo que o periférico é
   composto pelas fibras aferentes e suas conexões com os órgãos sensoriais e pelas
   fibras eferentes, conexas com os músculos [Machado, 1993] [Costa, 1996]. A
   Figura 4.2 apresenta um esquema detalhado das divisões do sistema nervoso.
   Sistema
   Nervoso
   Sistema
   Sistema
   Nervoso
   Nervoso
   Central
   Periférico
   Encéfalo
   Medula
   Gânglios e
   Nervos
   terminações
   nervosas
   Cerebelo
   Cérebro
   Tronco
   Espinhais
   Cranianos
   Telencéfalo
   Diencéfalo
   Ponte
   Bulbo
   Mesencéfalo
   Fig. - 4.2 – Subdivisões do Sistema Nervoso [Costa, 1996].
   Neste trabalho estaremos mais interessados no cérebro, que é composto
   pelo diencéfalo e telencéfalo. Na Figura 4.3 encontramos uma ilustração das
PA divisões do encéfalo onde podemos encontrar essas duas regiões. O diencéfalo fica
   localizado na base do telencéfalo. Um dos componentes do diencéfalo é o tálamo,
   que é composto por duas regiões localizadas simetricamente em sua porção látero-
   dorsal. A grande maioria dos caminhos sensoriais fazem conexões ao tálamo, entre
   115
   CAPÍTULO 4
   eles o caminho visual, uma vez que o núcleo geniculado lateral faz parte do
   complexo do tálamo.
   Telencéfalo
   Diencéfalo
   CÉREBRO
   Mesencéfalo
   ENCÉFALO
   Ponte
   Tronco
   Bulbo
   Encefálico
   Cerebelo
   Fig. - 4.3 – Divisões do Encéfalo.
   O telencéfalo por sua vez é composto pelos dois hemisférios cerebrais
   (direito e esquerdo) e pelo corpo caloso, através do qual os hemisférios são
   interconectados. Os hemisférios podem ser divididos em duas partes: o córtex
   cerebral e o centro branco medular. O córtex é aonde estão concentrados a grande
   maioria dos neurônios de todo o sistema nervoso, também denominado de matéria
   cinza, que possui cerca de 2mm de espessura nos mamíferos. Devido à sua
   natureza superficial, o córtex é alojado dentro da cavidade craniana assemelhando-
   se a um jornal amassado. Desta maneira, formam-se diversos sulcos, giros e lobos
   (Figura 4.4). Conforme já comentado, essa foi uma estratégia encontrada pela
   natureza a fim de que o córtex ocupasse uma área menor e possibilitando deste
   modo ficar contido dentro do crânio. O córtex reveste o centro branco medular, que
   é constituído pelos axônios que interconectam as regiões corticais e também pela
   conexão das regiões corticais com os centros subcorticais (ex: tálamo, que funciona
   como uma estação de distribuição dos sinais sensoriais).
   116
   OS CAMINHOS PARALELOS DA VISÃO
   Sulco central
   Lobo parietal
   Lobo frontal
   Sulco
   parieto-occipital
   Lobo occipital
   Lobo temporal
   Sulco lateral
   Cerebelo
   Fig. - 4.4 – Lobos e sulcos corticais.
   4.5.2 – NEURÔNIOS
   A Figura 4.5 apresenta um neurônio típico transmitindo sinais eletroquímicos
   a outras três células neurais. Os neurônios são células especializadas na condução
   e processamento de sinais eletroquímicos. Embora exista uma grande quantidade
   de classes de neurônios, que são agrupados através de suas características
PA funcionais e morfológicas, a base de seu comportamento eletroquímico é a mesma
   para todas as classes [Costa, 1996]. Os neurônios são delimitados por uma
   membrana celular e são constituídos basicamente de um corpo celular ou soma,
   um filamento alongado denominado axônio e dendritos (caracterizados pela sua
   natureza arborizada).
   As dimensões, formas e localização do soma em relação à árvore dendrítica
   variam muito entre os diversos tipos de neurônios. Os diâmetros podem ir da ordem
   de 2 mícrons a mais de 0,5 milímetros. Em geral os neurônios apresentam apenas
   um único axônio. Sua função básica é a transmissão de sinal, resultante do
   processamento de informações recebidas pelos dendritos, através de pulsos
   elétricos. O axônio se caracteriza por ser um filamento de diâmetro uniforme que se
   projeta do neurônio percorrendo distâncias que vão desde centenas de mícrons até
   mais de um metro. O diâmetro dos axônios está relacionado à velocidade de
   transmissão: quanto maior o diâmetro, maior é a taxa de transmissão do sinal
   [Costa, 1996]. No Sistema Nervoso Periférico, axônios aferentes [Machado, 1993]
   transportam a informação proveniente dos sensores para o Sistema Nervoso
   117
   CAPÍTULO 4
   Central. O caminho inverso também ocorre, quando as informações são
   transmitidas pelos eferentes ao organismos. Os axônios podem se agrupar em
   feixes. Quando agrupados no Sistema Nervoso Periférico, esse conjunto recebe o
   nome de troncos nervosos ou nervos, que podem conter desde poucas unidades a
   dezenas de milhares de axônios. No Sistema Nervoso Central, os agrupamentos
   são denominados de tractos [Kovács, 1997].
   Fig. - 4.5 – Estrutura de um neurônio típico.
   Nos vertebrados a maioria dos axônios são revestidos por uma cobertura
   gordurosa denominada de capas de mielina (bainha de mielina). Essa substância é
   produzida por células neurogliais de Schwamm [Kovács, 1997]. Este tipo de arranjo
   permite o isolamento elétrico das fibras aumentando a sua velocidade de
   transmissão e diminuindo seu diâmetro. Estima-se que nosso cérebro seria dez
   vezes maior caso não fosse adotada as capas de mielina [Dowling, 1992]. Os
   invertebrados, em geral, não possuem esse mecanismo, o que indica que a
   mielinização dos axônios foi um passo evolutivo, que aumentou a velocidade de
   propagação dos impulsos nervosos e diminuiu a dimensão das fibras nervosas,
   oferecendo uma significativa vantagem competitiva.
   Se por um lado os axônios têm como função a transmissão dos impulsos
   nervosos, cabe aos dendritos a sua recepção. Os dendritos são prolongamentos
   filamentares de arranjo arbóreo, constituindo a parte receptiva dos neurônios. Sua
   natureza de ramificação arbórea tem como finalidade possuir uma ampla área para
   a recepção dos sinais. A transmissão do sinal entre os axônios e dendritos ocorre
   118
   OS CAMINHOS PARALELOS DA VISÃO
   em estruturas de contato denominadas sinapses. Embora as sinapses
   freqüentemente ocorram entre axônios e dendritos (axodendríticas), elas podem
   ocorrer também entre axônios e a soma (axossomáticas), e em casos mais raros
   entre: axônio-axônio (axoaxônicas), dendrito-dendrito (dendrodendríticas), dentrito-
   soma (dendrossomáticas), soma-soma (somatossomáticas), soma-dendrito
   (somatodendríticas) e soma-axônio (somatoaxônicas) [Machado, 1993].
   (a)
   (b)
PA Fig. - 4.6 – (a) Ilustração de uma sinapse. (b) Fenda sináptica. [Dowling, 1992]
   A Figura 4.6a apresenta uma sinapse. Nela podemos observar duas
   membranas: pré-sináptica e pós-sináptica. A membrana pré-sináptica transmite o
   sinal, enquanto que a pós-sináptica o recebe. Ambas as membranas sinápticas são
   separadas por uma fenda denominada de fenda sináptica, que podemos observar
   na Figura 4.6b. Quando um pulso nervoso chega pelo axônio até a membrana pré-
   sináptica, esta libera vesículas com mediadores químicos, denominados de
   neurotransmissores (Figura 4.6), que através da fenda sináptica, chegam à
   119
   CAPÍTULO 4
   membrana pós-sináptica, provocando alteração em sua polaridade. Uma
   característica fundamental da sinapse é a de propagar sinais em um único sentido:
   da membrana pré-sináptica para a membrana pós-sináptica.
   Quanto à função, podem ocorrer dois tipos de sinapses: excitatória e
   inibitória. De acordo com as características químicas dos neurotransmissores pode
   haver uma despolarização ou hiperpolarização da membrana pós-sináptica, onde a
   despolarização desta é denominada de potencial pós-sináptico excitatório (PPSE) e
   a hiperpolarização denominada potencial pós-sináptico inibitório (PPSI) [Coelho,
   1998]. A Figura 4.7 ilustra as sinapses excitatória e inibitória assim como as PPSE
   e PPSI.
   Cada sinapse (PPSE ou PPSI) produz um efeito mínimo no neurônio. No
   entanto os neurônios apresentam muitas sinapses, segundo Kovács [Kovács, 1997]
   a ordem de sinapses é de 5000 nos neurônios motores da medula e pode chegar
   até mesmo a 95000 nas células de Purkinje (neurônio do córtex cerebelar) e que
   para cada milímetro cúbico do córtex cerebral existam 105 neurônios e 109
   sinapses. Assim, o neurônio funciona como um integrador de sinais, de modo que o
   conjunto dos sinais sinápticos determinará a resposta do neurônio.
   Fig. - 4.7 – Sinapses excitatória, Sinapses inibitória, PPSE e PPSI.
   Cada sinapse pode produzir polarizações diferentes, que são determinados
   por um conjunto de fatores, tais como: tamanho da sinapse, quantidade de
   neurotransmissores liberados, distância do ponto sináptico ao soma e tipo da
   120
   OS CAMINHOS PARALELOS DA VISÃO
   sinapse (PPSE – despolarização e PPSI – polarização) [Kovács, 1997] [Costa,
   1996]. Para que o neurônio responda ao estímulo, a somatória da polarização das
   sinapses deve produzir uma despolarização suficiente para ultrapassar um limiar,
   conhecido como limite de disparo. Acontecendo isso, a membrana despolariza em
   questão de microsegundos muito além do limiar, e o estímulo é transmitido pelo
   axônio, fazendo que deste modo a polarização da membrana retorne lentamente
   (em relação ao disparo) à sua polarização original. Este fenômeno é denominado
   potencial de ação. A velocidade de transmissão do impulso nervoso é de algumas
   dezenas de centímetros por segundo em fibras não mielinizadas e até 150 metros
   por segundo em fibras mielinizadas [Kovács, 1996].
   Existe um grande número de modelos matemáticos de neurônios e redes
   neurais. A motivação inicial da modelagem de neurônios artificiais ocorreu em 1943
   com o trabalho de McCul och e Pitts [McCulloch & Pitts, 1943]. Por algumas
   décadas essa idéia não teve muitos seguidores até emergir novamente na década
   de 80 com força renovada nas linhas de pesquisa. A Figura 4.8 apresenta um
   modelo matemático típico de um neurônio. Nele os estímulos X1...Xn são integrados
   com o produto interno de seus respectivos pesos W produzindo s, que sofre uma
PA transformação não linear implementada pela função f. Transpondo essa
   representação para o modelo biológico temos cada entrada X representada por
   uma sinapse, que apresenta “pesos” diferentes sob determinados aspectos [Costa,
   1996], cuja despolarização é integrada pela soma celular que, caso exceda o limiar,
   dispara um impulso nervoso representado por y.
   X1
   W1
   X2
   .
   W2
   f
   y
   .
   s
   r r
   .
   y = f ( xT w
   . )
   Wn
   Xn
   Fig. - 4.8 – Modelo matemático típico de uma célula neural.
   121
   CAPÍTULO 4
   4.6 – O CAMINHO VISUAL
   Assim como os demais sentidos, a visão tem como objetivo a percepção,
   compreensão e até mesmo (nos seres mais evoluídos) a modelagem do meio
   ambiente e dos objetos a sua volta. A diferença básica entre a visão e os demais
   sentidos é a quantidade de informações que são adquiridas por este sentido e sua
   complexidade. A importância, assim como sua complexidade, é tamanha que 60%
   de todo o mecanismo neural do córtex é utilizado para esse sentido [Hubel, 1995]
   [Tovée, 1996] [Levine, 1985]. Nesta seção vamos discutir o caminho visual, que se
   inicia com a luz refletindo nos objetos e sendo transformada em impulsos nervosos
   pelos fotorreceptores e finaliza com a abstração e percepção dos sinais nervosos
   processados pela retina e córtex visual primário.
   4.6.1 – CAPTANDO A LUZ
   Os olhos têm como função básica captar a luz e focalizá-la na retina, uma
   fina camada localizada na parede posterior interna composta de neurônios
   especializados em converter os sinais eletromagnéticos em neurológicos. Entende-
   se por luz visível a região do espectro da radiação eletromagnética visível pelos
   seres humanos. Embora possua um sistema de visão eficiente, o homem é cego à
   grande maioria das ondas eletromagnéticas. A Figura 4.9 apresenta o espectro da
   radiação eletromagnética, destacando a porção percebida pelo nosso sistema de
   visão.
   Fig. – 4.9 – Espectro da radiação eletromagnética com destaque para a porção
   visível.
   122
   OS CAMINHOS PARALELOS DA VISÃO
   A Figura 4.10 apresenta a estrutura geral do olho humano. O olho apresenta
   funcionamento semelhante a uma câmara fotográfica, através do seu sistema de
   lentes, composto pela córnea e pelo cristalino, focaliza a imagem na retina. A luz é
PA inicialmente refratada pela córnea, que através de sua superfície côncava, converte
   os raios luminosos para o interior do olho. Após os raios refratados terem passado
   pela córnea e pelo humor aquoso, atingem a superfície curva anterior da lente do
   cristalino e então a superfície curva posterior (lente convexa). Deste modo os raios
   luminosos são refratados em três locais diferentes e através dessas refrações são
   convergidos e focados na retina. O cristalino é flexível e pode ser alongado e
   comprimido pela ação dos músculos ciliares. Através dessa alteração da forma do
   cristalino a dioptria do sistema óptico é alterada, possibilitando focar objetos
   localizados em distâncias diferentes. Enquanto o cristalino é responsável pelo
   ajuste fino do foco, a córnea é a maior responsável pela convergência dos raios,
   cerca de 70% da refração é realizada por ela [Tovée, 1996]. Uma outra forma de
   alterar a dioptria de um sistema óptico seria o deslocamento do cristalino, do
   mesmo modo como é utilizado nas câmaras fotográficas. Embora esse método não
   seja utilizado pelos primatas, alguns animais, como por exemplo a rã, adotam essa
   estratégia [Schmidt, 1980].
   Fig. – 4.10 – Olho humano, corte lateral.
   O globo ocular é sustentado por três pares de músculos, que são
   responsáveis por sua movimentação, conforme mostra a Figura 4.11. Os músculos
   de cada pa trabalham em oposição e são responsáveis pelo movimento em relação
   123
   CAPÍTULO 4
   a três planos perpendiculares. Os movimentos do globo ocular possuem precisão
   da ordem de um minuto de arco e podem fornecer um ângulo de visão de no
   mínimo 140o [Braham, 1996]. O sistema de movimentação do globo ocular trabalha
   em conjunto com uma coleção de reflexos precisamente sintonizados, incluindo os
   que controlam a posição da cabeça [Hubel, 1995].
   (a)
   (b)
   Fig. – 4.11 – Músculos de sustentação do globo ocular. (a) Globo ocular vista
   dorsal. (b) Disposição dos músculos na cavidade ocular.
   4.6.2 – A RETINA
   A retina, localizada na parede posterior do olho, recebe toda a luz captada
   pelo sistema óptico. Uma vez focalizada a imagem na retina, inicia-se o processo
   de transformação da luz em impulso nervoso.
   A retina é uma parte do cérebro que se desprendeu através da evolução e
   permaneceu conectada através do nervo óptico. Ela é composta por três camadas
   de corpos de células nervosas separadas por duas camadas de sinapses,
   compostas por axônios e dendritos. As estruturas da retina encontram-se altamente
   organizadas. A retina tem a forma de uma placa ou camada e encontra-se
   depositada na parede posterior do olho, possuindo uma espessura de
   aproximadamente 0,25 mm [Hubel, 1995]. A Figura 4.12 apresenta uma ilustração
   contendo um olho e a retina ampliada apresentando suas estruturas. Curiosamente
   a última camada da retina é composta pelos fotorreceptores, células nervosas
   sensoriais capazes de converter a luz em sinal nervoso. Deste modo a luz
   atravessa todas as demais estruturas da retina até chegar nos fotorreceptores.
   124
   OS CAMINHOS PARALELOS DA VISÃO
   (a)
   (b)
   Fig. – 4.12 – Corte da retina (a) e mapa da distribuição vascular dos capilares
PA na mácula (b).
   A retina costuma ser considerada em duas camadas: a neurossensorial e o
   epitélio pigmentar. A retina sensorial é uma estrutua celular complexa, estratificada,
   composta pelas células fotorreceptoras, ganglionares, interneurais (bipolar,
   horizontal, amácrina e interplexiforme) e glias. A retina sensorial subdividi-se em
   duas partes: (i) interna, englobando a membrana limitante até a nuclear interna
   (todas as células de processamento neurológico descritas anteriormente) e (i )
   externa constituindo da plexiforme externa aos fotorreceptores. A retina sensorial
   interna é vascularizada a partir dos vasos sangüíneos oriundos da artéria central da
   retina, ao passo que a retina externa é avascular, sendo nutrida pela coróide (a
   nutrição atravessa o eptélio pigmentar) [Bruno, 1999].
   4.6.2.1 – OS FOTORRECEPTORES
   Os fotorreceptores são células nervosas adaptadas, responsáveis pela
   conversão do sinal luminoso em sinal nervoso. Existem dois tipos de
   fotorreceptores na retina: os cones e os bastonetes. A retina humana contém cerca
   de 120 milhões de bastonetes e 6 milhões de cones [Tovée, 1996]. A Figura 4.13
   apresenta um gráfico que ilustra a distribuição dos cones e bastonetes ao longo da
   retina. Como podemos observar, os cones estão concentrados na região central da
   retina. Sua concentração apresenta um pico numa região denominada fóvea. Os
   bastonetes por outro lado, se concentram mais nas regiões periféricas, tendo uma
   presença praticamente nula na região foveal.
   125
   CAPÍTULO 4
   2m
   Ponto cego
   m
   por
   es
   Bastonetes
   onet
   s e bast
   cone
   Cones
   de
   ero
   Núm
   Fóvea
   Periferia nasal
   Periferia temporal
   Fig. – 4.13 – Distribuição dos cones e bastonetes ao longo da retina.
   Ainda observando a distribuição dos fotorreceptores na retina, podemos
   observar o ponto cego, que constitui a região por onde chega a vascularização até
   a retina e também a região por onde sai o nervo óptico, conjunto de axônios que
   levam as informações processadas na retina ao córtex.
   Além da distribuição ao longo da retina, os cones e bastonetes também se
   diferenciam quanto a forma e função. Os bastonetes são mais sensíveis à luz que
   os cones, possuindo uma maior percepção para locais com pouca iluminação ou
   visão noturna, entretanto sua resolução é menor. Os cones por outro lado são os
   sensores utilizados para a visão diurna com alta precisão. Alguns primatas, entre
   eles o homem, possuem três tipos de cones, sensíveis a diferentes freqüências
PA eletromagnéticas: ondas curtas (azul), médias (verde) e longas (vermelho). Sendo
   assim, os cones são responsáveis pela visão cromática. A Figura 4.14 apresenta as
   curvas sensibilidade a freqüência para cada classe.
   A grande maioria dos cones se encontra na fóvea, devido a este fato, essa
   região da retina é responsável pela visão de precisão. Cerca de 5% a 10% do
   cones, respondem ao azul. Eles ficam distribuídos na região periférica da fóvea,
   formando assim uma estrutura anular. Os cones que respondem ao vermelho e
   verde são arranjados de forma bastante regular, estabelecendo padrões na retina.
   A razão entre os cones sensíveis ao vermelho e verde é de 2 para um [Tovée,
   126
   OS CAMINHOS PARALELOS DA VISÃO
   1996].
   (%)
   rção relativaso
   Ab
   Comprimento de onda (nm)
   Fig. – 4.14 – Sensibilidade dos três tipos de cones da retina dos primatas.
   Bastonete
   Cone
   rodopsina
   rodopsina
   Terminações
   sinápticas
   (A)
   (B)
   Fig. – 4.15 – (A) Diagrama esquemático dos fotorreceptores (cones e
   bastonetes) [Tovèe, 1996]. (B) Imagem microscópica apresentando os
   fotorreceptores (em destaque cone) [Dowling,1992].
   Tanto os cones quanto os bastonetes, possuem funcionamentos
   semelhantes, baseados em moléculas sensíveis à luz, intituladas rodopsinas. O
   conjunto das moléculas rodopsinas, localizadas no segmento exterior das células
   fotorreceptoras é responsável por sua excitação, um único bastonete humano
   contém cerca de 100 milhões de moléculas, que são interligadas proximamente,
   127
   CAPÍTULO 4
   cuja distância entre moléculas possui cerca de 20 nm [Tovèe,1996]. A Figura 4.15a
   apresenta uma comparação entre um cone e um bastonete em relação à forma
   assim como a disposição das moléculas de rodopsina e a Figura 4.15b apresenta
   uma imagem dos fotorreceptores.
   4.6.2.2 – RETINA SENSORIAL INTERNA
   Há algumas décadas atrás acreditava-se que a única função da retina era
   converter a luz em sinais nervosos e transmiti-los para o córtex. No entanto,
   existem cerca de 126 milhões de fotorreceptores na retina, cada um transmitindo
   informações sobre a luz absorvida em um determinado ponto da retina. A
   informação é transmitida para o córtex através do nervo óptico, que é o conjunto
   dos axônios das células ganglionares, e existem apenas 1 milhão deste. A relação
   126 milhões para 1 milhão, deixa bastante clara a existência de processamento nas
   células da retina sensorial interna.
   As evidências indicam que a retina realize os primeiros processamentos da
   informação visual [Goldstein, 1989] [Hubel, 1995], destacando a detecção de
PA bordas [Marr, 1982] [Bruce & Green, 1990]. Além da detecção de bordas, uma outra
   função importante implementada na retina é o início da divisão dos caminhos
   visuais (parvo e magno), que será comentada mais adiante.
   A retina sensorial interna é formada por quatro tipos de células neurais:
   células bipolares, células horizontais, células amácrinas e células ganglionares (ver
   Figura 4.12). Embora essas células tenham sido vastamente estudadas, estaremos
   interessados neste trabalho nas células ganglionares, que são a última camada de
   células nervosas na retina, sendo que seus axônios formam o nervo óptico.
   Nas células ganglionares da retina de primatas foram encontrados dois tipos
   distintos de células : M e P (Magno e Parvo) [Shapley & Perry 1986]. As células M
   tem como características um campo dendrítico pequeno na região foveal, que
   aumenta em tamanho de forma linear quanto mais as células se distanciam da
   fóvea ao passo que as células P são muito mais numerosas e possuem um campo
   dendrítico pequeno, que se mantém de tamanho constante ao longo de toda a
   retina. Essas células irão originar os caminhos Magnocelular e Parvocelular,
   caminhos independentemente correlacionados que percorrem quase todo o sistema
   visual. Conforme veremos em breve (Seção 4.6.3.1) as propriedade dos caminhos
   Parvocelular e Magnocelular sugerem uma correlação direta entre as células
   ganglionares M e P e as duas classes de fotorreceptores (cones e bastonetes).
   128
   OS CAMINHOS PARALELOS DA VISÃO
   4.6.2.3 – CAMPOS RECEPTIVOS DA RETINA
   O campo receptivo se caracteriza por uma região sensorial que influencia
   uma célula específica. Os campos receptivos são encontrados e estudados em
   diversos pontos do caminho visual. Na retina, os campos receptivos são
   classicamente estudados a partir das células ganglionares. Deste modo cada célula
   ganglionar possui uma região na retina (fotorreceptores) que a influencia.
   On-Center
   Off-Center
   On-Off
   Estímulo
   Estímulo
   Centro
   Único ponto
   Periferia
   Sentido
   preferencial
   Centro e
   Sentido
   periferia
   contrário
   (A)
   (B)
   (C)
   Fig. – 4.16 – Campos receptivos das células ganglionares da retina. (a) “On-
   Center” - excitação na região central e inibição na região periférica. (b) “Off-
   Center” - inibição na região central e excitação na região periférica. (c) “On-
   Off” – respostas a movimentos.
   Na retina os campos receptivos se caracterizam por formarem estruturas
   concêntricas conhecidas como centro-periferia, apresentando basicamente três
PA tipos quanto a funcionalidade: “On-Center”, “Off-Center” e “On-Off”. Na Figura 4.16
   temos exemplos das respostas das células em relação aos estímulos em seus
   campos receptivos. As células com campos receptivos “On-Center” (Figura 4.16a)
   disparam quando o centro do campo receptivo é iluminado, ao passo que com as
   células com campos “Off-Center” (Figura 4.16b) ocorre justamente o contrário. As
   células com campos receptivos “On-Off” (Figura 4.16c) são sensíveis ao
   movimento, respondendo quando um ponto luminoso percorre uma direção e
   sentido preferencial [Dowling, 1992] [Coelho, 1998] [Costa, 1996].
   129
   CAPÍTULO 4
   É importante observar que os campos receptivos se sobrepõem, de modo
   que uma célula fotorreceptora da retina pode fazer parte de muitos campos
   receptivos de diferentes células ganglionares [Hubel, 1995]. Quanto ao tamanho
   dos campos receptivos, este difere de uma célula para outra, tendo em média
   tamanhos menores quando o campo receptivo está nas regiões foveais e maiores
   na periferia. David Marr [Marr, 1982], descreve uma modelagem matemática dos
   campos receptivos da retina, que se tornou um clássico na literatura, sendo
   conhecida como filtro de Marr-Hildreth, que é descrita pelo laplaciano da gaussiana
   (Equação 4.1). Segundo tal modelo, os campos receptivos ganglionares são
   excelentes detectores de bordas.
   2
   2
   1
   r
   r
   2
   2
   2
   G( r) =
   1
   e
   (4.1)
   4
   2
   2
   4.6.3 – CONEXÕES ENTRE A RETINA E O CÓRTEX
   O próximo passo no caminho visual é a transmissão da informação
   processada na retina para o córtex visual. As informações luminosas capturadas e
   processadas na retina são enviadas até o LGN (Núcleo Geniculado Lateral). A
   conexão entre a retina e o LGN é realizada pelo nervo óptico, que nada mais é do
   que o conjunto de axônios das células ganglionares. Pode-se dizer que a retina é
   mapeada topograficamente nas células do LGN [Zeki, 1993], o que ocorre
   entretanto é que o mapeamento obedece a sofisticadas estratégias, que privilegiam
   a fóvea e fazem a integração das imagens obtidas pelas duas retinas.
   A Figura 4.17 apresenta um diagrama do caminho óptico. A imagem é
   focalizada na retina e então processada e transmitida através do nervo óptico. Após
   passar pelo quiasma óptico, o nervo óptico recebe a denominação de trato óptico,
   chegando até o LGN ou núcleo geniculado lateral. Deste ponto a informação é
   finalmente transmitida até o córtex, através dos axônios das células do LGN, fibras
   que são denominadas radiação óptica.
PA 130
   OS CAMINHOS PARALELOS DA VISÃO
   Olho
   Nervo óptico
   Quiasma óptico
   Trato óptico
   LGN
   Radiação óptica
   Córtex visual primário
   Fig. – 4.17 – Caminho óptico: trajetória dos sinais visuais, da retina ao córtex
   visual primário.
   Vamos comentar agora a estratégia de mapeamento que propicia a
   integração das imagens obtidas nas retinas assim como a priorização da região
   foveal no percurso óptico. Antes de prosseguirmos, devemos lembrar que cada
   retina é dividida em quatro partes ou quadrantes [Zeki,1993], e que quando o olho
   focaliza uma imagem, esta é sobreposta nos quadrantes de cada retina (Figura
   4.18).
   A Figura 4.18 apresenta um diagrama que demonstra o mapeamento da
   imagem formada na retina em cada etapa do caminho óptico. Para
   compreendermos melhor esse diagrama, devemos observar o campo visual e a sua
   projeção e sobreposição em cada uma das retinas, onde a região central do campo
   visual (coloração mais escura) corresponde à região da imagem que será projetada
   na região foveal da retina, assim como as regiões periféricas do campo de visão
   respectivamente na periferia da retina.
   O primeiro tipo de mapeamento da imagem vai ocorrer já na própria retina
   que, como dissemos anteriormente, possui na região foveal uma concentração
   maior de fotorreceptores (cones). Como a dimensão dos campos receptivos
   ganglionares é menor nessa região, de modo a favorecer o tamanho dessa região
   no mapa, ocorre uma distorção ampliando essa região no mapa.
   131
   CAPÍTULO 4
   Região central
   Região periférica
   intermediária
   Campo Visual
   Região periférica
   extrema
   Imagem
   projetada na
   retina
   Mapeamento da
   retina no LGN
   Mapeamento da
   retina no córtex
   visual primário
   Fig. – 4.18 – Diagrama da estratégia de mapeamento da imagem ao longo do
   caminho óptico.
   No quiasma óptico ocorre a integração dos dois mapas visuais. Se
   dividirmos o campo visual em duas partes (direita e esquerda), a parte esquerda do
   campo visual é projetada na porção nasal da retina do olho esquerdo e na temporal
PA da retina do olho direito ao passo que a parte direita do campo visual na porção
   nasal da retina do olho direito e na temporal da retina esquerda. Deste modo,
   teremos em cada retina informação sobre as duas partes do campo visual (direita e
   esquerda). Quando o nervo óptico de cada uma das retinas chega até o quiasma
   óptico, as imagens do campo visual são integradas e o mapa de cada retina
   separado, de forma que toda a informação referente ao lado esquerdo do campo
   visual, integrada com informações de ambas retinas, se dirija ao hemisfério direito
   do cérebro, acontecendo o mesmo com o outro lado, que se integra e dirige-se para
   o hemisfério esquerdo.
   Os mapas correspondentes a cada lado do campo visual (esquerdo e
   132
   OS CAMINHOS PARALELOS DA VISÃO
   direito), são então enviados até o LGN pelo trato óptico. Nas células do LGN a
   retina continua mapeada, embora esse mapeamento seja relativo ao topográfico, a
   sua distribuição difere, devido à quantidade maior de células voltadas a região
   central (mácula e fóvea). A partir do LGN, as informações visuais são transmitidas
   para o córtex visual primário. As células do córtex visual continuam mapeando
   topograficamente a retina. Esse mapeamento é demostrado a partir da análise de
   lesões de V1 [Zeki, 1993], assim como dos campos receptivos. No caso dos
   campos receptivos, verifica-se que células adjacentes em V1 apresentam campos
   receptivos adjacentes, comprovando a manutenção do mapeamento da retina no
   córtex, sempre lembrando que ocorre uma distorção devido a uma super-
   representação celular da região foveal. Além de V1 outras regiões do córtex visual
   também apresentam em suas células o mapeamento topográfico da imagem
   correspondente à retina, no entanto observa-se que à medida que a informação
   caminha de V1 para as regiões seguintes, os campos receptivos, embora
   continuem adjacentes, aumentam de tamanho, caracterizando uma maior abstração
   de informação [Zeki, 1993].
   4.6.3.1 – NÚCLEO GENICULADO LATERAL
   O Núcleo Geniculado Lateral ou LGN (do inglês "Lateral Geniculate
   Nucleus"), é um núcleo talâmico que faz a mediação entre a retina e o córtex visual
   primário, aqui as informações transmitidas pela retina sofrem a primeira conexão
   sináptica. Conforme comentamos anteriormente, o mesmo mapeamento celular das
   informações visuais transmitidas pela retina é mantido nesse núcleo, de forma
   precisa. Em relação ao processamento realizado pelo LGN, foram detectadas
   respostas em suas células em relação a impulsos cromáticos e iluminação difusa,
   no entanto existem evidências de que ocorram outros tipos de processamentos
   [Costa, 1996].
   Nesse trabalho estaremos interessados em duas características do LGN: (i)
   a segregação dos caminhos parvo e magno iniciados na retina e (ii) a distribuição e
   replicação do mapa visual para o córtex visual.
   133
   CAPÍTULO 4
   Camadas
   parvocelular
   Camadas
   magnocelular
   Fig. – 4.19 – Núcleo Geniculado Lateral [Hubel,1995].
   Conforme iremos comentar, o caminho visual como um todo é caracterizado
   pelo dualismo do caminho Parvo e Magno. Embora esses dois caminhos se iniciem
PA na retina, (nas células ganglionares da retina observa-se a existência de duas
   classes celulares, P e M) a divisão mais marcante ocorre no LGN, a qual pode ser
   observada não somente através da forma e função celulares mas também no nível
   da sua organização. O LGN é formado por seis camadas conforme podemos
   observar na Figura 4.19. Destas seis camadas, quatro são caracterizadas por
   células pequenas, parvocelulares, e duas camadas por células grandes, magno
   celulares [Hubel, 1995]. A Tabela 4.1 apresenta um resumo das características
   entre as células magno e parvo do LGN. Observando as características desta
   tabela, podemos concluir que o caminho magno possui características menos
   evoluídas que o caminho parvo. Isto pode ser notado principalmente pela diferença
   de resolução e velocidade de resposta.
   Característica
   Magno
   Parvo
   Tamanho do soma
   Menor
   Maior
   Sensibilidade a Cor
   Não
   Sim
   Resolução
   Baixa
   Alta
   Velocidade
   Rápidas e Transientes
   Lentas e Contínuas
   Contraste
   Mais Sensitivo
   Menos Sensitivo
   Tabela 4.1 – Principais diferenças entre as células magno e parvocelular.
   134
   OS CAMINHOS PARALELOS DA VISÃO
   Como segunda característica do LGN temos a distribuição e replicação do
   mapa visual para o córtex visual. Como vimos, o LGN é composto de seis camadas
   (4 parvo e 2 magno), cada olho sendo mapeado em 3 das 6 camadas (2 parvo e 1
   magno). Deste modo, a retina é mapeada três vezes no LGN [Livingstone & Hubel,
   1988]. Essa característica é especialmente importante para esse trabalho por
   evidenciar o paralelismo do sistema visual, onde podemos supor que, assim como
   nos sistemas computacionais, a natureza foi obrigada a fazer cópias, devido a
   necessidade de enviá-las a sistemas distintos que trabalharam com as informações
   de modo independente. A grande maioria das informações correspondentes aos
   mapas replicados do LGN são transmitidos para camadas distintas do córtex visual
   primário (V1), embora uma pequena parcela seja projetada em outras regiões [Zeki,
   1993].
   4.7 – O CÓRTEX VISUAL
   Embora, o processamento visual se inicie logo após a captação da imagem,
   nas células nervosas da retina, a grande maioria do processamento visual, ou seja,
   a abstração da informação visual em algo inteligível para o maquinário neural, é
   realizado pelo córtex visual. O córtex visual se localiza no lóbulo occiptal, (ver
   Figura 4.4), que se encontra na região posterior do cérebro ou, segundo a divisão
PA de Broadmann, nas áreas 17 e 18. Possui uma aparência bastante uniforme,
   podendo a uma primeira instância ser reveladas duas regiões: o córtex estriado e o
   córtex pré-estriado. O córtex pré-estriado, através de diferentes técnicas (ex:
   citoarquitetura e citocromo oxidase), quando analisado demonstra ser composto por
   quatro regiões distintas. Deste modo, o córtex visual é composto por cinco áreas,
   que apresentam características funcionais bem definidas, sendo cada uma delas
   respectivamente denominadas de: córtex visual estriado ou V1, córtex visual pré-
   estriado ou V2, V3, V4 e V5. Algumas dessas regiões apresentam estruturas bem
   definidas (como "blobs", colunas, "stripes", etc), que obedecem a uma hierarquia.
   Ao longo de todo o córtex visual sua espessura é formada por seis camadas de
   estratificação (citoarquiteturas), que são caracterizadas em termos de tipo e
   distribuição de células neurais.
   Nesta seção discutimos a organização, o funcionamento e as estratégias de
   paralelismo do córtex visual dos primatas.
   135
   CAPÍTULO 4
   4.7.1 – ESPECIALIZAÇÃO FUNCIONAL DO CÓRTEX
   VISUAL
   As informações transmitidas pelo LGN são enviadas para a área 17 de
   Broadmann, também conhecida como córtex visual primário, ou ainda V1, de onde
   prosseguem para as demais regiões corticais que constituem o córtex visual. As
   regiões do córtex visual apresentam uma modularização hierárquica. Entre as
   teorias a respeito da modularidade do córtex visual destaca-se a teoria da
   especialização funcional do córtex visual de Zeki e Shipp [Zeki & Shipp, 1988],
   segundo a qual o córtex visual é dividido em módulos, que são responsáveis por
   atributos específicos ou seja, especializados e agregados segundo a função que
   exercem no processamento visual. Estaremos especialmente interessados na teoria
   da especialização funcional do córtex visual. Também a levaremos em conta como
   inspiração biológica para alguns modelos apresentados futuramente neste trabalho.
   4.7.2 – NÍVEIS DE PARALELISMO
   Antes de avançarmos no caminho visual discorrendo sobre a organização
   do córtex visual comentaremos um pouco a respeito dos prováveis níveis de
   paralelismo cortical. Conforme veremos, não apenas o córtex visual, mas todo o
   córtex é massivamente paralelo. Conforme mostrado na Figura 4.20, o paralelismo
   do córtex visual se apresenta em múltiplas escalas. Na micro escala, ocorre
   paralelismo entre os neurônios; na escala intermediária entre regiões e sub-regiões
   corticais; e no topo da escala o macro paralelismo ocorre entre os dois hemisférios
   cerebrais.
   Diversas evidências apresentam o paralelismo em cada uma das escalas.
   Quanto ao nível celular, o paralelismo não tem novidade alguma, estando presente
   na própria natureza das células neurais, cuja principal característica é receber e
   integrar informações que chegam simultaneamente de diferentes células. Além
   disso, a velocidade de processamento é individualmente lenta nos neurônios,
   impossibilitando a existência de sistemas seriais complexos e velozes, como
   encontramos normalmente na maioria dos seres vivos. De fato o paralelismo
   encontrado na natureza das células nervosas tem motivado intensamente áreas
   como as redes neurais artificiais.
   Quanto ao paralelismo em macro escala, vivenciamos suas evidências todos
   136
   OS CAMINHOS PARALELOS DA VISÃO
PA os dias. O simples fato do cérebro possuir dois hemisférios é a maior prova desse
   paralelismo. Cada hemisfério do cérebro possui processamento independente e, do
   ponte de vista motor e sensorial, cada hemisfério é responsável por uma metade do
   corpo. De fato, a nossa própria arquitetura, composta por pares (membros, olhos,
   ouvidos, etc.), pode estar associada a essa composição. Do ponto de vista da visão
   cada hemisfério recebe informações e é responsável por uma metade do campo
   visual. A integração dos dois hemisférios é realizada pelo corpo caloso [Gazzaniga,
   1998].
   MICRO
   Entre células
   Estruturas de sub-regiões (ex: "blobs", "stripes")
   INTERMEDIÁRIO
   Entre sub-regiões
   Áreas corticais
   MACRO
   Hemisférios
   Fig. – 4.20 – Paralelismo em multi-escala.
   Neste trabalho estamos especialmente interessados no paralelismo entre
   regiões e sub - regiões corticais. As evidências que indicam o paralelismo entre as
   regiões corticais estão presentes nas conexões entre as áreas. Podemos observar
   que todas as regiões corticais enviam saídas para mais de uma região. A existência
   de saídas paralelas indicam a replicação de dados e o funcionamento de regiões
   em paralelo [Zeki, 1993]. Além de ocorrer concentrações nas conexões de saídas
   entre regiões, o mesmo acontece também entre sub-regiões, demonstrando as
   evidências de paralelismo nesse nível.
   O paralelismo entre as áreas, sub-áreas corticais e micro estruturas ("blobs",
   "stripes", etc.) visuais está estreitamente relacionado com a teoria da
   especialização funcional. Assim as regiões especializadas em atributos diferentes
   estariam executando processamento das informações em paralelo. A primeira
   evidência para comprovar esse fato ocorre já na conexão do LGN com o córtex
   visual estriado ou V1, onde a retina é replicada 3 vezes (2 cópias para o caminho
   Parvo e 1 para o magno), onde cada cópia é enviada para uma sub-área distinta de
   V1, comprovando a existência do paralelismo entre suas sub-áreas.
   137
   CAPÍTULO 4
   O mesmo tipo de paralelismo pode ser observado no córtex visual pré-
   estriado ou V2. Depois de processado em V1, as informações visuais são enviadas
   para V2. Novamente, três cópias da retina são enviadas para três regiões distintas
   em V2, confirmando uma arquitetura semelhante a V1. Observa-se que cada
   milímetro de V1 envia fibras anatomicamente separadas para diferentes áreas do
   córtex pré-estriado. Essas fibras possuem diferentes diâmetros, o que indica que o
   sinal é transmitido em velocidades diferentes, evidenciando o sincronismo (cada
   área recebe os sinais em tempos diferentes). Ainda quanto ao paralelismo entre as
   sub-áreas de V1 e V2 (blobs, interblobs, e faixas) observa-se que estas formam
   conjuntos de arranjos repetidos, onde cada conjunto é formado por diversas
   estruturas replicadas, indicando a ocorrência de paralelismo dentro de uma sub-
   área.
   Além de enviar sinais para o córtex pré-estriado, o córtex estriado (V1) envia
   mapas de informação visual para as áreas V3, V4 e V5 simultaneamente. O mesmo
   ocorre com a área V2, que também transmite para essas regiões. Essa arquitetura
PA de conexões apresenta as evidências de paralelismo entre as áreas. Conforme
   vamos apresentar futuramenovo campo receptivo, semelhante as células simples e
   complexas, é seletivo à orientação. No entanto, além da orientação sua resposta
   depende do comprimento do estímulo e, assim como as células complexas, é
   indiferente a posição do estímulo. As células hipercomplexas recebem conexão das
   células complexas. Devido as suas características devem haver conexões
   inibitórias operando em conjunto com as excitatórias, a fim de possibilitar a
   seletividade ao comprimento do estímulo.
   Quando marcada com citocromo oxidase, V2 também revela estruturas, no
   entanto elas são bastante diferentes das estruturas que comentamos na seção
   anterior. Conforme podemos observar na Figura 4.28, a arquitetura citocromo
   oxidase de V2 é apresentada na forma de tiras ou faixas paralelas que formam um
   ângulo quase perpendicular com V1. As faixas são formadas por três conjuntos
   (finas, grossas e pálidas), que ficam arranjados de forma intercalada.
   147
   CAPÍTULO 4
   V2
   V1
   Fig. – 4.28 – Regiões V1 e V2 do macaco esquilo marcadas por citocromo
   oxidase [Zeki, 1993].
   As faixas finas e grossas se caracterizam por suas cores escuras e se
   diferenciam por sua espessura, a terceira faixa apresenta uma cor mais clara,
   sendo denominada por essa característica de pálida, sendo também conhecida
   como estrutura “entre faixas”. Os neurônios das faixas grossas recebem a maioria
   de suas conexões das células da camada 4B de V1 (caminho magno), e suas
   células possuem características semelhantes às desta camada de V1, possuindo
   seletividade a orientação, movimento e também apresentam disparidade ocular,
   função primordial para a visão estéreo.
   As células das estruturas "blobs" de V1 projetam parte de seus axônios para
   os neurônios das faixas finas. Os neurônios dessa estrutura não são sensíveis à
   orientação. No entanto, mais da metade deles responde ao comprimento de onda,
   assim como as células dos "blobs". No entanto, verifica-se a ocorrência de um
   número maior de células com oponência cromática dupla. Os neurônios das áreas
   entre "blobs" de V1, enviam parte de suas fibras para as estruturas pálidas ou entre
   faixas. Essa região possui células que são sensíveis à orientação, mas não
   apresentam sensibilidade à direção (movimento) ou cor.
   Os dois caminhos parvo e o caminho magno encontrados em V1, continuam
   presentes em V2. De fato, em V2 a divisão do caminho visual fica ainda mais
   evidente, uma vez que ela se encontra visível nas estruturas (faixas) desta área. Tal
   divisão é uma demonstração de paralelismo em V2, que apresenta três mapas com
   representações distintas, separadas, independentes e praticamente integrais da
PA retina [Zeki, 1993]. Cada mapa corresponde a uma estrutura (faixa) de V2, assim as
   faixas grossas apresentam um mapa de orientação e movimento (caminho magno),
   148
   OS CAMINHOS PARALELOS DA VISÃO
   as faixas finas um mapa cromático (parvo B) e as pálidas apresentam um mapa de
   disparidade e orientação relacionada a formas de alta definição (parvo I). Uma
   demonstração de que cada um dos mapas possui uma representação praticamente
   integral da retina está no fato de que estruturas adjacentes (faixas finas, grossa e
   pálidas) apresentam campos receptivos sobrepostos, indicando que representam a
   mesma região retinal. Cada um dos mapas de V2 é transmitido para áreas
   especializadas em atributos específicos. Deste modo a V2 assim como V1
   continuam exercendo o papel de segregação e distribuição de sinais.
   4.7.3.3 – ÁREAS V3, V4 E V5
   A exploração e mapeamento detalhado que ocorre na áreas V1 e V2 não
   ocorre em mais nenhuma outra área do córtex visual, uma vez que ainda não foi
   descoberta nenhuma técnica que permite revelar suas arquiteturas. Deste modo,
   pouco sabemos a respeito destas áreas. Os estudos fisiológicos, entretanto,
   demonstram que diferentemente de V1 e V2 que apresentam todas as modalidades
   dos atributos visuais (cor, movimento, forma e estéreo), essas áreas são mais
   especializadas, tornando responsáveis por atributos específicos. Esta é a situação
   de V5, que foi denominado de área de movimento [Zeki, 1993] [Costa, 1996] por
   possuir mais de 90% de suas células relacionadas com esse atributo.
   Além de ocorrer a especialização de toda a área para um atributo específico
   observamos também que as representações vão se tornando cada vez mais
   complexas e abstratas à medida em que o caminho visual vai adentrando as
   regiões corticais. A representação topográfica da retina não é mais encontrada em
   nenhuma área, de modo que a previsão do campo receptivo das células vizinhas
   não é mais tão óbvia quanto em V1 ou V2. Outra característica que vem comprovar
   o crescente nível de abstração é o tamanho dos campos receptivos, onde o
   tamanho do campo receptivo de V1 é menor do que o de V2 que é menor do que as
   demais áreas. A Figura 4.29 contém uma ilustração que apresenta a diferença de
   tamanho relativo e conseqüente abstração entre os campos receptivos de
   diferentes áreas do córtex visual.
   Quanto ao paralelismo nestas áreas, devido a falta de conhecimento sobre
   suas arquiteturas, pouco sabemos a respeito da concorrência dentro de uma única
   área, com exceção de V4, que recebe as duas divisões do caminho parvo (I e B),
   indicando a existência de no mínimo dois sistemas independentes. Subindo a
   escala do paralelismo e considerando a concorrência entre as áreas, V3, V4 e V5
   149
   CAPÍTULO 4
   trazem fortes evidências para este nível de paralelismo. Isso pode ser observado se
   considerarmos a independência entre essas áreas, e suas conexões. Deste modo
   os mapas das áreas V1 e V2 que, como vimos, são processados paralelamente, se
   estendem para essas áreas em caminhos distintos e consequentemente paralelos.
   Entraremos em maiores detalhes sobre esse assunto na próxima seção.
   V1
   V2
   (a)
   (a)
   (b)
PA (c)
   (c)
   (b)
   V3
   V5
   (a)
   (a)
   (b)
   (b)
   (c)
   Fig. – 4.29 – Comparação entre os campos receptivos das regiões V1, V2, V3 e
   V5, demonstrando o aumento do tamanho do campo receptivo e da abstração,
   no sentido de não ocorrer mais previsão do trajeto do campo receptivo em
   relação ao trajeto da penetração do eletrodo. (a) Região explorada e trajetória
   do eletrodo, (b) dimensão e disposição dos campos receptivos e (c) trajetória
   dos centros dos campos receptivos. [Zeki, 1993]
   150
   OS CAMINHOS PARALELOS DA VISÃO
   Conforme já comentamos, cada uma dessas áreas é responsável por um
   atributo ou modalidade de visão, o que as diferencia das áreas V1 e V2 que
   possuem representações de todas as modalidades e, consequentemente,
   designam o papel de segregadoras de sinal. Entretanto, evidências foram
   encontradas, especialmente na projeção de fibras para diversas áreas corticais, que
   indicam a ocorrência de segregação de sinal nas áreas especializadas (V3, V4 e
   V5). Assim, devemos supor que as modalidades representadas por cada uma
   dessas áreas deve ser ainda dividida em atributos distintos. Essa idéia se torna
   mais clara à medida em que vão sendo descobertas as áreas satélites (V5
   complexa, V4 complexa, etc.) [Zeki, 1993]. As áreas satélites são regiões próximas
   às áreas especializadas que processam a mesma modalidade da área principal. Em
   relação ao controle de paralelismo, é importante observar que essas áreas recebem
   poucas ou nenhuma projeção de V1, indicando que o controle dessas regiões é
   realizado pelas regiões especialistas. Deste modo a existência das áreas satélites
   contribui para a visão modular e estruturada do córtex visual, assim como seu
   arranjo sob o perfil de estratégias de paralelismo. A seguir vamos comentar as
   principais características de cada uma dessas áreas:
   Área V3 – É adjacente a V2 e recebe conexões das faixas grossas, assim como da
   camada 4B de V1. Essa área se caracteriza por apresentar a grande maioria de
   seus neurônios sensíveis à orientação, não possuir células com sensibilidade a
   estímulos cromáticos e por apresentar indicações de que esteja relacionada com o
   processamento de forma dinâmicas. Dentre as áreas especializadas, V3 é a que
   mantém traços de ordenações em relação a topografia da retina. Em alguns
   primatas, com exceção dos homens, foi encontrada uma subdivisão de V3,
   denominada de V3A. A principal diferença entre V3A e as demais partes de V3 é
   que ela não recebe conexões de V1.
   Área V4 – Recebe projeções das faixas finas e das pálidas de V2, assim como dos
   "blobs" de V1, deste modo as duas subdivisões do caminho parvo (B e I) são
   contidas nessa área. Embora, como as demais áreas especializadas, apresenta
   hegemonia quando marcada com citocromo oxidase, é possível traçar as conexões
   de seus neurônios através da utilização de algumas substâncias (entre elas as
   enzimas peroxidase). Essas conexões, quando analisadas, sugerem que os dois
PA caminhos parvos continuam divididos, uma vez que geram padrões de conexão
   151
   CAPÍTULO 4
   distintos. Deste modo, acredita-se que a divisão do caminho parvo continue em V4,
   indicando portanto a existência de dois sistemas independentes.
   Encontramos nessas áreas como principais características a seletividade à
   cor e à orientação apresentadas pela grande maioria das suas células, sendo que
   os estímulos são bem mais complexos que nas áreas anteriores. Em relação a
   sensibilidade cromática, em vez de simplesmente responder ao comprimento de
   onda, as células de V4 respondem à cor. Esse fenômeno é denominado de
   constância cromática e pode ser exemplificada pela impressão que temos quando
   um objeto embora iluminado com diferentes fontes de luz (comprimentos de onda
   diferentes) permanece com a mesma percepção de cor [Goldstein, 1989] [Zeki,
   1993]. Quanto à seletividade à orientação, V4 possui características de
   processamento de formas e objetos, que foram demonstradas através de
   experimentos realizados em macacos, através de estudos eletrofisiológicos de
   respostas celulares e lesões [Toveè, 1996]. V4 projeta a maior parte de suas fibras
   para o córtex visual temporal, onde aparenta ocorrer uma integração entre a cor e a
   forma dos objetos. Neurônios nessa região demonstraram ser seletivos a padrões e
   objetos complexos, como rostos [Rol s et al., 1994].
   Área V5 – Assim como V3, a área V5 recebe projeções do caminho magno, sendo
   parte da camada 4B de V1 e parte da faixa grossa de V2. Se caracteriza por
   possuir praticamente todos os seus neurônios seletivos ao movimento e não
   apresentar respostas aos estímulos cromáticos. Está associada ao processamento
   de informações de movimento e estéreo. V5 projeta principalmente para o córtex
   parietal, que demonstra ser uma região de continuidade do caminho magno,
   integrando movimento, estéreo e profundidade em representações espaciais.
   4.7.4 – ORGANIZAÇÃO DO CÓRTEX VISUAL
   Já discutimos algumas das áreas que compõem o córtex visual, assim como
   suas arquiteturas e, embora tenhamos comentado individualmente as conexões
   entre áreas, estaremos apresentando nesta seção as conexões e a organização do
   córtex visual como um todo, suas estratégias de paralelismo e de segregação e
   integração de sinais.
   152
   OS CAMINHOS PARALELOS DA VISÃO
   Córtex Inferotemporal
   Córtex Parietal
   V4
   V5
   (comp. de onda;
   (direção;
   orientação;
   orientação;
   disparidade)
   disparidade)
   V3
   (direção;
   orientação;
   disparidade)
   Pálidas
PA Faixas finas
   Faixas grossas
   (comp. de onda)
   (comp. de onda;
   (direção; orientação;
   orientação;
   disparidade)
   V2
   disparidade)
   blobs
   interblobs
   4B
   (comp. de onda)
   (comp. de onda;
   (direção;
   V1
   orientação;
   orientação;
   disparidade)
   disparidade)
   LGN parvocelular
   LGN magnocelular
   Cones
   Bastonetes
   Fig. – 4.30 – Mapa simplificado das interconexões do córtex visual. [Zeki,
   1993] [Zeki & Shipp, 1988] [Levine & Shefner, 1991] [Livingstone & Hubel,
   1988].
   153
   CAPÍTULO 4
   A Figura 4.30 apresenta um mapa simplificado das interconexões entre as
   áreas e sub-áreas do córtex visual. As considerações que faremos no decorrer
   deste seção serão referentes a ela. A primeira segregação no processo visual se
   inicia já na retina, que apresenta dois tipos de células especializadas para
   diferentes informações visuais. Mediante o dualismo dos fotorreceptores, que
   mantém as suas conexões separadas em camadas distintas do LGN, podemos
   concluir que além do paralelismo entre as células, a retina também apresenta dois
   sistemas distintos e independentes no seu maquinário neurológico.
   Conforme vimos na Seção 4.6.3, a visão tem um sofisticado mecanismo de
   integração das informações do campo visual que estão em cada uma das retinas,
   que ocorre com o cruzamento das fibras do nervo óptico no Quiasma óptico. Depois
   disso, é realizada a primeira conexão sináptica no núcleo lateral geniculado (LGN)
   onde, mais uma vez o sinal é segregado e consequentemente ocorre sua
   distribuição. Como vimos, o LGN possui dois grupos distintos de células (magno e
   parvo), que estão relacionados com os dois grupos de fotorreceptores da retina. Ele
   é composto por seis camadas das quais quatro correspondem ao caminho parvo
   celular e duas ao magno celular, os quais caracterizam três mapas distintos da
   retina.
   Se já tivemos uma divisão de caminhos entre parvo e magno, teremos ainda
   uma segregação do caminho parvo em LGN. Deste modo, ocorrem três projeções
   básicas de LGN para V1. As células do caminho magno projetam fibras para V1,
PA que serão relacionadas com o processamento realizado na camada 4B, e as
   células do caminho parvo, que foram segmentadas em dois mapas replicados da
   retina, projetam um mapa que será relacionado com as estruturas "blobs" e outro
   mapa que será relacionado à estrutura entre "blobs".
   O mapa da Figura 4.30 é muito simplificado e apresenta apenas as
   principais conexões realizadas. Embora apresentamos no mapa apenas um sentido
   para as conexões, essas são na sua grande maioria bi-laterais, sendo essa uma
   importante característica do processamento visual. Seus dois sentidos de
   transferência de informações durante o processamento é referenciada muitas vezes
   na literatura como “top-down” e “botton-up” [Levine, 1985]. O córtex visual primário,
   por exemplo, projeta fibras de volta para o LGN.
   Para cada hemisfério cerebral é enviada uma metade de cada retina que,
   juntas, compõem um lado do campo visual. O córtex visual primário possui uma
   arquitetura (colunas de dominância ocular) para o tratamento individual de cada
   154
   OS CAMINHOS PARALELOS DA VISÃO
   uma das retinas (binocularidade), que indica ser um sistema de integração entre as
   imagens de cada retina. O estímulo celular com preferência binocular não é
   encontrado em nenhuma outra área cortical, sugerindo que V1 seja realmente a
   área responsável pela junção desses sinais.
   Quanto à organização V1 apresenta três sistemas independentes, que são
   respectivos aos três caminhos incidentes nesta área ou seja, dois caminhos parvos,
   recebem o nome de parvo I (“interblob”) e parvo B (“blob”) e magno. Devido à
   independência, destino principal individual e seu aspecto funcional, acredita-se que
   eles sejam paralelos. Além do paralelismo entre os três caminhos, encontramos
   também, devido ao amplo estudo e exploração de V1, sub-estruturas replicadas
   para cada um dos caminhos replicados, indicando o paralelismo multi-escalar
   dentro dessa área.
   O córtex visual primário caracteriza-se como um segregador, distribuidor de
   sinais e provavelmente também como gerenciador ou escalonador, devido à
   diferença de diâmetro, que consequentemente influencia na velocidade de
   transmissão de suas fibras. Deste modo, V1 projeta fibras para diversas áreas
   corticais, dentro e fora do córtex visual, assim como projeções extra-corticais
   (culículo superior, LGN, etc.). Dentre as principais conexões de V1 destacam-se as
   projeções para V2 e para as áreas especialistas V3, V4 e V5. As conexões entre as
   áreas corticais em geral obedecem a padrões restritos, que indicam que os
   estímulos estão sendo transmitidos em conjunto através de mapas.
   A área V2 recebe três mapas de V1, relativos aos três caminhos (magno,
   parvo I e parvo B). Esses caminhos continuam em V2 como sistemas
   independentes e são associados a estruturas anatômicas que assemelham a faixas
   (faixas grossa, finas e pálidas). Assim como V1, V2 projeta fibras para todas as
   áreas especialistas do córtex visual (V3, V4 e V5). Embora não esteja representado
   no mapa da Figura 4.30, as áreas V3, V4 e V5 apresentam em suas proximidades
   áreas satélites, que processam os mesmos atributos e recebem a maior parte das
   fibras eferentes das áreas principais. As áreas satélites nos apresentam fortes
   indícios da distribuição de processamento que ocorre nas áreas V3, V4 e V5 [Zeki].
   Em função das áreas satélites especializadas, encontramos uma peculiar
   diferença entre as áreas V1 e V2. Embora possuam características semelhantes,
   como segregadoras de sinais, e ambas apresentam conexões com todas as regiões
   especializadas, somente V2 apresenta conexões com as áreas satélites de V3, V4
PA e V5.
   155
   CAPÍTULO 4
   Os caminhos visuais são projetados a partir de V1 e V2 para as áreas mais
   especializadas do córtex visual: V3, V4 e V5. Essas áreas se diferenciam de V1 e
   V2 por lidarem com atributos mais específicos e, consequentemente, por
   apresentarem apenas representações destes. O caminho magno, correspondente à
   camada 4B de V1 e faixas grossas de V2, é projetado para duas áreas
   especialistas: V3 e V5. A área V3 é principalmente responsável pelo
   processamento de formas dinâmicas e a área V5 por movimento. Os dois caminhos
   parvos (I e B), entretanto, são projetados para uma única área: V4. Essa área é
   responsável pelos processamentos cor (Parvo B) e formas de alta definição
   cromática (Parvo I).
   Cada uma das áreas especialistas trocam informações entre si. Essas
   informações permitem o enriquecimento da informação local com componentes
   processados pela outra área. Dentre as comunicações entre as áreas
   especializadas destacam-se as conexões entre V3 e V4. Segundo Zeki [Zeki, 1993],
   existem indicações que através dessas conexões é realizada a integração de sinais
   para o processamento de formas. Desta forma, V3, responsável pelo
   processamento de formas dinâmicas, enriquece seu processamento com os
   resultados de V4, responsável por formas cromáticas de alta definição, e vice-
   versa.
   A partir das áreas especialistas, a informação visual é transmitida para
   regiões mais profundas no córtex, ficando cada vez mais complexa e abstrata.
   Basicamente, encontramos dois caminhos principais que nos levam a dois sistemas
   de visão localizados respectivamente no córtex inferotemporal e no córtex parietal.
   Aparentemente essas conexões são extensões dos caminhos parvo e magno e são
   as bases da famosa doutrina “o que” e “onde”. Segundo essa doutrina, as
   informações visuais são separadas em duas primitivas básicas quando organizadas
   na memória associativa. Uma delas é responsável pelo processamento e
   armazenamento de todas as informações relativas à localização no espaço, e a
   outra, pelo processamento e armazenamento das informações relativas às
   propriedades físicas dos objetos [Kosslyn, 1996] [Hundert, 1995].
   A doutrina “o que – aonde” entretanto não é amplamente aceita no meio
   científico, sendo duramente criticada por alguns autores. Dentre as críticas,
   destaca-se a de Zeki [Zeki, 1993], que sugere que a doutrina constitua de um erro
   sistematicamente histórico, que ocorre na tentativa de neuro-cirurgiões
   simplificarem as estratégias corticais, devido ao limitado conhecimento de sua
   156
   OS CAMINHOS PARALELOS DA VISÃO
   constituição e funcionamento. Segundo Zeki, o mesmo ocorreu com a teoria da
   plasticidade cortical, que via o cérebro como uma caixa preta e sem nenhuma
   modularidade específica e também com a idéia de processamento linear da
   informação visual, defendida até ser contestada pelos experimentos de Hubel e
   Wiesel.
   4.7.5 – ESTRATÉGIAS DE INTEGRAÇÃO DA
   INFORMAÇÃO AO LONGO DO PERCURSO VISUAL
   Os diversos estudos sobre o córtex visual apresentam diversas noções de
   divisão de trabalho e de segregação funcional. A nossa experiência diária,
   visualizando um mundo uniforme diferente, nos leva a crer na unidade do campo
PA visual e de sua percepção, onde todos os atributos são processados
   simultaneamente. Para que essa percepção seja válida devem ocorrer sofisticados
   métodos e processos de integração de sinais. Levados pela lógica, podemos supor
   que deveria existir uma região mestre no córtex, que receberia e seria responsável
   pela integração de todas as informações. No entanto não existe uma região no
   córtex a qual todas as demais se reportam. Essa afirmativa é válida não apenas
   para o córtex visual, mas sim para todo o córtex.
   Muito pouco sabemos a respeito das estratégias de integração de sinais
   utilizadas pelo córtex. Mesmo no bem explorado córtex visual, ainda não temos
   nenhum perfil de integração e, diferentemente dos processos de segregação de
   sinais que foram vastamente estudados, o que é feito são apenas especulações
   sobre essas estratégias. Vamos a seguir apresentar algumas supostas estratégias
   de integração realizada pelo córtex visual. Com base em algumas evidências,
   podemos supor três estratégias básicas para a integração dos estímulos visuais:
   Aumento do tamanho do campo receptivo, e permitindo que as células estejam
   hábeis a coletar informações de partes maiores do campo visual e que
   respondam ao conjunto de seus estímulos. Observamos, que à medida que
   vamos adentrando o percurso visual, percebemos que as células ficam com seus
   campos receptivos cada vez maiores, de modo que o campo receptivo das
   células de V1 são maiores que as do LGN, que por sua vez os campos
   receptivos de V2 são maiores que V1 e menores que V3, que por sua vez é
   menor que V5. Finalmente quando comparamos os campos receptivos das
   células do córtex inferotemporal e parietal notamos que são maiores que as das
   157
   CAPÍTULO 4
   áreas do córtex visual.
   Aumento da complexidade do estímulo. Ocorre simultaneamente com a primeira (i),
   uma vez que as células aumentam seus campos receptivos, automaticamente
   elas tratam com sinais cada vez mais complexos e propriedades mais
   específicas. A Figura 4.31 apresenta exemplos das estratégias (i) e (i ).
   Unificação dos sinais de diferentes fontes, representando diferentes atributos
   visuais (ex: forma e movimento). A unificação não significa necessariamente que
   os sinais devam ser direcionados para uma célula específica, uma possibilidade
   é que a unificação venha a ser realizado por células distantes respondendo em
   sincronismo a um evento em comum [Zeki, 1993].
   158
   OS CAMINHOS PARALELOS DA VISÃO
   (a)
   (b)
   (c)
   Fig. – 4.31 – Estratégias de integração de sinal visual através do aumento do
   campo receptivo e da complexidade do estímulo. (a) (reta) Células centro-
   periferia do LGN e células simples de V1. (b) (cor) Projeção das células dos
   "blobs" em V1 para faixas finas em V2 e finalmente em V4, observar a
   pirâmide de projeção. (c) (movimento) Enquanto em V1 as células são
   estimuladas pela orientação das bordas independentes (um vetor de direção
   para cada lado) ocorre a integração em V5, de modo que suas células são
   capazes de fornecer a direção do objeto. [Zeki, 1993]
   159
   CAPÍTULO 4
PA 4.7.6 – INTEGRAÇÃO DA INFORMAÇÃO DOS DOIS
   HEMISFÉRIOS
   O nível mais alto de paralelismo do processamento visual que encontramos
   no córtex é demonstrado pela divisão do cérebro em dois hemisférios. Como já
   apresentamos, a aquisição de todo o campo visual é realizada em cada uma das
   retinas e reorganizadas (quiasma óptico) de modo que o córtex visual de cada
   hemisfério receba estímulos correspondentes a uma metade do campo visual.
   Embora exista essa divisão no campo visual, o sistema de visão possui uma
   integração perfeita, sendo que nos é impossível percebê-la.
   O corpo caloso é um corpúsculo formado pela aglomeração de fibras, cuja
   principal característica é a conexão dos dois hemisférios. Através do corpo caloso
   as áreas pares de cada hemisfério são interconectadas e assim o cérebro é
   integrado. Em geral, as conexões são organizadas de forma bem definida e distinta
   em uma das áreas corticais, formando um bom referencial sobre o número e a
   divisão destas. Cada área é conectada separadamente com sua correspondente no
   hemisfério oposto, exatamente porque as duas metades (uma em cada hemisfério)
   possuem mecanismos que são diferentes das outras áreas e assim requerem
   conexões separadas.
   Como sabemos, o córtex visual estriado possui um mapeamento topográfico
   preciso da retina. Deste modo, seria de se esperar que apenas as regiões
   posicionadas na linha divisória do campo visual possuíssem conexões entre
   hemisférios. De fato é exatamente isso que ocorre nas conexões entre o córtex
   visual primário e o corpo caloso, onde a sua regularidade traça exatamente a linha
   do meridiano vertical do campo visual em cada hemisfério.
   Como o córtex visual primário, V2 possui um mapeamento topográfico
   preciso da retina, apresentando também conexões com o corpo caloso, presentes
   apenas nas células da linha divisória do campo visual. Desta forma, seu traçado
   corresponde exatamente ao meridiano vertical do campo visual. À medida que
   avançamos no córtex visual as áreas se tornam mais específicas e abstratas e,
   consequentemente, seus mapas ficam cada vez mais desorganizados em relação à
   topografia da retina. Assim, a conexão das áreas com o corpo caloso não formam
   mais uma trilha de indicação do meridiano do campo visual, já que as células
   correspondentes a essa região encontram-se espalhadas. Enquanto V1 e V2
   apresentam uma estrutura muito definida, traçando o limiar do campo visual, V3
   160
   OS CAMINHOS PARALELOS DA VISÃO
   possui conexões espalhadas e, V4 e V5 não possuem nenhum tipo de ordenação
   clara na conexão com o corpo caloso.
   Além de caracterizar as diferentes áreas espalhadas pelo córtex e definir a
   precisão do mapeamento topográfico da retina nas diferentes áreas do córtex
   visual, o corpo caloso também evidencia o paralelismo entre hemisférios e entre
   áreas. O primeiro caso é bastante óbvio, a simples existência de dois hemisférios
   por si só é uma prova de paralelismo nesse nível. Em relação ao paralelismo entre
   áreas, para que ela ocorra é necessário que as diferentes áreas do córtex visual
   apresentem uma representação completa do campo visual. A conexão com o corpo
   caloso, independente entre cada uma das áreas é a indicação de que cada área
   possui sua própria representação completa do campo visual através da conexão
   com seu par no outro hemisfério, indicando consequentemente sua independência
   e paralelismo.
   161
PA CAPÍTULO 4
   162
   CAPÍTULO
   5
   CYVIS-1 E YNERGOS
   163
   CAPÍTULO 5
   164
   Cyvis-1 e ynergos
   CAPÍTULO 5 – CYVIS-1 E YNERGOS
   5.1 – INTRODUÇÃO
   Neste capítulo iremos apresentar os projetos que motivaram e constituíram
   os princípios para o desenvolvimento do trabalho apresentado nesta tese.
   Conforme já apresentamos, uma das bases da visão natural é o seu
   processamento paralelo. Entretanto, a visão artificial não vem utilizando este
   recurso como prioridade de pesquisa. A vasta maioria da literatura sobre visão
   computacional, visão artificial e processamento de imagens tem uma forte
   tendência seqüencial. Isso se deve principalmente aos fundamentos dessas áreas,
   se tomarmos os livros mais clássicos, e entre eles a bíblia da visão, o livro “Vision”
   de David Marr [Marr, 1982]. Embora siga a linha da inspiração biológica, Marr, não
   considerou esse recurso, que como vimos, foi plenamente explorado pela natureza
   nos sistemas de visão.
   Apresentaremos neste capítulo dois projetos audaciosos do grupo de visão
   cibernética do IFSC - USP. O primeiro é o Cyvis-1, um sistema de visão versátil,
   fortemente inspirado em biologia, mais especificamente no modelo da
   especialização funcional do córtex visual. Assim como os sistemas biológicos, o
   Cyvis-1 se caracteriza pelo perfil modular, onde cada módulo é especializado em
   um atributo visual. Assim como o modelo biológico, o projeto é baseado em
   processamento paralelo. Apresentaremos também alguns projetos similares ao
   Cyvis-1 encontrados na literatura e faremos uma breve comparação explorando as
   vantagens e desvantagens dos sistemas. O outro projeto, ynergos, é um ambiente
   e laboratório de desenvolvimento e análise de técnicas de visão e processamento
   de imagens, que tem como objetivo auxiliar a pesquisa, implementação,
   caracterização, validação de métodos e realização de experimentos nestas áreas.
   Ambos os projetos possuem em comum o processamento paralelo de
   algoritmos e sistemas de visão. A filosofia de processamento linear agregada a
   visão, a falta de pesquisas abrangentes de paralelismo nessa área, assim como a
   necessidade de ferramentas de desenvolvimento, controle e análise de sistemas
   paralelos para programadores não-especializados em computação paralela, foram
   165
   CAPÍTULO 5
   alguns dos principais fatores de motivação do nosso trabalho, que serão
   comentados na parte final deste capítulo.
   5.2 – O PROJETO CYVIS-1
   Um dos maiores desafios, senão o maior, na visão artificial, é o
   desenvolvimento de visão versátil. Entendemos por visão versátil a capacidade de
   um sistema se adaptar facilmente a diferentes situações e ambientes, assim como
   realizar o reconhecimento visual de objetos diversos. Ao longo da evolução a
   natureza desenvolveu uma quantidade enorme e variada de sistemas de visão
   versáteis, como os sistemas de visão dos vertebrados. A grande maioria dos
PA vertebrados, mesmo os mais primitivos, possuem sistemas de visão capazes de
   responder a uma grande variedade de objetos, nas mais diversas situações e
   ambientes. A despeito dos muitos avanços tecnológicos e científicos, os sistemas
   de visão que somos capazes de construir atualmente, se compararmos sob o
   aspecto da versatilidade no reconhecimento de objetos, são medíocres em relação
   aos sistemas de visão dos mais primitivos vertebrados, e até mesmo de
   invertebrados.
   Normalmente a abordagem clássica adotada pelos sistemas de visão é a
   exploração de poucos atributos e seu tratamento individual, elaborando algoritmos
   cada vez mais sofisticados, mas isolados. Muito temos que aprender com a
   natureza, e de fato diversos algoritmos eficientes de visão foram nela inspirados.
   Entretanto, observando as divergências entre os sistemas naturais e os artificiais,
   podemos perceber nos sistemas artificiais de visão ausências de algumas
   estratégias utilizadas pela natureza com êxito, das quais podemos citar:
   Estratégias de processamento em duplo sentido, não apenas indo do baixo nível
   para alto nível, mas também o sentiddo
   processamento que realimente o sistema com conhecimento.
   O processamento da informação no LLIS é baseado em regras, onde as
   informações referentes ao processamento são todas analisadas com comparações
   lógicas: (e) e (não-e). Quando as operações lógicas são verdadeiras então os
   predicados, ou seja ações aliadas aos operadores, são executados.
   Inicializador
   Análise de linhas
   S
   Análise de regiões
   L
   T
   T
   Análise de área
   M
   M
   Atenção de foco
   Supervisor
   Fig. - 5.7 - Diagrama em blocos do sistema LLIS.
   O LLIS é formado de módulos que compõem os processos de controle e
   segmentação, assim como duas memórias associativas, conforme apresentado na
   figura 5.7. Os dados referentes à imagem de entrada, segmentação e estrutura de
   saída são armazenados na memória STM (Memória de curta duração do inglês:
   Short Term Memory), ao passo que na memória LTM (Memória de longa duração
   do inglês: Long Term Memory) é armazenado o conhecimento do sistema a
   respeito do processamento de baixo nível (regras lógicas sobre o comportamento
   dos dados), assim como as regras referentes as estratégias de controle. Os dados
   contidos na STM podem ser alterados durante o processamento, apagados ou
   ainda pode-se inserir dados, ao passo que a memória LTM é fixa, podendo ser
   188
   Cyvis-1 e ynergos
   programada com as regras de comportamento antes do processamento.
PA Inicialmente a imagem situada na STM é processada e binarizada,
   resultando pontos que são agrupados em linhas e produzem o primeiro mapa da
   imagem. Estes resultados são armazenados também na STM. Uma área inicial do
   mapa é então selecionada, e é realizado o processamento de mais alto nível que
   determinará características da região, tais como: saturação, cor, posicionamento e
   relacionamento entre os objetos (linhas e regiões). Este processamento irá resultar
   em características de análise e comparação tais como: adjacência entre as regiões,
   relacionamentos como em frente de, atrás, em paralelo, a esquerda, a direita e etc.,
   para as linhas e relacionamento entre linhas e regiões tais como: a região está a
   esquerda ou a direita da linha, a linha toca ou interseciona a região e etc. E ainda
   em relação ao comportamento de áreas: com textura, nebulosa e a sua
   proximidade com linhas, etc.
   Após determinadas estas dependências lógicas, que podemos denominar
   de processamento de baixo nível, é realizado o processamento de alto nível (ao
   qual é dedicado de fato o LLIS), que é realizado pelo modelo baseado em regras.
   As regras são divididas em três classes: regras de estratégia, regras de controle e
   meta regras e regras de conhecimento (região, linha e análise de área), que ficam
   alojadas na memória LTM. As regras de estratégia, e as regras de controle e meta
   regras não executam nenhuma alteração na memória STM, elas são destinadas ao
   controle dos processos de ação, que operam as regras de conhecimento.
   As regras de conhecimento são responsáveis pelo processamento da
   segmentação. Nelas são tomados pares ou conjuntos de informações de
   propriedades referentes a linhas, regiões e áreas, sendo então comparadas
   logicamente. Caso as situações lógicas satisfaçam à decisão lógica, então é
   executada a ação respectiva. O funcionamento das regras é bastante simples,
   conforme podemos observar na figura 5.8, onde temos o formato e um exemplo de
   uma regra. Por um lado nós temos um conjunto de combinações lógicas, e do
   outro, a ação executada caso a condição seja satisfeita. Conforme já comentamos,
   as regras ficam alojadas na memória LTM e executam ações sobre a memória
   STM, com dados também armazenados na STM.
   CONDITION.AND.CONDITION...............AND.CONDITION - ACTIONS
   189
   CAPÍTULO 5
   IF: THERE IS A LOW DIFFERENCE IN REGION FEATURE 1
   THERE IS A LOW DIFFERENCE IN REGION FEATURE 2
   THERE IS A LOW DIFFERENCE IN REGION FEATURE 3
   THEN: MERGE THE REGIONS
   Fig. - 5.8 - Exemplo de regras do modelo.
   Tendo comentado o modelo baseado em regras, voltemos ao sistema. Após
   realizada a primeira segmentação (baixo nível) e definidos os mapas, o sistema fica
   sob controle do módulo supervisor (figura 5.7). O módulo de foco de atenção
   seleciona uma determinada área, e é realizado o processamento através das regras
   pelos módulos de análise de linha, região e área (figura 5.7), que irão alterando
   dados na memória STM que realimenta o sistema. Após finalizado o
   processamento em uma área de atenção, é iniciado o processamento em uma nova
   área de atenção, e assim sucessivamente. Após ter visitado todas as áreas de
   atenção da imagem, o sistema determina então se existe a necessidade de
   processar novas áreas, e caso afirmativo, repete a visita a essas áreas. Caso o
   sistema já tenha visitado todos os focos (áreas) de atenção, o sistema processa o
   mapa da imagem como um todo, e é finalizada a segmentação da imagem.
PA 5.3.1.1 - PONTOS POSITIVOS DO LLIS
   A primeira característica interessante do sistema é a elaboração de uma
   estrutura de dados, na qual é armazenado um sistema de conhecimento, que pode
   ser compartilhado entre diferentes heurísticas. No caso do LLIS informações sobre
   linhas e regiões compartilham a mesma estrutura de dados. Essa estrutura torna-se
   ainda mais interessante por apresentar a possibilidade de ser flexível a outras
   heurísticas. A combinação de heurísticas no processamento, no caso
   processamento de linha e região é um outro ponto forte da proposta.
   Uma outra abordagem muito interessante adotada pelo sistema é a seleção
   de determinadas áreas da imagem, e a concentração da atenção, ou enfoque de
   processamento, nestas áreas. Esta abordagem, além de ter fortes bases biológicas
   [Kosslyn, 1996] [Goldstein, 1989] [Bal ard & Brown, 1982], também possui um
   interessante mecanismo de realimentação ou fluxo inverso de informações em
   190
   Cyvis-1 e ynergos
   tempo de execução. Como o resultado das regras alteraram a mesma memória em
   que os dados das características da imagem são armazenados, ocorre então uma
   realimentação natural do sistema, ocorrendo um somatório de processamento, que
   pode vir a enriquecer a qualidade de processamento.
   5.3.1.2 - PONTOS NEGATIVOS DO LLIS
   Um dos maiores desafios da visão computacional é a segmentação de baixo
   nível. Determinar a posição de uma linha, onde ela começa, onde termina, se faz
   laço, se é paralela a outra, se apresenta descontinuidade, e se uma área apresenta
   uma determinada textura, ou possui uma segmentação nebulosa, ou ainda obter as
   características de regiões, é uma tarefa extremamente difícil e que se encontra
   plenamente aberta para pesquisa. Na proposta do LLIS, é necessário uma pré-
   segmentação na imagem, de modo que devolva as propriedades e características
   de retas e regiões da imagem. Porém, a extração destas informações é algo longe
   de ser trivial, não existindo ainda algoritmo capaz de fazê-lo com a eficiência
   exigida pelo suposto modelo.
   É nesse aspecto que encontramos as principais falhas no modelo do LLIS.
   O modelo baseado em regras, não segmenta de fato as imagens, apenas executa
   operações lógicas de alto nível em dados já extraídos desta. Os autores não
   comentam como um algoritmo consegue extrair informações da imagem original
   com performance suficiente, para operar a gramática de regras apresentada no
   artigo.
   5.3.1.3 - LLIS VERSUS CYVIS-1
   Uma das semelhanças que podemos observar entre a proposta do sistema
   Cyvis-1 e o LLIS é o uso do processamento modular. O LLIS apresenta módulos de
   processamento específicos para linhas, regiões e áreas, do mesmo modo como o
   Cyvis-1, que é dividido em módulos específicos a uma determinada característica
   (cor, estéreo, borda, textura). Ainda uma outra semelhança é a utilização de um
   módulo de controle, para supervisionar os módulos de processamento. Embora
   possuam estas semelhanças, a abordagem difere, uma vez que o Cyvis-1 busca o
   paralelismo, solução adotada pelo sistema de visão natural (Capítulo 4) para
   resolver diversas questões, entre elas a integração, sendo que o LLIS é
   essencialmente serial devido a sua modelagem, baseada em regras e predicados
   191
   CAPÍTULO 5
   de inteligência artificial convencional.
PA Além de possuírem módulos distintos para diferentes tipos de
   processamento, uma outra similaridade entre os sistemas é a tentativa de
   compartilhamento de informações entre os módulos a fim de melhorar a
   interpretação e processamento da imagem. Porém a maneira com que é realizada a
   abordagem é um pouco diferenciada. O LLIS tem uma memória global
   compartilhada (STM) onde os dados do processamento além de estarem
   compartilhados, ainda dividem a mesma estrutura de dados, ao passo que o
   Cyvis-1 possui além de uma base de conhecimento geral, uma memória distribuída
   para cada módulo, onde as informações são trocadas a partir de mensagens entre
   os módulos e o supervisor.
   5.3.2 - SISTEMA DE VISÃO DO MIT (MASSACHUSSETTS
   INSTITUTE OF TECHNOLOGY)
   O sistema de Visão do MIT, apresentado por Poggio e Weinshal [Poggio &
   Weinshal , 1993], denominado MIT Vision Machine, possui inspiração parecida com
   o Cyvis-1, sendo também baseado em paralelismo e inspirado pela natureza. Os
   sistemas biológicos, ao realizarem o processamento visual (em seus primeiros
   estágios), integram diferentes atributos de processamento da cena para realizar a
   interpretação. Tal fato é constatado na literatura, e os autores acreditam ser esta a
   chave para as características de flexibilidade, reaproveitamento e robustez dos
   sistemas biológicos. Inspirado na integração de diferentes atributos visuais,
   realizado pelos sistemas biológicos, foi proposto este sistema, sendo sua proposta
   a integração e desenvolvimento de algoritmos paralelos para visão.
   A organização geral do sistema pode ser observada na figura 5.9. Uma das
   intenções do sistema é explorar o desenvolvimento de algoritmos paralelos para
   visão. Desta forma, as imagens são processadas paralelamente por diferentes
   algoritmos e módulos, que correspondem a diferentes propriedades visuais. Além
   dos módulos responsáveis por diferentes atributos sendo executados em paralelo,
   ainda cada um dos algoritmos que compõe os módulo são igualmente executados
   simultaneamente, constituindo uma abordagem altamente paralela. O sistema
   possui como plataforma um computador massivamente paralelo do MIT, o
   Connection Machine [Almasi & Gottlieb, 1994].
   Os módulos são caracterizados pelos diferentes atributos de visão
   192
   Cyvis-1 e ynergos
   utilizados, que nesse sistema são: processamento de borda, estéreo, cor, textura e
   movimento. Os módulos são executados em concorrência e ao final do
   processamento é gerado um mapa de descontinuidade global ou mapa resultante,
   que é formado pela integração dos mapas de cada módulo, com as informações
   complementares de cada um.
   Imagem
   original
   Cor
   Textura
   Borda
   Movimento
   Estéreo
   nhas e processos
   ntínuos
   Li
   co
PA Descontinuidades
   Mapa
   físicas rotuladas
   final
   Fig. - 5.9 - Diagrama da organização da máquina de visão do MIT.
   A seguir vamos descrever sucintamente cada um dos módulos de
   processamento do sistema:
   Detecção de borda - O módulo de detecção de borda procura encontrar
   descontinuidades no brilho da imagem. Para realizar este processamento são
   utilizados dois algoritmos no sistema, o primeiro é o cruzamento por zero do
   Laplaciano da Gaussiana [Marr, 1982], e o segundo na convolução do template de
   Canny [Gonzalez & Woods, 1993] [Parker, 1997]. O cruzamento por zero, pode ser
   usado pelo módulo de estéreo e movimento, ao passo que o Canny, é a entrada
   para a integração utilizando os campos markovianos.
   Estéreo - Para a realização de processamento de visão Estéreo, o sistema requer
   dois dispositivos de aquisição de imagem diferentes. Estes deverão focalizar a
   mesma cena porém através de ângulos diferentes. Embora a cena seja a mesma,
   193
   CAPÍTULO 5
   devido a binocularidade, ocorrerá disparidades entre as imagens. O módulo de
   estéreo consiste em encontrar essas disparidades nas imagens, gerando deste
   modo um mapa das disparidades.
   Movimento - O módulo de movimento objetiva o cálculo do campo de fluxo óptico.
   Este procedimento consiste em armazenar um vetor de imagens, e comparar suas
   disparidades resultantes do movimento. Por exemplo, considere que, temos uma
   imagem E(x,y) e uma outra imagem, formada no instante seguinte, E + t (x,y).
   Logo, quando é encontrada a disparidade entre E(x,y) e E + t (x,y) é obtido um
   mapa de descontinuidade contendo as bordas dos objetos em movimento.
   Cor - O módulo de cor consiste em encontrar as fronteiras da superfície da função
   de reflectância espectral, ou seja descontinuidades cromáticas da imagem.
   Textura - O módulo de textura dedica-se a encontrar as descontinuidades entre
   regiões preenchidas por padrões semelhantes. O resultado deste processo
   converge num mapa das fronteiras das regiões com textura. Nesse módulo, é
   utilizado uma versão simplificada do algoritmo paralelo de textura desenvolvido por
   Voorhees e Poggio [Voorhees & Poggio, 1988].
   Os módulos são processados paralelamente originando mapas de
   descontinuidade. Cada um dos mapas contém informações características (de
   baixo nível) de cada um dos atributos respectivos a cada módulo. O objetivo do
   sistema é integrar estes módulos a fim de obter um mapa de descontinuidade geral,
   enriquecido com cada uma das características específicas de cada um dos
   atributos (cor, borda, estéreo, movimento e textura). Como resultado desta
   integração temos um mapa de bordas da imagem original. Embora existam
   inúmeros algoritmos que obtenham mapas de bordas, a contribuição dada pelo
   sistema de Visão do MIT é um mapa enriquecido pela integração de inúmeros
   atributos, contendo deste modo concentrada e filtrada diversas informações. O
   resultado proveniente do processamento de cada um dos atributos é esparso e
   ruidoso. Com a adoção do modelo MRF é realizada a integração dos diferentes
   atributos e simultaneamente a filtragem do ruído, originando um mapa mais
   confiável.
   194
PA Cyvis-1 e ynergos
   5.3.2.1 - CYVIS-1 VERSUS MÁQUINA DE VISÃO
   Embora tanto o Cyvis-1 quanto o Vision Machine tenham o mesmo propósito, ou
   seja, incorporar diferentes atributos para realizar o processamento de imagem, a
   filosofia, estrutura e estratégia de cada um dos sistemas é bastante divergente.
   Discutiremos as diferenças entre os dois sistemas relativamente aos seguintes
   tópicos: Estrutura, Hierarquia, Organização de Dados e Aspectos Computacionais.
   5.3.2.1.1 - Estrutura
   A estrutura dos dois sistemas a grosso modo é bastante parecida: ambos
   são sistemas de visão computacional de baixo nível, tempo real e com plataforma
   computacional paralela. Os dois sistemas também processam diferentes atributos
   da mesma imagem, e tentam integrá-los na obtenção de um único resultado, e para
   cada um desses atributos, os sistemas adotam módulos e algoritmos
   independentes. O que realmente diverge, é a organização e transferência de dados,
   assim como a hierarquia dos sistemas.
   No sistema MIT Vision Machine, os módulos não apresentam ordem
   hierárquica definida. Os módulos são processados paralelamente, sem
   dependência de dados, de maneira síncrona. Ao final do processamento de todos
   os módulos é então realizada a integração de seus resultados para obtenção de um
   mapa de resultados. Nessa abordagem não existe hierarquia de processos nem
   mesmo de dados. A única preocupação do sistema é a integração estatística dos
   resultados através do modelo de campos aleatórios de Markov (MRF).
   O Cyvis-1 apresenta ordem hierárquica significativa. Os módulos possuem
   diferentes níveis hierárquicos e ocorre dependência de dados entre eles. Deste
   modo, por exemplo, um módulo de detecção de borda de nível hierárquico mais alto
   não poderá ser executado sem o resultado de um módulo de cor, com nível
   hierárquico inferior, já que num nível hierárquico mais alto, o módulo de detecção
   de borda necessita de informações cromáticas da imagem.
   Deste modo, a estratégia de integração entre os sistemas também é
   bastante diferenciada. Se no Vision Machine a integração é resolvida num único
   processo matemático (MRF), no Cyvis-1 a integração é realizada ao longo do
   processamento de modo mais ameno. Os módulos de hierarquia superior tem como
   sua entrada de dados os resultados dos módulos de hierarquia inferior. Deste modo
   é realizada a integração dos diferentes módulos de um mesmo atributo. Além de
   necessitar dos resultados dos níveis hierárquicos mais baixos (de um mesmo
   195
   CAPÍTULO 5
   módulo), existem módulos que necessitam também de dados provenientes de
   módulos de atributos diferentes. Estes módulos são responsáveis pela integração
   de diferentes atributos, que ocorre em diferentes etapas.
   Uma outra singularidade no Cyvis-1 é a característica de fornecer caminho
   inverso na hierarquia de processamento (“back propagation”). Esta propriedade faz
   com que seja possível a um módulo de alta hierarquia requerer que um módulo de
   baixa hierarquia seja executado novamente, e passar parâmetros complementares
   para este. Com isso, é possível obter informações que anteriormente não foram
   extraídas.
   5.3.2.1.2 - Organização e transferência de Dados
   Devido à diferença entre a estrutura e hierarquia, a organização e
   transferência dos dados apresenta também diferentes aspectos em cada sistema.
   No caso do Vision Machine, a estrutura dos dados é comum entre os módulos. O
PA resultado de cada módulo é constituído de um mapa de descontinuidades, bastante
   semelhante entre cada um dos módulos. Como não há escala hierárquica, não
   ocorre dependência de dados. Os resultados de cada um dos módulos de atributo
   são semelhantes e serão integrados nos mesmos passos. Deste modo, além da
   transferência dos dados ser unidimensional, também não é estimulada a
   comunicação entre módulos de diferentes atributos.
   A organização dos dados no Cyvis-1 não é uniforme, e sua estrutura varia
   entre diferentes módulos de atributos, assim como entre os diferentes níveis
   hierárquicos. A medida que subimos a escala hierárquica, os dados tornam-se mais
   compactos e as informações mais simbólicas. Nesse modelo, ocorre a dependência
   de dados entre processos, ou seja, um processo não pode ser executado enquanto
   não tiver o resultado de um processo e nível hierárquico inferior. Diferente da
   estratégia utilizada no Vision Machine, em que a integração ocorre num estágio de
   integração matemática (MRF), no Cyvis-1, a integração na transferência e
   organização de dados ocorre a cada módulo.
   Do mesmo modo que a organização de dados, o fluxo de transferência
   também se altera no decorrer do sistema. Nos níveis hierárquicos mais baixos, a
   transferência entre os módulos envolve grande quantidade de dados com uma
   freqüência baixa. A medida que vamos subindo a escala hierárquica, os pacotes de
   dados vão diminuindo e o fluxo de transferência aumentando.
   5.3.2.1.3 - Aspectos Computacionais
   196
   Cyvis-1 e ynergos
   Os dois sistemas utilizam estratégias de paralelização, do ponto de vista
   computacional. O Cyvis-1 adota uma arquitetura MIMD. Deste modo, foi adotado a
   utilização de microcomputadores padrão PC, interconectados por rede e
   multiprocessados. Nesta abordagem, os algoritmos dos sistemas são distribuídos
   entre as máquinas e então processados de modo síncrono. Esta abordagem, além
   do desempenho, visa a padronização e baixo custo.
   Por outro lado, o MIT Vision Machine adota como plataforma de computação
   paralela um sistema desenvolvido pelo próprio MIT denominado Connection
   Machine, um super computador massivamente paralelo [Almasi & Gottlieb, 1994].
   Assim, temos duas abordagens diferentes, por um lado o MIT Vision
   Machine, utilizando uma plataforma exclusiva que deixa o sistema isolado (sem
   portabilidade), porém essa plataforma é poderosa e possui características
   singulares em computação paralela, possibilitando uma pesquisa mais abrangente
   e, consequentemente, um melhor desempenho.
   Em oposição à essa estratégia temos o Cyvis-1, cuja preocupação, além de
   desempenho, é portabilidade de baixo custo. Deste modo, utiliza uma plataforma
   bastante popular (PCs) e barata, trazendo assim o benefício da padronização e
   portabilidade ao seu favor.
   5.3. 3 - MODELO DO SISTEMA DE VISÃO DE KOSSLYN
   O modelo de Kosslyn é apresentado no livro Image and Brain [Kosslyn,
   1996]. Diferentemente dos modelos convencionais de visão que tratam do assunto
   sob o ponto de vista da percepção visual, o modelo de Kosslyn refere-se às
   imagens mentais, que são formadas em nosso cérebro quando mentalizamos
   simples objetos ou ambientes inteiros.
   Quando desejamos consultar a nossa base de dados, a fim de
   relembrarmos um objeto ou ambiente, precisamos extrair as informações contidas
   em nossa memória. Essas informações no entanto, são compiladas pelo
PA processamento cerebral, e armazenadas de forma otimizada. Para lembrarmos, por
   exemplo, as cores da faixa dorsal do famoso fusca de Hollywood, (Herby - Se meu
   fusca falasse - Walt Disney), temos que encontrar a informação em nossa memória
   associativa referente a imagem do carro. A fim de compreendermos essa imagem,
   e lembrarmos de seus detalhes, ela deverá ser “descompilada” e armazenada em
   nossa memória visual. Agora, com a informação em nossa memória visual
   197
   CAPÍTULO 5
   poderemos “ver” mentalmente a imagem do fusca e então fazer um novo
   processamento a nível de detalhes a fim de relembrar a forma e coloração das
   faixas que marcavam o carro, assim como o logotipo formado com seu número.
   Experimentos demostraram que o fenômeno da formação das imagens mentais
   possuem essa linha de processamento. Deste modo, podemos constatar o
   compartilhamento das áreas de processamento visual de alto nível entre percepção
   e mentalização. A característica biológica de que as conexões que levam
   informações das áreas processamento de alto nível para níveis superiores existem
   em número aproximado às que fazem o percurso inverso vem a fortalecer ainda
   mais o modelo.
   Busca de informação
   Seletor de atenção
   Mapa
   Módulo de propriedades espaciais
   Visual
   Memória
   Associativa
   Janela de
   Atenção
   Módulo de propriedades de objetos
   Fig. - 5.10 - Exemplo de regras do modelo.
   Kosslyn propõe um interessante modelo de processamento visual de alto
   nível. A partir desse modelo, ele apresenta de forma empírica o compartilhamento e
   a reconstrução de imagens mentalizadas. A figura 5.10 apresenta o modelo de
   Kosslyn o qual, devemos lembrar, se refere a um modelo de identificação de
   objetos que é compartilhado entre percepção e mentalização.
   Vamos agora fazer uma breve descrição de cada um dos elementos do
   modelo:
   Mapa Visual - Entrada de informação provinda dos olhos, porém
   processada topograficamente pelas regiões de baixo nível.
   198
   Cyvis-1 e ynergos
   Janela de Atenção - Área do Mapa Visual destinada ao processamento
   detalhado.
   Módulo de propriedades de objetos - Ou sistema ventral, são áreas do
   cérebro do lóbulo occipital inferior para o lóbulo temporal inferior. Em macacos,
   podemos dizer que o sistema ventral inclui as regiões V3, V4, TEO, TF e TE. As
   células destas regiões tipicamente respondem as propriedades dos objetos, como
   forma, cor e textura.
   Sua principal função é a codificação dessas informações para o
   armazenamento na memória associativa.
   Módulo de propriedades espaciais - Ou sistema dorsal, são áreas
PA formadas pelas regiões de conexões que vão do lóbulo occipital até o lóbulo
   parietal. Este sistema também é denominado "O que / Onde", e é responsável pelas
   informações de localização, navegação. As principais propriedades processadas
   aqui são localização e tamanho dos objetos. O sistema dorsal funciona
   simultaneamente ao sistema ventral.
   Uma das principais funções do sistema dorsal é codificar informações que
   são utilizadas primeiramente para guiar ações, como movimento dos olhos.
   Memória Associativa - As saídas dos sistemas dorsal e ventral chegam
   simultaneamente e são armazenadas na memória associativa. Na memória
   associativa os dados não são armazenados somente como representações de
   percepção, mas também de modo mais abstrato (nomes, categorias, partes de
   pronúncia, etc.).
   Em alguns casos as informações enviadas pelos sistemas dorsal e ventral
   são boas o suficiente para selecionar a representação adequada na memória
   associativa, deste modo a identificação é realizada. Em outros quando não é
   possível realizar a identificação por falta de dados, o sistema deve então solicitar
   uma nova coleta de dados.
   Busca de informação - Quando os dados codificados pelos sistemas
   ventrais e dorsais não implicam inicialmente um objeto específico, mais informação
   deve ser coletada. Nessas circunstâncias, nós não precisamos olhar aleatoriamente
   para o objeto, para coletar informações adicionais. O sistema de busca de
   199
   CAPÍTULO 5
   informação realiza um processamento "top-down", ou seja ele procura informações
   na memória associativa relevantes as informações anteriormente obtidas, e o
   sistema gera então a partir dessas informações um guia para a obtenção das
   informações auxiliares necessárias para a identificação. Deste modo, o sistema
   visual saberá exatamente o que procurar na tentativa de reconhecimento.
   Seletor de atenção - No processo "top-down", não somente o acesso à
   informação é necessário, como também o acionamento de mecanismos que dão
   maior atenção à região visual onde o objeto ou cena possuem as informações
   características. O mecanismo de atenção seletiva posiciona o corpo, cabeça, olhos
   e a janela de atenção, onde uma porção da imagem pode ser processada com mais
   detalhes.
   Tendo brevemente discutido os componentes do modelo de Kosslyn, vamos
   agora descrever o seu funcionamento. Para a percepção, em termos sucintos, a
   imagem proveniente da retina é processada pelas áreas de processamento de
   baixo nível, e então transmitida ao mapa visual. A imagem contida no mapa visual
   deverá ser então codificada para a sua representação na memória associativa.
   Esse processamento ocorre simultaneamente nos sistemas Dorsal ( módulo de
   propriedades espaciais) e Ventral ( módulo de propriedades de objetos), onde
   respectivamente as propriedades de localização e propriedades de forma, cor,
   textura, borda, etc., são codificadas. A representação codificada do objeto é então
   transferida para a memória associativa. Caso as informações estejam satisfatórias
   e existam dados coerentes ao objeto na memória associativa, então o objeto é
   reconhecido, caso contrário, o módulo de busca de informação irá pesquisar na
   memória associativa quais informações características são necessárias. Essas
   informações são então transmitidas para o seletor de atenção, que posicionará a
   janela de atenção no mapa visual, e/ou solicitará novos detalhes da imagem para o
   sistema visual. Caso não tenha necessidade de coletar nova imagem (atenção
PA seletiva), então a informação contida na janela de atenção será processada
   novamente passando apenas pelo sistema ventral. Esse ciclo é repetido até o
   objeto ser identificado.
   Na mentalização de imagens, as mesmas áreas são utilizadas. Embora
   exista o compartilhamento, a utilização do modelo é um pouco diferente. Por
   exemplo, no caso do Herby, quando perguntamos as cores e formas das listras
   200
   Cyvis-1 e ynergos
   dorsais e logotipos do carro, precisaremos mentalizá-lo a fim de que possamos
   recordar. O módulo de busca de informação, deverá fazer uma busca na memória
   associativa a fim de encontrar as representações do carro. Feito isso, a imagem é
   reconstruída no mapa visual, como se tivesse sido originada pela percepção do
   sistema óptico. O mecanismo seletor de atenção, posicionará a janela de atenção
   na porção da imagem que contém as informações necessárias. A imagem será
   então reprocessada pelo sistema ventral, a fim de que possa ocorrer a identificação
   das cores e formas das listras. Supondo que não recordamos ainda do logotipo,
   pois apenas nos lembramos dele na lateral do carro. O mecanismo seletor de
   atenção irá então posicionar a janela de atenção na posição adequada para
   detalhar o logotipo. Pelo processamento ventral, e novamente pelas consultas na
   memória associativa, agora podemos identificar o logotipo, sua forma cor e o
   número presente.
   As principais diferenças entre a percepção e a mentalização de imagens
   são:
   As imagens desaparecem rapidamente no processo de mentalização.
   As imagens mentais são criadas a partir de imagens armazenadas. Diferentemente
   das imagens pelo processo de percepção, que são originadas a partir do mundo
   exterior.
   As imagens mentais, diferentes da percepção, podem ser recriadas com diferentes
   modos. Por exemplo, podemos rotacionar o objeto, ampliar um detalhe, mudar a
   distância, movê-lo e etc.
   5.3.3.1 - O MODELO DE KOSSLYN E O CYVIS-1
   Mesmo sendo o modelo de Kosslyn de visão de alto nível, diferentemente do
   baixo nível do Cyvis-1, podemos fazer algumas comparações entre os sistemas,
   assim como motivações para o Cyvis-1. O modelo de Kosslyn é estritamente
   biológico, através do qual é realizada uma modelagem dos processos de alto nível
   do sistema visual humano. Esse modelo se caracteriza pelo paradigma dos
   caminhos o que / onde ( what/where ), teoria que se baseia na dualidade dos
   caminhos de informações visuais no córtex. No entanto esta teoria recebeu duras
   críticas na literatura, como sendo uma simplificação de um problema complexo
   [Zeki, 1993].
   Dentro do modelo de Kosslyn os sinais (atributos) são agrupados em dois
   conjuntos e integrados. Assim, os sinais referentes ao caminho o que (cor, linhas,
   201
   CAPÍTULO 5
   formas, etc.), são separados e integrados separadamente dos sinais referentes ao
   caminho onde (movimento, estéreo, etc.). No Cyvis-1 não é realizado o
   agrupamento de sinais, assim, pode ocorrer a integração entre qualquer
   combinação de atributos.
   Os mecanismos de atenção seletiva foram bastante explorados no modelo
   de Kosslyn, conforme podemos observar na figura 5.10, dos 7 módulos que
PA compõe o modelo, 3 são voltados para esta questão. O Cyvis-1 também incorpora a
   atenção seletiva, que é realizada pelo mestre. No entanto, o modelo de Kosslyn nos
   sugere que esta questão é complexa e necessita de um mecanismo mais robusto
   para sua implementação, podendo nos levar no decorrer do projeto Cyvis-1 à
   incorporação de um módulo específico para essa questão. O que falta no modelo,
   entretanto, é uma explanação maior sobre os detalhes de cada módulo. Por
   exemplo, a procura de informações na memória associativa está descrita de forma
   bastante subjetiva. Ainda em atenção seletiva, o modelo de Kosslyn é fortemente
   baseado na divisão de sinais onde/o que, uma vez que apenas o caminho o que ou
   propriedades do objeto estão envolvidas diretamente com o processo.
   5.3.4 - SEEMORE
   Uma abordagem clássica nos sistemas de visão artificial é a análise
   profunda de uma característica ou atributo marcante para a extração de
   propriedades para a classificação de objetos. Ultimamente, podemos observar a
   tendência de seguir a mesma abordagem estabelecida pelos sistemas de visão
   biológica, ou seja a combinação de diversos atributos para a classificação de
   objetos. O sistema de visão artificial Seemore, de autoria de Barlett Mel [Mel, 1997],
   é mais um exemplo de um sistema de visão que combina diferentes atributos da
   imagem para uma classificação mais efetiva dos objetos.
   O funcionamento básico do sistema consiste na extração do maior número
   possível de características da imagem, e sua eventual classificação através de
   ferramentas estatísticas. Para analisar o sistema foram treinadas para classificação,
   100 imagens, formadas por objetos sólidos rígidos (telefone) e flexíveis (cabo
   espiral de telefone) assim como imagens complexas de duas dimensões. O
   Seemore demostrou ser capaz de reconhecer as imagens em diferentes ângulos e
   escalas variando em fator de 2. Todas as imagens foram capturadas no mesmo
   ambiente com iluminação normalizada.
   202
   Cyvis-1 e ynergos
   O treinamento do Seemore consiste na captura de 12 a 36 diferentes vistas
   dos objetos dependendo de sua natureza. Para objetos rígidos, são necessários 12
   vistas em diferentes ângulos, variando em intervalos de 60o em média em torno da
   esfera visual do objeto, e mais 3 imagens escaladas para cada vista, tendo 67%,
   100% e 150% da original. Para objetos flexíveis as vistas são tiradas de modo
   aleatório em diferentes posições e escalas.
   O processamento do sistema Seemore consiste na extração de 102
   características da imagem. Cada característica é denominada de canal, e o
   conjunto dos canais constituem o vetor de características que é a entrada para o
   classificador estatístico. Deste modo, o banco de dados para cada objeto possui um
   total de 1224 a 3672 inteiros. Os 102 canais são divididos em 5 grupos:
   23 canais de cor, cada um dos quais correspondem a pequenos nódulos
   parametrizados pela melhor matiz e saturação.
   11 canais de cantos, parametrizados pelo ângulo de abertura.
   12 canais de características parametrizados pela forma principal (alongada ou
   arredondada) e pelo tamanho do objeto.
   24 canais com características de contorno.
   16 canais de textura e forma baseados na saída da função de Gabor [Faugeras,
   1996].
   O processamento do Seemore é seqüencial, mesmo não existindo
   dependência de dados entre os 5 módulos e possuindo uma estrutura que permite
PA uma exploração de paralelismo, essa questão não foi levada em conta pelo autor.
   Deste modo, a execução do sistema é realizada de modo a extrair as
   características uma após a outra até o montante de 102. Após a extração, as
   características são enviadas para o classificador estatístico que compara o
   resultado atual com o banco de dados formado pelo treinamento, para o
   reconhecimento do objeto.
   5.3. 4.1 - CYVIS-1 VERSUS SEEMORE
   Embora combine diversos atributos para o reconhecimento de objetos, o
   Seemore possui uma estrutura muito mais simples que o Cyvis-1, uma vez que não
   existe a integração dos atributos, estratégias de paralelismo, análise de dados
   automática, cooperação entre atributos e análise "top-down" (caminho inverso),
   entre outras. Numa visão simplificada, podemos resumir o Seemore como um
   sistema que extrai o maior número possível de características da cena sem análise
   203
   CAPÍTULO 5
   prévia ou direcionamento, e alimenta com um grande número de parâmetros um
   classificador estatístico. Deste modo o Cyvis-1, em termos de arquitetura de
   sistema e de visão, tem mais a ensinar do que a aprender com Seemore. Mesmo
   possuindo uma arquitetura simplificada em termos de visão, os resultados de
   reconhecimento apresentados revelam uma boa performance do sistema. Ainda
   quanto aos resultados de reconhecimento, Mel [Mel, 1997], apresentou uma tabela
   onde compara a performance da classificação do Seemore utilizando apenas um
   atributo (cor, textura ou forma) e a combinação de atributos. Os resultados
   demostraram a eficiência da classificação quando alimentada com os dados dos
   diferentes atributos. Este é um dado relevante para o Cyvis-1, uma vez que além de
   combinar os atributos, ele também desempenha a integração e cooperação.
   A execução do Seemore é seqüencial. Mesmo não possuindo dependência
   de dados e hierarquia rígida, o que facilita a implementação paralela, essa questão
   não foi abordada, diferentemente da filosofia do Cyvis-1, que mantém a
   implementação paralela como um de seus principais objetivos.
   5.4 – O PROJETO YNERGOS
   No desenvolvimento de sistemas e na realização de experimentos em visão,
   apresentam-se uma série de dificuldades, que devem ser vencidas pelo esforço, a
   fim de que o sistema ou experimento em questão possa ser realizado com êxito.
   Dentre essas dificuldades podemos citar: (i) a validação das técnicas: é bastante
   trabalhoso certificar que as técnicas e algoritmos estão funcionando perfeitamente;
   (i ) a implementação correta de algoritmos muitas vezes direcionados a linguagens
   de modelagem (ex: MATLAB); e (iii) a análise estatística dos dados obtidos a partir
   do processamento: muitas vezes diversos atributos extraídos de uma imagem
   classificam-na de modo igual, tornando-se redundantes, assim como em algumas
   ocasiões os atributos extraídos podem não estar distinguindo adequadamente
   diferentes classes, sendo necessário a adição de características no sistema.
   Normalmente, os pesquisadores desenvolvem algoritmos específicos para a
   realização de testes e análises, ou estudam através de seus experimentos para
   uma melhor compreensão dos problemas apresentados acima. No entanto, isso é
   bastante trabalhoso e custoso, implicando num tempo muito maior para o
   desenvolvimento de sistemas e experimentos. Esses problemas, comuns na área
   de visão, motivaram o desenvolvimento de uma ferramenta para auxiliar a
   204
   Cyvis-1 e ynergos
PA pesquisa, experimentos e desenvolvimento de sistemas em visão, em nosso grupo.
   O projeto ynergos [Bruno et al., 2000] [Consularo et al., 1999] [Bruno et al.,
   1998], tem como objetivo fornecer um ambiente, formado por um conjunto de
   ferramentas, para auxiliar no desenvolvimento de sistemas e experimentos em
   visão. O ynergos é composto por um conjunto de módulos caracterizados por
   ferramentas que atuam em áreas específicas. Os principais módulos do ynergos
   são:
   Pesquisa em Visão Computacional: Este módulo inclui ferramentas tradicionais
   para visão computacional e processamento de imagens, tais como Fourier e
   outros métodos de transformação, detecção de bordas, segmentação de
   imagens, etc.;
   Pesquisa em Visão biológica: É composto por ferramentas para diferentes
   atividades relacionadas à visão biológica, assim como psicofísica e síntese e
   modelagem de estruturas biológicas.
   Análise dos Dados e Classificação: Nesse módulo são tratados os procedimentos
   de reconhecimento de padrões, análise de classes e funções estatísticas. Sendo
   útil para auxiliar na validação das características.
   Validação e Testes: Este módulo contém métodos para a verificação da integridade
   das rotinas implementadas, assim como para avaliar e melhorar a performance
   dos algoritmos.
   Base de Dados: Base de dados para imagens e dados genéricos, fornece o alicerce
   para que diferentes métodos tais como os de performance de algoritmos,
   validação e selecionador automático de características, possam agir.
   Computação Paralela: Esta abordagem é responsável pelo auxílio em
   implementações de aplicações de tempo real através da paralelização de
   algoritmos. A base paralela adotada pelo ynergos é o CVMP (ver Capítulo 6).
   Inteligência Artificial: Aqui se encontram as rotinas para aquisição de conhecimento
   de sistemas especialistas ou de experimentos (exemplo algoritmo genético
   [Goldberg, 1989]).
   Mineração de dados (Data Mining): Este módulo se refere as funções para
   encontrar regras gerais em conjuntos de dados, que podem ser usadas para
   modelar estruturas biológicas ou para aquisição de conhecimento em sistemas
   especialistas, por exemplo.
   Visualização e GUI: Módulo responsável pela visualização científica dos dados e da
   interface entre o usuário e máquina.
   205
   CAPÍTULO 5
   Internet: Interação com a Internet em três diferentes situações: (a) síntese: geração
   automática de documentos HTML; (b) análise: processamento de imagens e
   dados provenientes do WWW; (c) processamento: aplicações rodando através
   da internet (via cgi-bins, Perl ou Java, por exemplo).
   Interação com aplicativos externos: Este módulo é responsável por permitir que o
   ynergos possa interagir e comunicar com outras aplicações tais como Matlab
   ou ADOBE PhotoShop, tornando-o um versátil ambiente para a investigação de
   imagens.
   A principal idéia por trás do projeto
   ynergos, além de auxiliar o
   desenvolvimento de sistemas e experimentos, está o conceito de sinergia, que se
   exprime pela sentença de que a soma das partes é maior do que o todo. Deste
   modo o resultado da união de diversos métodos computacionais em um único
PA sistema pode ser maior do que a soma de suas partes, uma vez que as vantagens
   e desvantagens relativas de cada módulo podem se complementar.
   USUÁRIO
   I/O (GUI'S)
   GERÊNCIA
   BIBLIOTECA PRÓPRIA
   PROGRAMAS
   DATABASES
   APLICAÇÕES
   INTERNET
   COMPUTAD. REMOTOS
   Fig. - 5.11 - Modelo em camadas do ynergos.
   Deste modo, o ynergos pode ser caracterizado como um sofisticado
   laboratório de visão, através do qual podem ser desenvolvidos poderosos
   experimentos baseados na interação entre seus módulos. A figura 5.11 apresenta
   um modelo de camadas que expressa sua arquitetura. O ynergos está sendo
   implementado principalmente pelo colega de grupo Luís Augusto Consularo
   [Consularo et al., 1999], utilizando o ambiente de programação Delphi e a
   plataforma Windows NT/9X. O ambiente Delphi possui ferramentas para
   programação visual, bases de dados, programação Internet (cgi-bin) e programação
   orientada a objetos (OOP), e desse modo tem contribuído para a implementação
   efetiva dos conceitos envolvidos no projeto.
   Uma das características do ynergos é a sua natureza paralela e distribuída.
   206
   Cyvis-1 e ynergos
   A implementação paralela e distribuída está sendo implementada utilizando as
   ferramentas CVMP ( Cybernetic Vision Message Passage - ver Capítulo 6), tendo
   como plataforma computacional máquinas IBM/PC conectadas via rede com um ou
   mais processadores (multiprocessadas), e sistema operacional Windows NT/9X. A
   adoção da plataforma PC / Windows foi adotada preferencialmente por: (i) As
   máquinas IBM-PC atingiram um alto nível de performance (ex: 1000 MHz), (ii)
   portabilidade e popularidade tanto do hardware quanto do software e (iii) baixo
   custo.
   5.5 – PARALELISMO E VISÃO, UM DESAFIO
   Neste capítulo discutimos e apresentamos alguns sistemas de visão artificial
   e suas necessidades de paralelismo. Entretanto, a demanda por paralelismo nas
   áreas relacionadas com a visão computacional é muito mais ampla, uma vez que
   esta envolve a manipulação de grandes quantidades de dados (imagens) sendo
   processados por um elevado número de operações aritméticas, o que
   consequentemente resulta num grande consumo computacional e tempo. Além da
   questão de desempenho, existe também a integração e colaboração entre atributos
   visuais. Ainda que esses conceitos estejam em fase inicial de pesquisa, motivados
   pelos sistemas biológicos, acreditamos estar no paralelismo as soluções para essas
   questões.
   Embora a visão computacional e diversas outras áreas científicas, que
   necessitem de grande poder computacional, venham a ser beneficiadas com a
   utilização de paralelismo, algumas barreiras freqüentemente impedem sua adoção,
   tais como:
   Necessidade de escrever novo código voltado para o paralelismo e em muitos
   casos alterar a estratégia do algoritmo, gerando um aumento de trabalho na
PA implementação dos algoritmos e não permitindo a utilização dos códigos já
   desenvolvidos.
   Os programas paralelos obedecem a princípios de funcionamento e de
   programação que diferem dos seriais. Isso dificulta sua implementação, uma vez
   que a formação típica dos programadores é em processamento seqüencial,
   sendo necessário conhecimento sobre os princípios básicos do paralelismo e
   ambientação.
   O código paralelo é em geral voltado para uma determinada arquitetura paralela,
   207
   CAPÍTULO 5
   reduzindo a portabilidade do código e padronização.
   Necessidade de mudar de linguagem e ambiente de desenvolvimento. Poucos
   ambientes de programação apresentam soluções para a implementação de
   código paralelo, especialmente os comerciais integrados e visuais (Delphi, C++
   Builder, Visual C++ e Visual Basic), sendo necessário em algumas situações a
   mudança de ambiente de trabalho e até mesmo de linguagem de programação.
   Com isso, além de não reutilizar o código, os programadores são obrigados a
   aprender a operar novos ambientes e linguagens e a se familiarizar com eles.
   A grande maioria das ferramentas e linguagens de programação voltadas ao
   paralelismo se caracterizam por serem voltadas aos especialistas em
   computação paralela, não se preocupando com o programador comum. Com
   isso dificultam a implementação de programas concorrentes e aumentam
   drasticamente a curva de aprendizado [Hayes, 1990] [Baber et al., 1993] [Preece
   et al., 1994].
   Alto custo, especialmente para soluções de paralelismo que envolvem
   computadores com arquiteturas não convencionais.
   Analisando as barreiras podemos constatar que os maiores empecilhos para
   o desenvolvimento de programas paralelos estão relacionados ao trabalho humano.
   Se observarmos a história da ciência da computação verificaremos a importância
   da interação entre o homem e o computador, e consequentemente das interação e
   simplicidade de uso das ferramentas, tanto de operação quanto de programação.
   As idéias de simplificar o modo de operação e as ferramentas computacionais são
   conceitos que atingiram seu ápice em relação a pesquisa no projeto PARC [Bruno,
   1995] que culminou na tecnologia GUI [Peddie, 1992], na programação orientada a
   objetos e em linguagens visuais (Smalltalk) [Hurson et al., 1993] [Cox, 1986].
   Graças a esses elementos páginas foram viradas na história da computação e a
   informática teve um grande impulso em sua expansão, chegando a fazer parte
   direta ou indiretamente de toda as nossas atividades científicas.
   A importância de ferramentas simples no desenvolvimento de programas
   pode ser também observada na popularidade das plataformas computacionais,
   sendo esse o principal motivo da difusão do Windows, que apresenta diversas
   ferramentas que possibilitam a criação de aplicativos de maneira simples,
   destacando o Visual Basic, linguagem para iniciantes, simples de utilizar, e que
   possui o maior número de aplicativos desenvolvidos.
   208
   Cyvis-1 e ynergos
   Embora os conceitos de interação entre homem e máquina sejam
   consagrados e amplamente difundidos, eles não foram empregados de forma
   efetiva na computação paralela. Isso provavelmente se deve a sua natureza
   científica, uma vez que sua aplicação se restringe ao meio científico e
PA consequentemente aos ecléticos especialistas da computação paralela.
   DevidLGN e no córtex visual, de modo que cada área ou módulo
PA especializado do córtex visual receba um fluxo de sinal principal, proveniente de um
   caminho com um sinal específico. Essa característica, além de fundamentar o
   processamento especializado, também o define como distribuído. Deste modo, a
   especialização de processos e caminhos, do ponto de vista computacional, permite
   um alto grau de paralelismo.
   5.2.1.8 – INTEGRAÇÃO DE MÚLTIPLOS ESTÁGIOS
   Os princípios discutidos anteriormente, modularidade, hierarquia,
   paralelismo, troca de mensagens, tráfego de sinais em duplo sentido e
   especialização de processos, constituem a organização funcional do córtex. Uma
   de suas principais características é a interconexão entre os módulos e caminhos
   especializados (atributos específicos) assim como entre os diferentes estágios
   hierárquicos, e foi denominada por Zeki e Shipp [Zeki & Shipp, 1988] de Integração
   de múltiplos estágios. Através dessa estrutura, os módulos especialistas que
   compõem um caminho ou atributo visual podem trocar informações em qualquer
   estágio hierárquico com módulos de outros atributos, possibilitando complementar a
   informação. A colaboração entre os módulos, permite uma precisão e performance
   melhores no reconhecimento dos objetos ou regiões da imagem.
   173
   CAPÍTULO 5
   A colaboração entre os módulos inspirou profundamente o projeto Cyvis-1 e
   constitui atualmente um dos maiores desafios, uma vez que pouquíssimos sistemas
   artificias utilizam características de auxílio mútuo entre módulos, e quase nenhuma
   referência na literatura apresenta essa integração de atributos em visão artificial.
   5.2.1.9 – VISÃO FOVEAL
   Uma diferença muito grande entre os sistemas artificiais e os naturais está
   presente na estratégia de aquisição de imagens. Em visão artificial,
   tradicionalmente, as imagens são captadas por câmeras de vídeo (estáticas), que
   registram e convertem toda a cena em matrizes lineares de duas dimensões. Deste
   modo, toda a cena capturada é armazenada e cada um dos pixels da imagens (ou
   elementos da matriz) são processados igualmente. Conforme comentamos na
   Seção 4.6.2.1, a distribuição dos fotorreceptores na retina não é linear, e a maior
   concentração na região central ou fóvea faz com que essa região tenha uma
   resolução muito maior do que as demais. A região foveal compreende uma
   pequena porção do campo visual e a maioria do maquinário neural está envolvida
   especificamente com o seu processamento.
   Para a compreensão total de uma cena, o sistema visual utiliza a
   movimentação dos olhos, e consequentemente da fóvea, por toda a cena,
   processando-a região por região. A figura 5.2 ilustra essa situação, onde foi
   registrada o percurso da região foveal humana em uma cena durante sua
   percepção.
   (a)
   (b)
   Fig. - 5.2 – Movimento dos olhos durante a percepção de uma face. Os traços
   da figura (b) apresentam a posição da região central dos olhos durante o
   rastreamento para a percepção da imagem [Dowling, 1992] [Hubel, 1995].
   Embora a uma primeira instância possa parecer mais objetiva a estratégia
   de captar toda a cena de uma só vez, com alta resolução em matrizes lineares,
   esse tipo de abordagem apresenta diversas desvantagens em relação ao sistema
   174
   Cyvis-1 e ynergos
PA foveal, entre as quais podemos citar:
   Alto custo com hardware e pouca compactação: Se o sistema de visão humano não
   fosse foveal, certamente o complexo de células do sistema neural não caberia
   na caixa craniana.
   Alto custo computacional: Preferindo uma pequena parte, ao invés de todo o campo
   visual, o poder computacional é economizado, considerando-se custosos
   algoritmos de processamento de sinais.
   Tempo de processamento: O elevado custo computacional acarreta num tempo
   maior de processamento.
   Menor interação com a imagem: Uma vez que o tempo de processamento é maior,
   o sistema tem um tempo de resposta igualmente maior e, deste modo, possui
   interação menor, necessária especialmente quando se trata de operações que
   envolvem movimentos.
   5.2.1.10 – ATENÇÃO SELETIVA
   O paralelismo, nos sistemas visuais naturais, possui uma estrutura
   piramidal, de forma que a base da pirâmide, formada pelos estágios de baixo nível,
   são massivamente paralelos, e à medida que a escalamos, encontramos estágios
   de processamento de níveis cada vez mais altos e com menor paralelismo, de
   modo que no topo da pirâmide os processos são quase seqüenciais.
   A atenção seletiva é um mecanismo através do qual os sistemas de alto
   nível concentram temporariamente a atenção em regiões ou objetos localizados na
   fóvea, obtendo uma análise detalhada dos elementos da imagem um por um. Assim
   como na visão foveal, onde a cena é rastreada pela região central da retina através
   dos movimentos dos olhos e depois integrada como um todo pelo córtex, na
   atenção seletiva, cada detalhe, região ou objeto localizado na fóvea, é rastreado
   através de atenção dedicada, um a um, e são integrados pelo córtex formando um
   conjunto detalhado.
   5.2.1.11 – INTEGRAÇÃO COM NÍVEIS DE CONHECIMENTO
   MAIORES
   Esse princípio está diretamente relacionado com o alto nível de aprendizado
   que os sistemas naturais utilizam. Assim, o processo visual através de consultas à
   175
   CAPÍTULO 5
   memória, realiza uma análise de contexto, ambiente, localização e história,
   comparando a cena com observações anteriores reconhecidas e registradas, o
   sistema pode receber informações adicionais e deste modo proceder o
   reconhecimento. A figura 5.3 apresenta um exemplo de como nossa percepção é
   fortemente influenciada pela análise de contexto. A análise das retas do corredor,
   dão uma informação contextual de distância, de modo que na imagem (a) temos a
   impressão que uma pessoa está distante da outra, e na (b) ocorre uma situação
   diferente da percepção normal a que fomos treinados ao longo de nossas vidas, e
   portanto temos a idéia de que é uma miniatura. Observem também que as duas
   mulheres têm o mesmo tamanho na imagem, entretanto percebemos que a da
   imagem (a) é maior.
   (a)
   (b)
   Fig. - 5.3 – Importância do contexto na percepção visual humana. Embora
   sejam do mesmo tamanho, na imagem (b) a figura da mulher à direita parece
   menor do que a da imagem (a) [Dowling, 1992].
   5.2.2 – O SISTEMA DE VISÃO CIBERNÉTICA – CYVIS-1
PA Com o intuito de prover a visão versátil nasceu um dos mais audaciosos
   projetos do Grupo de Visão Cibernética, o Cyvis-1, que foi introduzido em 1994 por
   Costa e colaboradores [Costa et al., 1994]. Com base em modelos de visão
   biológica, especialmente no modelo de integração de estágios múltiplos do
   processamento visual do cérebro dos primatas, proposto por Zeki e Shipp [Zeki &
   Shipp, 1988], o sistema de visão cibernética Cyvis-1 é um modelo conceitual para a
   visão versátil em tempo real.
   Devido a grande dificuldade proporcionada e ao seu caracter de vanguarda
   176
   Cyvis-1 e ynergos
   e pioneirismo, o projeto foi idealizado num plano de pesquisa de longa duração, do
   qual participarão diversos pesquisadores. Atualmente, o projeto encontra-se na fase
   inicial, que consiste na implementação de protótipos, visando o estudo do
   comportamento de sistemas de visão sob o aspecto de distribuição e integração de
   tarefas, assim como no desenvolvimento de algoritmos mais eficientes para cada
   uma das etapas dos módulos de processamento específico. Nesta seção iremos
   descrever o projeto, assim como alguns itens da sua implementação.
   Fig. - 5.4 – Diagrama de blocos do modelo estrutural do sistema Cyvis-1,
   apresentando sua organização geral. Adaptado de [Bruno & Costa, 1997]
   [Costa et al., 1994].
   A figura 5.4 apresenta um diagrama de blocos do modelo estrutural do
   sistema de visão cibernética. A organização geral do Cyvis-1 consiste em um
   conjunto de sistemas dedicados, responsáveis pelo processamento e análise
   independente de atributos visuais (cor, bordas, formas, textura, estéreo e etc.),
   representados pelas barras horizontais, um par de câmeras, responsável pela
   captura das imagens e o módulo de controle.
   Os sistemas dedicados são responsáveis pelo processamento dos atributos
   visuais específicos. O processamento é dividido em diferentes estágios, que
   177
   CAPÍTULO 5
   obedecem a uma escala hierárquica correspondente ao seu nível de
   processamento visual. A escala hierárquica de processamento visual possui
   natureza similar ao caminho visual do sistema de visão biológico, que, como vimos
   no Capítulo 4, inicia-se com o processamento de baixo nível na retina, onde são
   extraídas características fundamentais da imagem (ex: bordas) e prossegue pelo
   processamento no LGN, córtex visual primário, secundário e demais áreas corticais,
   onde em cada etapa do caminho visual as informações vão se tornando mais
   complexas, mais abstratas e representativas (exemplo: bordas -> retas -> formas ->
   objetos). Deste modo, o sistema dedicado é dividido em diversos módulos, sendo
   que cada um é responsável pelo processamento individual dos níveis do caminho
   visual do atributo.
   Os módulos são representados na figura 5.4 por pequenas caixas no interior
   das barras horizontais, onde os responsáveis pelos processamento de baixo nível
   estão à esquerda e os de alto nível à direita. Assim, a imagem capturada pela
   câmera é transmitida para o módulo de mais baixo nível, e após ser processada,
   gera um mapa, que é enviado para o próximo módulo da hierarquia e assim
   sucessivamente até o nível mais elevado. Como nos sistemas biológicos, ocorre
   também o sentido inverso do fluxo de informação, indicado pelo duplo sentido das
   conexões entre os módulos. Em algumas ocasiões, o alto nível realimenta os
   módulos de baixo nível com informações de imagens processadas anteriormente,
PA contribuindo no processamento e reconhecimento da cena.
   Assim como nos sistemas biológicos, cada módulo dos sistemas dedicados
   possui um método de representação de dados particular e estratégia de
   processamento própria. Deste modo, os módulos de baixo nível possuem
   representações mais generalizadas, menos abstratas e que necessitam de maior
   espaço de armazenamento. À medida que subimos nas etapas hierárquicas de
   processamento, as informações vão ficando mais concisas, específicas e abstratas
   e consequentemente necessitam de um espaço menor para o armazenamento.
   Assim como ocorre uma alteração evolutiva na forma de representação dos
   dados, o mesmo acontece com a estratégia de processamento. Nos módulos de
   baixo nível, o processamento é mais localizado, independente e em geral requer
   um número maior de operações aritméticas, bem como maiores recursos
   computacionais. Entretanto, devido a sua natureza de processamento disperso e
   independente, os níveis mais baixos possibilitam estratégias de paralelismo mais
   eficientes. Por outro lado, os níveis mais altos, envolvem processamentos com
   178
   Cyvis-1 e ynergos
   maior dependência de dados e mais globalizados, tornando-se cada vez menos
   viável a implementação paralela de seus algoritmos, chegando a níveis
   predominantemente seqüenciais, como por exemplo, os algoritmos de classificação.
   Além das conexões horizontais, que como vimos integram os diferentes
   módulos de processamento de um atributo específico, o Cyvis-1 possui também
   conexões verticais, que ligam os sistemas dedicados permitindo a troca de
   informações entre atributos. É através destas conexões verticais que ocorre a
   colaboração entre os sistemas dedicados. Como exemplo, vamos explicar a
   colaboração entre os sistemas dedicados a bordas e cor: suponhamos que o
   sistema dedicado ao processamento de bordas não consiga definir as bordas de
   uma determinada região da imagem. Então, o sistema dedicado ao atributo borda,
   requer ao sistema dedicado ao atributo cor informações adicionais sobre essa
   região, e, de posse das informações recebidas, as bordas da região, podem ser
   agora reconhecidas.
   Todos os sistemas dedicados são controlados pelo módulo mestre, que
   além de manipular o fluxo das informações em cada atributo, pode também
   concentrar temporariamente todo o processamento dos sistemas em uma
   determinada região da imagem, ou em um atributo específico, assim como a
   atenção seletiva dos sistemas biológicos. O mestre é também responsável pelo
   gerenciamento da base de conhecimento global do sistema e pela classificação e
   reconhecimento final. Para isso, recebe as informações resultantes dos
   processamentos de cada atributo. Cada sistema dedicado é também provido de
   uma base de conhecimento local, utilizada para decisões independentes da
   supervisão do mestre. O fluxo de execução é em parte determinado pelos próprios
   sistemas dedicados, tomando decisões a partir de sua base de conhecimento local,
   e em parte pelo mestre, que é responsável pelo processamento total e pelas
   decisões sobre o foco de atenção.
   5.2.3
   –
   IMPLEMENTAÇÃO,
   REQUISITOS
   E
   NECESSIDADES
PA Nesta seção iremos abordar os principais requisitos, necessidades e
   dificuldades de implementação do projeto Cyvis-1, além dos diversos desafios
   179
   CAPÍTULO 5
   científicos e tecnológicos encontrados em: visão computacional, processamento de
   imagens, computação paralela, sistemas distribuídos, integração de atributos
   visuais, controle e escalonamento de tarefas, e outros mais. O projeto também se
   confronta com a difícil tarefa de integrar os recursos humanos envolvidos.
   Conforme já comentamos, trata-se de um projeto ambicioso de longa duração, que
   utiliza o trabalho cooperativo de diversos pesquisadores.
   O primeiro passo a ser dado para se iniciar a implementação é a definição
   da plataforma de desenvolvimento. Essa definição engloba a escolha da plataforma
   de hardware, do sistema operacional e das ferramentas e linguagens de
   programação. A decisão desses requisitos foi baseada primordialmente nas
   ferramentas de desenvolvimento. O grupo de Visão Cibernética possui hoje como
   plataformas de desenvolvimento o MATLAB [Etter, 1995] e o Scilab [Gomes et al.,
   1999] para o modelagem matemática dos algoritmos, e o Delphi [Cantù,1995]
   [Calvert, 1999] e o C++ Builder [Calvert, 1997] para a implementação efetiva.
   Estando todos os membros do grupo familiarizados com estas ferramentas, a
   escolha óbvia para a plataforma de desenvolvimento do projeto fixou-se nestas
   alternativas.
   As linguagens de cálculo matricial são excelentes ambientes de
   desenvolvimento, mas podem não atender os requisitos necessários para a
   implementação do sistema, uma vez que além de lentas (em geral são
   interpretadas), não possuem toda a versatilidade das linguagens de uso geral.
   Normalmente, em nosso grupo, os algoritmos desenvolvidos nesses ambientes são
   convertidos em C++ ou Pascal para sua utilização e consequentemente sua
   compilação nos ambientes Delphi e C++ Builder. Existem também ferramentas que
   possibilitam a utilização direta dos algoritmos nestes ambientes, tal como o
   Matcom, também utilizado pelo grupo [Consularo & Costa, 1998].
   Deste modo, o par Delphi e C++ Builder foi adotado como plataforma de
   desenvolvimento do projeto, uma vez que essa escolha reduz drasticamente a
   curva de aprendizado, pois além de serem bastante populares e de fácil
   aprendizado para novos membros, os pesquisadores atuais do grupo já estão
   familiarizados com essas ferramentas. E também atendem aos requisitos de
   performance, versatilidade de manipulação de baixo nível (hardware/sistema
   operacional), programação orientada a objetos OOP e o inverso (“top-down” e “botton-up”);
   Paralelismo: a biologia investiu ao longo da evolução em estratégias de
   paralelismo, de modo que elas não apenas possibilitam a execução em tempo
   real dos sistemas de visão, mas também estão intrinsecamente ligados aos
   mecanismos de integração e compartilhamento de informações;
   Modularidade e integração: estão presentes nos sistemas naturais de visão e são
   fundamentais para sua grande performance. Estando intimamente associadas às
   estratégias e arquiteturas paralelas adotadas pela natureza [Costa et al., 1994];
   166
   Cyvis-1 e ynergos
   Hierarquia: fundamental para a organização da informação e dos processos, ainda
   mais quando de modo não linear, conforme sugerido pelos itens anteriores;
   Representação visual efetiva. [Costa et al., 1994]
   Cyvis-1, cujo nome é derivado do inglês “Cybernetic Vision System 1” é um
   ambicioso projeto do nosso grupo de pesquisa, fortemente inspirado na biologia,
   cujo intuito é o desenvolvimento de um sistema de visão versátil capaz de se
   adaptar de modo quase automático a diferentes tipos de problemas de visão [Costa
   et al., 1994]. Uma das bases para o desenvolvimento do Cyvis-1 é o estudo e a
   incorporação de estratégias de paralelismo, uma vez que a natureza nos demonstra
   que para o problema de visão não são apenas necessárias sofisticadas
   representações e algoritmos, mas também estruturas paralelas/concorrentes para,
   além de atender no menor tempo possível a enorme quantidade de dados
   necessários para o processamento (especialmente nos níveis mais baixos), força
   também a constituição de estruturas modulares e hierárquicas, capazes de trocar
   informações durante o processamento, efetuando deste modo a sua integração.
   5.2.1 – APRENDENDO COM A NATUREZA
   A engenharia reversa realizada em sistemas biológicos é uma linha de
   pesquisa que, devido ao seu sucesso, está se tornando cada vez mais popular.
   Deste modo, ao invés de reinventarmos as soluções, analisamos o modo pelo qual
   a natureza em milhões de anos de evolução solucionou seus problemas. Essa linha
   de raciocínio é um dos pilares fundamentais da Visão Cibernética, que procura na
   biologia a solução para os problemas de visão artificial. Seguindo esta estratégia,
   encontramos a base do sistema de visão artificial Cyvis-1, cuja principal
   característica é a sua forte inspiração biológica. Nesta seção, vamos apresentar
   alguns dos principais princípios biológicos de processamento, representação e
PA organização incorporados no projeto Cyvis-1 [Costa et al., 1994].
   5.2.1.1 – PARALELISMO, DISTRIBUIÇÃO DE PROCESSOS E
   TROCA DE MENSAGENS
   Tradicionalmente, os sistemas de visão artificiais são seqüenciais. A figura
   5.1 apresenta um diagrama de um sistema de visão artificial clássico, nele
   encontramos um dispositivo de aquisição de imagens, um módulo de pré-
   167
   CAPÍTULO 5
   processamento, o qual realiza algumas operações de tratamento de imagem, um
   módulo de processamento primário, o qual extrai características básicas da
   imagem, como as bordas por exemplo, e um ou alguns poucos módulos de
   processamento de atributos, que extrai as propriedades da imagem e finalmente o
   módulo de classificação, que recebe os resultados. Ao contrário dessa abordagem,
   a natureza, ao longo de milhões de anos de evolução, investiu profundamente no
   paralelismo, e nos ensina que esta é uma solução natural para a questão da visão.
   cena
   Aquisição
   Pré-
   de imagens
   processamento
   câmera
   Processamento
   Processamento
   Processamento
   de atributo 3
   de atributo 2
   de atributo 1
   Classificação
   Resultado
   Fig. - 5.1 – Diagrama de um sistema de visão artificial clássico.
   Quando pensamos em paralelismo, a primeira questão que nos vem à
   mente é o desempenho, uma vez que basicamente utilizamos o paralelismo com o
   intuito de aumentar a performance de sistemas que necessitem de respostas
   rápidas e demandem grande poder computacional. Sem dúvida alguma, o
   desempenho é uma questão muito importante. Especialmente para os sistemas de
   visão versátil que, tentando resolver diversos problemas, tem necessariamente que
   se defrontar com uma série destes que estão envolvidos diretamente com
   processamento em tempo real. Nesse contexto, a situação se agrava ainda mais,
   uma vez que a visão utiliza algoritmos dispendiosos que demandam grande poder
   computacional, e que se tornam muitas vezes impraticáveis, especialmente com
   imagens de alta resolução, devido ao tempo de execução prolongado e
   consequentemente um elevado uso de recursos computacionais.
   No entanto, a natureza demonstra que sua opção pelo paralelismo não se
   deu única e exclusivamente devido ao benefício do aumento de desempenho (uma
   vez que os neurônios são relativamente lentos). O paralelismo está diretamente
   168
   Cyvis-1 e ynergos
   relacionado com inúmeras outras questões, que juntas caracterizam o sistema
   visual. A natureza modularizou e distribuiu o sistema visual de modo que os
   atributos visuais (cor, textura, formas, estéreo, movimento e etc.) pudessem ser
PA executados concomitantemente. Além disso, como discutimos no Capítulo 4, cada
   um dos módulos é ainda formado por inúmeras estruturas concorrentes. Ademais,
   os sinais são separados e percorrem caminhos diferentes ao longo de todo o
   sistema, caracterizando a sua distribuição. Dentro do conceito de módulos e
   múltiplos caminhos, o paralelismo, a distribuição de processos e a troca de
   mensagens desempenham um papel fundamental, uma vez que informações são
   trocadas entre os módulos de diferentes atributos, assim como de diferentes
   estágios dentro de um mesmo caminho, de modo a aprimorar o processamento
   visual. Esse tipo de processamento colaborativo não teria sentido em um regime de
   processamento seqüencial.
   Além do trabalho cooperativo entre o processamento simultâneo de
   diferentes atributos, o córtex também apresenta a integração e colaboração de
   diferentes níveis de conhecimento. Ao mesmo tempo que as informações são
   processadas de baixo para alto nível, o mesmo ocorre em sentido inverso, e a troca
   de mensagens entre esses dois sentidos realiza a integração das informações,
   aumentando o poder de processamento e reconhecimento de padrões do sistema
   biológico. Novamente, esse tipo de estratégia não teria sentido sem a utilização de
   uma arquitetura massivamente paralela.
   5.2.1.2 – ALTA RESOLUÇÃO PARA A REPRESENTAÇÃO DE
   IMAGENS
   Esta é uma das lições mais básicas que a natureza nos ensina. Por
   questões de desempenho, é ainda raro encontrar um sistema de visão artificial que
   exceda a dimensão de 512x512 (262144 pontos), no entanto os sistemas naturais
   de visão apresentam resoluções de ordens muito maiores. Na retina de cada um
   dos olhos dos seres humanos, são encontradas cerca de 126 milhões de
   fotorreceptores. A indicação que podemos tirar dessa grande diferença é de que
   resoluções mais altas podem aumentar substancialmente a performance da
   qualidade em reconhecimento de padrões, assim como dos resultados das técnicas
   de processamento de imagens.
   169
   CAPÍTULO 5
   Evidentemente, o aumento da resolução do sistema aumenta
   proporcionalmente o custo computacional do processamento, especialmente nos
   primeiros estágios da visão, que de um modo geral, operam a imagem pixel a pixel
   e usualmente utilizam métodos que empregam convoluções, tornando ainda mais
   drástico o tempo de processamento e o consumo de poder computacional, devido
   ao grande número de multiplicações utilizadas [Levine, 1985]. Para solucionar esse
   problema, a natureza utiliza o processamento massivamente paralelo, replicando as
   estruturas de processamento nos módulos, processando diversos módulos
   simultaneamente e até mesmo desenvolvendo mecanismos de processamento
   paralelo de sinais intimamente ligados às estruturas de aquisição de imagem (o
   maquinário neural encontrado na retina). Este é mais um ponto que evidencia a
   necessidade do paralelismo, que é uma das bases do projeto.
   5.2.1.3 – HIERARQUIA
   Organização hierárquica do processamento sempre foi característica dos
   sistemas de visão artificiais, sendo talvez uma conseqüência natural do
   processamento visual. No sistema de visão dos primatas, a hierarquia é bem nítida
   e pode ser sintetizada pela seqüência: retina, núcleo lateral geniculado, córtex
   visual e áreas corticais de alto nível. A cada estágio hierárquico a informação visual
   se torna mais compacta e mais abstrata e complexa, incorporando cada vez mais
PA informações. Assim como os demais princípios apresentados aqui, a hierarquia
   também está relacionada diretamente com outros tópicos, especialmente com a
   modularidade, paralelismo e com a representação visual efetiva.
   5.2.1.4 – TRÁFEGO DA INFORMAÇÃO EM SENTIDO DUPLO
   Um princípio que exerce um papel fundamental no desempenho do
   reconhecimento de padrões dos sistemas biológicos é a realimentação de
   informações ou o duplo sentido da informação. A vasta maioria dos sistemas de
   visão artificial apresentam apenas um único sentido no tráfego de imagem, o qual
   vai dos níveis baixos para os níveis altos de processamento. Entende-se por nível
   baixo de processamento, os processamentos primários, tais como detecção de
   bordas, normalização de histograma, suavização e etc. À medida que as
   informações processadas vão ficando mais complexas (retas, regiões, formas,
   objetos e etc.), dentro dessa nomenclatura, o processamento vai se tornando de
   170
   Cyvis-1 e ynergos
   nível mais alto.
   Nos sistemas de visão biológicos o tráfego das informações é realizado em
   sentido duplo. Deste modo, tanto os módulos de baixo nível transmitem
   informações para os de alto nível, como o reverso também ocorre. A grande
   vantagem dessa estratégia é que as informações processadas de alto nível,
   armazenadas em processamentos realizados anteriormente, quando enviadas para
   os módulos de processamento de baixo nível, contribuem para a eficácia e
   performance de seus processamentos, enriquecendo a informação visual.
   Ocasionalmente, quando observamos um objeto ou uma cena, e temos uma
   percepção instantânea que não condiz com a realidade, muitas vezes isto é fruto de
   um erro concebido pelo fluxo de informações de alto para baixo nível.
   5.2.1.5 – MODULARIDADE
   Principalmente devido à característica de plasticidade apresentada em
   determinadas situações pelo córtex, nos primórdios da neurociência, acreditava-se
   que o cérebro, mais especificamente o córtex, era uma massa uniforme, dividida
   apenas entre regiões de motoras - sensoriais e memória associativa [Zeki, 1993].
   Essa antiga crença ainda influencia o âmbito computacional que se inspira em
   neurociências. Podemos observar que a grande maioria das redes neurais artificiais
   são caracterizadas por interconexões uniformes constituídas de apenas um único
   tipo de neurônio artificial. A pesquisa científica, entretanto, elucidou essa questão e
   pôs fim à crença da uniformidade. Como sabemos o córtex, longe de ser uniforme,
   apresenta arquiteturas e conexões distintas em diferentes regiões. Tomando
   apenas o exemplo da córtex visual, o capítulo anterior apresenta diferentes
   arquiteturas que caracterizam as diferentes áreas do córtex visual.
   A modularidade apresenta para os sistemas de visão a utilização de uma
   organização lógica e estrutural, que proporciona, as bases para o processamento
   paralelo, assim como inúmeras outras vantagens nos aspectos arquitetônicos, que
   sob o ponto de vista computacional são vitais. Ferramentas e métodos para a
   modularização do software e hardware são vitais para a ciência da computação,
   como bom exemplo disso podemos citar a programação orientada a objetos em
   software, assim como o desenvolvimento do circuito integrado em hardware.
   171
   CAPÍTULO 5
   5.2.1.6 – REPRESENTAÇÃO VISUAL EFETIVA
   Uma das questões mais importantes nos sistemas de processamento de
PA dados consiste no modo pelo qual a informação será representada. Esse ponto é
   importante para os sistemas de processamento visual, uma vez que operam em
   grandes quantidades de dados, que são armazenados sucessivamente para cada
   um dos estágios do processamento. No modelo biológico, a preocupação com a
   representação visual é claramente observável, e aqui vamos tomar como exemplo o
   sistema visual dos primatas e suas diferentes representações ao longo de sua
   hierarquia.
   A imagem projetada na retina é convertida em sinal nervoso por cerca de
   126 milhões de fotorreceptores, dos quais existem duas classes principais (cones e
   bastonetes) que possuem sensibilidades distintas. De modo, temos dois mapas
   com representações específicas. Na retina, é realizado um pré processamento de
   detecção de borda pelo seu maquinário neural, que culmina nas células
   ganglionares. Os dois mapas são então reorganizados e as suas representações
   compactadas. Assim as imagens são representadas pelas terminações nervosas de
   apenas 800 mil células ganglionares, que formam o nervo óptico. Se não ocorresse
   o pré processamento e uma representação mais efetiva do sinal, o nervo óptico
   seria muito maior, desperdiçando recursos, que a natureza prima por economizar.
   Segundo Marr [Marr, 1982], isso é possível devido à riqueza das informações
   contidas nas bordas, que são suficientes para representar grande parte da cena.
   Dos gânglios da retina a informação é então enviada para o LGN, que então
   redistribui representações distintas para entradas específicas do córtex visual
   primário, onde é realizado processamento de um nível mais alto. Nessa etapa as
   informações são representadas de forma a arranjar contextos mais ricos, tais como
   mapas cromáticos, mapas de segmentos de retas, disparidade e movimento, entre
   outros. Embora ainda sejam pouco conhecidas as representações em escalas
   ainda maiores, devido ao comportamento do córtex de elaborar representações
   mais abstratas e complexas a partir das anteriores, podemos presumir, nessa linha
   de raciocínio, que existem representações abstratas capazes de conter de forma
   concisa e precisa, objetos e cenas inteiras.
   5.2.1.7 – ESPECIALIZAÇÃO DE PROCESSOS
   A antiga crença na uniformidade do córtex, além de influenciar as questões
   172
   Cyvis-1 e ynergos
   estruturais e arquiteturais, como vimos na Seção 5.2.1.5, também caracterizou de
   modo impróprio o seu aspecto funcional. Deste modo, acreditava-se que todas as
   partes do córtex eram capazes de realizar qualquer tipo de processamento, e que
   não existiam centros ou regiões repensáveis por determinados atributos. A partir da
   localização da área Broca [Broca, 1861], esse conceito mudou e, mais tarde, com a
   descoberta das áreas especializadas no córtex visual, a teoria da especialização
   funcional do córtex veio a se consolidar. Deste modo além de apresentar módulos
   com perfil arquitetônico e estrutural distintos, cada um desses módulos possui
   também funções distintas.
   Nos primatas, assim como em outros mamíferos de ordem superior, o
   processamento dos atributos visuais (movimento, orientação, cor, textura e etc.) é
   realizado por distintas especializações de processamento [Zeki & Shipp, 1988]
   [Livingstone & Hubel, 1988] [Zeki, 1993] [Hubel, 1995] [Levine & Shefner, 1991]
   [Julesz, 1995]. A segregação do sistema visual inicia-se já na retina, além de
   possuir diferentes células fotorreceptoras possui também caminhos diferentes de
   processamentos: magnocelular e parvocelular. Esses caminhos são novamente
   divididos no o à demanda por paralelismo em visão computacional, e mais
   especificamente para os projetos do Grupo de Visão Cibernética e carência de
   ferramentas de simples utilização para a implementação paralela compatíveis com
   a linguagem e com o ambiente de programação vigentes, fomos motivados a
   desenvolver um conjunto de ferramentas para implementação de aplicações
   paralelas que viessem a atender a estas necessidades.
   Nasceu assim o CVMP ("Cybernetic Vision Message Passage"), que será
   apresentado no próximo capítulo. Um conjunto de ferramentas visuais para a
   implementação de aplicações paralelas, de simples utilização, voltada para a visão
   computacional. Através do CVMP os pesquisadores do Grupo de Visão Cibernética
   não necessitam mais mudar de linguagem e ambiente de desenvolvimento para a
   implementação de programas concorrentes, poupando árduos treinamentos, longos
   períodos de familiarização e o trabalho de portar códigos. Deste modo, podem de
   maneira simples e efetiva, através de programação visual e orientada a objetos,
   desenvolver programas paralelos e se integrar em grandes projetos de visão
   computacional, que necessitam de paralelismo, tais como o Cyvis-1 e o ynergos.
   209
   CAPÍTULO 5
   210
   CAPÍTULO
   6
   CVMP - CYBERNETIC VISION
   MESSAGE PASSAGE
   "Todas as coisas complexas estão condenadas à decadência"
   Buda
   211
   CAPÍTULO 6
   212
   CVMP
   CAPÍTULO 6 – CVMP
   6.1 - INTRODUÇÃO
   Neste capítulo estaremos apresentando a base para o paralelismo proposta
   nesse trabalho, o CVMP. Iniciaremos este capítulo comentando os aspectos que
   nos levaram ao desenvolvimento dessa plataforma, depois estaremos
   apresentando seus princípios e funcionamento e em seguida suas estratégias de
   comunicação e seu desempenho, assim como sua disponibilidade de utilização nas
   plataformas MIMD memória compartilhada e MIMD memória distribuída.
   Finalizamos o capítulo apresentando o conjunto de ferramentas que constituem o
   CVMP.
   6.2 - MOTIVAÇÃO E HISTÓRIA
   Como vimos no capítulo anterior, embora a computação paralela traga
   inúmeros benefícios para as áreas de visão computacional, processamento de
   imagens e áreas relacionadas, alguns obstáculos impedem sua proliferação. Dentre
   estes, o principal obstáculo é a dificuldade de implementação de programas
   concorrentes, uma vez que a maioria das ferramentas para o desenvolvimento de
   programas paralelos é destinada a especialistas da área. Essa dificuldade aumenta
   ainda mais devido à necessidade de mudar de ambientes de programação e até
   mesmo linguagens em determinados casos, de modo que além do tempo gasto
   com o aprendizado das metodologias paralelas, é necessário também investir
PA tempo no processo de familiarização com as novas ferramentas de programação,
   além da necessidade de portar ou reescrever o código para outra plataforma.
   Observando essas dificuldades, fomos motivados a idealizar uma
   metodologia para o desenvolvimento de programas concorrentes de forma simples
   e efetiva. Além da simplicidade de utilização, uma questão primordial para facilitar o
   desenvolvimento de programas concorrentes é a utilização das linguagens e
   ambientes de programação integrados (visual) a que os programadores já estejam
   ambientados, reduzindo assim o tempo de aprendizado e de portar, ou reescrever o
   213
   CAPÍTULO 6
   código. Tendo nosso grupo adotado como plataforma de desenvolvimento o
   Borland Delphi [Cantù, 1995], que além de bastante popular, obedece as
   características necessárias de uma plataforma de desenvolvimento moderna (ver
   5.2.3), optamos pela utilização deste ambiente.
   A história do CVMP é parecida com diversos outros produtos que nasceram
   derivados de outros projetos. Essa situação é bastante comum na Ciência da
   Computação, um bom exemplo é o mouse ou o do conceito de orientação a
   objetos, que surgiram no PARC (Palo Alto Research Center) [Bruno, 1995], através
   de um grande projeto de interação entre homem e máquina realizado pela Xerox ao
   longo de toda a década de 70. No caso do CVMP o projeto em questão é o Cyvis-1,
   que foi apresentado no capítulo anterior. Uma das bases do Cyvis-1 é a adoção de
   paralelismo em sistemas de visão que, como vimos, além de desempenho, exerce
   papel fundamental sobre a integração e a corporação de atributos visuais. Uma das
   características do projeto Cyvis-1 é o número de pessoas envolvidas, pois devido à
   sua complexidade, o Civis-1 requer o trabalho cooperativo de diversos
   pesquisadores de visão cibernética, especialistas nas diversas modalidades
   exigidas pelo sistema, para o seu desenvolvimento.
   Sendo os pesquisadores que participam e virão a participar do projeto
   especialistas em visão e processamento de imagens, defrontamos com a grande
   barreira da computação paralela. Dentre as inúmeras dificuldades que já
   mencionamos (ambientes e linguagens diferentes, portar código, dificuldade de
   implementação, etc.), que acompanham os benefícios da computação paralela, nos
   defrontamos principalmente com a questão da dificuldade de implementação de
   sistemas em paralelo. Uma das características que podemos observar na
   Computação Paralela, que também se manifesta em diversas outras áreas da
   ciência, é o seu perfil eclético. Dificilmente encontramos sistemas comerciais
   paralelos. Em geral, a utilização de paralelismo em sistemas de computação
   repousa no berço da pesquisa científica, encontrando nela o seu principal nicho.
   Provavelmente por essa razão, não existe uma preocupação efetiva como a
   interação entre homem e máquina [Preece et al., 1994] nesta área, fato que
   podemos facilmente comprovar pela natureza complicada de suas ferramentas de
   implementação, como é o caso das famosas MPI [Pacheco, 1997] e PVM [Geist et
   al., 1996], que através da dificuldade de utilização, limitam os benefícios do
   paralelismo aos especialistas da área.
   Assim, devido à grande dificuldade de implementação de sistemas
   214
   CVMP
   paralelos, fomos motivados a desenvolver uma ferramenta que trouxesse os
   benefícios da computação paralela ao mundo da visão computacional e
   processamento de imagens, de modo simples de usar, possibilitando o
PA desenvolvimento de programas paralelos por pesquisadores da área de visão sem
   conhecimento específico em computação paralela. Nascia assim a ferramenta de
   troca de mensagens CVMP. Os principais requisitos que encontramos e atendemos
   de forma a simplificar ao máximo o desenvolvimento de programas paralelos,
   foram:
   Plataforma de desenvolvimento convencional: Como já comentamos o treinamento
   com novas plataformas e linguagens de desenvolvimento e o tempo gasto
   portando programas é um grande empecilho. Por esta razão optamos pela
   adoção de uma plataforma de desenvolvimento convencional e popular.
   Optamos pelas ferramentas Borland Delphi e C++ Builder, que além de
   serem bastante populares, são as ferramentas adotadas pelo grupo de
   visão, de modo que os pesquisadores possam facilmente desenvolver
   versões paralelas de seus programas na mesma linguagem e ambiente com
   os quais já estão familiarizados.
   Programação Visual: A programação visual, diretamente associada com o
   paradigma da orientação a objetos, é uma tecnologia que trouxe inúmeros
   benefícios para o desenvolvimento de software. Através da programação
   visual, o tempo de desenvolvimento de aplicativos é menor e a utilização de
   linguagens de programação mais simples e fácil.
   Programação Orientada a Objetos: Inúmeros são os benefícios proporcionados por
   essa tecnologia. Em termos de operação de computadores, o conceito de
   programação orientada a objetos surgiu simultaneamente com a interface
   gráfica com o usuário (GUI), que possibilitou um enorme passo para a
   popularização da informática. Na engenharia de software, esse paradigma
   possibilitou benefícios similares ao conceito de circuitos integrados em
   eletrônica [Cox, 1986]. O conceito de programação orientada a objetos é a
   coluna dorsal do CVMP, uma vez que este paradigma possibilita além de
   simples utilização, a reutilização de código e a modelagem de sistemas
   complexos.
   A partir dessas primitivas e outros conceitos que iremos apresentar no
   decorrer desse capítulo, o conjunto de ferramentas CVMP se transformou na base
   de desenvolvimento paralelo para o projeto Cyvis-1. A partir da idéia de criar uma
   215
   CAPÍTULO 6
   ferramenta de desenvolvimento de aplicações paralelas, simples de utilizar, e que
   permite sua utilização por profissionais de diferentes áreas, tem demonstrado ser
   um interessante meio de tornar os benefícios da computação paralela acessíveis
   para as demais áreas da ciência da computação.
   6.3 - CVMP - CYBERNETIC VISION MESSAGE
   PASSAGE
   O CVMP é uma abreviação do inglês "Cybernetic Vision Message Passage",
   que podemos traduzir como ferramenta de troca de mensagens para visão
   cibernética. Trata-se de um conjunto de ferramentas para o desenvolvimento de
   programas paralelos em plataforma Delphi / C++ Builder, utilizando os conceitos de
   programação visual e orientação a objetos. Seu ideal, é o de contribuir com a
   proliferação da computação paralela e especialmente sua utilização de forma
   simples em nossa área (visão e processamento de imagens). Atualmente tem
   demonstrado sua eficiência como plataforma de desenvolvimento paralelo do grupo
   de visão cibernética, através de sua utilização por diversos pesquisadores no
   desenvolvimento de projetos que se beneficiem com a paralelismo, sendo de modo
PA especial, a base para o desenvolvimento do Cyvis-1, cujo conceito de paralelismo é
   vital para o seu modelo.
   O CVMP é composto por um conjunto de componentes ( VCL - Visual
   Component Library) nativos em Delphi e alguns aplicativos. Os componentes são
   compostos por cinco grupos: CVMP básico, CVMP processor farm, CVMP image
   processing, Estatística e Launcher, e os aplicativos em dois grupos: Estatística e Launcher.
   A Figura 6.1 apresenta a paleta de componentes do ambiente Delphi com os
   componentes CVMP.
   Fig. - 6.1 – Paleta de componentes CVMP em ambiente Delphi.
   216
   CVMP
   6.3.1 - OBJETOS CVMP
   No decorrer deste capítulo forneceremos maiores detalhes sobre cada um
   dos componentes e também dos aplicativos que compõe o conjunto de ferramentas
   CVMP. A seguir vamos apresentar rapidamente cada um dos seus grupos de
   componentes.
   CVMP básico: Esse grupo é composto por dois componentes, que fornecem as
   primitivas de troca de mensagens, sendo um componente para sistemas MIMD de
   memória distribuída e o outro para MIMD de memória compartilhada:
   CVMP Pro: Contém uma biblioteca de funções e procedimentos e um componente
   CVMP básico com esta biblioteca encapsulada (CVMP Pro). A biblioteca CVMP Pro
   contém funções e procedimentos para a manipulação de pacotes de mensagens,
   para a sincronização da troca de mensagens, semáforos e mecanismos de controle
   que podem ser utilizadas em conjunto com o CVMP básico, além de suporte para
   operações básicas com imagens, tais como partição e divisão em blocos.
   CVMP processor farm: Contém componentes com a arquitetura fazenda de
   processadores (processor farm) implementada para até 4, 8 e 16 máquinas
   escravas. Através do CVMP processor farm, o usuário pode de modo visual
   implementar facilmente uma aplicação distribuída, sem precisar escrever nenhuma
   linha de controle para essa estratégia de paralelismo. Cada CVMP processor farm
   (até 4 e até 8 máquinas escravas) é composto por uma dupla de componentes, um
   mestre e um escravo. O componente mestre é responsável pela supervisão dos
   escravos e pela divisão automática de tarefas, enquanto que o componente escravo
   é responsável pela execução das tarefas.
   CVMP Image processing: Cada técnica de processamento de imagem
   implementada pelo CVMP pode ser facilmente convertida em um novo componente
   e reutilizado futuramente. Dentro deste conjunto, temos algumas técnicas de
   processamento de imagem implementadas e prontas para sua utilização, tais como:
   transformada de Fourier, convolução de máscaras (Sobel) e transformada de
   Hough. Enfim, esta categoria está sempre em expansão e pode ser implementada
   pelo próprio usuário, como é o caso do componente personalizado desenvolvido em
   217
   CAPÍTULO 6
   conjunto com Alan Salvany Felinto e Jander Moreira [Moreira et al., 1999], que
   possui inúmeros protocolos personalizados e um método para aquisição remota de
   imagens (a partir de placa de aquisição de imagens de vídeo), para o sistema de
   integração entre cor e estéreo, que apresentaremos futuramente.
   Estatística: É composto por dois componentes, um para análise estática e outro
   análise dinâmica, para auxiliar na análise estatística do comportamento de
   execução dos programas concorrentes desenvolvidos com o CVMP, tais como fluxo
PA e tempo de execução e o tráfego de mensagens. O componente de análise estática
   faz as medidas de desempenho diretamente através do código do programa, que
   deve conter em pontos estratégicos, estipulados pelo programador, chamadas a
   métodos do objeto. A partir destas chamadas, o componente realiza o cálculo do
   tempo e o armazena em um arquivo que pode ser visualizado com o aplicativo de
   estatística, que faz parte do conjunto de ferramentas CVMP. O componente para
   análise dinâmica possui a mesma estratégia de utilização de seu parceiro,
   entretanto, ao invés de serem armazenadas em arquivo, as análises são enviadas
   em tempo de execução para o aplicativo de análise dinâmica, podendo deste modo
   ser feito a visualização do desempenho, fluxo de execução e troca de mensagens,
   enquanto o sistema é executado.
   Launcher: Composto por um único componente, o CVMP-Launcher, possibilita o
   disparo de aplicativos nas máquinas da rede. Isto é realizado em conjunto com os
   aplicativos Launcher. A partir de chamadas aos métodos do objeto, o programa
   pode disparar a execução de um determinado programa em uma máquina
   específica da rede.
   6.3.2 - APLICATIVOS CVMP
   Os aplicativos CVMP são programas que auxiliam na utilização ou
   funcionamento dos objetos CVMP. Os aplicativos se dividem em dois grupos:
   Análise estatística, contendo aplicativos voltados para a análise de fluxo de
   execução, desempenho e troca de mensagens e o Launcher, contendo aplicativos
   que permitem o disparo de programas em máquinas remotas.
   Estatística: Existem dois aplicativos para análises estatísticas, sendo um para
   218
   CVMP
   análise estática e outro para dinâmica. O Aplicativo para a análise estática é um
   utilitário que permite a visualização e análise dos resultados gerados a partir do
   componente de estatística. O aplicativo para análise dinâmica é mais complexo.
   Assim como o estático ele também permite a visualização e análise dos resultados,
   no entanto os resultados são obtidos em tempo de execução. Para isso o aplicativo
   recebe mensagens do componente através de compartilhamento da memória
   virtual. A cada mensagem recebida é atualizada a janela de exibição, permitindo
   desse modo uma análise do comportamento do sistema em tempo real.
   Launcher: É composto por dois aplicativos, o módulo central e os disparadores. Os
   disparadores são aplicativos que ficam na barra de tarefas do windows (tray) e
   ficam aguardando ordens. Através das ordens que recebem eles executam os
   programas determinados. O módulo central é um aplicativo que recebe comandos
   do objeto Launcher, ou entradas diretas pelo usuário. Sua missão é transmitir as
   ordens para a execução de programas para os disparadores espalhados pela rede.
   6.4 - te as áreas V1 e V2 apresentam um forte perfil de
   segregação, separando sinais de diferentes atributos e enviando para as regiões
   mais especializadas (V3,V4 e V5). Esse tipo de estrutura sugere a existência de
   uma arquitetura estilo “pipeline” entre as áreas de segregação V1 e V2 e as mais
   especializadas (V3, V4 e V5), devido a dependência de dados. Devemos observar
   entretanto, que a comunicação no córtex visual é extremamente complexa, e ainda
   pouco sabemos a respeito de sua arquitetura. Existem comunicações entre as sub-
   regiões de uma mesma área, assim como entre áreas, de forma a favorecer a
   integração e segregação da informação dos diferentes atributos visuais. Além disso,
   devemos observar também que não existe um caminho unidirecional. As
   informações transitam em ambos sentidos de forma que as camadas superiores da
   hierarquia visual realimentam as primeiras camadas do processo.
   Nas próximas seções estaremos discutindo a organização, as conexões e o
   funcionamento do córtex visual, consequentemente explorando seu provável
   paralelismo. Para concluirmos esta seção, devemos lembrar a forte correlação
   existente entre a distribuição da informação e o paralelismo. Desta forma, a busca
   pelo paralelismo no processamento biológico implica na procura pela distribuição e
   replicação de sinas. Uma vez que todas as áreas corticais possuem saídas
   paralelas para outras diferentes áreas, chegamos à conclusão que não apenas o
   138
   OS CAMINHOS PARALELOS DA VISÃO
   sistema visual é um sistema paralelo-distribuído, mas sim todo o cérebro.
   4.7.3 – DIVISÕES DO CÓRTEX VISUAL
   Fig. – 4.21 – Fatia do córtex visual, apresentando suas áreas [Zeki, 1993].
   O córtex visual se localiza no lóbulo occiptal, nas áreas 17 e 18 de
   Bradmann, que se caracterizam pelo seu aspecto, respectivamente como córtex
   visual estriado e pré-estriado. O córtex visual estriado constitui uma das cinco áreas
   do córtex visual, também conhecido como V1 ou córtex visual primário, ao passo
   que o córtex visual pré-estriado é dividido segundo critérios anatômicos e funcionais
   em quatro áreas (V2, V3, V4 e V5). A Figura 4.21 apresenta uma fatia do córtex na
   qual podemos observar a localização anatômica de cada uma das áreas do córtex
   visual. Nesta seção apresentamos cada uma dessa áreas.
   4.7.3.1 – ÁREA V1
   Também conhecida como córtex visual estriado, córtex visual primário ou
   ainda área 17 de Broadmann, V1 é a região mais estudada e melhor compreendida
   de todo o córtex. Em V1 são recebidas e processadas todas as modalidades de
   atributos visuais, sendo que a sua principal função é a segregação e a distribuição
   139
   CAPÍTULO 4
   dos atributos. Conforme comentamos anteriormente, o LGN envia para V1 três
   mapas que replicam as informações visuais da retina, onde cada mapa é enviado
   para uma camada cortical específica. É importante observar que V1 é a única área
   cortical que recebe as informações visuais do LGN. A conexão entre o LGN e V1 é
   feita ponto a ponto, de modo que encontramos em V1 mapas topográficos da retina,
   ou seja células adjacentes em V1 recebem informações de regiões adjacentes da
   retina. Deste modo as vizinhanças do campo visual são precisamente mantidas,
   sendo também conhecida como córtex retinal devido a essa característica. Como
   na retina e em todo o sistema visual, em V1 continua ocorrendo uma super-
   representação da região central do campo visual, onde praticamente metade de V1
PA é responsável por seu processamento [Costa, 1996].
   Fig. – 4.22 – Micrografia do córtex visual primário [Dowling, 1992].
   Assim como as demais áreas do córtex visual, o córtex visual primário é
   composto por seis camadas, conforme apresentado na micrografia da Figura 4.22.
   Observando essa Figura vemos que as camadas 1 e 2 não podem ser distinguidas
   nessa imagem e que a camada 4 é dividida em 3 sub-camadas: 4a, 4b e 4c. Cada
   uma dessas camadas apresentam um tipo diferenciado de composição celular que
   é apresentado na Tabela 4.2.
   As fibras que saem do LGN chegam ao córtex visual primário através da
   matéria branca (representado pela letra W na Figura 4.22). Os axônios
   provenientes das camadas magno celulares fazem conexão com os neurônios da
   metade superior da camada 4c, conhecida como 4c , ao passo que os axônios das
   camadas parvo celulares se conectam em duas camadas: na outra metade da
   camada 4c (4c ) e na camada 4a. A Figura 4.23 apresenta um diagrama
   140
   OS CAMINHOS PARALELOS DA VISÃO
   simplificado das entradas e saídas das conexões de V1 e como podemos observar
   as camadas corticais não se diferem apenas pela sua natureza celular (Tabela 4.2)
   mas também por suas conexões.
   Camada
   Tipos de células predominantes
   astrócitos, oligondendrócitos, microgliais e neurônios
   1
   com corpos celulares ovais
   2
   células piramidais de dendritos curtos
   3
   células piramidais de tamanho médio e pequeno
   neurônios estrelados espinhosos e neurônios
   4 (a, b e c)
   poligonais
   (provavelmente neurônios piramidais modificados)
   neurônios poligonais pequenos e médios e células
   5
   piramidais
   várias células, entre elas, neurônios piramidais
   6
   pequenos e médios e células triangulares
   Tabela 4.2 - Composição citoarquitetural de cada camada do córtex visual
   primário.
   A dualidade do sistema visual, caminhos Parvo e Magno, continua presente
   em V1, sendo diferenciadas pelas camadas em que realizam suas principais
   conexões. O caminho Magno após fazer conexão na camada 4c , envia
   informações para a camada 4B. Nesta camada, a maioria das células são seletivas
   a orientação e também algumas de suas células apresentam seletividade para
   direção e movimento. Alguns desses neurônios ainda são binoculares ou seja
   necessitam de estímulos de ambos os olhos e apresentam sensibilidade a
   disparidade retinal (visão estéreo) [Tovée, 1996].
   O caminho Parvo, por sua vez, após conectar nas camadas 4c e 4a, envia
   informações para as camadas superiores de V1 e divide-se em dois novos
PA caminhos. Onde o primeiro deles está relacionado com cor e é denominado P-B e o
   outro relacionado com a percepção de formas precisas e orientação do estímulo,
   conhecido como P-I.
   141
   CAPÍTULO 4
   Entrada
   Saída
   1
   2, 3
   4a
   4b
   4c
   5
   6
   LGN - Magno
   LGN -
   Outras
   Estruturas cerebrais
   áreas
   distantes
   Fig. – 4.23 –Diagrama apresentando as principais conexões das camadas do
   córtex visual primário [Hubel, 1995].
   As camadas do córtex visual apresentam conexões entre camadas, entre as
   demais áreas do córtex visual ou ainda podem apresentar conexões com regiões
   mais distantes, sendo corticais ou não. Todas as camadas com exceções de 1, 4a e
   4c apresentam conexões para fora do córtex. As camadas 2, 3 e 4B apresentam a
   grande maioria de suas conexões para as demais áreas do córtex visual, ao passo
   que as camadas mais inferiores 5 e 6 projetam suas conexões além do córtex, para
   o colliculu superior e de volta ao LGN respectivamente. Devemos lembrar que essa
   estratégia de realimentação do LGN realizada pela camada 6 é uma forte evidência
   do pré-processamento da informação visual realizada no LGN.
   142
   OS CAMINHOS PARALELOS DA VISÃO
   Fig. – 4.24 – Colunas de dominância ocular na camada 4c (projeção 2D),
   marcadas por dois deoxiglucose [Hubel, 1995].
   Como vimos na Seção 4.6.3, a área V1 de cada hemisfério recebe
   informações visuais de apenas um lado do campo visual composto pelas metades
   dos dois olhos, recebendo assim sinais de ambos os olhos. Essa natureza dual da
   informação visual apresenta estruturas no córtex visual primário denominadas
   colunas de dominância ocular. As colunas de dominância ocular foram reveladas
   através de marcações com dois deoxiglucose por Hubel e colaboradores [Hubel et
   al., 1977] [Hubel & Wiesel 1977], e se apresentam ao longo de todo o córtex visual
   estriado. A Figura 4.24 apresenta uma projeção 2D da camada 4C do córtex visual
   primário, revelando as colunas de dominância. A dominância ocular se mantém
   constante ao longo da espessura do córtex, apresentando-se no entanto de forma
   mais graduada a medida que as camadas se distanciam de 4C, camada que recebe
   os aferentes do LGN. A dominância ocular demonstra evidências de ser um dos
   mecanismos responsáveis pela integração da informação proveniente de cada olho.
   Além de campos receptivos semelhantes aos encontrados na retina e no
   LGN, V1 apresenta dois novos tipos de campos receptivos, denominados de
PA simples e complexos. Os campos receptivos simples são sensíveis a orientação e
   posição dos estímulos, e os complexos específicos à orientação, mas os estímulos
   podem aparecer em diversas posições (movimentos). A Figura 4.25 apresenta um
   modelo para o mecanismo das células simples [Hubel, 1995], no qual as células
   centro-periferia de LGN aferem impulsos para as células simples. Através da
   combinação destes estímulos, ocorre a resposta à orientação. Seguindo essa
   mesma filosofia, podemos compreender o funcionamento das células complexas.
   Assim, as células simples de mesma orientação enviam sinais para as células
   143
   CAPÍTULO 4
   complexas. A combinação dos sinais das células simples explicaria o
   funcionamento das células complexas, que possuem campos receptivos maiores
   que as simples e respondem a mesma orientação indiferente da posição do
   estímulo no campo receptivo.
   Fig. – 4.25 – Diagrama ilustrando o campo receptivo das células simples, sua
   composição a partir de células centro-periferia do LGN e as suas respostas a
   estímulos de diferentes orientações [Zeki, 1993].
   Uma outra peculiaridade importante de V1 é o arranjo no qual se encontram
   as células estimuladas à orientação. Experimentalmente, Hubel e Wiesel [Hubel,
   1995] perceberam que quando o eletrodo era introduzido perpendicularmente às
   camadas, as células mantinham praticamente a mesma orientação, ao passo que
   quando o caminho de penetração do eletrodo era tangencial, a resposta à
   orientação das células variavam linearmente ao longo do percurso, embora
   houvesse algumas variações abruptas inexplicáveis. Estas características inspiram
   o clássico modelo das hipercolunas, apresentado na Figura 4.26, que integra as
   colunas de dominância ocular e a distribuição das células de orientação seletiva.
   144
   OS CAMINHOS PARALELOS DA VISÃO
   od
   to
   to
   rei
   quer
   rei
   Di
   Es
   Di
   Fig. – 4.26 – Modelo das hipercolunas de Hubel e Wiesel.
   Quando marcado com a técnica de citocromo oxidase, o córtex estriado
   apresenta marcas na forma de pequenas bolhas (“blobs”, no inglês), conforme
   podemos observar na Figura 4.27. Do ponto de vista fisiológico desse arranjo, foi
   observado que os "blobs" não apresentavam células sensíveis à orientação, mas
   que por outro lado respondiam a variações do comprimento de onda (cor). No
   entanto, a região entre os "blobs" apresenta seletividade à orientação. Para corrigir
   as variações abruptas do modelo de hipercolunas, Braitenberg & Braitenberg
   propuseram um modelo teórico que, devido ao seu aspecto, foi denominado cata-
   vento [Braitenberg & Braitenberg, 1979]. Experimentos recentes [Costa, 1996]
   [Bonhoeffer & Grinvald, 1991] [Blasdel, 1986] indicam que o modelo teórico do cata-
   vento coincide com os "blobs" do citocromo oxidase, de forma que o centro do cata-
   vento, insensível a orientação seja o "blob", e a região que o contorna possui a
PA estrutura de orientação seguindo o padrão de cata-vento.
   Além de coincidir com o modelo de Braitenberg, os "blobs" também explicam
   a dualidade do caminho parvo celular (P-B e P-I) que ocorre em V1. O caminho
   parvo P-B (de Parvo-Blob) privilegia as informações cromáticas e está relacionado
   com as células pertencentes aos "blobs". O caminho parvo P-I ( de Parvo-Interblob)
   é voltado a percepção precisa de formas, localizando nas regiões entre os "blobs",
   contém neurônios que apresentam respostas à orientação (linhas e barras). Uma
   vez que as células dos "blobs" não respondem à orientação, elas possuem campos
   receptivos diferentes dos simples e complexos encontrados em V1, e respondem a
   estímulos envolvendo cromaticidade. Assim como no LGN foram encontradas
   células com campo receptivo de oponência cromática. Esse mecanismo envolve os
   pares de cores vermelho/verde e azul/amarelo, que ficam arranjados nas estruturas
   centro-periferia dos campos receptivos e podem ser observados através de uma
   série de experimentos psicofísicos [Goldstein, 1989].
   145
   CAPÍTULO 4
   (b)
   (a)
   Fig. – 4.27 – (a) Corte longitudinal do córtex estriado, com tratamento de
   citocromo oxidase. (b) Detalhe do corte paralelo (linha da imagem a)
   apresentando as camadas 2 e 3. As estruturas em forma de pontos claros são
   os "blobs" [Zeki, 1993].
   Uma vez que discutimos as estruturas encontradas no córtex estriado visual,
   comentaremos agora sobre seu funcionamento em termos gerais, enfocando
   sempre as questões de paralelismo. Uma das principais funções de V1 é a
   segregação dos sinais visuais. Deste modo, o sinal que vem do LGN é separado de
   acordo com o atributos e retransmitido para as áreas mais especializadas. Do ponto
   de vista do paralelismo, a segregação realizada em V1 é uma evidência muito forte
   do paralelismo entre as diferentes áreas. Nesse perfil, o córtex visual primário tem
   como função a divisão das tarefas, uma vez que direciona cada atributo para uma
   área especialista, e além disso o sincronismo de sinas, como já comentamos, V1
   possui fibras eferentes com diferentes espessuras indicando velocidades diferentes.
   Ainda quanto ao paralelismo, este pode ocorrer em diferentes níveis dentro
   do córtex estriado (Seção 4.7.2). No nível mais baixo da escala temos o paralelismo
   entre neurônios, uma forte evidência desse nível em V1 são as células simples e
   complexas. Como vimos, as células simples recebem sinal das células centro-
   periferia e as células complexas das células simples, isso evidência o paralelismo
   entre neurônios em V1, e para que os impulsos sejam integrados pelo neurônio,
   eles devem ser concomitantes, indicando a ocorrência de células processando
   paralelamente. Subindo a escala encontramos diversas estruturas replicadas
   indicando paralelismo entre estas assim como regiões respondendo a diferentes
   146
   OS CAMINHOS PARALELOS DA VISÃO
   orientações. E, finalmente, encontramos em V1 três sistemas distintos: um magno e
   dois parvos. Sendo responsáveis por diferentes atributos, ocupam espaços físicos
   separados (embora ocorra conexões entre eles) em estruturas ou camadas
   diferentes, indicando através dessa independência a existência de paralelismo
   entre esses sistemas.
   4.7.3.2 – ÁREA V2
   Adjacente à região V1, e embora não tão explorada quanto esta, V2 é a
PA segunda região mais explorada do córtex visual. Semelhante em diversos aspectos
   ao córtex visual primário, do qual é o alvo principal das fibras aferentes, essa região
   segrega as informações visuais distribuindo para áreas mais especializadas e,
   deste modo, também incorpora todas as modalidades visuais. Outra característica
   que preserva do córtex estriado é a constância do mapeamento da retina,
   possuindo as células vizinhas campos receptivos vizinhos no campo visual, uma
   vez que células adjacentes em V1 conectam-se com células também adjacentes
   em V2.
   Na região V2, além dos campos receptivos que já apresentamos
   anteriormente, encontramos um novo tipo peculiar, denominado de células
   hipercomplexas. Esse nOS CANAIS VIRTUAIS
   A comunicação entre os objetos CVMP é realizada sempre aos pares,
   dentro do conceito mestre/escravo, conforme apresenta a Figura 6.2. A partir de um
   par de objetos CVMP é estabelecido um canal virtual [Bruno & Costa, 1997] [Bruno
   & Costa, 2000]. O conceito de canal virtual é a base da ferramenta CVMP, ele foi
   inspirado nos canais dos transputer [Inmos, 1988] [Inmos, 1989], famosos
   processadores utilizados na década de 80, que impulsionaram forte interesse em
   paralelismo em sua época, devido à facilidade de implementação de hardware
   paralelo que eles proporcionavam. Assim como nos canais dos transputers, os
   canais virtuais são fixos e, uma vez definidos, não podem mais ser alterados. A
   estratégia de fixar a conexão entre os componentes foi idealizada de modo a
PA simplificar ao máximo sua utilização.
   Cada canal virtual conecta dois processos, onde cada processo utiliza um
   objeto CVMP, que pode através dele enviar e receber mensagens. Os processos
   podem estar na mesma máquina, sendo executados em concorrência através da
   multitarefa do sistema operacional, podendo estar também em diferentes
   processadores de uma máquina multiprocessada, assim como em máquinas
   conectadas por rede.
   219
   CAPÍTULO 6
   M
   S
   Fig. - 6.2 – Exemplo do conceito mestre/escravo e da conexão através do
   Canal Virtual. A caixa M simboliza um objeto CVMP configurado como mestre,
   enquanto que a S, configurado como escravo. A barra vertical representa o
   Canal Virtual.
   Para a comunicação de processos em diferentes máquinas conectadas via
   rede (sistema distribuído), o Canal Virtual possui duas conexões, uma para o
   tráfego de pacotes, com pequena granularidade, e utilizando protocolo TCP/IP, e
   outra para pacotes, de alta granularidade, utilizando o protocolo NetBeui ou IPX/SX.
   Essa estratégia permite um desempenho melhor da rede, possibilitando um tráfego
   de pacotes mais ágil. Comentaremos nas próximas seções esta estratégia de forma
   mais detalhada.
   Em uma primeira instância, pode parecer que, tanto a utilização de canais
   fixos como a conexão entre pares limitam as possibilidades de conexões. No
   entanto, não existe um limite para o número de canais virtuais e nem para o número
   de objetos CVMP utilizados por processo. Deste modo, arquiteturas complexas
   podem ser facilmente implementadas. A Figura 6.3 apresenta alguns exemplos de
   configurações permitidas utilizando os canais virtuais, demonstrando sua
   flexibilidade. As configurações apresentadas são as mesmas tanto para sistemas
   distribuídos (MIMD distribuído) como para máquinas multiprocessadas (MIMD
   compartilhado). Em (a) temos uma máquina conectada a outras máquinas
   utilizando pares de CVMP conectados por Canais Virtuais; em (b) existem dois
   processos conectados em uma máquina monoprocessada (multitarefa); em (c)
   temos a combinação de (a) e (b); e em (d) temos uma situação mais complexa,
   ilustrando a versatilidade do CVMP.
   220
   CVMP
   A )
   B )
   M
   S
   M
   S
   M
   S
   C )
   M
   S
   M
   S
PA M
   S
   D )
   S
   Máquina ou processador
   M
   S
   Canal Virtual
   S
   M
   M
   S
   M
   CVMP mestre
   M
   M
   S
   M
   S
   S
   CVMP escravo
   Fig. - 6.3 – Possíveis configurações utilizando canais virtuais.
   6.5 - ARQUITETURAS MIMD
   Nessa seção discutimos as arquiteturas paralelas utilizadas para a
   implementação de sistemas através do CVMP, assim como as técnicas
   computacionais utilizadas para a implementação do CVMP em cada uma delas.
   Como já comentamos anteriormente, o CVMP incorpora duas estratégias de
   arquitetura paralela: sistemas distribuídos e máquinas multiprocessadas. Na
   literatura, o termo sistema distribuído é amplamente empregado, discriminando
   sistemas operacionais (Amoeba) [Mul ender et al., 1990], servidores de bases de
   dados e sistemas de computação distribuída. No nosso trabalho estaremos
   empregando esse termo para designar aplicações (ou programas) concorrentes que
   são executados em diferentes máquinas conectadas via rede, ou seja computação
   distribuída. Podemos classificar os sistemas distribuídos implementados com
   CVMP como máquinas MIMD com memória distribuída (ver Capítulo 2). Uma outra
   possível arquitetura de paralelismo permitida pelo CVMP é o desenvolvimento de
   programas
   concorrentes
   em
   máquinas
   multiprocessadas.
   Máquinas
   multiprocessadas são sistemas computacionais que apresentam mais de um
   processador principal. Existe uma grande diversidade de máquinas que se
   enquadram nesse perfil [Almasi & Gottlieb, 1994]. No entanto, o CVMP está limitado
   a sistemas padrão IBM-PC multiprocessados com plataforma Windows-NT. Em
   221
   CAPÍTULO 6
   relação a arquitetura anterior, podemos classificar este tipo de sistema como MIMD
   memória compartilhada.
PA 6.5.1 ARQUITETURA MIMD DISTRIBUÍDA
   Dentro do contexto do CVMP, denominamos arquitetura MIMD distribuída
   um conjunto de máquinas IBM-PC com plataforma Windows NT/9x conectadas em
   rede, apresentando um conjunto de aplicações, que através de utilização das
   ferramentas CVMP, conseguem cooperar executando processamento em conjunto.
   A Figura 6.4 apresenta um exemplo dessa arquitetura, nela temos um sistema
   paralelo formado por 3 processos alojados em máquinas distintas conectadas por
   rede, dos quais dois são escravos (extremidades) e um mestre (no centro). Através
   dos objetos CVMP, representados na figura por pequenos quadrados cinza no
   interior dos processos, são estabelecidos canais virtuais que possibilitam a troca de
   mensagens entre os processos.
   Canal Virtual
   CVMP
   Processo
   Fig. - 6.4 – Exemplo de uma aplicação paralela em uma arquitetura MIMD
   distribuída.
   Para cada arquitetura, MIMD distribuída e MIMD compartilhada, é utilizado
   um objeto de base CVMP específico, que implementa as primitivas de troca de
   mensagens apropriadas e estabelecem os canais virtuais. No modelo MIMD
   distribuído, existem dois mecanismos de troca de mensagem específicos para
   pacotes de pequena granularidade, baseada no protocolo de rede TCP/IP e na
   interface de rede socket e de alta granularidade, baseada na troca de arquivos
   através dos protocolos NetBeui e IPX/SX.
   222
   CVMP
   6.5.1.1 - MENSAGENS EM TCP/IP - SOCKET
   Os canais virtuais são estabelecidos através de conexões entre interfaces
   socket [Dumas, 1995], mecanismo desenvolvido pela Universidade de Berkeley
   para facilitar a troca de mensagens através do protocolo TCP/IP, sendo nativo para
   o UNIX, mais especificamente para o BSD ( Berkeley Software Distribution). Os
   ambientes Windows utilizam uma versão do socket de Berkeley denominado de
   Winsock. Nesses sistemas o Winsock é caracterizado por uma DLL (biblioteca de
   ligação dinâmica) [Bruno, 1995], que exerce o papel de uma API (interface de
   programação de aplicativo) que pode ser acessada através de programação.
   Embora o Delphi apresente em suas novas versões alguns componentes
   que simplificam o acesso ao Winsock, o CVMP foi implementado sem a utilização
   desse recurso, fazendo chamadas diretas à API, para melhorar a performance,
   possuindo um conjunto de primitivas de troca de mensagens.
   6.5.1.2 - TROCA DE ARQUIVOS
   Observamos que em processamento de imagens e visão computacional,
   especialmente nos primeiros estágios, é bastante comum a transferência de
   arquivos com imagens ou dados com grande quantidade de memória. A plataforma
   Windows, dependendo da configuração das máquinas da rede, não apresenta o
   melhor desempenho para a troca de pacotes utilizando protocolo TCP/IP. Visando
   melhorar a performance da rede, foi incorporado uma alternativa no CVMP para
   este protocolo nas situações de troca de alta granularidade ou seja na troca de
   arquivos. Deste modo o CVMP também possui uma estratégia de troca e
   compartilhamento de arquivos através de métodos de API Windows que utilizam os
   protocolos nativos NetBeui e IPX/SX, determinado pela configuração do Windows
   que, segundo a configuração, aumenta a performance da troca de pacotes.
PA 6.5.1.3 - COMPARAÇÃO ENTRE PLATAFORMAS DE TROCA DE
   MENSAGENS
   O CVMP pode ser visto como uma camada de software adicional à interface
   socket de acesso ao sistema de redes (CVMP distribuído), cujo objetivo é fornecer
   um modelo orientado a objetos, simples de usar, flexível e reutilizável para o
   desenvolvimento de programas concorrentes. Embora exista uma grande
   223
   CAPÍTULO 6
   diversidade de métodos para o desenvolvimento de sistemas distribuídos e
   programação concorrente, que também constituem-se de camadas de software
   sobre os protocolos de rede, acreditamos que a principal contribuição do CVMP é a
   simplificação da metodologia, tornando mais simples e ágil o trabalho do
   especialista e provendo os benefícios do paralelismo para programadores não
   especialistas.
   Dentre as ferramentas para troca de mensagens, podemos destacar entre
   as mais populares atualmente: PVM, MPI, DCOM e CORBA. Elas representam
   duas classes distintas de estratégias de concorrência: bibliotecas de funções e
   objetos distribuídos. A primeira, classe é composta pelo PVM (Parallel Virtual
   Machine) [Geist et al., 1996] e pelo MPI (Message Passing Inteface) [Pacheco,
   1997], que são baseadas em bibliotecas de funções, contendo primitivas para o
   desenvolvimento de programas concorrentes, podendo ser incorporados como
   extensões de linguagens de programação genérica ou específicas ou ainda parte
   integrante de algumas linguagens paralelas. A outra classe, objetos distribuídos, é
   caracterizada pelo DCOM (Distributed Component Object Model) [Grimes, 1997] e
   CORBA (Common Object Request Broker Architecture) [Grimes, 1997]. Nesse caso
   o paralelismo fica a cargo de uma camada extra de software integrada ao sistema
   operacional, que é responsável pela distribuição e comunicação dos objetos. Um
   exemplo mais específico do funcionamento dessa estratégia é apresentado pelo
   DCOM. O DCOM é um aperfeiçoamento do COM, e por isso denominado na
   literatura de COM de longo alcance. COM (Component Object Model) [Grimes,
   1997] é uma evolução do antigo padrão OLE (Object Linking and Embedding)
   [Wil iams, 1994]. Como é uma camada de software que fica acima das APIs do
   sistema, e possibilita a criação de interfaces em aplicações, que permite que essas
   se comuniquem com outras em tempo de execução. O DCOM é baseado na
   mesma filosofia do COM, no entanto ao invés de aplicações da mesma máquina se
   comunicarem, essa tecnologia permite que aplicações de diferentes máquinas
   conectadas via rede se comuniquem.
   Enquanto as bibliotecas de funções (PVM e MPI) foram desenvolvidas com
   a finalidade específica de computação científica de alta performance, ou seja
   voltadas para a computação paralela, a tecnologia dos objetos distribuídos, possue
   uso mais voltado à integração de aplicações dentro de um ambiente GUI, como é o
   caso do COM/DCOM, para a plataforma Windows e o CORBA para o projeto
   GNOME (GNU Network Object Model Environment) [GNOME], para plataforma
   224
   CVMP
   UNIX. Embora possa ser utilizado para programação concorrente, a utilização mais
   freqüente desta classe se destina a integração de aplicações e interfaces gráficas
   com o usuário sobre a rede, aplicações de banco de dados e Internet.
   Dentre essas duas alternativas as que mais se adequam ao
   desenvolvimento de programas concorrentes são as bibliotecas de funções para
PA troca de mensagens. Entretanto, a sua utilização apresenta os mesmos problemas
   comuns à computação paralela como um todo, ou seja a dificuldade de
   desenvolvimento de programas, limitando seus horizontes de utilização aos
   especialistas em computação paralela. Embora a computação paralela aparenta
   possuir um perfil eclético, ou seja concentre seus esforços para os especialistas,
   dificultando sua utilização para o programador comum, outra razão inviabiliza
   estudos mais arrojados para torná-las mais amigáveis, uma vez que essas
   ferramentas possuem uma natureza de programação estruturada por
   procedimentos, fato que impede a utilização direta dos paradigmas da programação
   orientada a objetos. Ainda que a tecnologia de objetos distribuídos seja toda
   baseada no conceito de orientação a objetos, a sua utilização para a computação
   paralela está muito longe de ser simples para o usuário, especialmente em
   ambiente Windows. Além de dificuldade de programação das interfaces COM,
   mesmo sendo parte integrante dessa plataforma, é necessária toda uma
   configuração dos sistemas em rede para a sua utilização. Outro fator limitante para
   a utilização dessa tecnologia, é o fato de que apenas as máquinas NT podem ser
   servidoras DCOM, as máquinas com a plataforma Windows 95 se limitam apenas a
   serem clientes.
   O CVMP, mais do que um conjunto de ferramentas para a implementação
   de programas paralelos baseados em troca de mensagens, representa um novo
   conceito, que mostra como a computação paralela pode ser estendida para
   diversas áreas e utilizada por um espectro de usuários muito maior. Dentro desse
   prisma, o CVMP nada mais é do que uma camada adicional de software, criada
   para tornar a programação paralela simples e amigável. Neste contexto o CVMP
   pode estar baseado em qualquer mecanismo de troca de mensagens, podendo
   assim, ser uma camada adicional ao PVM e MPI e até mesmo ao DCOM e CORBA.
   Em algumas situações essas alternativas podem ser especialmente atraentes, uma
   vez que possibilitariam uma integração imediata com sistemas e programas
   paralelos já implementados nessas plataformas.
   225
   CAPÍTULO 6
   6.5.1.4 - DESEMPENHO EM REDE
   Nessa seção vamos discutir alguns resultados do desempenho da
   transferência de pacotes pela rede. O desempenho da comunicação em rede
   depende de diversos fatores, que vão desde o hardware até as diversas camadas
   de software envolvidas na comunicação, a descrição do modelo de camadas da
   rede e suas funções são apresentados de forma bastante didática por Tanenbaum
   [Tanenbaum, 1989]. O CVMP é baseado em chamadas diretas às APIs, em ambas
   as estratégias de troca de mensagens (baixa e alta granularidade), de modo que,
   embora seja uma camada de software adicional ao sistema de rede, é praticamente
   desprezível, no cálculo do desempenho, uma vez que é diversas vezes mais leve
   que as demais camadas envolvidas no processo. Deste modo o desempenho da
   comunicação CVMP é praticamente igual ao desempenho do Winsock, para
   pacotes de granularidade baixa e ao protocolo NetBeui - IPX/SX para as
   granularidades altas.
   Os gargalos que influenciam o desempenho da rede, podem ser
   comparados a uma pirâmide, onde a base (meio físico e hardware) determina o
   desempenho máximo, que diminui a cada camada adicional. Deste modo a
   configuração da rede é um fator imprescindível para a eficiência da comunicação. A
   interface entre o software e o hardware, é um elemento que pode limitar bastante a
PA performance. Essa interface é realizada através de programas conhecidos como
   device driver. Usualmente os sistemas operacionais possuem device drivers
   genéricos, que não exploram as características específicas do hardware, e
   consequentemente comprometem a sua performance.
   Realizamos as medidas de desempenho de comunicação do CVMP em uma
   rede de computadores plataforma Windows com configuração genérica. Uma vez
   que o CVMP possui um consumo de software desprezível em relação as outras
   camadas da rede, nossas medidas expressam o desempenho do próprio sistema
   operacional em uma rede padrão ethernet NE2000 de 10 Mbits/s.
   226
   CVMP
   a)
   b)
   c)
   Fig. - 6.5 – Gráficos do desempenho de transferência de pacotes via rprogramação visual efetiva
   baseada em integração de ferramenta CASE [Bruno & Costa, 1996] [Bruno & Costa
   1997] [Bruno & Costa, 2000].
   180
   Cyvis-1 e ynergos
   Tendo definido a plataforma de desenvolvimento, temos que fazer a escolha
   dos hardwares e sistemas operacionais. Como escolha de hardware foram
   adotadas máquinas baseadas no padrão IBM-PC, que possuem baixo custo, são
   populares, e sua performance atingiu o nível das estações de trabalho (já existem
   hoje máquinas neste padrão, com múltiplos processadores, cuja freqüência de
   operação aumenta a cada dia). Quanto ao sistema operacional, tivemos que fazer
   nossa escolha com base nas plataformas de desenvolvimento. Embora os sistemas
   operacionais baseados em UNIX para IBM-PC possuam mais vantagens quanto ao
   desenvolvimento em sistemas de redes e computação científica, atualmente eles
PA possuem um déficit de ambientes de desenvolvimento integrados (como o Delphi e
   o C++ Builder - programação visual, OOP, Base de dados, etc.). Devido a tais
   fatores optamos pela utilização do Windows 95/98/NT, escolha esta que num futuro
   próximo deverá ser estendida, uma vez que o fabricante das ferramentas de
   desenvolvimento escolhidas está portando-as para UNIX [Kylix].
   Como vimos nas seções anteriores, devido a sua inspiração biológica, uma
   das bases de desenvolvimento do projeto Cyvis-1 é o paralelismo. Defrontamos
   assim com um grande desafio para a implementação do sistema. Já discutimos a
   importância do paralelismo na computação e nos sistemas biológicos, e como
   embora sendo vitais, acarretam uma série de problemas. O desenvolvimento de
   programas paralelos envolve o aprendizado de linguagens de computação com
   extensões paralelas assim como de ferramentas de implementação paralela. Um
   dos grandes problemas nesses casos é que os algoritmos já desenvolvidos deverão
   ser portados para a nova plataforma de desenvolvimento, e na grande maioria dos
   casos, adaptados e reescritos. Além das dificuldades encontradas para portar os
   códigos, encontramos mais um senão. A computação paralela tem sido voltada, no
   decorrer da história, ao âmbito científico apenas. Com isso sua utilização se limita,
   na maioria dos casos, a especialistas da área, de modo que pouco se tem pensado
   para minimizar a curva de aprendizado das linguagens e ferramentas para a
   computação paralela.
   Como já comentamos, uma das principais linhas de desenvolvimento do
   Cyvis-1 é o trabalho cooperativo realizado por pesquisadores de visão e
   processamento de imagens. Sendo assim, o objetivo principal é que esses
   profissionais possam se integrar facilmente no desenvolvimento de um sistema
   paralelo, aproveitando seus trabalhos já realizados, sem desperdício de tempo com
   o longo aprendizado exigido para o domínio das ferramentas tradicionais de
   181
   CAPÍTULO 5
   computação paralela. Com a deficiência de ferramentas de desenvolvimento
   paralelo intuitivas que sejam fáceis de usar, assim como pela insipiência desse
   aspecto nos ambientes de desenvolvimento utilizados pelo nosso grupo, fomos
   motivados a desenvolver uma série de ferramentas para prover paralelismo nos
   ambientes de desenvolvimento Delphi / C++ Builder e no sistema operacional
   Windows 95/98/NT, a fim de possibilitar o desenvolvimento rápido e efetivo de
   algoritmos de visão e processamento de imagens paralelos, possibilitando deste
   modo a integração e cooperação de diferentes pesquisadores para o
   desenvolvimento do sistema. No Capítulo 6 descreveremos esse conjunto de
   ferramentas intitulado de CVMP do inglês “Cybernetic Vision Message Passage”.
   5.2.4 – MODELO COMPUTACIONAL
   Tendo discutido as principais características conceituais e de
   implementação, vamos agora apresentar o modelo formal computacional escolhido
   como base para o desenvolvimento inicial do projeto. A figura 5.5 apresenta um
   exemplo de um modelo de implementação, nele temos 5 computadores IBM-PC
   conectados via rede, representados por blocos horizontais. Neste exemplo, cada
   atributo visual (estéreo, cor textura e borda) é processado por uma máquina
   específica, que é supervisionada pelo sistema mestre, processado também em uma
   única máquina distinta. Além dessa função, a máquina mestre possui também uma
   base de conhecimento e um classificador estatístico. A base de conhecimento é
   alimentada a cada processamento pelos resultados dos atributos, através dela e
   das bases locais de cada atributo, o sistema realiza o processamento em sentido
PA inverso, ou seja a partir do nível maior para o menor.
   A classificação da imagem também é de responsabilidade do mestre. À
   medida que é realizado o processamento nos sistemas dedicados de atributos, as
   características vão sendo extraídas e enviadas para a unidade mestre. De posse
   das características, o mestre consulta o classificador estatístico, e caso a resposta
   da consulta seja satisfatória para a classificação, então o sistema finaliza o
   processamento. Caso contrário, são aguardadas novas características para
   alimentar o classificador, até que o resultado seja representativo, ou tenham já sido
   extraídas todas as características. Essa estratégia de classificação por demanda,
   ou seja, a tentativa de classificação para cada característica extraída, possibilita um
   aumento de desempenho do sistema, uma vez que alguns objetos são
   182
   Cyvis-1 e ynergos
   reconhecidos com poucas características, e deste modo o sistema não precisa
   executar todos os seu processos, poupando tempo de execução. Além do
   desempenho, esta estratégia possibilita também um melhor controle de supervisão
   para o mestre. Com os resultados obtidos pela classificação, o mestre obtém uma
   lista das características mais promissoras para uma classificação ágil, e com essa
   informação, através de supervisão, concentra os recursos para priorizar a extração
   delas.
   Fig. - 5.5 - Diagrama de blocos apresentando a organização de hardware do
   Cyvis -1. Neste exemplo, cada atributo de imagem está sendo processado em
   uma diferente máquina. Os computadores estão conectados por rede.
   Adaptado de [Bruno & Costa, 1997] [Costa et al., 1994].
   As imagens são capturadas através do par de câmeras que se encontra
   conectado ao sistema. Apenas o atributo estéreo necessita de visão binocular,
   sendo que os demais atributos recebem informações provenientes de uma câmera.
   Poderiam ser utilizadas duas câmeras, trazendo benefícios de informação, porém
   com maior custo computacional. As câmeras são conectadas diretamente nas
   máquinas de cada um dos atributos. Embora essa medida exija investimento de
   hardware, uma vez que as placas de aquisição de imagens deverão ser replicadas
   para cada uma das máquina, ela reduz drasticamente o gargalo da distribuição de
   imagens. Nos primeiros experimentos, ao invés da arquitetura apresentada na
   183
   CAPÍTULO 5
   figura 5.5, conectamos as câmeras no mestre, que também ficava responsável pela
   aquisição e distribuição das imagens [Bruno & Costa, 1996]. Observamos no
   entanto que o gargalo gerado pelo processo de distribuição era demasiado, o que
   comprometia o desempenho do sistema. Através de nossas observações e do
   trabalho de Cantoni e Lombardi [Cantoni & Lombardi, 1999] chegamos à
   configuração atual.
   Tendo definido a arquitetura do sistema em termos de hardware e de sua
   funcionalidade vamos agora apresentar o modelo computacional utilizado para a
   implementação paralela. Dentre os modelos formais para a abordagem paralela,
   optamos pelo paradigma da fazenda de processadores ( processor farm) [Bruno &
   Costa, 1997] [[Inmos, 1989] [Atkin, 1987], que freqüentemente possui uma
   utilização de processador próxima do ideal. O paradigma da fazenda
   tradicionalmente envolve um processador mestre, que é conectado, na maioria dos
   casos através de canais, a um número de processadores escravos. As tarefas, por
   exemplo subproblemas que podem ser executados independentemente, são
PA distribuídas pelo mestre de acordo com a disponibilidade dos processadores
   escravos, garantindo assim um bom balanceamento total de carga. Esse paradigma
   é particularmente apropriado quando a comunicação pode ser realizada em
   concorrência com o processamento, como ocorre com os Transputers [Inmos,
   1988] [Inmos, 1988b] [Inmos, 1989].
   No caso específico do Cyvis-1, após algumas análises, optamos por uma
   abordagem de paralelização baseada em uma versão modificada do paradigma da
   fazenda (processor farm). Assim como no paradigma da fazenda de processos
   tradicional, o Cyvis-1 é composto como podemos observar na figura 5.6, de um
   conjunto de escravos supervisionados por um mestre. Estamos nos referindo aos
   módulos retangulares, onde temos 4 sistemas dedicados referentes aos atributos
   cor, borda, textura e estéreo, supervisionados pelo mestre. A primeira diferença
   entre o modelo adotado e o tradicional é que cada um dos módulos responsáveis
   pelos atributos, assim como o próprio mestre, são sistemas independentes que
   também obedecem ao paradigma da fazenda. Assim, cada módulo possui um
   processo mestre, que controla diversos outros processos escravos. Na figura 5.6 os
   processos locais mestre e escravos estão representados pelas letras M e S
   respectivamente.
   184
   Cyvis-1 e ynergos
   Fig. - 5.6 - Modelo de paralelismo adotado.
   Quanto às tarefas, estas são inicialmente divididas de acordo com os
   atributos, pelo mestre do sistema, e distribuídas para os módulos de atributos. Cada
   uma dessas tarefas são novamente divididas pelo processo mestre de cada módulo
   e repassada para os escravos. Assim como nos sistemas biológicos, o Cyvis-1
   também possui mecanismo para atenção seletiva [Cantoni & Lombardi, 1999]
   [Gonçalves, 1999], que está relacionado com a supervisão e a distribuição de
   tarefas realizadas pelo mestre do sistema. Deste modo, em determinadas
   situações, o mestre pode concentrar o processamento do sistema em uma
   determinada região ou atributo, alojando um número maior de escravos para o
   mestre do respectivo módulo.
   Dentro do sistema estão previstos ainda diferentes tipos de recursos, que se
   classificam segundo a natureza de execução, entre o seguinte:
   Paralelismo de Máquina: são processos que são executados em um único
   computador conectado pela rede (sistema distribuído).
   Paralelismo de Processador: processos que são executados em diferentes
   processadores de máquinas com múltiplos processadores.
   Multitarefa: são processos que são executados concorrentemente, utilizando o
   mesmo recurso de hardware, através do mecanismo de multitarefa do sistema
   operacional da máquina.
   Específicos: são processos que somente podem ser alojados em máquinas que
   contém hardware específico. São exemplos desta modalidade máquinas com
   185
   CAPÍTULO 5
   placa de aquisição de imagem ou ainda com dispositivos de processamento de
   sinais específicos.
   Quanto ao alojamento e a distribuição, os recursos computacionais do
   sistema se dividem em dois grupos:
   fixos: recursos que pertencem a um determinado módulo (atributo ou unidade de
   controle) e executam apenas processos associados a seu módulo, não podendo
PA ser redirecionados para outros fins.
   móveis: recursos computacionais que podem ser utilizados por qualquer um dos
   módulos do sistema, desde que sejam redirecionados.
   Os processos mestres de cada um dos módulos são caracterizados por
   utilizar sempre recursos fixos. O escravos podem ser dos dois tipos, um grupo
   pequeno de escravos são fixos, e somente podem servir a um determinado módulo.
   Desse grupo fazem parte os escravos que necessitem de recursos computacionais
   extra (ex: hardware específico, placa de aquisição de imagem e etc.), aqueles
   envolvidos com a base de conhecimento local de cada módulo e ainda os escravos
   fixos por motivos estratégicos, exemplo, encontram-se em condições de se
   comunicar mais eficientemente com os recursos computacionais de determinado
   mestre (ex: máquina com processadores múltiplos).
   Temos alguns motivos para a mista distribuição de recursos (parte
   específicos e parte homogêneos) , ao invés do clássico conjunto homogêneo de
   recursos ( pool of slaves):
   Maior similaridade com o sistema biológico, que não prima pela homogeneidade,
   arquitetura e processamento diferente para módulos distintos.
   Possibilidade de incorporação de hardware dedicado para o processamento
   específico de determinado atributo visual.
   Os módulos podem manter dados localmente armazenados assim como bases de
   conhecimentos locais.
   Sendo o sistema misto, entre um conjunto homogêneo e outro específico, podemos
   tirar proveito das vantagens dos sistemas com recursos específicos descritos
   acima e também das vantagens de distribuição, concentração dinâmica de
   recursos e melhor balanceamento de carga dos sistemas homogêneos.
   5.3 – SISTEMAS E MODELOS DE VISÃO E SUAS
   186
   Cyvis-1 e ynergos
   COMPARAÇÕES COM O CYVIS-1
   Nesta seção vamos apresentar sucintamente alguns sistemas e modelos de
   visão encontrados na literatura, que possuam características similares ao do
   Cyvis-1, especialmente a integração de atributos, representação e composição de
   características da imagem, versatilidade de visão e processamento paralelo. Além
   da breve descrição de cada sistema, vamos discutir suas similaridades e diferenças
   relativas ao Cyvis-1.
   5.3.1 - SISTEMA INTELIGENTE PARA SEGMENTAÇÃO
   BAIXO NÍVEL DE IMAGENS
   O sistema inteligente para segmentação de imagens, ou LLIS (do inglês:
   Low Level Image Segmentation), proposto por Nazif e Levine [Nazif & Levine,
   1984], é um sistema para a segmentação primária ou segmentação de baixo nível
   de imagens, e consiste basicamente uma abordagem ao problema que engloba a
   integração de características para a representação das imagens, lógica e memória
   associativa.
   O primeiro estágio na visão computacional para a compreensão de imagens
   é a segmentação de baixo nível. Nesta etapa, deve-se extrair algumas
   características básicas da imagem, que possuem informações a respeito de seu
   contexto assim como: bordas, linhas, regiões, etc. Em geral, os sistema tradicionais
   limitam-se a apenas uma abordagem, ou seja, são específicos à extração de uma
   única característica. O LLIS se preocupa com a integração e representação de
   diversas características, de modo a formular uma representação mais rica e
PA complexa da informação visual.
   Um dos problemas em visão computacional é a modelagem dos dados
   resultantes do processamento de segmentação de imagem. Como modelar uma
   estrutura de dados de tal forma que esta seja significante na representação da
   informação? A maioria dos modelos de segmentação não estruturam ou modelam
   os dados resultantes, de forma a apresentarem como resposta simplesmente
   imagens realçadas. Tais resultados, embora demonstram vasta aplicação, não são
   devidamente significativos quanto ao armazenamento, transporte e aproveitamento
   de informações (para níveis superiores de processamento), principalmente na
   187
   CAPÍTULO 5
   representação da informação.
   O LLIS é um modelo para a segmentação de baixo nível de imagens que
   procura diferenciar-se dos modelos tradicionais de segmentação de baixo nível por
   apresentar algumas propostas de motivação biológica, tal como memória
   associativa e lógica, assim como apresentar uma estrutura de representação efetiva
   para combinar diferentes atributos visuais de baixo nível, analisar e traçar em
   tempo de execução estratégias de processamento mais apropriadas para diferentes
   situações, assim como a geração de uma base de dados, a partir ede. (a)
   CVMP usando protocolo TCP/IP, (b) CVMP usando transferência de arquivo
   através de chamada a API, utilizando protocolo NetBeui e (c) comparação
   entre os resultados de (a) e (b).
   A Figura 6.5 apresenta os gráficos com os resultados obtidos da
   transferência de diferentes tamanhos de pacotes em função do tempo. Neles são
   apresentados os resultados dos dois procedimentos de transferência de dados do
   CVMP. Na Figura 6.5 (a), é apresentado o resultado do desempenho de
   transferência do Winsock usando TCP/IP, através dos procedimentos do CVMP
   para baixa granularidade e no gráfico (b) os procedimentos para alta granularidade,
   que consistem na troca de arquivos através de chamadas a API usando o protocolo
   227
   CAPÍTULO 6
   NetBeui e IPX/SX. Como podemos observar no gráfico (c) os protocolos NetBeui e
   IPX/SX apresentam um desempenho melhor de transferência de dados que o
   protocolo TCP/IP em plataforma Windows, o que nos motivou a implementar dois
   métodos diferentes para troca de mensagens via rede, um para alta e outro para
   baixa granularidade de pacotes, a fim de otimizar a comunicação. As linhas do
   gráfico (c) representam o traçado da reta ajustada a partir da regressão linear dos
   pontos de cada caso, obtivemos como resultados as taxas aproximadas de 5
   megabits/s e 8 megabits/s respectivamente para os protocolos TCP/IP e NetBeui.
   6.5.2 - ARQUITETURA MIMD COMPARTILHADA
   A arquitetura MIMD compartilhada, diferente da arquitetura MIMD
   distribuída, é caracterizada pelo multiprocessamento, ou seja, por uma máquina
   constituída de diversos processadores que compartilham memória. Assim como os
   sistemas distribuídos, comentados anteriormente, os processadores dessa
   arquitetura, podem trabalhar em conjunto, efetuando comunicações através da
   troca de mensagens. Nesse modelo, os processadores utilizam a memória
   compartilhada para a comunicação.
   processador
   Canal Virtual
   CVMP
   memória
   Processo
   Fig. - 6.6 – Exemplo de uma aplicação paralela CVMP em uma arquitetura
   MIMD compartilhada. Nesse exemplo temos uma máquina multiprocessada
PA com 3 processadores.
   A Figura 6.6 apresenta um exemplo dessa arquitetura, nela temos uma
   máquina constituída por 3 processadores, que compartilham a mesma memória.
   228
   CVMP
   Em cada um dos processadores está alojado um processo, dos quais os dois da
   extremidade são escravos e o central é o mestre. Assim como na arquitetura
   distribuída, através dos objetos CVMP (pequenos quadrados no interior dos
   processos), são estabelecidos canais virtuais, que possibilitam a troca de
   mensagens entre os processos.
   Processo A
   Processo B
   Processador 1
   Processador 2
   Memória compartilhada
   Fig. - 6.7 – Diagrama ilustrativo do mecanismo de troca de mensagens em
   sistema MIMD compartilhado.
   Nos objetos CVMP memória compartilhada, os canais virtuais utilizam a
   memória compartilhada para trocar mensagens. A Figura 6.7 apresenta uma
   ilustração desse conceito. Nela temos dois processadores efetuando troca de
   mensagens a partir de memória compartilhada.
   A troca de mensagens através da memória compartilhada é realizada no
   CVMP através do mecanismo do Windows denominado de "filemapping", que
   consiste num conjunto de APIs que permitem a manipulação da memória global
   (memória RAM e memória virtual) com requintes de tratamento de arquivos [Deatz,
   1997] [Petzold, 1995] [Petzold & Yao, 1996] [Richter, 1995]. Através desse
   mecanismo, são estabelecidos os Canais virtuais, que permitem que diferentes
   processos, alojados em processadores diferentes ou no mesmo processador,
   possam realizar a troca de mensagens através de objetos CVMP.
   A performance da comunicação nessa arquitetura é muito superior à
   distribuída, sendo que a taxa de transferência entre processador e memória RAM é
   incomparavelmente mais alta do que em rede, mesmo se considerarmos a
   229
   CAPÍTULO 6
   transferência através da memória virtual, que pode envolver operações em disco,
   ainda assim o desempenho seria muito superior ao obtido via rede. Além de taxa de
   transferência superior, o tempo de acesso também é bastante inferior, diminuindo
   assim a latência da comunicação. Deste modo, essa arquitetura pode ser bastante
   promissora para sistemas na área de visão, que demandam considerável troca de
   dados. Entretanto, o alto custo de hardware, assim como o número relativamente
   baixo de processadores por máquinas disponíveis no mercado (4 processadores
   por máquina) ainda inviabilizam essa arquitetura. A combinação das duas
   arquiteturas, MIMD compartilhado e distribuído aparenta ser uma solução bastante
   interessante, uma vez que aumenta o número de máquinas no sistema paralelo
   assim como possibilita estratégias de balanceamento de carga, algoritmos com
   maior gargalo em troca de mensagens alojados na arquitetura compartilhada e
   menor na distribuída.
   6.6 - FUNCIONAMENTO BÁSICO CVMP
   O CVMP básico é o objeto elementar da ferramenta CVMP. Trata-se de um
   componente VCL nativo em Delphi que possui propriedades e métodos que
PA efetuam a troca de mensagens e controle entre processos, sendo composto de
   duas versões, uma para arquitetura MIMD distribuída (Tcvmp) e outra para
   arquitetura MIMD compartilhada (Tcvmps).
   A operação do CVMP é bastante simples. Como primeiro passo, usualmente
   nas operações de VCL do Delphi, o programador deve arrastar e soltar o CVMP
   básico da paleta de componentes CVMP sobre o seu formulário. Efetuado esse
   procedimento, deve-se então criar um arquivo de configuração do objeto. O arquivo
   de configuração é um arquivo em formato ASCII que contém as informações (a
   respeito das máquinas, redes e porto socket) necessárias para que o objeto possa
   estabelecer um canal virtual. A Figura 6.8 apresenta um exemplo típico de um
   arquivo de configuração.
   O arquivo de configuração pode ser criado e editado de diferentes maneiras.
   O usuário pode criar o arquivo com um editor de textos qualquer ou então utilizar o
   gerador automático de arquivo de configuração, que acompanha as ferramentas
   CVMP. O gerador automático é uma aplicação bastante simples, onde o usuário
   preenche os campos e a partir desses dados são gerados os arquivos de
   configuração. Ainda outra alternativa é configurar as propriedades do componente
   230
   CVMP
   CVMP diretamente. Isto pode ser feito através de programação, ou ainda pela
   janela Object Inspector do ambiente Delphi, através das propriedades: master_ip (ip
   da máquina), master_n (nome e domínio), master_pt (porto socket), slave_ip,
   slave_n e slave_pt.
   Conteúdo do arquivo de
   configuração
   Número IP da máquina
   [slave]
   Informações sobre
   ip=10.6.1.2
   a máquina escrava
   name=neon.river.omb
   Nome e domínio
   path=c:\cyvis\temp
   ;
   [master]
   Localização do diretório
   Informações sobre
   ip=10.6.1.1
   para troca de arquivos
   a máquina mestre
   name=acara.river.omb
   path=d:\cyvis\temp
   ;
   Informações sobre
   [port]
   o canal virtual
   port=5000
   Fig. - 6.8 – Exemplo de um arquivo de configuração do objeto CVMP.
   Uma vez editado o arquivo de configuração deve ser atribuído à propriedade
   mp_init_file o nome e o diretório onde se encontra o arquivo de configuração
PA correspondente ao objeto. Devemos lembrar que cada canal virtual possui dois
   arquivos de configuração idênticos, um para o objeto mestre e o outro para o
   escravo. Os arquivos de configuração são idênticos para os objetos CVMP MIMD
   compartilhado e distribuído. Nos objetos CVMP para arquitetura distribuída, a
   configuração port define o porto do socket a ser utilizado pelo canal virtual,
   enquanto que, para a arquitetura compartilhada, o port define os rótulos dos
   ponteiros para a memória. Não poderão haver mais de um Canal Virtual com o
   mesmo número de port em uma mesma arquitetura.
   Após a configuração dos objetos CVMP, o canal virtual está pronto para ser
   estabelecido e realizar a troca de mensagens, sendo estas tarefas de programação
   realizadas a partir da manipulação dos métodos e propriedades do objeto CVMP.
   No momento do estabelecimento dos canais virtuais, são definidos os papéis de
   cada objeto. No objeto escravo é executado o método mp_listen ou mp_slave,
   231
   CAPÍTULO 6
   deste modo, esse objeto ficará aguardando a primeira conexão de seu par mestre
   para que o canal virtual seja estabilizado. Estando o objeto escravo aguardando a
   conexão, deve ser então executado, no objeto a ser definido como mestre o método
   mp_connect ou mp_master. Deste modo está estabelecido um canal virtual entre os
   dois objetos, permitindo a troca de mensagens entre estes dois componentes
   (mestre e escravo).
   6.6.1 - PROGRAMAÇÃO
   A programação de aplicações paralelas com o CVMP é realizada a partir de
   um conjunto de primitivas, que realizam a troca de mensagens, caracterizadas por
   métodos e propriedades do objeto CVMP. Figura 6.9 apresenta as principais
   primitivas de troca de mensagens e suas respectivas funções.
   mp_init_file
   Propriedade, determina o nome e a
   localização do arquivo de configuração.
   mp_listen, mp_slave
   Método, define o objeto como escravo.
   Utilizado para estabilizar o Canal Virtual.
   mp_connect, mp_master Método, define o objeto como mestre.
   Utilizado para estabilizar o Canal Virtual.
   mp_send(mens:str)
   Método, envia uma mensagem através do
   Canal Virtual.
   str:=mp_receive
   Método, função que retorna a primeira
   mensagem da fila de mensagens recebidas.
   setblocking
   Método, define se as mensagens são
   bloqueantes ou não.
   sendfile(str)
   Método, envia mensagem de alta
   granularidade (arquivos).
   receivefile(str)
   Método, recebe mensagem de alta
   granularidade (arquivos).
   mp_close
PA Método, termina o Canal Virtual.
   Fig. - 6.9 – Principais primitivas de troca de mensagens.
   A partir da utilização das primitivas é possível desenvolver as aplicações
   paralelas, programando as diferentes estratégias de paralelismo a partir das trocas
   de mensagens. Referências para algumas estratégias de paralelismo são
   encontradas em [Almasi & Gottlieb, 1994] [Amorin et al.,1988] [Bem-Ari, 1990]
   [Brawer, 1989] [Codenoti & Leoncini, 1994] [Foster, 1995].
   A Figura 6.10 apresenta um exemplo de um algoritmo concorrente utilizando
   232
   CVMP
   as primitivas CVMP. Nele temos quatro computações sendo realizadas, A, B, C e D,
   onde os cálculos C e D são obtidos mediante os resultados de A e B. Vamos supor
   que cada um destes cálculos leva um tempo igual a t. Supondo que t é muito maior
   que o tempo da troca de mensagem realizada (basicamente os resultados e
   parâmetros da computação), então podemos desconsiderar o tempo tomado pelos
   processos de comunicação. Caso esse algoritmo hipotético seja implementado de
   modo seqüencial, o tempo total seria de 4t. O algoritmo apresentado na Figura 6.10
   é uma versão paralela para essa computação tal que os cálculos A e B são
   executados simultaneamente em duas máquinas, e após a troca de resultados
   entre os processos, C e D são igualmente processados em concorrência, em cada
   uma das máquinas. Deste modo temos um tempo total de processamento igual a
   2t, obtendo uma performance de computação 2 vezes maior. Caso não houvesse a
   dependência de dados (C e D necessitarem dos resultados de A e B), o número de
   máquinas poderia ser maior, aumentando ainda mais a performance do sistema.
   Algoritmo processo Mestre
   Algoritmo processo Escravo
   cvmp1.MP_init_file(‘init.ini’);
   cvmp1.MP_init_file(‘cyv.ini’);
   cvmp1.MP_connect;
   cvmp1.MP_listen;
   cvmp1.MP_send:=‘start’;
   while f<>‘start’ do begin
   application.processmessages;
   f:=cvmp1.receive;
   CALCULA B
   end;
   cvmp1.MP_send:=b;
   CALCULA A
   a:=cvmp1.MP_receive;
   b:=cvmp1.MP_receive;
   CALCULA C
   cvmp1.MP_send:=a;
   (A em B)
   while f<>‘end’ do begin
   CALCULA D
   application.processmessages;
   (B em A)
   f:=cvmp1.receive;
   end;
   result2:=cvmp1.mp_receive;
PA cvmp1.mp_send:=‘end’;
   show (result1, result2);
   cvmp1.mp_send:=result2;
   Fig. - 6.10 – Exemplo de implementação de um algoritmo paralelo utilizando
   as primitivas CVMP.
   233
   CAPÍTULO 6
   6.6.2 - MODELO EM CAMADAS
   Devido à sua natureza orientada a objetos, o CVMP permite sua reutilização
   e consequentemente o desenvolvimento de outros objetos, que herdam suas
   propriedades. Esse conceito é fundamental para a arquitetura do CVMP, permitindo
   que sejam desenvolvidos outros objetos, com maior nível de especificidade, mais
   simples de utilizar, programação visual mais desenvolvida e etc. Desta forma, além
   do desenvolvimento das ferramentas que compõem o conjunto CVMP, também é
   possível o desenvolvimento personalizado de novos componentes, de acordo com
   as necessidades do programador. Assim, o CVMP pode ser visto como um modelo
   de camadas, onde o CVMP básico é a camada básica que permite a inserção de
   um número ilimitado de camadas adicionais.
   Nas próximas seções vamos apresentar uma série de objetos e aplicações
   que foram desenvolvidas a partir desse princípio. Um exemplo de componente
   personalizado é o CyComm [Moreira, 1999], desenvolvido em conjunto com Jander
   Moreira e Alan Felinto. Ele incorpora diversas características, tais como um editor
   interno para modificar o arquivo de configuração, protocolos adicionais para troca
   de imagens e servidor de imagem para máquinas com sistema de captura. Esse
   componente foi utilizado para desenvolver o sistema de comunicação e controle de
   alguns módulos do sistema descrito no Capítulo 8 desta tese.
   6.7 - DISPARADOR DE APLICAÇÕES (LAUNCHER)
   Launcher ou disparador de aplicações é a denominação que atribuímos à
   ferramenta responsável pela execução de processos remotos. Através de sua
   utilização o módulo principal do sistema pode disparar aplicativos, em geral
   escravos, ao longo da rede. O CVMP-launcher, é composto por dois aplicativos e
   um componente, sendo que os aplicativos são constituídos pelo módulo principal e
   pelos disparadores.
   Os módulos disparadores possuem um sistema de instalação que altera os
   registros do sistema operacional de forma que estes são executados toda vez que o
   Windows é reiniciado, não necessitando que o usuário sequer entre em sua área.
   Deste modo, mesmo máquinas sendo utilizadas por outros usuários podem ser
   solicitadas para executar processos do sistema paralelo. Os módulos disparadores
   são instalados nas diversas máquinas da rede, a serem utilizadas pelo sistema
   234
   CVMP
   distribuído; sua função é aguardar as ordens do módulo principal e mediante elas,
   disparar processos locais.
   (a)
   (b)
   Fig. - 6.11 – Módulo principal do aplicativo CVMP-Launcher. (a) Janela
   principal, (b) Janela de configuração.
   Na rede pode existir uma ou mais máquinas com módulos principais, em
   geral essa ou essas máquinas são responsáveis pelo controle do sistema, e vão
   requerer a execução de processos escravos espalhados pela rede. A Figura 6.11
PA apresenta a janela do módulo principal, com a respectiva janela de configuração.
   Os processos remotos podem ser disparados remotamente ou através do objeto
   Tlauncher, baseado no CVMP para memória compartilhada, esse componente
   envia mensagens para o modulo principal, ativando o disparo de mensagens para
   as máquinas remotas, de modo que estas possam executar os processos remotos.
   6.8 - CVMP PROCESSOR FARM
   O CVMP processor farm é constituído de um conjunto de componentes
   Delphi, desenvolvido sobre o CVMP, que permite a implementação visual de
   235
   CAPÍTULO 6
   aplicativos paralelos que utilizam a estratégia processor farm. Desenvolvido para
   simplificar a programação de algoritmos paralelos, o CVMP processor farm permite
   que até mesmo os programadores mais inexperientes possam desenvolver seus
   próprios sistemas distribuídos.
   Dentre as estratégias de paralelismo, observamos que o processor farm (ou
   fazenda de processadores) é bastante genérico e pode ser amplamente utilizado
   nos mais diversos algoritmos de visão. Uma característica bastante importante
   dessa estratégia é o balanceamento automático de carga, através do qual sistemas
   híbridos, com máquinas com performances diferentes, podem ser prontamente
   utilizados, sem que o programador se preocupe com a distribuição das máquinas
   que compõem o sistema e seu poder computacional.
   A Figura 6.12 apresenta um diagrama que ilustra essa estratégia. Como
   podemos observar, o processor farm consiste em um processo de supervisão que
   controla e distribui tarefas para um conjunto de processos escravos. Os processos
   escravos são ordenados através de uma fila de processos livres, que fica
   armazenada no supervisor. Quando for necessário distribuir uma tarefa, o
   supervisor escolhe o primeiro elemento da fila, atribui a este uma tarefa, e então
   retira-o da fila. À medida que os processos escravos vão terminando a execução
   das tarefas, vão sendo inseridos novamente na fila de processos disponíveis. O
   principal inconveniente dessa estratégia é a sua preferência a sistemas sem
   dependência de dados. No entanto, através de algumas adaptações, pode-se
   utilizá-la mesmo em sistemas com relativa dependência de dados.
   proce
   vres
   ss
   li
   os exe
   Supervisor
   cu
   rocessos
   ta
   p
   ndo
   la de
   ta
   Fi
   refas
   Fig. - 6.12 – Diagrama ilustrativo da estratégia de paralelismo processor farm.
   236
   CVMP
PA O CVMP processor farm foi desenvolvido com o intuito de fornecer
   sofisticados recursos para a implementação de sistema distribuídos e ao mesmo
   tempo ser simples de usar, de modo que até o mais inexperiente dos
   programadores possa desenvolver sua aplicação paralela. Assim, o CVMP
   processor farm é o ponto áureo do CVMP, permitindo o desenvolvimento genérico
   de aplicações paralelas de modo visual e intuitivo.
   Fig. - 6.13 – Janelas do object inspector do Delphi, mostrando as
   propriedades e eventos dos objetos CVMP Processor Farm (a) supervisor
   (TprocFarmM4) e (b) escravo (TprocFarmS).
   O CVMP processor farm é constituído basicamente de dois componentes:
   escravo e mestre (supervisor). Os componentes escravos, assim como o
   componente mestre, devem ser arrastados e soltos no formulário das aplicações
   escravas e de supervisão, respectivamente. Através do object inspector, o
   programador configura alguns poucos atributos e seleciona os eventos a serem
   programados. A Figura 6.13 apresenta a janela do object browser mostrando as
   propriedades e eventos dos objetos supervisor e escravo. O objeto supervisor
   utilizado na Figura 6.13 tem um limite de controle de 4 processos escravos
   (designados pelos eventos A,B,C e D), no entanto implementamos 3 objetos
   237
   CAPÍTULO 6
   supervisores, para controlar diferentes números máximos de processos escravos
   (4, 8 e 16 processos).
   A sua utilização simplificada permite, conforme vamos demonstrar, que um
   sofisticado sistema distribuído possa ser implementado mediante alguns cliques de
   mouse e poucas linhas de código. Para exemplificarmos, vamos imaginar um
   exemplo bem simples que possa ilustrar a utilização do CVMP Processor Farm.
   Dada uma função hipotética, a qual vamos chamar de F, que a partir de um
   determinado número de parâmetros ( p), realize um cálculo interativo retornando um
   resultado, vamos presumir que nosso problema necessite dos resultados de
   diversas chamadas a F. Supondo que, toda a vez em que F é executada, um
   demasiado poder computacional seja demandado; deste modo, uma solução
   paralela pode aumentar a performance do sistema e consequentemente diminuir o
   tempo de resolução. Assim, supondo que cada execução de F demore 1 minuto e
   nosso problema necessite de 120 cálculos, nossa aplicação levará 2 horas para ser
   executada em uma máquina. Nessa situação, se utilizarmos 4 máquinas iremos
   reduzir o tempo de execução em 1/4 (30 minutos).
   A Figura 6.14 apresenta a principal rotina da máquina escrava. Ela é
   chamada pelo evento OnTask, que podemos ver na Figura 6.13. Com pequenas
   linhas de código, o CVMP processor farm permite que o programador extraia os
   parâmetros, enviados pelo supervisor, para cálculo da função e depois de calculado
   F retorne o resultado para ele. Em nosso exemplo como temos um único modelo de
   escravo, não existe necessidade de escrever um código específico para cada
   máquina, bastando replicar o aplicativo e distribuí-lo na rede.
   procedure TForm1.ProcFarmS1Task(Sender: TObject; me: String);
   var index,result:string;
   vet:array [1..10] of real;
   x:integer;
   Extrai o primeiro elemento da mensagem
   begin
   Extrai os dez parâmetros para o cálculo de F
PA index:=ProcFarmS1.unpack(me);
   for x:=1 to 10 do vet[x]:=strtofloat(ProcFarmS1.unpack(me));
   result:=floattostr(calcf(vet));
   ProcFarmS1.pack(index,result);
   Calcula F - parâmetros passados por vet
   ProcFarmS1.mess:=result;
   end;
   Empacota o índice e o resultado
   Mensagem a ser re-transmitida para o supervisor
   Fig. - 6.14 – Exemplo de codificação do evento OnTask do componente
   escravo do CVMP processor farm.
   238
   CVMP
   Na Figura 6.15, temos alguns segmentos de código da aplicação
   supervisora. Para nosso exemplo, são necessários dois eventos para cada
   processo escravo, um para a designação das tarefas ( OnIniTask) e outro para o
   término das tarefas e recebimento do resultado ( OnEndTask), respectivamente
   mostrados na Figura 6.15 (A) e (B). Deste modo, como podemos observar através
   dos códigos, a programação do supervisor é muito simples, necessitando poucas
   linhas de código. Para iniciar o processamento paralelo, deve ser executado o
   método descrito em (C), onde o primeiro parâmetro deve conter o número de
   processos utilizados e no segundo, o número de tarefas a serem distribuídas.
   procedure TForm1.ProcFarmM1IniTaskA(Sender: TObject; t: Integer); (A)
   var mensagem:string;
   a:integer;
   Incrementa i, variável global que determina o índice da linha
   begin
   de mat, que contém os parâmetros a serem calculados por F
   i:=i+1;
   Empacota o índice em mensagem
   ProcFarmM1.pack(inttostr(i),mensagem);
   for a:=1 to 10 do ProcFarm1.pack(floattoint(mat[i,a]),mensagem);
   Empacota os parâmetros
   ProcFarmM1.task:=mensagem;
   end;
   Mensagem a ser enviada para o escravo
   procedure TForm1. ProcFarmM1EndTaskA(Sender: TObject; task: String); (B)
   var index:integer;
   begin
   Desempacota o índice, de task,
   index:=strtotint(ProcFarmM1.unpack(task));
   mensagem recebida pelo mestre.
   res[index]:=strtofloat(ProcFarmM1.unpack(task));
   end;
   Desempacota o resultado
   e armazena no vetor res.
   ProcFarmM1.execute(núm. de processos, núm. de tarefas)
   (C)
   Fig. - 6.15 – Exemplo de codificação dos eventos do componente supervisor
   do CVMP processor farm. (A) Evento OnIniTask , disparado antes de ser
PA atribuída a tarefa para um processo escravo. (B) Evento OnEndTask ,
   disparado assim que o escravo finalizou a tarefa. (C) Método para iniciar a
   execução do processamento.
   A configuração do sistema também é muito simples e pode ser realizada
   visualmente pelo próprio usuário, não necessitando ser feita via programação. Para
   isso deve ser executado o método config (do componente supervisor), que
   apresenta uma janela em tempo de execução na qual o usuário descrimina os
   239
   CAPÍTULO 6
   nomes, diretórios e IP dos processos escravos, conforme mostrado na Figura 6.16.
   Esse procedimento gera automaticamente todos os arquivos de configuração do
   sistema, tanto para o supervisor como para os escravos.
   Fig. - 6.16 – Janela de configuração automática da distribuição do sistema,
   exibida através de chamada ao método config do componente supervisor.
   Os componentes possuem ainda mecanismos para visualizar o
   processamento em tempo de execução. Se a propriedade watch (ver Figura 6.13)
   estiver atribuída como verdadeiro, então o sistema exibe uma janela que mostra
   simultaneamente um resumo do tráfego de mensagens enviadas e recebidas pelo
   objeto. Isso pode ser bastante útil para depurar o sistema, assim como para
   analisar seu comportamento. O componente supervisor possui também acesso
   automático à ferramenta de visualização de estatística e desempenho em tempo de
   execução, descrita na próxima seção.
   6.9 - ANÁLISE DE DESEMPENHO E ESTATÍSTICAS
   Uma tarefa muito importante nos projetos de programas paralelos é a
   análise de desempenho e estatísticas, através das quais vai ser estimada a
   performance, o balanço de carga e os gargalos do sistema. Um dos empregos do
   240
   CVMP
   paralelismo consiste em aumentar a performance dos mecanismos computacionais
   para uma execução mais rápida dos algoritmos. No entanto, os gargalos, a má
   distribuição das cargas e o emprego incorreto de uma determinada estratégia de
   paralelização podem fazer com que os sistemas paralelos sejam até mesmo mais
   lentos que os seqüenciais, perdendo completamente seu sentido de existência.
   As medidas de análise de desempenho e suas estatísticas constituem em
   uma árdua tarefa para o programador, que muitas vezes, devido à escassez de
   ferramentas apropriadas, tem que desenvolver programas para auxiliá-lo na
   realização dessas medidas, tomando grande parte de seu tempo. Devido a esses
   fatores, desenvolvemos algumas ferramentas para extrair medidas de performance,
   de modo a auxiliar o programador e simplificar esta importante etapa no
   desenvolvimento de sistemas paralelos.
   As ferramentas de análise de desempenho e estatística do CVMP se
   dividem em dois grupos: análise estática e análise dinâmica.
   6.9.1 - FERRAMENTAS PARA ANÁLISE ESTÁTICA
   As ferramentas para análise estática são compostas por um componente
   ( TStat) e um aplicativo de visualização. O componente TStat, é uma ferramenta de
   uso genérico para auxiliar as medidas de desempenho de programas seqüenciais
   ou paralelos. Através dela o programador pode estimar o tempo de duração dos
   procedimentos, funções, métodos utilizados em seus programas ou até mesmo o
   tempo de execução de uma linha ou de um conjunto de linhas de código.
   A Figura 6.17 contém um exemplo da utilização do TStat, mostrando a
PA utilização do componente para um caso hipotético. Nele são apresentados os
   métodos do componente TStat:
   initialize e terminate: Métodos utilizados para iniciar e terminar as medidas
   realizadas por TStat. Quando o método initialize é chamado, inicia a
   contagem do tempo total da medida, sendo concluída com o método
   terminate.
   start e finish: Marcam o tempo das linhas de código entre a chamada aos
   métodos start e finish.
   makefile: Grava um arquivo contendo as medidas realizadas.
   241
   CAPÍTULO 6
   stat.initialize:='medida';
   Inicia a análise (denominada medida)
   stat.start:='calcxtot';
   for a:=1 to 10 do begin
   stat.start:='calcx'+inttostr(a);
   Mede o tempo total
   x[a]:=calcx(a);
   Mede o tempo
   dos laço de cálculo
   stat.finish:='calcx'+inttostr(a);
   de calcx
   de calcxtot
   end;
   stat.finish:='calcxtot';
   stat.start:='calcB';
   Mede o tempo
   calcb(vet);
   de calcB
   stat.finish:='calcB';
   Termina a análise (denominada medida)
   stat.terminate:='medida';
   stat.makefile:='nomedoarquivo';
   Gera o arquivo das medidas
   Fig. - 6.17 – Exemplo da utilização do componente TStat.
   (a)
   (b)
   (c)
   Fig. - 6.18 – Janelas da aplicação StatViewer, apresentando algumas das
   diferentes formas de visualização em blocos das medidas. As linhas
   horizontais representam os 4 processos paralelos, formados pelos blocos
   que exprimem as tarefas. (a) Visualização com blocos simples, (b) com blocos
   pequenos e (c) com linhas.
   242
   CVMP
   O aplicativo de visualização, denominado StatViewer, apresenta as medidas
   para o usuário, a partir do arquivo gerado pelo componente TStat. Através de
   diagramas de barras, as medidas podem ser visualizadas, permitindo a análise da
   arquitetura paralela e da distribuição dos processos, a localização de gargalos e,
   deste modo, possibilitando o aprimoramento do projeto e seu consequente aumento
PA de performance. A Figura 6.18 apresenta um exemplo da visualização das medidas
   através do StatViewer, nela são mostradas 3 janelas com diferentes diagramas de
   barras que mostram os resultados de um sistema com arquitetura processor farm,
   composto por 4 máquinas escravas (processos), representadas pelas linhas
   verticais das janelas. Estas são compostas por blocos, onde cada um corresponde
   a uma tarefa.
   Além de permitir a visualização das medidas, o StatViewer possui uma série
   de métodos para auxiliar o usuário, entre eles: o zoom, permitindo observar maiores
   detalhes entre os processos e tarefas; a personalização das cores dos blocos,
   permitindo destacar ou agrupar blocos com cores específicas, facilitando assim a
   análise; e a listagem dos processos e tarefas com suas respectivas medidas.
   6.9.2 - FERRAMENTAS PARA ANÁLISE DINMICA
   As ferramentas para análise dinâmica se assemelham muito às estáticas,
   diferenciando-se essencialmente por permitirem a análise do sistema em tempo de
   execução. Assim como as ferramentas para análise estática, são constituídas por
   um componente ( TStatOnLine) e por uma aplicação de visualização ( StatOnLine).
   O componente TStatOnLine possui propriedades similares ao TStat,
   possuindo a mesma metodologia de utilização, no entanto, ao invés de armazenar
   as medidas e arquivá-las num arquivo, o objeto as envia para a aplicação
   StatOnLine, permitindo desta maneira sua visualização em tempo de execução. A
   comunicação entre o componente e a aplicação é realizada a partir do CVMP
   memória compartilhada, para tanto foi necessário encapsular este objeto no
   componente StatOnLine.
   243
   CAPÍTULO 6
   (a)
   (b)
   (c)
   Fig. - 6.19 – Janelas da aplicação StatOnLine, apresentando as medidas de
   performance de uma aplicação paralela (processor farm) com 4 máquinas
   escravas. Visualização com blocos(a) e (b) e listagem das medidas (c).
   A aplicação StatOnline fica à espera de mensagens contendo as medidas
   realizadas pelo componente, e uma vez que as recebe, armazena-as na memória
   e exibe-as, possibilitando visualizar o comportamento do sistema durante o
   processamento. A Figura 6.19 apresenta três janelas da aplicação StatOnline,
   exibindo as medidas de um sistema distribuído com estratégia processor farm,
   constituído de 5 máquinas (1 supervisor e 4 escravos). Em (a) temos um diagrama
   de blocos no qual as linhas horizontais representam as máquinas escravas, os
   blocos que constituem as linhas representam as tarefas executadas em função do
   tempo. Em (b) cada um dos gráficos (1, 2, 3 e 4) representa respectivamente cada
   máquina e os blocos das tarefas realizadas em cada uma, cuja duração é expressa
   por sua altura. Finalmente em (c) temos as listagens das medidas de tempo de
   244
   CVMP
   duração, início e término, de cada tarefa.
   6.10 - COMPONENTE VISUAL PARA OPERAÇÕES
   BÁSICAS DE PROCESSAMENTO DE IMAGENS
   A convolução de máscaras (templates) com a imagem constitui uma
   abordagem clássica para a operação de alguns filtros, tais como detectores de
   bordas (filtros passa alta, Sobel, Robert e outros), filtros de suavização (filtragem
PA gaussiana, média da vizinhança e outros) e de realce (passa baixa) [Castleman,
   1996] [Gonzalez & Woods, 1993] [Parker, 1997]. Por se tratar de operações básicas
   e por sua popularidade, esses filtros são amplamente utilizados. Nessa seção
   apresentamos um experimento realizado para demonstrar o potencial de criação de
   componentes personalizados e da extrema simplicidade de desenvolvimento e
   operação utilizando CVMP.
   Devido à simplicidade das técnicas de convolução de máscaras e a sua
   larga utilização, decidimos adotá-las para o experimento. A partir do componente
   TImage, que acompanha o Delphi, e do CVMP processor farm, foram
   desenvolvidos os componentes TSobelPar (mestre e escravo) e TMaskPar (mestre
   e escravo). Devemos lembrar que, ao invés de estarmos preocupados com as
   questões de performance, como é usual, tratando-se de sistemas paralelos, nesses
   experimentos nos preocupamos com a didática e com a máxima simplicidade de
   utilização do sistema.
   A Figura 6.20 mostra um diagrama ilustrativo de um sistema implementado
   utilizando os componentes TSobelPar. Nele temos quatro aplicações, uma mestra e
   três escravas. A operação e programação dos componentes são simplificados,
   bastando arrastar e soltar os componentes no formulário da aplicação, e executar
   uma linha de código nas aplicações escravas (método TSobelParS.run na máquina
   escrava) e uma nas aplicações mestras ( método TsobelParM.run(número de
   máquinas) ).
   Depois da execução do método na aplicação mestra é realizada a criação
   dos Canais Virtuais e em seguida, a aplicação mestre divide a imagem contida no
   componente visual TSobelParM, em tiras horizontais (no exemplo da Figura 6.20 a
   imagem é dividida em 4 tiras). Após essa divisão, uma das tiras permanece na
   aplicação mestre, enquanto as demais são transmitidas para as aplicações
   245
   CAPÍTULO 6
   escravas. Após a transmissão inicia-se a execução da convolução da máscara
   Sobel. As imagens dos componentes mestre e escravos são atualizadas para cada
   pixel resultante da convolução, apresentando de forma didática a execução
   paralela. Finalizado o processo de convolução em todas as aplicações (mestre e
   escravas), os dados resultantes são transmitidos para a aplicação mestre, a qual
   monta essas tiras, e exibe o resultado da convolução com a máscara Sobel.
   Fig. - 6.20 – Exemplo de uma aplicação paralela utilizando os componentes
   TSobelPar .
   Uma variação dos componentes TSobelPar são os componentes TMaskPar,
   que possuem um funcionamento semelhante, com a diferença de que a máscara a
   ser convoluída na imagem é determinada através de programação no componente
   mestre ( TMaskParM). A matriz (5x5), que contém a máscara personalizada é
   transmitida para as aplicações escravas juntamente com as tiras da imagem,
   permitindo que estas realizem a convolução.
   Este experimento teve caráter didático, uma vez que permitiu ao usuário a
   visualização da execução paralela, apresentando em cada uma das máquinas o
   processamento gráfico, perdendo com isso desempenho.
   246
   CVMP
   6.11 - PERSPECTIVAS CVMP
   O conjunto de ferramentas CVMP pode ser considerado como uma camada
   adicional aos protocolos de comunicação, memória compartilhada ou redes. Suas
PA principais vantagens em relação à outras metodologias que possibilitam a
   computação paralela, tais como o PVM e MPI, estão na simplicidade de utilização,
   programação visual, encapsulamento, reutilização de código e programação
   orientada a objetos.
   Embora o CVMP, como abordamos neste capítulo, possa estar relacionado
   diretamente com os protocolos de comunicação e suas primitivas (TCP/IP, NetBeui
   e Socket), nada impede que o CVMP seja desenvolvido sobre outras metodologias,
   redirecionando os métodos de comunicação para as primitivas de outras técnicas.
   Acreditamos que essa característica aumente o potencial do CVMP, ficando como
   sugestão para desenvolvimentos futuros versões do CVMP sobre PVM ou MPI.
   Deste modo, permitir-se-á o desenvolvimento de aplicações mistas que podem,
   além de se beneficiar com as amplas bases destas tecnologias, também prover a
   estas plataformas seus benefícios.
   Uma vez que tanto o MPI quanto o PVM são voltados para o mundo Unix, e
   o CVMP para o mundo Windows, é necessário aguardar o lançamento do Kylix
   [Kylix], ambiente compatível com Delphi versão Linux, previsto para o segundo
   semestre de 2000, justificando assim a portabilidade do CVMP. Acreditamos que a
   versão CVMP para UNIX, venha trazer uma grande facilidade de desenvolvimento
   paralelo para essa plataforma, possibilitando ainda o desenvolvimento de sistemas
   paralelos heterogêneos (plataforma UNIX e Windows).
   Outro aspecto interessante do CVMP é a sua versatilidade, possuindo
   inúmeras possibilidades para o desenvolvimento de arquiteturas paralelas, uma vez
   que apresenta um código simples e enxuto (componente CVMP básico com cerca
   de 980 linhas) e pode ser baseado em qualquer mecanismo de comunicação. Um
   bom exemplo de uma arquitetura não convencional que pode ser desenvolvida
   através de CVMP são as máquinas MIMD distribuídas baseadas em interface SCSI.
   Uma vez que a tecnologia de redes vem constituindo cada vez mais um gargalo,
   não conseguindo acompanhar a performance dos processadores atuais, as
   arquiteturas baseadas em interface SCSI apresentam-se como uma nova
   possibilidade de arquitetura paralela [Henry et al., 1998] [Mattson & Henry, 1998]
   [Phil ips, 1998].
   247
   CAPÍTULO 6
   248
   CAPÍTULO
   7
   ESTUDOS DE ALGORITMOS
   PARALELOS PARA VISÃO E
   SUA IMPLEMENTAÇÃO COM
   CVMP
   "Is computer design driven by problems looking for solutions, or by solutions looking
   for problems ? The anwer is, by both."
   Almasi & Gottlieb
   249
   CAPÍTULO 7
   250
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   CAPÍTULO 7 – ESTUDOS DE
   ALGORITMOS PARALELOS PARA VISÃO E
   SUA IMPLEMENTAÇÃO COM CVMP
PA 7.1 - INTRODUÇÃO
   Neste capítulo realizaremos um estudo sobre as estratégias e arquiteturas
   de implementação paralela de alguns algoritmos de visão computacional e
   processamento de imagens. Iniciaremos o estudo com operadores locais, seguindo
   pelo tratamento individual dos canais cromáticos em imagens, o paralelismo nos
   algoritmos de transformadas de Fourier 2D e continuando com estratégias de
   paralelismo da transformada de Hough e restauração de imagens baseados em
   campos aleatórios de Markov. Finalmente, encerramos o capítulo com a
   paralelização do cálculo da dimensão fractal de Minkowski. Todos os métodos
   foram implementados com as ferramentas CVMP, de forma que podem ser
   utilizados diretamente em outras aplicações ou mesmo convertidos para
   componentes personalizados, de modo a complementar o CVMP.
   7.2 - OPERADORES LOCAIS
   Definimos como operadores locais os algoritmos que atuam isoladamente
   em um conjunto local de pixels, de modo que não ocorra dependência de dados
   com os outros componentes da imagem. Assim, algoritmos locais podem estar
   baseados em transformações envolvendo um único pixel isoladamente ou em
   conjuntos de pixels locais.
   As transformações em conjuntos de pixels locais são conhecidas como
   operadores de vizinhança, que se caracterizam pela convolução de filtros em
   domínio espacial [Gonzalez & Woods, 1993]. Estas técnicas são largamente
   utilizadas nos algoritmos de processamento de imagens de baixo nível, através de
   filtros de borramento (passa baixa, filtragem mediana, etc.), filtros de nitidez (passa
   alta) e detectores de borda, que incluem os filtros diferenciais em geral (Sobel,
   Robert e Laplaciano da Gaussiana entre outros). Estas transformações podem ser
   251
   CAPÍTULO 7
   expressas como
   g( x, y) = T[ f ( x, y)]
   (7.1)
   onde f(x,y) é a imagem de entrada, g(x,y) é a imagem resultante do processamento
   e T é o operador de f, definido através de operações sobre a vizinhança dos pixels
   de (x,y), que pode ser definida como uma matriz cujo elemento central é a
   coordenada (x,y), conforme podemos observar a seguir:
   ( x
   ,
   1 y
   )
   1
   ( x, y
   )
   1
   ( x + ,
   1 y
   )
   1
   ( x
   ,
   1 y)
   ( x, y)
PA ( x + ,
   1 y)
   (7.2)
   ( x
   ,
   1 y + )
   1
   ( x, y + )
   1
   ( x + ,
   1 y + )
   1
   As transformações envolvendo um único pixel podem ser expressas pela
   equação
   s = T ( r)
   (7.3)
   onde s e r são as variáveis correspondentes aos valores de nível de cinza das
   coordenadas de g(x,y) e f(x,y) respectivamente, e T representa a operação a ser realizada na variável r. Por exemplo, sendo T um operador de limiar ou binarização,
   a transformação realizada por T é uma condicional, onde sendo r maior que um
   limiar, então s será igual a 1 e caso contrário igual a 0. As operações locais
   envolvendo um único pixel, além de serem utilizadas para a binarização de
   imagens, são também empregadas para variações da intensidade de brilho, para
   alterações de coloração de uma imagem [Gonzalez & Woods, 1993], ou ainda em
   conjunto com análises de histograma [Gonzalez & Woods, 1993]. Devido à pouca
   demanda computacional requerida pelos métodos dessa classe (apenas uma
   operação por pixel da imagem), não vamos discutir suas possibilidades de
   paralelização.
   Entretanto, os métodos de convolução no domínio do espaço, por
   envolverem diversas operações aritméticas para cada pixel da imagem requerem
   poder computacional e consequentemente tempo de execução suficiente para
   requererem soluções paralelas. Devemos lembrar que a demanda computacional
   aumenta proporcionalmente com a dimensão da máscara a ser convoluída.
   252
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   (a)
   (b)
   I
   II
   III
   IV
   V
   Fig. - 7.1 – Estratégia de paralelismo para operadores locais, para quatro
   unidades de processamento. (a) Divisão da imagem em faixas, (b) divisão da
   imagem em quadriláteros. As etapas I, II, III, IV e V representam
   respectivamente: a imagem original, divisão da imagem e sua distribuição,
   processamento de cada parte da imagem em uma unidade de processamento
   diferente, reconstrução dos resultados e resultado do processamento.
   Basicamente a estratégia de paralelismo para os algoritmos operadores
   locais consiste na divisão da imagem em partes e em sua distribuição, de forma
   que cada máquina ou processador fique responsável pelo processamento em um
PA pedaço da imagem dividida, e finalmente da união dos resultados. A Figura 7.1
   contém um diagrama que ilustra essa estratégia de paralelismo com duas
   abordagens diferentes de divisão de imagem, formuladas para arquiteturas
   contendo quatro unidades de processamento. A primeira (a), consiste na divisão da
   imagem em tiras, que são distribuídas para as unidades de processamento e após
   serem processadas o resultado é reconstituído, na segunda (b), a imagem é
   dividida em quadriláteros. A imagem pode virtualmente ser dividida em qualquer
   formato, entretanto essas duas maneiras apresentam os mais óbvios e simples de
   implementar.
   Em alguns sistemas paralelos (ex: multiprocessadores), a fragmentação da
   253
   CAPÍTULO 7
   imagem num número muito maior de porções (alta granularidade) apresenta
   algumas vantagens tanto em desempenho quanto em balanceamento de cargas.
   No entanto, devido a grande latência da comunicação via rede (computação
   distribuída), optamos por estratégias que utilizem pacotes com grande quantidade
   de dados (baixa granularidade), a fim de otimizar as transmissões de dados. Esta
   abordagem foi utilizada não somente nesta seção como nas demais
   implementações ao longo de toda a tese.
   (a)
   (b)
   Fig. - 7.2 – Detalhes da divisão imagem resolvendo a dependência de dados
   para uma máscara 3x3. (a) Imagem original, (b) frações da imagem com a
   vizinhança dos elementos das linhas divisórias (em cinza).
   O particionamento da imagem, deve levar em conta a dependência de
   dados ocasionada pelo filtro, uma vez que a manipulação de um pixel envolve
   computações referentes a sua vizinhança. Seja qual for a abordagem de divisão
   considerada, deve-se adotar uma metodologia a fim de embutir nas porções
   distribuídas a vizinhança necessária para o cálculo dos elementos das linhas
   divisórias. Na Figura 7.2 temos um exemplo que ilustra detalhes do processo de
   divisão, onde considera-se que o filtro possui dimensão de 3x3. Como podemos
   observar em (b), juntamente com a porção da imagem a ser dividida (de cor branca)
   é acrescentada a vizinhança dos elementos anexos às linhas de divisão, de modo a
   solucionar a dependência de dados no cálculo desses elementos.
   A implementação do algoritmo, através do CVMP, pode ser realizada de
   inúmeras maneiras e envolvendo diferentes números de máquinas ou unidades de
   254
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   processamento. Nossa opção foi uma versão da estratégia de processor farm, onde
   ao invés de um processo supervisor, temos um processo mestre, que além de
   distribuir as tarefas para os escravos também realiza processamento. Em nossa
   implementação utilizamos o componente CVMP básico e o CVMP launcher para
   disparar os processos escravos. A Figura 7.3 mostra o arranjo esquemático dos
   processos, objetos CVMP e Canais Virtuais.
   Escravo
   CVMP
   Canal Virtual
   Mestre
   Fig. - 7.3 - Variação da arquitetura processor farm adotada para paralelismo
   do algoritmo dos operadores locais, onde o mestre além de distribuir as
PA tarefas também processa uma porção da imagem.
   Na Figura 7.4 temos um diagrama que ilustra as trocas de mensagens num
   sistema composto por 4 máquinas. O mestre, representado por M, particiona a
   imagem e envia as partes para os escravos ( E). A seguir ocorre o processamento
   paralelo de cada parte da imagem, cujo resultado retorna ao mestre, finalizando o
   algoritmo. Podemos observar através dos blocos de processamento que este
   exemplo apresenta balanceamento de carga satisfatória, uma vez que as tarefas
   terminam quase simultaneamente. Isso se deve ao fato do sistema possuir uma
   distribuição uniforme de poder computacional. O balanceamento é automático
   quando as unidades de processamento forem uniformes. Entretanto, em sistemas
   heterogêneos, ou seja, com unidades de processamento com diferentes
   desempenhos, o balanceamento pode ser realizado através da divisão da imagem,
   onde o tamanho da porção de imagem a ser processado deve ser proporcional ao
   poder computacional de cada unidade de processamento.
   Podemos observar ainda no diagrama da Figura 7.4 três bolhas, devido ao
   algoritmo esperar o envio de todas as frações da imagem para iniciar o
   processamento. Essas bolhas podem ser eliminadas, tornando o sistema mais
   255
   CAPÍTULO 7
   eficiente, se imediatamente após o envio das porções de imagem o mestre solicitar
   aos escravos o processamento. No entanto, embora essa tática permita um
   desempenho maior, acarreta em uma necessidade de redimensionamento das
   frações no processo de partição da imagem, uma vez que devem ser considerados
   também os tempos referentes ao envio das porções da imagem no cálculo da
   divisão da imagem.
   Vamos a seguir apresentar os resultados de um experimento realizado
   mediante a implementação dessa arquitetura, através dos quais poderemos
   analisar o comportamento do algoritmo paralelo, assim como sua performance
   frente ao seu análogo seqüencial. Para o experimento, utilizamos uma rede
   composta por 4 computadores, interligados com placas ethernet NE2000 de 10
   Mb/s. Implementamos a arquitetura apresentada na Figura 7.4, com divisão igual
   dos componentes da imagem. Deste modo, para que não houvesse
   desbalanceamento de carga no sistema, as máquinas deveriam possuir
   performance homogênea. Para isso configuramos e ajustamos 4 máquinas para
   que tivessem uma performance equivalente a um microprocessadormpenho do sistema em
   plataformas com microprocessadores mais velozes, caracterizando a troca de
   mensagens como o gargalo do sistema. Como alternativas para eliminar o gargalo
   podemos citar: (i) Utilização de redes mais velozes. O sistema foi implementado
   utilizando rede ethernet NE2000 com taxa de transferência de 10 Mbits/s, se a rede
   for substituída por uma solução com taxa de transferência superior, o tempo de
   transferência pode ser reduzido diminuindo o gargalo. (i ) Utilizar imagens com
   265
   CAPÍTULO 7
   dimensões bem maiores que as empregadas no experimento, aumentando o tempo
   proporcional de processamento (caixa preta da Figura 7.14) frente ao tempo de
   transferência (caixa com barras diagonais, Figura 7.14). (i i) Implementar o sistema
   com arquitetura de memória compartilhada. Essa solução possibilita uma grande
   redução do gargalo, devido à performance superior de transferência de dados entre
   os processos. Uma das desvantagens de sua adoção, no entanto, é a limitação de
   processadores nos modelos comerciais. Atualmente os sistemas de hardware
   (tecnologia PC) possuem um número limitado de processadores, sendo indicados,
PA do ponto de vista da computação científica, para soluções com poucos processos
   paralelos, como é o caso especial do sistema apresentado nesta seção.
   K6-2
   Envia dados
   375 MHz
   Sobel + Hough
   Pentium
   Recebe dados
   225 MHz
   486 dx4
   100 MHz
   0
   20
   40
   60
   80
   Tempo (s)
   Fig. 7.14 - Comparação entre o tempo de execução do experimento em três
   diferentes sistemas homogêneos, em uma imagem de 30000 pixels.
   7.4 - TRANSFORMADA DE FOURIER
   Nesta seção vamos comentar a implementação paralela da transformada de
   Fourier rápida (FFT) de duas dimensões baseada no CVMP. A transformada de
   Fourier dispensa apresentações. Ela tem sido utilizada há muitos anos em
   processamento de sinais e imagens, tanto na teoria quanto nas aplicações,
   podendo ser caracterizada como uma das bases clássicas do processamento de
   sinais e imagens.
   A transformada de Fourier e sua inversa em sua forma analítica, são dadas
   pelas equações 7.4 e 7.5 respectivamente, enquanto que sua forma discreta podem
   ser encontradas nas equações 7.6 e 7.7. Observando a transformada de Fourier
   discreta ( TFD - Transformada de Fourier Discreta), podemos avaliar a grande carga
   computacional requerida para seu processamento, devido ao grande número de
   266
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   multiplicações e exponenciações. Para diminuir essa enorme carga foi elaborada a
   transformada de Fourier rápida (FFT - Fast Fourier Transform), um algoritmo
   baseado em alguns artifícios matemáticos capaz de diminuir o número de
   operações e agilizar o processamento [Brigham, 1988]. Embora o resultado da FFT
   seja uma aproximação da transformada de Fourier, e também seja limitada a
   vetores (ou sinais), cuja dimensão seja geralmente uma potência de 2, sua grande
   performance justifica sua utilização.
   F u
   ( ) =
   f ( x) exp[ j 2 ux dx
   ]
   (7.4)
   f ( x) =
   F u
   ( ) exp[ j 2 ux du
   ]
   (7.5)
PA N 1
   1
   F( u) =
   f ( x)exp[ j 2 ux / N]
   (7.6)
   N x=0
   N 1
   f ( x) =
   F( u)exp[ j 2 ux / N ]
   (7.7)
   x=0
   7.4.1 - TRANSFORMADA DE FOURIER 2D
   A transformada de Fourier em duas dimensões é dada pela equação:
   F u
   ( , v) =
   f ( x, y)exp[ j 2 ux
   (
   + vy dxdy
   )]
   (7.8)
   que, quando transposta para sua forma discreta (TFD - Transformada de Fourier
   Discreta) resulta:
   N
   M
   1
   F u
   ( , v) =
   ux
   f ( x, y) exp
   j 2
   + vy
   (7.9)
   MN x=0 y=0
   N
   M
   que pode ser escrita como:
   267
   CAPÍTULO 7
   M
   N
   1
   1
   F u
   ( , v) =
   ux
   vy
   f ( x, y) exp
   j 2
   exp
   j 2
PA (7.10)
   M y=0 N x=0
   N
   M
   possibilitando a separação de um dos núcleos da equação resultando em:
   M
   1
   F u
   ( , v) =
   vy
   F u
   ( , y) exp
   j 2
   (7.11)
   M y=0
   M
   Esse resultado demonstra que podemos obter a TFD 2D a partir da TFD 1D,
   valendo o mesmo para a transformada discreta inversa, que basicamente possui
   como diferença apenas o sinal do expoente da exponencial. Para isso, deve-se
   calcular a TFD 1D de cada uma das linhas da imagem f(x,y), obtendo F(x,v) e
   depois calcular a TFD 1D de todas as colunas de F(x,v), obtendo finalmente F(u,v)
   [Brigham, 1988] [Castleman, 1996] [Gonzalez & Woods, 1993] [Oppenheim &
   Schafer, 1975]. A decomposição da TFD 2D em 1D pode ser expandida também
   para a FFT, neste caso, ao invés de calcular a TFD 1D de cada passo deve ser
   calculada a FFT [Brigham, 1988].
   Classicamente a implementação do algoritmo paralelo da FFT 2D consiste
   nas combinações horizontais e verticais da FFT 1D, conforme apresentamos
   anteriormente. A Figura 7.15 apresenta um diagrama ilustrativo da implementação
   realizada a partir do CVMP, nela o mestre divide a imagem horizontalmente e envia
   cada uma das partes para os processos escravos, ficando com uma parte. Com
   isso, cada um dos processos realiza a FFT 1D de cada uma das linhas horizontais
   da sua porção de imagem e, ao final deste procedimento transmitem a parte real e
   imaginária do resultado para o mestre, que agora, divide os resultados
   verticalmente e distribui-os novamente. É então disparado o processamento
   vertical, em cada uma das máquinas, que consiste na FFT 1D das linhas verticais
   das matrizes complexas (parte real e imaginária). Finalmente os resultados (que
   consistem em uma matriz real e uma imaginária) são enviados para o mestre, onde
   são combinados formando as matrizes real e imaginária resultantes da FFT 2D da
   imagem. Esta e outras estratégias de paralelismo da FFT 2D podem ser
   encontradas em detalhes em [Chu & George, 1999] e [Morante et al., 1999].
   268
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   Linhas horizontais
   Linhas verticais
   Resultado real
   Resultados
   e imaginário
   horizontais
   Imagem
   (horizontal)
PA divididos
   FFT
   original
   verticalmente
   resultado
   FFT 1D
   FFT 1D
   algoritmo
   1
   1
   algoritmo
   2
   2
   1 2 3 4
   1 2 3 4
   3
   3
   4
   4
   Escravo A
   Escravo A
   2
   2
   2
   2
   Mestre
   3
   Escravo B
   3
   Mestre
   Mestre
   3
   Escravo B
   3
   Mestre
   4
   4
   4
   4
   Escravo C
   Escravo C
   1
   Mestre
   1
   1
   Mestre
   1
   Fig. 7.15 - Estratégia de paralelismo da FFT 2D. Exemplo para 4 processos
   (máquinas ou processadores).
   Como podemos verificar, o fluxo de dados é bastante intenso,
PA especialmente devido a combinação dos resultados do processamento horizontal e
   a combinação para o processamento vertical. Entretanto, além da intensidade de
   trocas da estratégia de paralelização, devido à natureza dos dados, o volume
   transmitido aumenta demasiadamente, tornando-se um enorme gargalo no sistema.
   O aumento do volume dos dados ocorre devida a duas circunstâncias: (i) alteração
   de tipo de dado e (ii) as matrizes da transformada são complexas (uma matriz real e
   uma matriz imaginária).
   No primeiro fator, caso estejamos aplicando a transformada de Fourier a
   uma imagem, e sendo a imagem de 256 níveis de cinza (usualmente utilizada em
   processamento de imagens), cada elemento da matriz imagem é constituída por um
   byte. Vamos tomar como exemplo uma imagem de 1024x1024 pixels com 256
   níveis de cinza. Neste caso, o espaço de memória ocupado para armazenar a
   imagem é de 1 megabyte, uma vez que cada elemento da matriz imagem, é
   constituído por um byte (256 = 28). A quantidade de memória é determinada pela
   área da imagem em pixels. Entretanto, o algoritmo da transformada oferece maior
   precisão em ponto flutuante. A Tabela 7.1 apresenta o espaço em bytes ocupada
   pelos principais tipos de variáveis presentes no Object Pascal do Delphi versão 4,
   como podemos ver, os espaços ocupados pelos elementos da matriz são
   multiplicados por 4 ou na pior das hipóteses, caso exista a necessidade de uma
   maior precisão, por 8, uma vez que os tipos de variáveis que permitem
   269
   CAPÍTULO 7
   armazenamento de ponto flutuante ocupam 4 bytes (single) ou 8 bytes (real e
   double). Assim, a matriz imagem 1024x1024, quando convertida para ponto
   flutuante, passa a ocupar 4 megabytes se for atribuída com o tipo single e 8
   megabyte para os tipos real e double.
   Tipo
   bytes utilizados
   byte
   1 byte
   integer
   4 bytes
   real
   8 bytes
   single
   4 bytes
   double
   8 bytes
   Tabela 7.1 - Tipos de variáveis do Object Pascal (Delphi 4) e a memória
   utilizada.
   No segundo caso, temos que considerar que a transformada de Fourier é
   baseada em números complexos. Deste modo, somos obrigados a duplicar os
   dados para constituir uma matriz complexa, através da utilização de uma matriz
   ponto flutuante para representar a parte real e outra para a parte imaginária. Assim,
   tomando o exemplo anterior, caso tivéssemos optado pelos dados do tipo single,
   teríamos que manipular com 8 megabytes, e 16 megabytes se tivéssemos optado
   pelo tipo real ou double.
   Dentro da estratégia de paralelismo utilizada, temos basicamente quatro
   conjuntos de trocas de mensagens: (i) correspondentes a distribuição da imagem
   ou matriz de entrada, (ii) retorno do resultado do processamento horizontal para o
PA mestre, (i i) redistribuição das porções verticais e (iv) envio do resultado final para o
   mestre. Se o algoritmo for utilizado para imagens, parte das mensagens pode ser
   constituída de fragmentos da imagem, diminuindo desta maneira o fluxo de dados.
   Com o grande volume de dados, envolvido nesses processos, o tempo de
   processamento gasto com as operações relacionadas a essas transferências de
   dados (processos de leitura, conversões e comunicação em rede) acaba sendo
   maior do que o tempo gasto com o processamento matemático, tornando a
   implementação dessa estratégia inviável em sistemas distribuídos com redes
   possuindo taxas de transmissão de 10 ou 100 Mbit/s.
   O sistema foi implementado com 4 máquinas conectadas em rede ethernet
   270
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   de 10 megabits/s. As máquinas utilizadas possuíam processadores AMD k6 II - 375
   MHz, caracterizando o sistema como homogêneo. A Figura 7.16 apresenta um
   diagrama ilustrativo de uma implementação utilizando quatro máquinas em sistema
   distribuído com rede de 10 megabits/s, mostrando o tempo estimado das trocas de
   mensagem e do processamento matemático, onde podemos observar o gargalo
   formado pelos processos envolvidos com as trocas de mensagens.
   Fig. 7.16 - Estratégia de paralelismo da FFT 2D. Exemplo para 4 processos
   (máquinas ou processadores).
   Como alternativa para a redução do grande volume de dados envolvidos nos
   processos de transferência, utilizamos o algoritmo LZW [Nelson, 1989] de
   compactação de memória. Dessa maneira, antes dos dados serem transmitidos via
   rede, efetuamos sua compactação na máquina local. A fim de estudar o
   comportamento do sistema sob diferentes situações e na tentativa de otimizar os
   mecanismos de troca de mensagem e consequentemente aumentar a performance
   da versão paralela, o sistema foi implementado de 4 diferentes maneiras:
   Utilizando a memória de massa (disco rígido) para armazenar todos os dados a
   serem transmitidos via rede.
   Utilizando memória de massa como em (i), com compactação de dados antes da
   transmissão.
   Utilizando a memória RAM para armazenar todos os dados a serem transmitidos
   via rede.
   Idem a anterior, com compactação dos dados antes da transmissão.
   A Figura 7.17 apresenta os tempos de execução das diferentes
   implementações paralelas frente à versão seqüencial em 5 tamanhos diferentes de
   imagens (128x128, 256x256, 512x512, 1024x1024 e 2048x2048). Nela podemos
   271
   CAPÍTULO 7
   observar a melhora de performance provocada pela compactação de dados antes
   da transmissão, que embora possua gastos computacionais nos processos de
   compactação e descompactação justifica sua utilização pela taxa de compactação,
   que reduziu o tamanho dos dados em cerca de 90% a 99%.
   400
   1000
   4000
   300
   s)
   s)
   800
PA s) 3000
   (m
   (m
   o 200
   o
   600
   p
   p
   o (mp 2000
   m
   tem
   400
   tem
   te
   100
   1000
   200
   0
   0
   0
   1
   2
   3
   4
   5
   1
   2
   3
   4
   5
   1
   2
   3
   4
   5
   128 x 128
   256 x 256
   512 x 512
   70000
   15000
   (1) - Seqüencial
   60000
   (2) Paralelo - disco rígido
   s)
   s) 50000
   m
   (3) Paralelo - disco rígido
   10000
   o (
   40000
PA p
   o (m
   + compactação LZW
   p
   m
   30000
   m
   (4) Paralelo -
   te
   5000
   te 20000
   armazenamento RAM
   10000
   (5) Paralelo -
   0
   armazenamento RAM
   1
   2
   3
   4
   5
   0
   1
   2
   3
   4
   5
   1024 x 1024
   + compactação LZW
   2048 x 2048
   Fig. 7.17 - Tempos de execução do sistema seqüencial (1) e modalidades
   paralelas (2, 3, 4 e 5) para diferentes tamanhos de imagem. As modalidades
   paralelas foram implementadas em sistemas distribuídos de 4 máquinas.
   A Figura 7.18 apresenta a porcentagem entre o tempo gasto com o
   processamento matemático e o gasto com os procedimentos relacionados com as
   trocas de mensagens (leitura, gravação, rede, compactação e conversões). Nela
   podemos observar como o consumo dos recursos computacionais é maior para os
   processos envolvidos com a troca de mensagens do que com o envolvido com o
   processamento matemático, justificando uma baixa performance dessa arquitetura
   para sistemas distribuídos.
   A Figura 7.19 apresenta a taxa de desempenho ou speed-up, dos sistemas
   paralelos frente ao seqüencial. Conforme podemos observar, embora a taxa de
   desempenho aumente gradativamente à medida que aumentam as dimensões das
   imagens, ela não atinge um patamar de desempenho satisfatório até a dimensão de
   2048x2048. A baixa performance não justifica a utilização desta implementação
   paralela da FFT 2D, uma vez que com quatro máquinas, o sistema ficou na maioria
   dos casos mais lento que a versão seqüencial e atingiu um desempenho máximo
   pouco maior que esta.
   272
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
PA 100
   100
   100
   al
   al
   n
   n
   al
   80
   80
   n 80
   tacio
   tacio
   u
   u
   tacio
   60
   60
   p
   u 60
   mp
   m
   pm
   co 40
   co 40
   40
   co
   rso
   rso
   rso
   cu 20
   cu 20
   20
   e
   e
   cu
   R
   R
   eR
   %
   0
   %
   0
   0
   1
   2
   3
   4
   1
   2
PA 3
   4
   %
   1
   2
   3
   4
   128 x 128
   256 x 256
   512 x 512
   100
   100
   al
   al
   n
   n
   (1) Paralelo - disco rígido
   80
   80
   (2) Paralelo - disco rígido
   tacio
   tacio
   u 60
   u 60
   + compactação LZW
   mp
   mp
   (3) Paralelo -
   co 40
   co 40
   armazenamento RAM
   rso
   rso
   (4) Paralelo -
   cu 20
   cu 20
   e
   e
   R
   R
   armazenamento RAM
   %
   0
   %
   0
   + compactação LZW
   1
   2
   3
   4
PA 1
   2
   3
   4
   1024 x 1024
   2048 x 2048
   Processamento matemático
   Proc. relacionado a transf. de dados
   Fig. 7.18 - Porcentagem da utilização de recursos computacionais entre o
   processamento matemático e os processos relacionados com as
   transferências de dados.
   1.5
   1.5
   1.5
   1.5
   p 1.0
   p
   p
   p
   U
   1.0
   U
   1.0
   U
   1.0
   U
   ed
   ed
   ed
   ed
   e
   e
   e
   e
   Sp 0.5
   Sp 0.5
   Sp 0.5
   Sp 0.5
   0.0
   0.0
   0.0
   0.0
   128
   256
   512
   1024 2048
   128
   256
   512
   1024 2048
PA 128
   256
   512
   1024 2048
   128
   256
   512
   1024 2048
   1
   2
   3
   4
   Fig. 7.19 - Gráficos da taxa de desempenho ou speed up em função do
   tamanho da imagem (dado pelo lado da imagem quadrada). Gráfico: (1) disco
   rígido, (2) disco rígido + compactação LZW, (3) RAM e (4) RAM + compactação
   LZW.
   Uma vez que o gargalo do sistema está situado no grande fluxo de
   tra AMD K6 II com
   freqüência interna de 375 MHz, caracterizando assim os computadores da rede
   com uma performance homogênea.
   Fig. - 7.4 - Diagrama ilustrando as trocas de mensagem e o balanceamento de
   carga do sistema.
   No experimento medimos o tempo de execução do algoritmo paralelo e
   seqüencial para quatro tamanhos de imagens diferentes (250x250, 500x500,
   750x750 e 1000x1000 pixels), sendo que para cada uma das imagens foram
   aplicadas operadores com máscaras de diferentes tamanhos (3x3, 5x5, 9x9, 15x15,
   31x31, 51x51, 71x71, 85x85 e 101x101 elementos). Utilizamos no experimento um
   dos operadores locais mais básicos que caracteriza uma filtragem passa baixa
   256
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   [Gonzalez & Woods, 1993], conforme mostrado na Figura 7.5 através de um
   exemplo com dimensão 3x3, consiste no somatório dos elementos da máscara
   fracionada pelo número de componentes do filtro.
PA 1
   1
   1
   1
   X
   1
   1
   1
   9
   1
   1
   1
   Fig. - 7.5 - Exemplo de filtro passa baixa com 3x3 elementos.
   Imagem 250x250
   Imagem 500x500
   Imagem 750x750
   Imagem 1000x1000
   Fig. - 7.6 - Comparação entre o tempo de execução do algoritmo paralelo e
   seqüencial.
   A Figura 7.6 apresenta quatro gráficos com os resultados do experimento,
   sendo que cada um deles é respectivo a um tamanho de imagem (250x250,
   500x500, 750x750 e 1000x1000 pixels). Os gráficos mostram o tempo, dado em
   257
   CAPÍTULO 7
   segundos no eixo y, e o número de elementos do filtro no eixo x.
   4.0
   Imagem 250x250
   4.0
   Imagem 500x500
   3.5
   3.5
   3.0
   3.0
   2.5
   Up
   2.5
   Up
   d
   d
   2.0
   2.0
   ee
   ee
   1.5
   Sp
   1.5
   Sp
   1.0
   1.0
   0.5
PA 0.5
   0.0
   0.0
   3x3
   5x5
   9x9
   15x15 31x31 51x51 71x71 85x85 101x101
   3x3
   5x5
   9x9
   15x15 31x31 51x51 71x71 85x85 101x101
   máscara
   máscara
   4.0
   Imagem 750x750
   4.0
   Imagem 1000x1000
   3.5
   3.5
   3.0
   3.0
   2.5
   Up
   2.5
   Up
   d
   d
   2.0
   2.0
   ee
   ee
   1.5
   Sp
   1.5
   Sp
   1.0
   1.0
   0.5
   0.5
   0.0
   0.0
   3x3
   5x5
   9x9
   15x15 31x31 51x51 71x71 85x85 101x101
   3x3
   5x5
   9x9 15x15 31x31 51x51 71x71 85x85 101x101
   máscara
   máscara
PA Fig. - 7.7 - Desempenho dos algoritmos paralelos.
   A performance da implementação paralela frente a seqüencial aumenta à
   medida que caminhamos no eixo x. Para filtros com poucos elementos, tais como
   3x3 e 5x5, o desempenho da versão paralela chega a ser inferior, conforme
   podemos observar na ampliação do detalhe do gráfico referente à imagem de
   750x750 pixel. Para analisarmos o comportamento da performance, utilizamos da
   medida de Speed Up ou medida de desempenho, dada pela razão entre o tempo de
   execução seqüencial e o tempo de execução paralelo. Na Figura 7.7 encontramos
   os gráficos de desempenho, correspondentes aos da Figura 7.6. Como podemos
   verificar, um resultado interessante é a pequena variação de desempenho frente a
   dimensão da imagem. Embora a imagem 250x250 possua um desempenho médio
   inferior, as demais dimensões possuem características próximas, com um aumento
   de performance muito pequeno para as imagens de tamanho maior, indicando que
   o fator fundamental no desempenho é o tamanho do filtro. A partir do filtro de
   15x15, a implementação paralela começa a ser justificável, atingindo um
   258
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   desempenho aproximado, que varia de 1,75 vezes (imagem 250x250) a 2,25 vezes
   superior (imagem 1000x1000). Para filtros maiores, o algoritmo paralelo
   implementado com 4 máquinas, atinge sua performance máxima, aproximadamente
   3,5 vezes superior à versão seqüencial.
   A razão da baixa performance do algoritmo paralelo para os filtros com
   poucos elementos pode ser compreendida através da relação entre o tempo de
   processamento e o tempo de transferência dos dados. Observando a Figura 7.4
   podemos verificar que a base computacional do algoritmo pode ser dividida em
   duas partes: transmissão dos dados e processamento do operador local. Na
   transmissão de dados, temos duas etapas: a distribuição das partes da imagem a
   serem processadas e a transmissão do resultado para a máquina mestra. À medida
   que os filtros se tornam maiores, a demanda computacional para o processamento
   do operador local aumenta, enquanto que a demanda requerida pela transmissão
   de dados continua a mesma. Como os dados envolvidos na transmissão são
   consideráveis, essa etapa consome grande recurso computacional, especialmente
   em sistemas distribuídos, que possuem uma baixa banda de transferência. Para
   justificar o tempo desperdiçado na transmissão de dados, os recursos
   computacionais gastos com a processamento do operador local precisam ser
   maiores que estes.
   100%
   80%
   60%
   40%
   20%
   0%
   3x3
   5x5
   9x9 15x15 31x31 51x51 71x71 85x85 101x101
   máscara
   Fig. - 7.8 - Comparação entre a porcentagem de tempo consumido entre o
   processamento e a transmissão de dados (imagem de 500x500).
   O gráfico da Figura 7.8 apresenta as porcentagens de tempo de execução
   259
PA CAPÍTULO 7
   em relação ao processamento do operador local e a transmissão de dados.
   Conforme podemos observar para as máscaras com poucos elementos, o
   percentual de demanda computacional requerido pelo processamento do operador
   local é pequeno, não justificando a implementação paralela. No entanto à medida
   que o poder computacional exigido pelo processamento aumenta, o percentual da
   transmissão de dados diminui, aumentando a performance do sistema.
   4
   3
   Upd 2ee
   Sp
   1
   10 Mbits/s
   0
   3x3
   5x5
   9x9 15x15 31x31 51x51 71x71 85x85 101x101
   100 Mbits/s
   máscara
   Fig. - 7.9 - Comparação entre a performance do sistema em rede de 10Mbits/s
   (ethernet) e 100Mbits/s (fast ethernet).
   Conforme vamos observar no decorrer desse capítulo, o gargalo da grande
   maioria dos sistemas distribuídos para processamento de imagens e visão se
   encontra na transmissão de dados, uma vez que o processamento dessas áreas
   está relacionado com imagens. Deste modo, uma maneira de aumentar a
   performance dos sistemas é utilizar redes mais rápidas ou sistemas de memória
   compartilhada.
   Na Figura 7.9 temos a comparação entre o nosso experimento executado
   em uma rede de 10 e 100 Mbits/s (imagem 500x500). Uma rede mais veloz fez com
   que a performance dos filtros menores (3x3, 5x5, 9x9 e 15x15) aumentasse
   consideravelmente, permanecendo entretanto com desempenhos próximos nos
   filtros de dimensão maior. Comparando este resultado com o gráfico da Figura 7.8,
   podemos justificar essa diferença de aumento de performance, já que à medida que
   os filtros aumentam, torna-se menor o gargalo constituído pela transmissão de
   dados. Diferente do convencional, na arquitetura apresentada nesta seção, as
   aplicações que envolvem grandes máscaras não justificam a utilização de redes de
   alto desempenho.
   260
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   7.3 - CANAIS CROMÁTICOS
   A cor é percebida pelos primatas através da composição da percepção de
   três diferentes fotorreceptores, que possuem absorções máximas de onda em
   diferentes faixas do espectro (vermelho, verde e azul). Nos sistemas
   computacionais, a cor é igualmente formada pela composição de contribuições das
   diferentes faixas do espectro. No entanto, ao invés de funções contínuas como
   ocorre nos sistemas de visão natural, as representações numéricas da cor são
   quantizadas através de funções discretas que, em geral, possuem 256 valores.
   Existem diversas representações cromáticas em sistemas computacionais,
   cujo princípio baseia-se na formação de um espaço de cores, que quantificam os
   estímulos cromáticos. Dentre os espaços de cores, existem os que combinam matiz
PA com brilho, iluminação e contraste, ao invés de combinar as cores diretamente,
   como é o caso dos sistemas YIQ, YUV, HSI e HSV entre outros [Moreira, 1999]
   [Pratt, 1984]. As representações mais comuns e mais utilizadas são aquelas que,
   assim como no modelo biológico, combinam as faixas do espectro. Dentro dessa
   classe temos o sistema RGB, o mais difundido de todos, que é análogo ao sistema
   tricromático biológico, sendo formado da combinação das matizes vermelho, verde
   e azul. Embora a grande maioria das representações sejam compostas por três
   canais, existem também aquelas que não seguem esse padrão, como é o caso do
   sistema CMYK, sistema de representação cromática baseada na absorção e
   combinação de tintas na formação de cores, largamente utilizado em aplicações
   envolvendo impressões gráficas, cuja combinação é formada com matizes azul
   claro - Cyan, vermelho claro - Margenta, amarelo e preto.
   Os canais de combinação dos sistemas de representações cromáticos
   podem ser considerados como planos ou imagens independentes. Tomemos por
   exemplo o sistema RGB, no qual as imagens cromáticas são formadas por três
   imagens em níveis de cinza, representando cada um dos planos de contribuição
   (azul, verde e vermelho), de forma que cada um dos planos possa ser processado
   com as técnicas convencionais de processamento de imagens em tons de cinza.
   Uma vez que cada plano pode conter informações diferenciadas, relativas às
   variadas absorções de espectro dos componentes da imagem, o processamento
   individual de cada plano possibilita a revelação de detalhes obtidos apenas na
   análise de um dos componentes.
   Do ponto de vista do paralelismo, os planos podem ser tratados de modo
   261
   CAPÍTULO 7
   isolado uma vez que não existe dependência de dados. Isto simplifica a
   implementação de algoritmos cromáticos que utilizam essa abordagem. Vamos
   apresentar como exemplo do paralelismo explorando os canais cromáticos um
   detector de retas em imagens cromáticas, cujo objetivo é mais didático do que
   prático. Partindo da idéia que informações diferentes podem estar concentradas
   nos diferentes planos da imagem cromática, esse algoritmo explora os planos
   individualmente na expectativa de encontrar retas não detectáveis na versão
   monocromática da imagem.
   Para cada plano cromático o algoritmo efetua a extração das bordas da
   imagem através do popular filtro Sobel [Sobel, 1970], e no resultado dessa
   operação é realizada a transformada de Hough com parametrização normal,
   responsável pela detecção das retas.
   Implementamos o sistema distribuído utilizando 3 máquinas conectadas por
   rede, uma mestra e duas escravas, conforme apresentado na Figura 7.10. A
   máquina mestra é responsável pela aquisição da imagem cromática e pela divisão
   dos 3 planos e a distribuição de dois destes para as máquinas escravas. Após a
   distribuição dos planos é realizado o processamento dos algoritmos Sobel e Hough,
   simultaneamente nas três máquinas. Finalmente o resultado é retornado à máquina
   mestra, onde pode ser combinado com operadores lógicos.
   Fig. - 7.10 - Diagrama ilustrando as trocas de mensagem e o balanceamento
   de carga do sistema. M - máquina mestra; S1 e S2 - máquinas escravas.
   Para compararmos a performance do sistema em situações distintas,
   implementamos três configurações diferentes: seqüencial, paralelo com duas
   máquinas e paralelo com três máquinas, conforme mostra a Figura 7.11. O
   experimento foi realizado em três redes homogêneas de computadores com três
PA máquinas, incluindo: uma formada por computadores com processadores 486dx4
   com freqüência interna de 100 MHz, outra com processadores Pentium MMX de
   225 MHz e a última com processadores AMD K6 II de 375 MHz. Todas as redes
   262
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   foram implementadas usando placas ethernet NE2000 de 10Mbits/s. Deste modo
   podemos comparar o desempenho do sistema paralelo versus sua versão
   seqüencial, frente a sistemas com diferentes performances, permitindo assim,
   avaliá-lo perante a evolução dos microprocessadores.
   (a)
   (b)
   (c)
   Aq - Aquisição da imagem
   GC - Canal Verde
   CS - Divisão dos Canais
   RC - Canal Vermelho
   S - Processamento Sobel
   BC - Canal Azul
   H - Processamento Hough
   GE - Resultado Verde
   ER - Receber Resultado
   RE - Resultado Vermelho
   LC - Combinação Lógica
   BE - Resultado Azul
   Fig. - 7.11 - Configurações do sistema: (a) seqüencial, (b) paralelo com 2
   máquinas e (c) paralelo com 3 máquinas.
   A Figura 7.12 (a) apresenta uma comparação entre a performance para a
   implementação paralela e a versão seqüencial. Nela é apresentado um gráfico do
   tempo de execução de cada uma das situações contra o número de pixels da
   imagem processada. Na Figura 7.12 (b) é apresentado um gráfico do tempo de
   execução em função do número de máquinas utilizadas, parametrizado pelo
   tamanho da imagem dado em pixels. O desempenho ou speed-up do sistema é
   aproximadamente uniforme para os diferentes tamanhos de imagem, ficando em
   263
   CAPÍTULO 7
   torno de 2,5 vezes superior, para o sistema rodando em três máquinas e 1,4 vezes
   superior para duas máquinas, conforme podemos verificar na Figura 7.13 (a).
   seqüencial
   (s)
   (s)
   po
   po
   m
   m
   te
   te
   paralelo
   (a)
   (b)
   Fig. 7.12 - Tempo de execução (máquinas 486dx4-100): (a) Em relação ao
PA número de pixels, comparação entre as versões seqüencial e paralela com 3
   máquinas e (b) Em relação ao número de processadores (P) parametrizado
   pelo número de pixels.
   Os resultados do experimento realizado em redes homogêneas com
   diferentes microprocessadores apresentam a queda de performance da versão
   paralela frente à seqüencial. Isso pode ser observado através speed-up ou medida
   de desempenho das três diferentes situações, através dos gráficos da Figura 7.13,
   (a) 486dx4 100MHz, (b) Pentium MMX 225MHz e (c) AMD K6-II 375MHz. Enquanto
   os microprocessadores apresentam performance diferentes, a taxa de transferência
   da rede continua a mesma, caracterizando-a como gargalo para os processadores
   mais velozes. Podemos observar na Figura 7.13 (b e c) uma taxa de crescimento
   de performance à medida que o tamanho da imagem aumenta. Assim, embora esta
   arquitetura paralela tenha se tornado inviável para as imagens utilizadas no
   experimento, deve atingir uma performance aceitável para imagens de grandes
   dimensões, já que nessa situação a carga de processamento tornará maior que a
   de transferência. Observamos ainda que a performance do sistema em 486dx4
   permanece constante para os diferentes tamanhos de imagem, indicando uma
   demanda superior para carga de processamento frente à transferência dos dados
   atingindo equilíbrio.
   264
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   3.0
   486dx4-100MHz
   3 máquinas
   2.5
   p
   2.0
   (a)
   eed USp
   1.5
   2 máquinas
   1.0
   5000
   10000
   15000
   20000
   25000
   30000
   pixels
   Pentium 225MHz
   K6-II 375MHz
   2.30
   1.55
   2.25
   1.50
   1.45
   2.20
   p
   p 1.40
   2.15
PA eed U
   eed U
   Sp
   Sp 1.35
   2.10
   1.30
   (b)
   (c)
   2.05
   1.25
   2.00
   5000
   10000
   15000
   20000
   25000
   30000
   5000
   10000
   15000
   20000
   25000
   30000
   pixels
   pixels
   Fig. 7.13 - Gráficos de desempenho em função do número do tamanho da
   imagem. As redes são homogêneas e são baseadas em ethernet NE2000 com
   taxa de 10Mbits/s. (a) rede formada por máquinas 486dx4-100MHz, (b) Pentium
   225MHz e (c) K6II 375MHz.
   A Figura 14 apresenta um diagrama ilustrativo, que compara os tempos de
   execução das versões paralelas (3 máquinas) em cada uma das plataformas em
   que foi realizado o experimento. Através dele podemos observar a diminuição
   crescente do tempo de execução frente ao tempo de transferência de dados,
   justificando assim a razão pelo decréscimo de desearâmetro conhecido. Somente dois valores de cliques são
   considerados, com pesos iguais, de forma a favorecer a uniformidade. Assim, a
   Equação 7.14 produz o seguinte critério de classificação:
   0
   p( d | f = 0 / p d | f = 1
   P f = 1| f
   / P f = 0 | f
   (7.15)
   i
   i
   ) ( i i )
   ( i
   N )
   ( i
   )
   i
   Ni
   <1
   Como pode ser verificado, os primeiros termos da condição de 7.15,
   refletem o modelo da imagem e o modelo do ruído, e o segundo termo expressa a
PA influência contextual do vizinho com adjacência imediata, que são similares ao
   primeiro e segundo termos da Equação 7.13.
   Uma versão mais flexível do critério descrito anteriormente é obtida por
   pesos adicionais, na forma de parâmetros , conforme podemos observar a seguir:
   0
   [ p( d | f = 0 p d f
   P f
   f
   P f
   f
   (7.16)
   i
   i
   )/ ( | =
   i
   i
   )1(.1 )+ ]
   [1 ( =1|
   i
   N )/
   ( = 0|
   i
   )(.1 )]
   <
   i
   Ni
   1
   Agora, as influências relativas do modelo imagem/ruído e a coação
   contextual podem ser continuamente variadas em termos do parâmetro . A Tabela
   7.2 ilustra alguns critérios que são obtidos em função de diferentes valores de .
   Enquanto para
   =0 a condição é exclusivamente governada pelo modelo
   imagem/ruído, para =1 somente a coação contextual é refletida. A condição
   original dada por 7.15 é obtida para =0,5. Diferentes influências são obtidas para
   valores de [0,1]. Alguns resultados experimentais são apresentados na Figura
   7.35, que claramente apresentam a flexibilidade permitida pela técnica.
   290
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   Critério
   0.00
   0
   p( d | f = 0 p d f
   i
   i
   )/ ( | =
   i
   i
   )1
   1
   <1
PA 0.25
   0
   ( .075). p( d | f = 0 p d f
   P f
   f
   P f
   f
   i
   i
   )/ ( | =
   i
   i
   )1
   ( .025). ( =1|
   i
   N )/
   ( = 0|
   i
   )+0 5.
   <
   i
   Ni
   1
   0.50
   0
   p( d | f = 0 / p d | f = 1
   P f = 1| f
   / P f = 0 | f
   i
   i
   ) ( i i )
   ( i
   N )
   ( i
   )
   i
   Ni
   <1
   0.75
   0
   ( .025). p( d | f = 0 / p d | f =1 + 0 5.
   0 75
   .
   . P f = 1| f
   / P f = 0 | f
   i
   i
   ) ( i i )
   (
   ) ( i
PA N )
   ( i
   )
   i
   Ni
   <1
   1.00
   0
   1
   P( f =1| f / P f = 0 | f
   i
   N )
   ( i
   )
   i
   Ni
   <1
   Tabela 7.2 - Exemplos de critérios obtidos em termos de .
   (a)
   (b)
   (c)
   (d)
   (e)
   Fig. - 7.35 - Resultados da técnica de restauração - (a) Imagem original
   100x100 corrompida por um ruído gaussiano com 2=0,5. Os resultados são
   respectivos a =0,3 (b), =0,5 (c), =0,7 (d) e =0,9 (e).
   7.6.1 - ESTRATÉGIA DE PARALELISMO
   Diferente das técnicas apresentadas anteriormente neste capítulo, o
   algoritmo de restauração de imagens baseado em campos aleatórios de Markov é
   um método iterativo, que se repete continuamente até que ocorra a convergência
   numérica. Do ponto de vista do paralelismo, esse fato acrescenta uma
   complexidade à estratégia, uma vez que a troca de mensagens entre os processos
   ocorre diversas vezes de forma a atualizar os dados a cada iteração, o que torna o
   291
   CAPÍTULO 7
   problema bastante interessante.
   A Figura 7.36 apresenta as bases da estratégia de paralelização para quatro
   elementos de processamento, onde a imagem é dividida pelo processo mestre, que
   distribui cada parte desta para os processos escravos, ficando com um fragmento.
   Após a distribuição, cada processo executa o algoritmo MRF, que consiste de uma
   série de iterações, envolvendo troca de mensagens e atualização de dados, que
   serão discutidos adiante. Uma vez tendo convergido a técnica, os resultados são
   enviados para o mestre, que une os fragmentos, formando o resultado sobre a
   imagem original.
   Imagem - aquisição
   divisão e distribuição
   MRF algoritmo
   Recebe e une o
   resultado
   Escravo A - MRF
PA 2
   2
   1 2
   1 2
   Mestre
   3
   Escravo B - MRF
   3
   Mestre
   3 4
   3 4
   imagem
   4
   4
   resultado
   Escravo C - MRF
   1
   Mestre - MRF
   1
   Fig. - 7.36 - Estratégia básica de paralelismo da técnica MRF.
   Nesta técnica (MRF), cada elemento é calculado considerando os cliques
   envolvendo a vizinhança dos 8 pontos em torno de cada pixel. Embora distâncias
   maiores sejam também verificadas, essa situação ocorre ao longo do tempo
   (iterações) através de propagação entre os elementos vizinhos. Deste modo, para
   cada iteração ocorre a dependência de dados entre os limites da divisão da
   imagem. Para solucionar essa dependência de dados e atualizar as porções de
   imagem em cada elemento de processamento, permitindo assim a propagação de
   informações ao longo de toda a imagem, foram implementadas três estruturas de
   atualização de dados, duas na forma de vetores e a última sendo um único ponto. A
   Figura 7.37 apresenta a configuração das estruturas de atualização para a parte 1
   da imagem. Como podemos observar, o vetor vertical é composto pelos pixels da
   borda da parte 3, ocorrendo o mesmo com o vetor horizontal, que é associado à
   parte 2. A pequena estrutura de atualização, caracterizada como um ponto, é
   292
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   composta pelo pixel do canto superior esquerdo da parte 4.
   Parte 1
   Parte 3
   da
   da
   Imagem
   Imagem
   Parte 2
   Parte 4
   da
   da
   Imagem
   Imagem
   Fig. - 7.37 - Estratégia básica de paralelismo da técnica MRF.
   A incorporação das estruturas de atualização permite que todas as iterações
PA sejam calculadas em concorrência, resolvendo a questão da dependência de dados
   e permitindo a convergência da técnica e a propagação dos dados através das
   vizinhanças. Para tanto, os módulos paralelos devem trocar as informações
   contidas nas estruturas de atualização após cada iteração do algoritmo MRF. A
   Figura 7.38 ilustra a troca de informações através das estruturas de atualização,
   nela são apresentados quatro módulos, representados pelas caixas numeradas,
   com suas respectivas estruturas de atualização, representadas pelas caixas
   preenchidas. Diferente da Figura 7.36, aqui não há distinção entre os processos
   mestre e escravo.
   Fig. - 7.38 - Diagrama de transferência das estruturas de atualização.
   Nesta arquitetura, o balanceamento de carga é definido pela quantidade de
   pontos a serem processados. Neste caso, em sistemas heterogêneos, ou seja,
   293
   CAPÍTULO 7
   aqueles em que as unidades de processamento possuem diferentes poderes
   computacionais, devem ser atribuídas porções de imagem proporcionais à
   performance de cada uma das unidades de processamento do sistema. Embora a
   Figura 7.38 apresente um diagrama limitado em apenas quatro unidades de
   processamento, sem a preocupação com o balanceamento de carga, a arquitetura
   permite um conjunto virtualmente infinito de configurações.
   A Figura 7.39 apresenta algumas possibilidades de configurações da
   arquitetura para 6 e 9 unidades de processamento, que demonstram que a
   arquitetura pode ser estendida facilmente para qualquer número de elementos de
   processamento. O balanceamento de carga do sistema pode ser realizado alojando
   mais de um módulo da imagem em uma única unidade de processamento. Essa
   abordagem é mostrada na Figura 7.40, onde são apresentados três exemplos
   envolvendo balanceamento de carga em sistemas heterogêneos. Os módulos
   agrupados em caixas estão alojados em um único elemento de processamento,
   permitindo desse modo uma distribuição irregular da carga computacional ao longo
   do sistema.
   (a)
   (b)
   Fig. - 7.39 - Diagrama de transferência das estruturas de atualização para 6 (a)
   e 9 (b) elementos de processamento.
   294
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   (a)
   (b)
   (c)
   Fig. - 7.40 - Exemplos de balanceamento de carga, com 3 elementos de
   processamento heterogêneos.
   Nesta técnica, o número de iterações depende do nível de ruído e da
   estrutura da imagem. Em alguns casos a convergência não é garantida. Assim, o
   processamento pode ser finalizado pelos eventos seguintes: (a) não ocorrendo
   modificação em nenhum dos módulos (convergência); ou (b) o número de iterações
   ultrapassa um limiar pré-estabelecido. Devemos observar também que cada
   módulo envia suas três estruturas de atualização para os outros módulos e essas
   estruturas são necessárias para a próxima iteração. Quando um módulo é
   finalizado, ele fica inativo até a próxima iteração. Se algum dado foi alterado
   (através das estruturas de atualização), então o módulo inicia outra iteração; caso
PA contrário, envia sua estrutura e aguarda os próximos dados.
   295
   CAPÍTULO 7
   MRF
   MRF
   MRF
   i1
   i2
   i3
   Classificação Bayeseana
   Mestre
   MRF
   Recebe estruturas
   Escravo 1
   Envia estrutura e continua
   Envia estrutura e para
   Escravo 2
   Confere as estruturas
   Envia os resultados
   Escravo 3
   Agrupa os resultados
   Fig. - 7.41 - Diagrama de execução do algoritmo MRF paralelo, para quatro
   elementos de processamento.
   A Figura 7.41 apresenta um diagrama que representa a arquitetura em
   execução para quatro elementos de processamento. O primeiro passo da técnica é
   a classificação Bayeseana realizada pelo mestre, que é então distribuída. A partir
   destes dados são iniciadas as iterações do MRF. O número de iterações do
   algoritmo MRF é variável, e devido a sua natureza estocástica não existe uma
   maneira de prever com precisão como será executado. Cada módulo pode parar
   em tempos diferentes, como pode ser observado, os módulos escravos 1 e 3
   terminam na primeira iteração e o módulo 2 termina na segunda iteração. No
   entanto, a qualquer iteração, um módulo parado pode voltar a ativa mediante
   alterações na estrutura de atualização. Isto pode ser observado no módulo escravo
   3, que recebe um dado diferenciado na iteração 2, sendo forçado a processar mais
   uma iteração. A tarefa de verificar o fim do algoritmo fica a cargo do mestre, que ao
   final de cada iteração recebe uma mensagem do estado de cada módulo,
   finalizando o processamento quando todos os módulos tiverem convergido. Após a
   finalização do algoritmo, todos os resultados são enviados para o mestre, que os
   combina formando o resultado final.
   7.6.2 - IMPLEMENTAÇÃO E RESULTADOS
   A estratégia de paralelismo para o algoritmo de restauração de imagens
   baseado em campos randômicos markovianos desenvolvida durante este
   doutorado foi implementada em sistemas distribuídos através do CVMP. Nesta
   296
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   seção vamos apresentar os resultados experimentais da implementação paralela da
   técnica em quatro máquinas conectadas por rede ethernet de 10 mb/s. No primeiro
   experimento, utilizamos máquinas com diferentes performances, que resultam em
   um sistema não balanceado. Deste modo, as máquinas mais velozes precisam
   esperar pelas mais lentas para continuar o processamento. Embora essa
PA abordagem leve a uma performance baixa, ela é ainda interessante para ilustrar
   algumas características do sistema. Utilizamos no primeiro experimento uma
   imagem binária de 200 x 200 pixels.
   A Figura 7.42 apresenta um diagrama caracterizando a execução do
   sistema, enquanto que a Figura 7.43 mostra um diagrama correspondente à
   transferência de dados. As máquinas utilizadas no experimento foram: uma
   Pentium de 150 MHz como mestre, um Pentium de 90 MHz como escravo A, um
   Pentium 133 MHz como escravo B e um Pentium 150 MHz como escravo C. O
   grande número de bolhas encontrado no diagrama da Figura 7.42 é devido
   especialmente às máquinas mais velozes, que tiveram que esperar pela vagarosa
   máquina de 90 MHz.
   Fig. - 7.42 - Diagrama de execução do algoritmo MRF paralelo em um sistema
   heterogêneo.
   297
   CAPÍTULO 7
   Fig. - 7.43 - Diagrama da troca de mensagens.
   Observando ainda os diagramas das Figuras 7.42 e 7.43 podemos verificar
   a dificuldade de estabelecer a performance real do sistema, uma vez que o sistema
   não é previsível quanto ao número de iterações. No experimento apresentado o
   mestre e o escravo C tiveram 3 iterações, enquanto os escravos A e B apenas
   duas.
   Para extrairmos medidas de desempenho mais consistentes, escolhemos
   situações em que tanto a versão seqüencial quanto a paralela tiveram quatro
   iterações. Realizamos esse experimento em sistema distribuído homogêneo com
   quatro máquinas Pentium 133 Mhz conectadas com rede padrão ethernet de 10
   mb/s. A Figura 7.44a apresenta o gráfico de tempo de execução das versões
   seqüencial e paralela para quatro máquinas. Conforme pode ser observado, a
   performance do sistema paralelo aumenta à medida que aumenta o tamanho da
   imagem, tornando-se 3,5 vezes mais rápido que a versão seqüencial nas imagens
   de 700x700 pixels (ver Figura 7.44b).
   298
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   4
   3
   p
   d u 2ee
   Sp
   1
   0 200x200 300x300 400x400 500x500 600x600 700x700
   Tamanho da imagem (pixels)
   (a)
   (b)
   Fig. - 7.44 - Comparações de performance entre a versão paralela e
   seqüencial. (a) Gráfico do tempo de execução em função do tamanho de
   imagem. (b) Gráfico da taxa de desempenho em função do tamanho de
   imagem.
   7.7 - DIMENSÃO FRACTAL
   Muitas formas na natureza são tão complexas e irregulares que são difíceis
   e até mesmo impossíveis de serem expressas e analisadas pela geometria
   euclideana. Através de estudos sobre a auto-similaridade e irregularidade,
PA Mandelbrot [Mandelbrot, 1977] introduziu a geometria fractal, que apresentou uma
   nova maneira de considerar tais formas. Através da geometria fractal, um grande
   número de objetos naturais, que vão de neurônios a nuvens, pode ser modelado e
   melhor compreendido. A Figura 7.45 apresenta dois exemplos de fractais, onde o
   primeiro é o triângulo de Sierpinski [Stanley, 1986] e o segundo uma forma de
   Mandrelbrot [Mandelbrot, 1983].
   A idéia de dimensão fractal surgiu na tentativa de se determinar uma medida
   de complexidade para formas como as da Figura 7.45. Embora inicialmente
   dedicado à geometria fractal, o conceito da dimensão fractal rapidamente se
   espalhou, permitindo sua aplicações em diversas áreas tais como: ciência dos
   materiais, geologia, visão computacional [Biswas et al., 1998], neuromorfologia
   [Costa,1996][Coelho, 1998], etc.
   Diversas técnicas para estimar a dimensão fractal foram descritas na
   literatura [Caserta et al., 1995] [Clark, 1986] [Kaye, 1989] [Kaye, 1994] [Smith et al.,
   1996], das quais a mais popular para processamento de imagens e provavelmente
   299
   CAPÍTULO 7
   também a mais simples é a de contagem de caixas [Peitgen & Saupe, 1988]
   [Falconer, 1990].
   (a)
   (b)
   Fig. - 7.45 - Dois exemplos de fractais, triângulo de Sierpinski (a) e Mandelbrot
   (b).
   Vamos nos limitar ao método de salsichas de Minkowski [Tricot, 1995]. O
   método para cálculo da dimensão fractal conhecido como de salsichas de
   Minkowski, produz uma estimativa da dimensão de Bouligand-Minkowski [Coelho,
   1998]. A técnica essencialmente se baseia na convolução de círculos com
   diferentes raios r na imagem. Com o resultado da convolução de cada círculo,
   calcula-se a área A ocupada pelos pixels significantes (não nulos). Projetam-se
   então os pontos obtidos pelos pares r e Ar em um gráfico log(r) x log(A).
   Usualmente os pontos irão caracterizar uma reta, que pode ser determinada
   através de regressão linear. A dimensão fractal é obtida pela inclinação desta reta.
   A paralelização da técnica é bastante simples, uma vez que não ocorre a
   dependência de dados durante a concorrência, e pode ser implementado
   diretamente com o componente Processor Farm do CVMP, simplificando muito a
   sua implementação (ver 6.8). Deste modo, através do CVnsferência de dados, a arquitetura paralela proposta, embora não seja
   promissora para sistemas distribuídos com rede convencionais, pode ser
   satisfatória em sistemas de memória compartilhada, uma vez que esses possuem
   uma velocidade muito maior na troca de mensagens. Para verificarmos sua
   performance em arquitetura com memória compartilhada, implementamos uma
   versão experimental do sistema com o CVMP memória compartilhada. Uma vez
   273
   CAPÍTULO 7
   que não dispúnhamos de uma máquina com múltiplos processadores, realizamos a
   simulação utilizando a característica de multitarefa do sistema operacional. As
   medidas foram feitas com cautela, para não beneficiar a arquitetura compartilhada.
   Em algumas situações optamos para que a simulação não se beneficiasse de
   algumas vantagens dessa arquitetura, concluindo portanto que num sistema real
   podemos realizar uma implementação com algumas otimizações.
   4.0
   (a)
   (b)
   6
   3.5
   3.0
   5
   p
   2.5
   Up
   4
   Ud
   2.0
   ed
   3
   ee
   1.5
   Spe
   Sp 2
PA 1.0
   0.5
   1
   0.0
   0
   128x128
   256x256
   512x512
   1024x1024 2048x2048
   128x128
   256x256
   512x512
   1024x1024 2048x2048
   Fig. 7.20 - Gráficos da taxa de desempenho ou speed-up em função do
   tamanho da imagem. Simulação de uma arquitetura de memória
   compartilhada de 4 processadores equivalentes a AMD K6-2 375 MHz. (a)
   Desempenho memória compartilhada frente a versão seqüencial. (b)
   Desempenho da memória compartilhada frente ao melhor caso da arquitetura
   distribuída (RAM + LZW).
   A Figura 7.20 apresenta os resultados da simulação. Nela temos o gráfico
   da taxa de desempenho ou speed up do sistema paralelo com quatro
   processadores de 375 MHz e memória compartilhada. Como podemos constatar,
   eliminando a transferência de dados via rede e o custo dos algoritmos de
   compactação de dados (LZW), o sistema obteve uma grande melhora de
   performance. No gráfico 7.20a temos a taxa de desempenho da arquitetura
   compartilhada em função da versão seqüencial. A performance foi muito superior
   aos sistemas distribuídos, chegando a quase 3.5 de speed up, o que viabiliza a
   utilização da versão paralela. O gráfico 7.20b mostra a taxa de desempenho da
   arquitetura compartilhada frente ao melhor caso da arquitetura distribuída, ou seja o
   caso iv (RAM + LZW), nele podemos observar que a implementação paralela em
   arquitetura compartilhada ficou entre 2,5 a 6 vezes mais rápida que a
   implementação em sistema distribuído.
   274
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   7.5 - TRANSFORMADA DE HOUGH
   Inicialmente elaborada para calcular a trajetória de partículas em câmaras
   de bolhas [Hough. 1959], a transformada de Hough se tornou uma ferramenta
   tradicional em análise de imagens para o reconhecimento de padrões globais. A
   idéia básica da técnica consiste em encontrar curvas que podem ser
   parametrizadas, tais como segmentos de reta, polinômios, círculos, elipses e etc.,
   em um espaço de parâmetros (arranjo acumulador). Embora possa ser utilizada em
   dimensões maiores, sua principal utilização consiste na localização de padrões em
   duas dimensões [Schalkoff, 1989] [Duda & Hart, 1972].
   Dentre os padrões globais disponíveis para a transformada de Hough, o
   mais amplamente difundido e utilizado é o segmento de reta (provavelmente devido
   a importância dessa modalidade em visão e processamento de imagens), sendo
   muitas vezes generalizada à transformada de Hough como uma técnica de
   detecção de retas. Nesta seção vamos nos concentrar apenas nessa modalidade
   da transformada de Hough.
   Os segmentos de reta encontrados em uma imagem podem ser
PA parametrizados como:
   = x cos + y sen
   (7.12)
   onde é a distância perpendicular até a origem e o ângulo com sua normal
   (Figura 7.21). Deste modo, os pontos co-lineares (xi,yi), onde i varia de 1 a N, são
   transformados em N curvas senoidais
   = x cos + y sen
   (7.12)
   i
   i
   no plano ( , ), que se intersecionam no ponto ( , ), conforme podemos observar
   na Figura 7.21.
   275
   CAPÍTULO 7
   (a)
   (b)
   Fig. 7.21 - Demonstração dos principais elementos envolvidos na
   parametrização de retas para a transformada de Hough. (a) Espaço de
   coordenadas original. (b) Espaço de Hough.
   O plano ( , ), é parametrizado em uma estrutura conhecida como arranjo
   acumulador. Trata-se de uma matriz cujas linhas e colunas são parametrizadas em
   função de e , onde para cada ponto do plano original são incrementados os
   elementos correspondentes a curva senoidal dada por (7.12). Assim, as retas ou os
   pontos colineares da imagem, se apresentam na forma de picos no arranjo
   acumulador, sendo caracterizados como máximos locais. A Figura 7.22 apresenta
   uma imagem com o seu respectivo espaço de Hough.
   (a)
   (c)
   (b)
   Fig. 7.22 - Detecção de retas através da transformada de Hough. (a) Imagem
   original, (b) Arranjo acumulador (espaço de Hough) e (c) Retas detectadas
   (com backmapping ).
   Cada ponto da imagem, corresponde a uma curva senoidal no espaço de
   Hough, que parametrizada incrementa o espaço acumulador, permitindo na técnica,
   ser processado isoladamente. Deste modo, a transformada de Hough pode ser
   entendida como uma série de operações locais, já que não ocorre dependência de
   276
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   dados entre os elementos da imagem. Baseado nisso, podemos paralelizar o
   algoritmo através da divisão da imagem original, ficando cada elemento de
   processamento responsável por um fragmento, onde no final do processamento o
   arranjo acumulador de cada unidade de processamento deverá ser somado
   constituindo o arranjo acumulador resultante da transformada. Informações
   adicionais sobre estratégias de paralelismo na transformada de Hough podem ser
   encontrados em [Guil & Zapata, 1997] e [Thazhuthaveetil & Shah, 1991].
   A Figura 7.23 exibe um diagrama que ilustra essa arquitetura para quatro
   unidades de processamento, onde a imagem é dividida em 4 e enviada para cada
   processador. Cada fragmento da imagem é então processado, gerando o seu
   respectivo espaço de Hough, parametrizado em um arranjo acumulador. No final,
   os elementos dos arranjos acumulador correspondentes a cada porção da imagem
PA são somados, gerando o resultado final.
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   I
   II
   III
   IV
   V
   VI
   Fig. - 7.23 – Estratégia de paralelismo para a transformada de Hough. As
   etapas I, II, III, IV, V e VI representam respectivamente: a imagem original,
   divisão da imagem e sua distribuição, processamento de cada fragmento da
   imagem, arranjos acumulador resultante do processamento de cada
   fragmento, somatório dos elementos dos arranjos acumulador e arranjo
   acumulador resultante.
   Implementamos versões do sistema, com 2, 3 e 4 unidades de
   processamento diferentes. A Figura 7.24 mostra um exemplo do diagrama de fluxo
   de dados e execução para a versão com quatro processadores, nela temos um
   277
   CAPÍTULO 7
   processo mestre e quatro escravos, onde cada processo está alojado em uma
   unidade de processamento distinta. O mestre é responsável pela divisão da
   imagem principal, e sua distribuição para as máquinas escravas, que juntamente
   com o mestre irão processar um dos fragmentos da imagem. Após o término da
   execução os arranjos acumuladores, resultantes do processamento, são enviados à
   máquina mestra, que realizará o somatório dos elementos de cada arranjo,
   constituindo desse modo a resultado final.
   Adotamos os arranjos acumuladores com dimensões equivalentes às
   imagens. Desta maneira, eles foram parametrizados de forma a possuir um número
   de elementos muito próximo ao número de pixels da imagem. Usualmente a
   transformada de Hough é aplicada sobre imagens binárias resultantes de detecções
   de bordas, portanto empregamos imagens de 1 bit de profundidade como entrada
   do sistema, diminuindo assim o tráfego de mensagens. Para as matrizes que
   armazenam os arranjos acumulador, adotamos o tipo de variável word, que
   apresenta dois bytes para o armazenamento, de modo que o arranjo acumulador
   ocupa uma memória de cerca de 16 vezes o tamanho das imagens
   correspondentes.
   Além de versões para diferentes quantidades de elementos de
   processamento, vamos apresentar o desempenho para diferentes modalidades de
   arquitetura que obedecem à mesma estratégia de paralelização: (i) sistema
   distribuído com rede ethernet de 10 Mb/s, (i ) sistema distribuído com rede fast
   ethernet de 100 Mb/s e (i i) sistema memória compartilhada.
   Todas as modalidades de sistemas foram implementadas utilizando
   processadores AMD K6 II com 375 MHz. O sistema de memória compartilhada foi
   simulado.
   Fig. - 7.24 - Diagrama ilustrando as trocas de mensagem e o balanceamento
   de carga do sistema.
PA 278
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   A Figura 7.25 apresenta três gráficos, com os tempos de execução dos
   sistemas em função do número de processadores. Cada um dos gráficos é
   referente a um tamanho de imagem utilizada no experimento (250x250, 500x500 e
   750x750 pixels). Diferente do que seria previsível, o tempo de execução da
   modalidade sistema distribuído de 10 Mb/s, ao invés de diminuir aumenta, à medida
   que o sistema é acrescido de unidades de processamento. Isso pode ser observado
   nos gráficos referentes as imagens de 250x250 e 500x500 pixels, ao passo que
   essa situação não ocorre nas imagens de 750x750 pixels. Esse fato é explicado
   pelo gargalo da transferência de dados. Conforme é apresentado na Figura 7.23,
   enquanto a imagem é dividida e distribuída para as unidades de processamento, o
   mesmo não ocorre com o arranjo acumulador. Embora as máquinas processem
   apenas um fragmento da imagem, o resultado obtido é um arranjo acumulador não
   fragmentado, ou seja, com a mesma dimensão da versão seqüencial. Com isso, as
   mensagens a serem retornadas para a máquina mestra, aumentam
   proporcionalmente ao número de processadores escravos, uma vez que não se
   fragmentam.
   250x250
   500x500
   750x750
   1200
   5000
   50000
   1000
   4000
   40000
   s)
   s)
   s)
   800
   (m
   (m 3000
   30000
   o
   (m
   600
   p
   o
   po
   p
   m
   2000
   m 20000
   te 400
   tem
   te
   200
   1000
   10000
PA 0
   0
   0
   1
   2
   3
   4
   1
   2
   3
   4
   1
   2
   3
   4
   n. de processadores
   n. de processadores
   n. de processadores
   Seqüencial
   Sistema distribuído (rede 10 Mb/s)
   Sistema distribuído (rede 100 Mb/s)
   Memória compartilhada
   Fig. - 7.25 - Gráficos do tempo de execução em função do número de
   processadores, com suas respectivas modalidades de implementação. Cada
   gráfico é definido mediante um tamanho de imagem.
   Embora ocorra uma situação semelhante com as outras modalidades, essa
   situação não é observada de forma tão nítida, devido ao fato do gargalo de
   transferência estar reduzido em relação ao sistema distribuído de 10 Mb/s. O
   mesmo fato ocorre nesse sistema no processamento de imagens de 750x750
   pixels, uma que o tempo de processamento aumenta consideravelmente em
   279
   CAPÍTULO 7
   relação ao tempo de transferência, fazendo com que o gargalo diminua.
   100
   100
   l
   100
   80
   80
   ciona
   80
   putacional
   putacional
   m 60
   puta 60
   m
   m 60
   40
   40
   40
PA recurso co 20
   20
   recurso co
   recurso co 20
   250x250
   %
   %
   %
   0
   0
   0
   a
   b
   c
   a
   b
   c
   a
   b
   c
   100
   l 100
   l 100
   80
   80
   80
   putacional
   putaciona
   putaciona
   m 60
   60
   60
   40
   40
   rso com
   40
   rso com
   recurso co 20
   recu 20
   recu 20
   %
   %
   %
   500x500
   0
   0
   0
   a
   b
   c
PA a
   b
   c
   a
   b
   c
   l
   l 100
   100
   100
   80
   80
   80
   taciona
   putaciona
   pu
   putacional
   60
   60
   m
   m 60
   40
   40
   rso com
   40
   rso co
   20
   recu 20
   recu
   recurso co 20
   750x750
   %
   %
   %
   0
   0
   0
   a
   b
   c
   a
   b
   c
   a
   b
   c
   2
   3
   4
   a Sistema distribuído (rede 10 Mb/s)
PA Proc. relacionado a transf. de dados
   b Sistema distribuído (rede 100 Mb/s)
   c Memória compartilhada
   Processamento Hough
   Fig. - 7.26 - Porcentagem da utilização de recursos computacionais entre o
   processamento da técnica e os processos relacionados com as
   transferências de dados. As linhas horizontais contém os gráficos
   relacionados ao tamanho da imagem, enquanto que as linhas verticais os
   números de processadores.
   A Figura 7.26 apresenta a porcentagem entre o tempo gasto com o
   processamento da técnica e com os procedimentos relacionados com as trocas de
   mensagens. Nela podemos observar a situação descrita anteriormente, que fica
   bem nítida com os sistemas distribuídos de 10Mb/s. Como podemos observar a
   porcentagem relativa ao tempo gasto com a troca de mensagem se torna maior a
   medida que aumentam os processadores. Com isso podemos concluir que essa
   arquitetura não favorece a utilização de sistemas massivamente paralelos, já que o
   aumento no número de processadores resulta igualmente num aumento do volume
   de mensagens, que deverá atingir um limite nos sistemas distribuídos de 100 Mb/s
   280
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   semelhante ao dos sistemas de 10 Mb/s a partir de um determinado número de
   processadores.
   As taxas de desempenho ou speed-up dos sistemas são mostradas nos
   gráficos da Figura 7.27. Através deles são determinadas as performances de cada
   modalidade frente à versão seqüencial. Conforme podemos observar, a arquitetura
   apresentou um bom desempenho para diferentes quantidades de unidades de
   processamento, com exceção dos sistemas distribuídos baseados em redes de
   ethernet de 10 Mb/s, que apresentaram uma performance pequena para as
   imagens de 250x250 e 500x500 pixels, especialmente com 3 ou 4 processadores.
   250x250
   500x500
   750x750
   4.0
   4.0
   4.0
   3.5
   3.5
   3.5
   3.0
   3.0
   3.0
   Up 2.5
   up 2.5
   up 2.5
   d 2.0
   d 2.0
   d 2.0
   ee
   ee
   ee
PA 1.5
   Sp
   1.5
   Sp
   1.5
   Sp
   1.0
   1.0
   1.0
   0.5
   0.5
   0.5
   0.0
   0.0
   0.0
   2
   3
   4
   2
   3
   4
   2
   3
   4
   n. de processadores
   n. de processadores
   n. de processadores
   Sistema distribuído (rede 10 Mb/s)
   Sistema distribuído (rede 100 Mb/s)
   Memória compartilhada
   Fig. - 7.27 - Gráficos da taxa de desempenho ou speed up em função do
   número de processadores. Os gráficos apresentam as três modalidades
   implementadas no experimento. Cada gráfico é correspondente a um tamanho
   de imagem.
   Devido às baixas performances obtidas com os sistemas distribuídos
   baseados em ethernet, decidimos explorar alguns mecanismos que possibilitassem
   a diminuição da carga de mensagens e consequentemente a ampliação do gargalo,
   de modo a aumentar o desempenho. O maior gargalo encontrado no sistema, se
   encontra na transferência dos arranjos acumuladores dos processos escravos,
   resultantes do processamento de cada fragmento de imagem para o processo
   mestre, portanto a solução estaria na redução do tamanho dos arranjos
   acumulador. Na tentativa de reduzir o tamanho dos arranjos acumulador, adotamos
   duas estratégias: (i) compactação LZW e (ii) lista de picos.
   Na primeira estratégia, utilizamos o algoritmo de compactação de dados
   para diminuir o volume dos dados do arranjo antes de ser transmitido para o
   281
   CAPÍTULO 7
   processo mestre. Deste modo, embora seja acrescida uma carga computacional,
   devido ao processamento do algoritmo LZW [Nelson, 1989], esperamos que seu
   tempo de execução seja menor que o tempo de transferência do arranjo sem
PA compactação.
   Como sabemos, muitas das informações contidas no arranjo acumulador
   não são utilizadas pelas maiorias das aplicações (detecção de retas), deste modo,
   os interesses estão concentrados nos picos, que caracterizam os maiores conjuntos
   de pontos colineares, ou seja, as retas da imagem. Considerando essa abordagem,
   elaboramos a segunda estratégia, que consiste na criação de uma lista ou vetor
   contendo as coordenadas do plano de Hough e seu conteúdo apenas as células
   que ultrapassam um determinado valor (limiar). Não exploramos as heurísticas para
   a determinação do limiar, no entanto este foi definido como a décima quinta parte
   do maior elemento do arranjo.
   A Figura 7.28 apresenta comparações entre as duas estratégias frente à
   versão experimentada nesta seção. Nela temos o tempo de execução da versão de
   4 máquinas conectadas via ethernet. Como podemos observar, as duas alternativas
   que utilizamos para a redução dos gargalos tiveram um bom resultado, aumentando
   consideravelmente a performance comprometida da transformada de Hough
   distribuída em rede ethernet 10 Mb/s.
   250x250
   500x500
   750x750
   20000
   1000
   4000
   800
   s)
   3000
   s)
   15000
   s)
   m
   m
   ( 600
   (
   o
   (m
   o
   p
   op 2000
   10000
   p
   m 400
   m
   m
   te
   te
   te
   1000
   5000
   200
   0
   0
PA 0
   a
   b
   c
   a
   b
   c
   a
   b
   c
   Convencional
   Compactação - LZW
   Lista de picos
   Fig. - 7.28 - Gráficos apresentando o tempo de execução relacionados com o
   tamanho da imagem, apresentando uma comparação entre as diferentes
   versões de implementação paralela para os sistemas distribuídos com rede
   ethernet 10 Mb/s.
   282
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   250x250
   500x500
   750x750
   l
   l
   l
   a 100
   a 100
   a 100
   90
   90
   90
   80
   tacion
   80
   tacion
   80
   tacion
   u 70
   u 70
   u 70
   mp 60
   mp 60
   mp 60
   o
   o
   o
   50
   50
   50
   40
PA 40
   40
   30
   30
   30
   ecurso c 20
   ecurso c 20
   ecurso c 20
   % r 10
   % r 10
   % r 10
   0
   0
   0
   a
   b
   c
   a
   b
   c
   a
   b
   c
   Processamento Hough
   Proc. relacionado a transf. de dados
   Fig. - 7.29 - Porcentagem da utilização de recursos computacionais entre o
   processamento da técnica e os processos relacionados com as
   transferências de dados (e afins: compactação e lista de picos). (a) Sistema
   distribuído 10 Mb/s, (b) Sistema distribuído com compactação e (c) Sistema
   distribuído com lista de picos.
   O aumento de performance é explicado pela redução no volume dos dados
   a serem transferidos, como mostra a Figura 7.29. Embora as duas alternativas (i) e
   (ii) reduzam o volume dos arranjos acumulador com uma taxa próxima
   (aproximadamente 85% do tamanho original), a compactação por LZW (i) é
   computacionalmente mais custosa e a lista de picos (i ) apresentou um melhor
   desempenho do sistema distribuído. A Figura 7.30 apresenta as taxas de
   desempenho ou speed-up, comparando as implementações paralelas.
   Embora a lista de picos (i ) tenha apresentado um resultado melhor na
   eliminação dos gargalos, e consequentemente na performance, devido à redução
   dos dados do arranjo acumulador; essa alternativa não pode ser utilizada pela
   totalidade das aplicações da transformada, uma vez que algumas destas podem
   envolver uma exploração maior dos dados presentes no arranjo acumulador. A
   compactação por LZW, entretanto, não altera o conteúdo do arranjo acumulador,
   permitindo portanto sua utilização em toda a gama de aplicações, uma vez que
   apresenta resultado idêntico ao da transformada de Hough.
   Apresentamos nesta seção algumas estratégias e implementações para a
   transformada de Hough paralela enfocando a detecção de retas. No entanto, estas
   podem ser estendidas para outras curvas parametrizadas no espaço de Hough,
   mediante algumas adaptações.
   283
PA CAPÍTULO 7
   250x250
   500x500
   750x750
   4
   4
   4
   3
   3
   3
   p
   p
   d u
   d u
   2
   2
   2
   eed up
   ee
   ee
   p
   p
   Sp
   S
   S
   1
   1
   1
   0
   0
   0
   a
   b
   c
   a
   b
   c
   a
   b
   c
   Convencional
   Compactação - LZW
   Lista de picos
   Fig. - 7.30 - Gráficos da taxa de desempenho ou speed up. Cada gráfico é
   correspondente a um tamanho de imagem.
   7.5.1 - RASTREAMENTO DO ARRANJO ACUMULADOR
   (BACKMAPPING)
   Um grande problema na transformada de Hough se encontra na localização
   dos picos do arranjo acumulador, uma vez que estes correspondem às curvas as
   quais a técnica espera detectar realmente. A grande dificuldade reside na
PA característica local de cada pico, sendo este um problema ainda não resolvido por
   completo pela ciência. Devido às limitações no processo de localização dos picos
   locais, como resultado da transformada podem ser apresentadas diversas falsas
   curvas, provocadas pela interferência de pontos colineares entre diferentes curvas,
   entre segmentos com poucos pixels e até mesmo o ruído presente na imagem.
   Um avanço na direção da solução desse problema foi publicado em 1986
   por Gerig e Klein [Gerig & Klein, 1986], que introduziram um passo adicional à
   transformada de Hough, denominado de backmapping (rastreamento). A técnica de
   backmapping consiste na criação de um novo arranjo acumulador, onde a
   transformada é novamente calculada para cada ponto da imagem. Para este novo
   espaço, contudo, somente são computadas as células que correspondem aos
   valores máximos de cada uma das senóides do arranjo original. Deste modo, essa
   abordagem corresponde a um reforço aplicado à transformada de Hough, na
   tentativa de localizar os picos locais e reduzir os picos causados pelos pontos
   284
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   colineares de curvas distintas, ruídos, interferência entre objetos e segmentos com
   poucos pontos.
   Devido ao novo cálculo da transformada aliado a buscas contínuas de
   pontos máximos para as curvas do espaço de Hough, correspondentes a cada
   ponto da imagem, essa técnica é bastante dispendiosa, consumindo grande poder
   computacional, motivando portanto seu paralelismo.
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   ( , )
   backmapping
   ( , )
   ( , )
   ( , )
   I
   II
   III
   IV
   Fig. - 7.31 – Estratégia de paralelismo para a técnica de rastreamento
   (backmapping) , para quatro unidades de processamento. I - Divisão da
   imagem e distribuição dos fragmentos, II - Distribuição do arranjo acumulador
   resultante da transformada de Hough, III - Processamento do backmapping a
   partir dos dados dos fragmentos da imagem e do arranjo acumulador , IV -
   transmissão do arranjo acumulador gerado pelo rastreamento para o
   processo mestre, onde os elementos de cada arranjo serão somados
   constituindo o resultado da técnica.
   Através de algumas adaptações à estratégia de paralelismo apresentada na
PA Figura 7.23, desenvolvemos uma estratégia para paralelizar o algoritmo de
   rastreamento ( backmapping). Podendo ou não ser utilizada em conjunto com a
   versão paralela da transformada de Hough, descrita em 7.5, o paralelismo da
   técnica de rastreamento consiste basicamente na distribuição do arranjo
   acumulador, obtido na transformada de Hough para os processos envolvidos na
   computação, e na fragmentação da imagem original, e sua distribuição, ou no caso
   da transformada de Hough paralela, na utilização dos fragmentos da imagem
   original já processada. A Figura 7.31 exibe um diagrama contendo as definições
   285
   CAPÍTULO 7
   para paralelização da técnica para quatro elementos de processamento, que pode
   ser expandida facilmente. Após serem distribuídos os fragmentos da imagem (fig.
   31 - I) e distribuídos os resultados da transformada de Hough para os elementos de
   processamento, são então realizadas o processamento do rastreamento
   simultaneamente para cada um dos fragmentos da imagem, produzindo um novo
   arranjo acumulador. Assim como na versão paralela da transformada de Hough, os
   arranjos são transmitidos para a unidade mestre, através do somatório deste
   constituíra o resultado final.
   Implementamos a versão paralela da técnica utilizando sistema distribuído
   em rede ethernet de 10 Mb/s, com quatro máquinas possuindo processadores
   semelhantes AMD K6 II - 375 MHz. A Figura 7.32 apresenta o tempo de
   processamento da versão seqüencial e das paralelas para dois tamanhos de
   imagem diferentes (250x250 e 500x500 pixels).
   250x250
   500x500
   25000
   100000
   20000
   s)
   s) 80000
   (m 15000
   (m
   po
   60000
   po
   10000
   tem
   tem 40000
   5000
   20000
   0
   0
   1
   2
   3
   4
   1
   2
   3
   4
PA n. de processadores
   n. de processadores
   Fig. - 7.32 - Gráficos do tempo de execução em função do número de
   processadores.
   Na Figura 7.33 temos os gráficos da porcentagem de utilização de recursos
   computacionais entre o processamento referente à técnica backmapping e aos
   processos relacionados com as transferências de dados. Embora possua um fluxo
   de dados muito maior do que a transformada de Hough, a porcentagem de recursos
   gastos com a transferência dos dados é menor. Já a técnica de backmapping é
   mais dispendiosa que a transformada de Hough, uma vez que além de conter os
   mesmos cálculos necessários da transformada, são realizados operações para
   obtenção dos pontos de máximo valor do arranjo acumulador para cada ponto
   analisado da imagem. Devido ao grande poder computacional requerido pelos
   cálculos, a transferência de dados não se torna um gargalo crítico para as versões
   paralelas.
   286
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   250x250
   500x500
   l 100
   l 100
   ciona 80
   ciona
   ta
   80
   ta
   pu
   pu
   m 60
   m 60
   co
   co
   o 40
   o
   rs
   40
   rs
   recu 20
   recu 20
   %
   %
   0
   0
   2
   3
   4
   2
   3
   4
   n. de processadores
PA n. de processadores
   Proc. técnica Backmapping
   Proc. relacionado a transf. de dados
   Fig. - 7.33 - Porcentagem da utilização de recursos computacionais entre o
   processamento da técnica e os processos relacionados com as
   transferências de dados.
   A porcentagem de recursos gastos com a transferência de dados,
   entretanto, vai aumentando proporcionalmente com o número de processos
   (processadores), uma vez que os arranjos acumuladores não são fragmentados.
   Com isso, embora a performance aumente com o acréscimo de elementos de
   processamento no sistema, aumenta também o gargalo, de modo que a razão entre
   o número de processadores e o ganho de performance diminua. Na Figura 7.34 são
   apresentados os gráficos de taxa de desempenho ou speed-up em função do
   número de processadores.
   250x250
   500x500
   4.0
   4.0
   3.5
   3.5
   3.0
   3.0
   up 2.5
   up 2.5
   d
   d
   2.0
   ee
   2.0
   ee
   1.5
   Sp
   1.5
   Sp
   1.0
   1.0
   0.5
   0.5
   0.0
   0.0
   2
   3
   4
   2
   3
   4
   n. de processadores
   n. de processadores
   Fig. - 7.34 - Taxa de desempenho em função do número de processadores.
   .
PA 287
   CAPÍTULO 7
   7.6 - RESTAURAÇÃO DE IMAGENS BASEADO EM
   CAMPOS RANDÔMICOS MARKOVIANOS
   Uma aplicação bastante comum em processamento de imagens é a
   eliminação de ruídos de uma imagem. Diversos fatores, tais como interferência em
   sistemas de aquisição de imagem, ruído em sistemas de comunicação, sistemas de
   imagem por satélite, sistema de aquisição de imagens médicas (ultra-som), etc.,
   podem ocasionar a adição de ruídos a imagem, de forma a poluí-la. Os algoritmos
   de restauração de imagens são técnicas que permitem a redução do ruído ou em
   alguns casos até mesmo sua completa eliminação.
   Nesta seção vamos apresentar a paralelização do algoritmo de restauração
   de imagens baseado em campos aleatórios de Markov, desenvolvido no decorrer
   deste doutorado. A nova técnica [Bruno & Costa, 2000] consiste em uma
   modificação dos campos aleatórios de Gibbs operando no modo condicional
   iterativo (ICM) [Chellappa & Jain, 1993].
   A primeira abordagem da técnica classifica o campo aleatório de Markov
   como um caso específico da teoria da regularização [Poggio et al., 1985]. A
   regularização de um problema "il -posed" pode ser compreendida em termos da
   equação Az=y, onde z é a solução procurada, y é o dado original, e A é o operador linear. Uma possível solução consiste em achar z que minimiza ( z) na Equação
   7.12, onde ||P z|| é o estabilizador funcional.
   ( z) = Az y 2 + Pz 2
   (7.12)
   Enquanto o primeiro termo da Equação 7.12 expressa a discrepância entre
   os dados originais e a solução, o segundo termo indica o sucesso da solução z no
   critério de regularização expresso pelo operador P. Através de variações no
   parâmetro é possível controlar o grau de similaridade do dado original e do
   resultado do processo de regularização. Para a técnica de restauração de imagem
   P é considerado linear. Aplicando o conceito em termos práticos, a Equação 7.13
   ilustra essa situação com respeito a dois termos funcionais, onde ƒ (x,y) é a imagem
   original e g(x,y) é a solução procurada. O primeiro termo força a similaridade entre
   a imagem original e a imagem modificada, o segundo termo conhecido como
   "membrana", impõe um certo grau de "borramento", controlado pelo parâmetro ,
   288
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   sobre a solução esperada g(x,y).
   2
   F ( x, y)=
   f ( x, y) g( x, y)2 + 2. r g( x, y) dxdy (7.13)
   image
   Embora o conceito dos campos aleatórios de Markov (MRF) não seja novo,
   sua aplicação em processamento de imagem e visão computacional foi apenas
   recentemente explorada [Bruno & Costa, 2000]. Basicamente, os campos aleatórios
   de Markov, são extensões de grandes dimensões da clássica abordagem da cadeia
   de Markov. Deste modo, ele assume que o valor de um dado ponto da imagem é
   influenciado somente pelo seu vizinho imediato. Pelo estabelecimento de uma
   conexão entre os campos aleatórios de Markov (locais) e a distribuição de Gibbs
   (global) dada pela mecânica estatística, o teorema de Hammersley-Clifford permitiu
   um significado essencial para o cálculo das probabilidades das possíveis
   configurações em MRF [Li, 1995] [Kindermann and Snell, 1980] [Chellappa & Jain,
PA 1993]. Mais especificamente, a probabilidade de uma dada configuração (dentro de
   um conjunto finito de valores quantificados), freqüentemente parametrizados pelo
   decréscimo de temperatura, é fornecida pela probabilidade da densidade de massa
   da distribuição de Gibbs [Geman & Geman, 1984], que é determinada pela
   temperatura e pela energia definida pelos potenciais de cliques. Embora grandes
   vizinhanças sejam possíveis, aplicações em análise e processamento de imagem,
   tipicamente consideram cliques com conexões de 4 ou 8 vizinhos em torno do pixel.
   A abordagem MRF permite muitas possibilidades na incorporação de contextos ao
   processamento de imagens, provavelmente uma das mais típicas seja na
   restauração de imagens.
   Considerando que unir as distribuições em um MRF é uma tarefa
   particularmente complicada, uma abordagem alternativa denominada de modo
   condicional iterativo (ICM) foi proposta por Besag [Besag, 1986]. Duas hipóteses
   são assumidas no ICM: (i) as observações di são independentes e cada observação
   possui a mesma densidade condicional conhecida p(di|ƒ i), que depende somente de
   ƒ i; e (i ) cada rótulo depende somente de um rótulo vizinho. A Equação 7.14
   apresenta um critério simplificado de classificação que consiste na maximização da
   probabilidade, onde S é o conjunto de sítios e N i são as vizinhanças no sítio i [Li,
   1995].
   289
   CAPÍTULO 7
   P( f | d, f
   p d | f . P f | f
   (7.14)
   i
   S i )
   ( i i) ( i N )
   { }
   i
   A técnica assume que as imagens binárias foram corrompidas por ruído
   Gaussiano, com um pos no espaço.
   Fig. - 8.2 - Modelo de arestas dos objetos que constituem o universo de
   reconhecimento do sistema (cubo, tetraedro e prisma).
   O módulo de reconhecimento faz uso de uma base de dados contendo os
   modelos dos objetos, que correspondem a um conjunto de segmentos de retas
   310
   APLICAÇÕES PARALELAS EM VISÃO
   contendo extremidades especificadas por coordenadas tridimensionais. O sistema
   de busca e reconhecimento é realizado mediante a comparação dos modelos da
   base de dados frente às informações extraídas da cena. A identificação do objeto
   se faz através de uma verificação exaustiva, que visa emparelhar o modelo da cena
   com o da base de dados. As escalas das descrições dos objetos não são
   consideradas, uma vez que ocorre a normalização dos segmentos antes do início
   da comparação. O emparelhamento é realizado mediante rotações e translações do
   modelo da base, a fim de possibilitar a identificação dos objetos tridimensionais
   para qualquer posicionamento espacial. Para cada emparelhamento, um erro geral
   é calculado, o qual será descrito na Seção 8.2.3. Com base nesse cálculo é
   realizado o reconhecimento do objeto.
   Fig. - 8.3 - Exemplos de cenas reais, nas quais o sistema realizou a
   identificação dos objetos [Moreira, 1999].
   A cena na qual os objetos são posicionados é real, contendo em muitas
   situações um grande número de segmentos de retas detectáveis que não
PA pertencem aos objetos (fundo de cena), ou ainda pertencentes a outros objetos
   posicionados na cena, que não fazem parte do universo de reconhecimento. Podem
   ocorrer ainda situações em que surgem alguns segmentos de retas pertencentes
   aos objetos de reconhecimento, que não satisfazem o modelo de reconhecimento
   poliédrico. Através de comparações com o modelo e limites de erro, o sistema
   elimina as informações indesejáveis, desconsiderando-as, permitindo assim a
   criação de um modelo poliédrico e o reconhecimento de objetos em cenas reais e
   complexas. A Figura 8.3 apresenta algumas imagens adquiridas pelo sistema, na
   311
   CAPÍTULO 8
   qual podemos observar a complexidade da cena.
   8.2.1.6 - CONTROLE GERAL
   O módulo controle geral é responsável pela supervisão dos demais
   módulos, assim como pelo controle do fluxo de informações. Toda a comunicação
   entre módulos é realizada pelo controle central. Conforme podemos observar na
   Figura 8.1, não existe conexão entre módulos que não passem pelo controle
   central. Todas as decisões, seqüências de operações, ciclo de execução e controle
   de dependência de dados do sistema são realizados sob a sua determinação, de
   modo que os demais módulos podem ser considerados como escravos ao seu
   comando. Deste modo o controle central promove a hierarquia e integração dos
   módulos que compõem o sistema.
   8.2.2 - CRITÉRIO DE AVALIAÇÃO
   Nesta seção vamos descrever o critério de avaliação utilizado para a
   realização do reconhecimento dos objetos. Implementado no módulo de
   reconhecimento, o critério de avaliação realiza a comparação entre o modelo do
   objeto, ou seja, o modelo retirado das imagens adquiridas pelos sistemas e o
   modelo da base de dados. O reconhecimento ocorre quando a discrepância entre
   os modelos, determinada pelo cálculo de erro, é a menor dentre as comparações
   com os modelos da base ou ainda se o erro for menor que um determinado limite
   pré-estipulado. O cálculo do erro é estabelecido pelo erro médio quadrático entre as
   distâncias das extremidades correspondentes de todos os segmentos
   emparelhados do modelo do objeto da imagem e da base de dados. A Equação 8.1
   apresenta o cálculo de erro, onde N indica o número de extremidades de
   segmentos, moi e mbi representam os pontos conjugados no espaço do modelo
   objeto da imagem e do modelo da base, respectivamente, e D( ) é a função de
   distância euclidiana.
   N
   1
   =
   D( mo , mb 2
   )
   (8.1)
   q
   [
   i
   i ]
   N i=1
   Embora o cálculo do erro estabeleça uma metodologia objetiva de
   comparação entre os modelos, existem algumas situações em que o cálculo do erro
   312
PA APLICAÇÕES PARALELAS EM VISÃO
   não é capaz de reconhecer os objetos com precisão, sendo necessário adicionar
   outras considerações ao critério de avaliação. Uma dessas situações ocorre devido
   à similaridade entre os objetos do universo de classificação. Como podemos
   observar na Figura 8.2, tanto o tetraedro como o prisma podem ser consideradas
   como objetos poliédricos formados a partir de cortes planares em cubos. Se
   tomarmos um cubo e fizermos um corte por um plano que passa por arestas
   opostas, teremos como resultado um prisma, assim como se o plano passar por
   três vértices não compartilhados pela mesma face e que não contenha uma
   diagonal, teremos um tetraedro.
   Deste modo se o analisador de formas detectar somente três segmentos de
   reta, conforme apresentado na Figura 8.4, e se utilizarmos esse modelo
   diretamente no emparelhamento e testarmos a seguir o critério de avaliação através
   do cálculo de erro, podem ocorrer falsos reconhecimentos devido à similaridade
   entre os vértices. Nesta situação, o erro médio quadrático q seria muito próximo,
   praticamente idêntico, impossibilitando um reconhecimento eficaz.
   Fig. - 8.4 - Modelo de arestas dos objetos que constituem o universo de
   reconhecimento do sistema (cubo, tetraedro e prisma).
   Para solucionar este problema, foi introduzida uma semântica na qual é
   ponderado o número de segmentos detectados como peso adicional ao critério de
   avaliação. Deste modo, é considerado o número total de arestas visíveis ao invés
   do total de arestas. O número total de arestas visíveis para os poliedros que
   constituem o universo de reconhecimento é de 9, 6 e 8 respectivamente para o
   cubo, tetraedro e prisma.
   N
   N
   v
   o
   = k
   (8.2)
   e
   Nv
   Com base nesse novo contexto, foi introduzido o erro relativo ao
   313
   CAPÍTULO 8
   emparelhamento de bordas, conforme indicado na Equação 8.2, onde Nv e No
   indicam, respectivamente, o número de arestas visíveis do modelo e o número de
   arestas (segmentos) da imagem que foram emparelhados. O fator k é um fator de
   correção da magnitude do erro, para que tenha a mesma variação máxima que o
   erro quadrático médio q. O erro e estabelece a razão entre a falha no
   emparelhamento esperado (número de arestas visíveis não relacionadas a arestas
   da imagem) e a expectativa inicial (número de arestas visíveis).
   = h + 1
   (
   h)
   (8.3)
   q
   e
   O erro total, definido pela Equação 8.3, consiste na ponderação entre os
   erros q e e, através do parâmetro h. O erro permite a distinção entre os modelos
PA de objetos da base de dados e o modelo do objeto das imagens a ser reconhecido,
   caracterizando desse modo o critério de avaliação do módulo de reconhecimento
   de objetos.
   8.2.3 - FUNCIONAMENTO GERAL E RESULTADOS
   O sistema é constituído de 6 módulos autônomos e independentes,
   distribuídos pelas máquinas que compõe a rede. Usualmente, uma máquina aloja
   mais de um módulo. Nos experimentos realizados no laboratório utilizou-se
   geralmente três máquinas compor o sistema. Nesta configuração uma das
   máquinas aloja somente o módulo de aquisição, o qual necessita de hardware
   especial (aquisição de imagens), enquanto que os módulos de cor, forma e controle
   partilham a segunda máquina e os demais módulos, ou seja, estéreo e
   reconhecimento, utilizam a máquina restante.
   Embora o sistema apresente arquitetura e estrutura paralela, havendo
   autonomia e independência entre os módulos que o compõe, o paralelismo foi
   utilizado para integração, não tendo sido especificamente exploradas as
   possibilidades de aumento de performance. Deste modo, o sistema apresenta uma
   cadeia de execução seqüencial. Supervisionados pelo controle geral, os módulos
   vão sendo executados um após o outro seguindo um determinado fluxo de
   314
   APLICAÇÕES PARALELAS EM VISÃO
   execução. O ciclo inicia-se com a aquisição dos pares de imagem. Para isso o
   módulo de controle solicita ao módulo de aquisição que cumpra sua tarefa
   preestabelecida, ou seja, efetuar a aquisição do par de imagens através das duas
   câmeras do sistema.
   Uma vez realizada a aquisição das imagens, o controle central solicita ao
   módulo cor que realize a segmentação de uma das imagens do par estéreo. Como
   resultado da segmentação por cor é produzido um mapa de bordas da imagem,
   através da classificação da imagem pelo método dos mapas auto-organizáveis
   [Moreira, 1999]. Para as configurações dos mapas auto-organizáveis foi adotado:
   mapas de dimensões 32x32, vizinhança circular inicial com raio de 25,6
   (equivalente a 80% da dimensão do mapa), taxa de aprendizado inicial de 60%,
   taxas de decaimento de 0,05% para o aprendizado e para o raio da vizinhança e foi
   adotado um erro de 10-4 estipulado para a verificação da convergência [Moreira,
   1999]. A Figura 8.5 apresenta os resultados de segmentação do módulo cor, em
   comparação com clássico método de gradiente Sobel [Sobel, 1970], nela temos
   uma das imagens do par estéreo, adquirido pelo sistema (esquerda), com o
   respectivo resultado de segmentação pelo método dos mapas auto-organizáveis
   (centro) e Sobel (direita).
   (a)
   (b)
   (c)
   Fig. - 8.5 - Exemplos de segmentação do módulo cor. (a) Imagem direita do
   par estéreo, adquirida pelo módulo de aquisição. (b) Resultado da
   segmentação do módulo cor (Mapas auto-organizáveis). (c) Segmentação por
   Sobel com finalidade comparativa.
   Uma vez gerado o mapa de bordas pela segmentação do módulo de cor, o
   315
   CAPÍTULO 8
   módulo de controle envia uma mensagem para o módulo de análise de formas,
   para este que o processe. Baseado na transformada de Hough e backmapping, o
PA módulo de análise de formas tem como função extrair os segmentos de retas da
   imagem. A Figura 8.6 contém os segmentos detectados para uma mesma cena,
   sob diferentes pontos de vista.
   Fig. - 8.6 - Segmentos de retas detectados em diferentes pontos de vistas de
   uma mesma cena (figura a esquerda).
   A próxima etapa do ciclo de execução do sistema é a tarefa do módulo
   estéreo. Finalizada a análise de formas, o módulo de controle geral solicita que o
   módulo estéreo inicie o processamento, que consiste basicamente na determinação
   da profundidade das extremidades dos segmentos de reta detectados. Através das
   coordenadas das extremidades dos segmentos de retas, o módulo estéreo localiza
   o conjugado e pelo cálculo de disparidade é determinada sua profundidade. A
   determinação da profundidade, entretanto, não é sempre possível, devido a fatores
   como as diferenças de perspectiva, que causam oclusões parciais, ou introduzem
   reflexos diferenciados e a imprecisão dos segmentos, além de reflexos nas cores e
   determinadas sombras, que acarretam em imprecisões no mapa de bordas.
   Estas situações fazem com que as bordas e os segmentos detectados não
   fiquem precisamente localizados nas posições reais dos objetos. Desse modo, as
   coordenadas das extremidades dos segmentos podem coincidir com o a base ou
   com o fundo da cena. Deste modo o valor da profundidade calculado se torna
   relativo ao fundo da cena ou sua base, deturpando as dimensões e posições dos
   objetos de interesse. Para evitar modelos incorretos, se os pontos conjugados de
   uma das extremidades do segmento de reta não for determinado de modo
   adequado, o segmento é excluído do modelo do objeto.
   Além da exclusão pela falta de determinação correta do conjugado, ocorrem
   situações em que os segmentos não são emparelhados com o modelo da base,
   sendo nestes casos também eliminados. Os segmentos desconsiderados dessa
   316
   APLICAÇÕES PARALELAS EM VISÃO
   forma pertenciam ao fundo da imagem, reflexos, sombras, ou outros objetos da
   imagem.
   (a)
   (b)
   (c)
   Fig. - 8.7 - Exemplos de reconhecimento de objetos. Na coluna esquerda é
   apresentada a imagem direita do par estéreo e na coluna direita, o modelo
   obtido do objeto sobreposto ao modelo reconhecido do banco de dados.
   Finalizado o processamento do módulo estéreo, o controle central determina
   a execução da última etapa do processamento, tarefa realizada pelo módulo de
   reconhecimento, o qual compara o modelo do objeto da imagem com os modelos
   da base de dados, identificando a comparação que apresente o menor erro
   (definido na Equação 8.3). A Figura 8.7 apresenta três resultados do processo de
   reconhecimento, ilustrando cada um dos objetos do universo de reconhecimento.
   Na coluna esquerda temos as imagens adquiridas pela câmera direita e na coluna
   direita seus respectivos modelos (sobreposição objeto e banco de dados).
   Para o primeiro experimento (Figura 8.7 a), o objeto utilizado foi um cubo,
   reconhecido através da identificação de 6 arestas, com um erro = 7,0x10-3. No
   segundo experimento (Figura 8.7 b), o prisma foi reconhecido com um erro =
   7,4x10-3. E finalmente o tetraedro (Figura 8.7 c) foi identificado com um erro =
   317
   CAPÍTULO 8
PA 1,2x10-2. Experimentos similares foram realizados em cerca de 20 cenas, com
   diversas condições de iluminação, fundo e quantidade de objetos diferentes, que
   diagnosticando que o sistema ainda possui um índice considerável de
   reconhecimentos incorretos. Nos casos onde o sistema reconheceu os objetos
   corretamente, os erros apresentados oscilaram em valores próximos aos da Figura
   8.7. Maiores detalhes sobre o funcionamento do sistema, técnicas utilizadas e
   resultados podem ser obtidos na tese de doutorado de Moreira [Moreira, 1999].
   8.2.4 - SISTEMA DISTRIBUÍDO E PARALELISMO
   O sistema foi implementado em arquitetura distribuída, sobre a plataforma
   Windows/Delphi e com a ferramenta de paralelismo CVMP. Graças à sua
   arquitetura distribuída, todos os módulos que compõe o sistema são
   independentes, podendo ser dispostos em máquinas diferentes (conectadas por
   redes) ou ainda na mesma máquina (multitarefa). Conforme comentamos
   anteriormente, embora possua todos os requintes da arquitetura paralela, na qual
   os módulos do sistema são autônomos, separados e independentes, o fluxo de
   execução ocorre de forma seqüencial, uma vez que o objetivo do sistema prima a
   integração.
   Quanto ao controle, os módulos do sistema podem ser divididos em dois
   grupos: supervisor e escravos. O grupo dos escravos, é composto por todos os
   módulos com exceção do módulo de controle central. Basicamente, os módulos
   escravos podem ser considerados como sistemas independentes, que ficam
   aguardando o recebimento de ordens, através de troca de mensagens (CVMP).
   Uma vez recebida a tarefa, o módulo a executa de forma autônoma e
   independente, retornando o resultado do processamento, e voltando ao estado de
   vigília, ao qual permanece até que seja requisitada uma nova tarefa.
   O módulo supervisor do sistema é o módulo controle geral. Sua finalidade é
   supervisionar e controlar todos os demais módulos, atribuindo tarefas aos escravos,
   através de trocas de mensagens, recebendo as respostas e coordenando o ciclo de
   execução do sistema. Embora essa estrutura paralela permita a execução
   simultânea entre módulos, a concorrência não ocorre, parcialmente devido à
   dependência de dados entre módulos e também pelo esforço generalizado do
   projeto na integração.
   Mesmo tendo uma forte dependência de dados entre os módulos, que
   318
   APLICAÇÕES PARALELAS EM VISÃO
   impossibilita a execução simultânea, devido a sua arquitetura paralela e distribuída,
   pode ser facilmente incorporado ao sistema diversos aspectos de paralelismo, que
   proporcionam concorrência e consequentemente melhoram a performance. Essas
   estratégias de paralelismo, que não implicam grandes modificações no sistema,
   podem ser divididas em duas abordagens: (i) Paralelizar o processamento interno
   de cada módulo e (ii) Adaptar o sistema para processamento intermitente, e
   adicionar mecanismos de paralelismo temporal ("pipeline") entre os módulos.
   Na primeira situação (i), os módulos do sistema, responsáveis por
   processamento de cor, estéreo e análise de formas, podem ser substituídos por
   uma versão paralela. Deste modo, visto a independência entre os módulos e sua
   autonomia, os módulos de processamento poderiam ser paralelos, possuindo dessa
   forma sub-módulos. Estes seriam alojados em diferentes máquinas, no caso do
   modelo distribuído ou em diferentes processadores, no caso de máquinas
   multiprocessadas. No caso específico, do módulo de análise formas, a
   paralelização dos processamentos referentes a transformada de Hough e
PA backmapping, foram implementados via CVMP nesse trabalho, e encontram-se
   exemplificados nas Seções 7.5 e 7.51.
   Reconhecimento
   Reconhecimento
   Estéreo
   Estéreo
   Estéreo
   Forma
   Forma
   Forma
   Forma
   Cor
   Cor
   Cor
   Cor
   Cor
   Aquisição
   Aquisição
   Aquisição
   Aquisição
   Aquisição
   tempo
   Fig. - 8.8 - Exemplo de pipeline de 5 estágios entre os módulos do sistema
   (aquisição, cor, forma, estéreo e reconhecimento).
   Na segunda abordagem (ii) é proposta a adição de paralelismo temporal ao
   sistema, na forma de pipeline entre os módulos. Para essa abordagem o sistema
   deveria funcionar em intermitência, ou seja, estar sempre adquirindo, processando
   e analisando as imagens provenientes das câmeras. Nesse caso, conforme mostra
   a Figura 8.8, o sistema seria baseado em estrutura pipeline de 5 estágios, e
   enquanto a seqüência de execução de uma cena (aquisição do par de imagens,
   processamento de cor, processamento de formas, processamento estéreo e
   reconhecimento de padrões) estivesse sendo realizada, novas seqüências já
   319
   CAPÍTULO 8
   iniciariam o processamento simultaneamente.
   8.2.5 - INTEGRAÇÃO ENTRE PESQUISADORES
   O primeiro protótipo do Cyvis-1 consolidou o CVMP como uma plataforma
   amigável e versátil, através da qual pesquisadores do Grupo de Pesquisa em Visão
   Cibernética puderam tornar paralelas suas aplicações, promovendo uma maior
   performance e a possibilidade de visão em tempo real. Além de permitir a adição ao
   contexto da visão artificial, toda a filosofia de integração, modularidade e
   independência, exigida pelos modelos mais complexos do córtex, em especial a
   especialização funcional proposta por Zeki e Ship [Zeki & Shipp, 1988],
   possibilitando novos estudos científicos nessa área.
   Neste protótipo tivemos a oportunidade e a satisfação de trabalhar
   juntamente com dois pesquisadores do grupo, especialistas em visão e
   processamento de imagens: Jander Moreira, na época do projeto, doutorando
   especialista em cor, e Alan Salvany Felinto, doutorando especialista em estéreo.
   Além do desenvolvimento do primeiro protótipo do Cyvis-1, a colaboração dos dois
   colegas foi fundamental para estudos do CVMP, tais como simplicidade de
PA utilização, validação e também as características de herança (OOP) da ferramenta,
   que foram validadas através do desenvolvimento de um objeto herdado do Tcvmp,
   para utilização específica no protótipo (ver Seção 6.6.2).
   Esse trabalho, em especial, ilustrou uma nova forma de integração entre os
   pesquisadores no desenvolvimento de sistemas de visão, através da ferramenta
   CVMP. A integração é propiciada devido à independência e autonomia entre os
   diferentes módulos do sistema, presentes nos sistemas distribuídos ou paralelos.
   Graças a estas características, cada módulo se comporta como uma caixa preta,
   seguindo a mesma filosofia do conceito de programação orientada a objetos [Cox,
   1986]. Nesse caso, os pesquisadores não precisam conhecer os detalhes sobre a
   técnica ou implementação dos módulos, uma vez que basta enviar uma mensagem
   e aguardar a resposta do processamento do módulo.
   Essa abordagem facilita muito o trabalho cooperativo, uma vez que
   concentra os esforços de cada indivíduo no desenvolvimento de uma parte
   específica do sistema. A independência e autonomia modular, aliadas ao
   alojamento distribuído de cada módulo, propiciou um ambiente de desenvolvimento
   bastante interessante no nosso laboratório, em que cada pesquisador ficou
   320
   APLICAÇÕES PARALELAS EM VISÃO
   responsável por uma máquina, na qual estava alojado um módulo específico do
   sistema. Com isso, os colaboradores do projeto puderam trabalhar
   simultaneamente em máquinas distintas e, a qualquer momento, testar a integração
   de sua parte com todo o sistema. Para isso, enquanto trabalhavam no
   desenvolvimento, os pesquisadores disponibilizaram uma versão do módulo, sendo
   executado em multitarefa em suas máquinas. Assim, tanto o módulo quanto a
   máquina poderiam ser utilizados para testes pelos outros módulos, ao mesmo
   tempo em que a máquina estava sendo utilizada para o desenvolvimento de novas
   versões do seu respectivo módulo.
   Graças ao ambiente de desenvolvimento e teste distribuído, foi possível o
   trabalho cooperativo e simultâneo para a implementação do primeiro protótipo do
   projeto Cyvis-1, que exemplificou não apenas a utilização do paralelismo para a
   integração de atributos visuais em sistemas de visão artificial, mas também a
   integração e harmonização do trabalho de pesquisa de pesquisadores do Grupo de
   Pesquisa em Visão Cibernética.
   8.3 - YNERGOS - INVESTIGAÇÃO DA PERCEPÇÃO
   HUMANA NA COMPLEXIDADE DAS FORMAS
   No Capítulo 5 discutimos o projeto ynergos, um sistema baseado na
   sinergia, conceito através do qual a associação simultânea de diversos fatores
   contribuem para uma ação coordenada, cujo objetivo fundamental é a
   implementação de um poderoso e versátil laboratório de visão computacional, para
   auxiliar o desenvolvimento e a validação de técnicas, sistemas e experimentos em
   visão. Nesta seção, vamos apresentar um experimento psicofísico realizado através
   do projeto ynergos, no qual diversos paradigmas, em especial Internet, sistemas
   distribuídos, computação paralela, inteligência artificial e visão biológica, são
   utilizados de forma integrada para investigar a percepção humana na complexidade
   das formas e com base nessa investigação, desenvolver um modelo
   matemático/computacional dessa sensação humana [Bruno et al., 2000].
   8.3.1 - O EXPERIMENTO PSICOFÍSICO
   A percepção visual humana envolve processos altamente complexos e não
   321
PA CAPÍTULO 8
   lineares, organizados em uma estrutura hierárquica [Marr, 1982] [Zeki, 1993], se
   inicia com a conversão do sinal físico (luz) em estímulo nervoso e termina com sua
   completa caracterização e descrição (sensação do estímulo). Deste modo, para
   cada estímulo físico em uma dada modalidade sensitiva, será criada uma
   percepção correspondente, a qual na maioria das vezes obedece a uma
   dependência não linear. Em psicofísica, esse tipo de correspondência pode ser
   caracterizado e modelado em termos da lei de Fechner, dada pela Equação 8.4,
   onde c é uma constante proporcional, P é a intensidade do estímulo físico e S é a
   magnitude subjetiva [Barlow & Mol om, 1982].
   S = c Log P
   (8.4)
   Para investigar como os parâmetros da lei de Fechner podem se relacionar
   com a percepção humana na complexidade das formas, planejamos um
   experimento que consiste em apresentar uma série de imagens para um indivíduo,
   que avaliará a imagem atribuindo-lhe uma nota de 1 a 10. Para que o experimento
   se torne estatisticamente representativo, um grande número de imagens deve ser
   considerado, com a natureza mais divergente possível (ex: fotografia de um
   escritório, fotografia de um elefante, etc.).
   Uma fonte de imagens vasta e bastante variada é a própria Internet. Através
   do módulo de Internet e do WebWorm, que será discutido mais adiante, o ynergos
   é capaz de montar uma base de dados de imagens variadas, que são organizadas
   e apresentadas ao espectador para a realização do experimento. Os resultados
   obtidos podem ser então comparados com funções definidas por valores medidos.
   Nesse trabalho optou-se por duas funções: (i) combinações lineares das
   características, dada pela Equação 8.5 e (i ) combinações lineares do logaritmo das
   características (devido a lei de Fechner), expressa na Equação 8.6. O fator de
   influência, determinado pelo parâmetro bias é necessário para possibilitar eventuais
   deslocamentos do hiperplano definido pela função de suas coordenadas de origem,
   caso seja preciso.
   N f
   S
   =
   a f + bias
   (8.5)
   C 1
   ,
   i i
   i=1
   N f
   S
   =
   a log
   +
   (8.6)
   C,2
   i
   ( fi ) bias
   i=1
   322
PA APLICAÇÕES PARALELAS EM VISÃO
   Os resultados obtidos pela análise humana são então relacionados com os
   resultados obtidos através da análise de complexidade de alguns métodos
   computacionais, os quais serão discutidos a seguir. Desta forma, é determinada a
   combinação linear, que ditará o modelo computacional mais próximo do
   comportamento humano.
   Em termos computacionais, boas aproximações para as combinações
   lineares são aquelas que apresentem o menor número de fatores possível. Uma
   aplicação direta para essa consideração seria a possibilidade de utilização dos
   modelos em tempo real, onde, quanto menor o número de fatores considerados,
   menores serão os recursos computacionais requeridos e consequentemente, mais
   rápido será o sistema.
   8.3.2 - WEBWORM
   A construção do banco de imagens é realizada através de uma coleta de
   imagens dos mais variados assuntos, extraídas da Internet. Deste modo, coletando
   imagens ao acaso pela Internet estaremos garantindo que as imagens
   apresentadas no experimento psicofísico possuirão natureza amplamente variada,
   não apresentando características em comum (que poderiam ocorrer caso as
   imagens fossem recolhidas de algum banco de dados específico e obtidas por
   alguma pessoa ou grupo de pessoas). Para permitir a aquisição das imagens foi
   desenvolvido um aplicativo, incorporado ao módulo Internet do ynergos, o qual
   denominamos de WebWorm, cujo funcionamento básico consiste em acessar
   páginas HTML e trazer as imagens.
   O WebWorm é uma aplicação desenvolvida em Delphi, que através de
   sockets (winsock) [Dumas, 1995], se conecta com o porto 80 (servidor Web)
   através das máquinas pela Internet, estabelecendo comunicação com os servidores
   WWW. O WebWorm opera um navegador Netscape, através do mecanismo
   sendkey do Windows, fazendo com que o Netscape abra as páginas HTML
   requisitadas.
   323
   CAPÍTULO 8
   INTERNET
   Netscape
   Web Worm
   ynergos
   Netscape
   Cache
   Fig. - 8.9 - Diagrama apresentado as interações do WebWorm.
   A Figura 8.9 apresenta um diagrama esquemático contendo sua estrutura de
   funcionamento. Após carregar uma página HTML, o WebWorm analisa o código e
   monta duas listas, a primeira, denominada de lista de espera, contendo os
   ponteiros para outras páginas HTML e a outra com as imagens do documento
   HTML. Feito isso, o aplicativo apaga todos os arquivos do diretório cache do
   Netscape e solicita a este que a página em questão seja carregada. Uma vez que a
   página e todas as suas imagens (arquivos GIF, JPEG, BMP e etc.) são carregadas,
   o WebWorm, transfere as imagens (.JPG) do diretório cache do Netscape para um
   diretório de entrada de imagens do ynergos.
   O processo é repetido para todas as páginas na lista de espera, de modo
   que o WebWorm é capaz de percorrer automaticamente todas as páginas
   apontadas por um determinado sítio ( site), podendo deste modo percorrer milhares
PA de páginas. Esse processo é encerrado quando um determinado nível de
   profundidade de acesso foi alcançado. A Figura 8.10 ilustra um exemplo do
   processo de navegação. Nesse caso a página inicial apresenta três ponteiros
   ( hyperlinks) para três outras páginas, que por sua vez, são conectadas a quatro,
   três e uma páginas respectivamente. Se o WebWorm for instruído para percorrer
   apenas um nível de profundidade, serão carregadas apenas as imagens da página
   inicial; para dois níveis, as imagens das páginas correspondentes ao primeiro e
   segundo nível e assim sucessivamente.
   Nessa abordagem nós assumimos que o WebWorm realiza uma busca cega
   na Internet, iniciada a partir de uma determinada página. Assim, para que se torne
   mais interessante, iniciamos a busca a partir da página resultante de determinada
   324
   APLICAÇÕES PARALELAS EM VISÃO
   pesquisa em um mecanismo de busca como o AltaVista ou Yahoo (com as chaves
   " photo" e " pictures").
   Página
   Primeiro nível
   inicial
   Segundo nível
   Terceiro nível
   Fig. - 8.10 - Exemplo de navegação do WebWorm.
   A vasta maioria das imagens utilizadas na Internet utiliza dois formatos de
   imagens: JPEG e GIF. Uma vez que as imagens GIF não apresentam canais de
   cores reais (RGB) devido ao mecanismo de paleta (cores indexadas) incorporado
   ao formato, consideramos apenas as imagens JPEG, que em geral apresentam
   canais de cores reais (24bits - RGB), transferindo somente imagens com a
   terminação JPG para o diretório de entrada do ynergos. Sendo todas as imagens
   das páginas com formato JPEG consideradas, temos uma grande variedade de
   figuras utilizadas na Internet, tais como botões, banners, texto em formato gráfico,
   propaganda e outros. A tarefa de separar imagens específicas é realizada pelo
   ynergos, que analisa cada uma das imagens do diretório de entrada, considerando
   sua dimensão, complexidade, e estrutura do histograma (imagens sintéticas são
   caracterizadas por apresentar histogramas bem definidos), a fim de filtrar apenas as
   imagens desejadas, no caso do experimento, imagens fotográficas.
   8.3.3 - MÉTODOS CONSIDERADOS
   Conforme mencionamos, os dados extraídos do experimento psicofísico
   deverão ser correlacionados com modelos matemáticos para analisar e medir a
   complexidade das imagens. Nesse trabalho, escolhemos 4 métodos para obtenção
   de medidas de complexidade: (i) Entropia dos níveis de cinza [Gonzalez & Woods,
   1993], (ii) Tempo de decaimento multi-escala da variância da distribuição dos níveis
   de cinza da imagem (variância do histograma) [Bruno et al., 2000], (iii) circularidade
   325
   CAPÍTULO 8
   [Bruno et al.,2000] e (iv) dimensão fractal por salsicha de Minkowski [Tricot, 1995].
   O estudo desses métodos como medidas de complexidade foi realizado através de
   diversos experimentos conduzidos pelo Grupo de Pesquisa em Visão Cibernética,
   voltados particularmente para a análise morfológica de neurônios, onde a
   complexidade tem sido considerada por neurocientistas como uma importante
   característica para classificar neurônios [Cesar & Costa, 1998] [Costa & Velte,
   1999] [Costa, 1996] [Coelho, 1998].
PA O conceito entropia usualmente empregado em processamento de imagens
   [Gonzalez & Woods, 1993] é baseado na distribuição de probabilidade dos níveis
   de cinza da imagem (histograma). Dentro deste contexto, a entropia é uma medida
   de desorganização ou incerteza sobre a distribuição, podendo ser empregada como
   uma forma de caracterização da complexidade da imagem. A natureza do método,
   entretanto, enfoca a complexidade sobre o ponto de vista da variação de brilho na
   imagem, uma vez que é analisada apenas a freqüência de cada nível de cinza e a
   distribuição espacial dos pontos ao longo da imagem não influencia o cálculo da
   entropia.
   O tempo de decaimento da variância multi-escala da distribuição dos níveis
   de cinza foi escolhido devMP, define-se uma
   arquitetura Processor Farm. O processo mestre distribui uma cópia da imagem para
   todos os escravos, e a seguir distribui para cada processo escravo uma tarefa,
   enviando um determinado valor de raio r. A tarefa se constitui na convolução de um
   círculo de raio r (determinado pelo mestre) e na determinação da área do resultado
   Ar, que é enviada para o mestre assim que calculada. O mestre supervisiona o
   conjunto de escravos e, à medida que as tarefas vão sendo executadas, novas são
   300
   ESTUDOS DE ALGORITMOS PARALELOS PARA VISÃO
   atribuídas aos escravos desocupados, até que sejam calculados todos os Ar,
   definidos pelo número de raios determinados pelo mestre. Assim que todos os
   resultados são obtidos, o mestre realiza a regressão linear dos pontos ( r,Ar) em
   log(r) x log (A) e inclinação da reta obtida finalmente determina a dimensão fractal
   da imagem.
   Uma das vantagens da utilização dessa abordagem é o balanceamento de
PA carga automático, possibilitando a utilização de um conjunto heterogêneo de
   elementos de processamento sem a necessidade de realizar qualquer alteração na
   implementação. Para explorar essa versatilidade, implementamos a técnica em um
   sistema distribuído em rede de padrão ethernet de 10 Mb/s, com 4 máquinas
   baseadas no processador AMD K6 II com freqüências distintas: 200, 250, 300 e 375
   MHz. Na máquina mais veloz 375 MHz, foi alojado o processo mestre e um
   escravo.
   Utilizamos como método para a convolução, a multiplicação do disco com a
   imagem no domínio da freqüência de Fourier [Brigham, 1988]. Deste modo, o
   processo de convolução se caracteriza basicamente pela FFT da imagem e do
   disco, o produto complexo de seus domínios complexos, e sua FFT inversa,
   constituindo o resultado da operação de convolução.
   Realizamos o experimento para uma imagem binária de 512x512 pixels. O
   número de discos utilizados foi de 32, com raios variando em 2. A Figura 7.46
   apresenta o diagrama de execução, obtido através das ferramentas de estatística
   do CVMP. Devido ao pequeno fluxo de dados nas trocas de mensagens em rede, o
   sistema possui uma ótima performance (observe a pequena quantidade de bolhas).
   Uma prova da excelente performance está no fato de que o sistema paralelo com
   quatro máquinas heterogêneas (200 MHz, 250 MHz, 300 MHz e 375 MHz) é
   aproximadamente 2,7 vezes mais rápido que a versão seqüencial executada na
   máquina mais veloz (375Mhz).
   301
   CAPÍTULO 7
   Fig. - 7.46 - Diagrama de execução para 4 máquinas.
   O CVMP Processor Farm pode ser utilizado em muitas outras aplicações de
   processamento de imagens e visão computacional. Os problemas de multi-escala
   [Cesar, 1997], especificamente os bidimensionais, possuem uma metodologia de
   implementação idêntica à dimensão fractal de Minkowski descrita nesta seção,
   bastando apenas substituir no processo de convolução os discos de raio variado
   por gaussianas com diferentes desvios padrão.
   302
   CAPÍTULO
   8
   APLICAÇÕES PARALELAS
   EM VISÃO
   "Never trust a computer you can't throw out a window."
   Steve Wozniak
   303
   CAPÍTULO 8
   304
   APLICAÇÕES PARALELAS EM VISÃO
   CAPÍTULO 8 – APLICAÇÕES PARALELAS
   EM VISÃO
   8.1 - INTRODUÇÃO
   No capítulo anterior vimos algumas estratégias de paralelismo e
   implementações de métodos para visão computacional e processamento de
   imagens. Neste capítulo iremos apresentar 3 aplicações inéditas desenvolvidas no
   CVRG. A primeira a ser discutida é um protótipo do Cyvis-1, que utiliza o
   paralelismo como ferramenta de integração de informações, neste caso os atributos
   visuais cor e estéreo. Como segunda aplicação temos um experimento do projeto
PA ynergos, na qual, através de psicofísica, é desenvolvido um modelo matemático
   para complexidade de imagens, baseado no padrão da percepção humana.
   Finalizamos o capítulo apresentando o projeto TreeVis, um sistema paralelo de
   reconhecimento de plantas arbóreas.
   8.2 - INTEGRAÇÃO DE COR E ESTÉREO NO PROJETO
   CYVIS-1
   Podemos caracterizar a computação paralela como uma ciência cujo
   objetivo fundamental, senão único, é a performance. Deste modo, seu emprego
   dentro da temática da visão artificial seria o desenvolvimento de estratégias e
   arquiteturas para reduzir o tempo de execução dos algoritmos e métodos
   envolvidos nesta atividade. A natureza, entretanto, adota o paralelismo de modo
   versátil. Conforme discutimos no Capítulo 4, além de ser fundamental para o
   desempenho do processamento de informações nos sistemas biológicos, realizado
   por um conjunto de estratégias de paralelização de massa e multinível (4.7), a
   natureza encontrou também no paralelismo a chave vital para seus mecanismos de
   integração de informações, através da qual desenvolve um papel fundamental na
   integração dos atributos visuais, modularizados no córtex visual [Zeki, 1993].
   Uma das bases do sistema de visão artificial Cyvis-1, apresentado no
   305
   CAPÍTULO 8
   Capítulo 5, é o modelo de especialização funcional do córtex visual dos primatas,
   proposto por Zeki e Ship [Zeki & Shipp, 1988]. Segundo este modelo, o sistema
   visual é organizado em módulos independentes, onde cada módulo é responsável
   pelo processamento especializado de um atributo visual. Durante o processamento
   das informações, cada módulo pode permutar informações com outros módulos,
   ocorrendo a colaboração entre os diferentes atributos visuais. Esta abordagem
   caracteriza a integração de múltiplos estágios (Seção 5.2.1.8), que conta como
   princípio básico a integração dos atributos visuais.
   Diferentemente de todas as abordagens de paralelismo apresentadas nesta
   tese, onde, de forma tradicional, o paralelismo atuou como uma ferramenta de
   performance, iremos apresentar nesta seção uma proposta de integração entre
   atributos visuais, na qual o CVMP é utilizado para exercer a integração, através da
   troca de informações. A forma como os atributos visuais distintos podem cooperar
   para atingir um determinado objetivo, embora ainda seja uma lacuna dentro da
   visão artificial, constitui uma das colunas fundamentais do projeto Cyvis-1. Deste
   modo estaremos apresentando o primeiro passo desse projeto, onde temos um
   sistema de visão artificial baseado na integração das informações provenientes de
   atributos visuais distintos, no caso: cor e estéreo.
   Os atributos são especificados no sistema como módulos ou subsistemas,
   possuindo cada um sua própria meta de resultados. O módulo cor é responsável
   pela segmentação das imagens adquiridas pelo sistema, fornecendo informações
   referentes às regiões e suas bordas, enquanto o módulo estéreo utiliza as
   informações providas pelo atributo cor para determinar uma representação mais
   abstrata da cena. Assim, o sistema representa os objetos não apenas a partir das
   informações de regiões e bordas (2D), mas também da informação de
   profundidade, caracterizando a reprodução da estrutura dos objetos de forma
   tridimensional.
   O sistema proposto foi desenvolvido com o intuito de realizar o
   reconhecimento de objetos poliédricos. Um dos módulos do sistema é responsável
   pela identificação dos objetos (cubos e pirâmides).
PA Conforme já comentamos, uma das características do projeto Cyvis-1 é o
   trabalho cooperativo entre diversos pesquisadores. Além de prover o paralelismo de
   forma simples, eliminando a restrição de que somente especialistas em
   computação paralela sejam capazes de desenvolver aplicações paralelas, permite
   que os demais pesquisadores também possam implementar sistemas paralelos,
   306
   APLICAÇÕES PARALELAS EM VISÃO
   mesmo que sejam complexos. O CVMP atua, ainda, como uma ferramenta de
   integração entre os pesquisadores, que podem desenvolver módulos em máquinas
   individuais que se conectam e integram formando o sistema como um todo.
   Podendo ser definido como o primeiro protótipo do Cvyis-1, o sistema de
   integração entre cor e estéreo apresentado neste capítulo foi desenvolvido pelo
   trabalho cooperativo de três doutorandos do Grupo de Visão Cibernética. Alan
   Salvany Felinto [Moreira et al., 1999] foi responsável pela implementação do
   módulo de estéreo e Jander Moreira [Moreira, 1999] pelo módulo de cor. A
   participação do autor, além do CVMP, base de desenvolvimento paralelo do
   sistema, envolveu a colaboração no planejamento e estruturação do sistema.
   8.2.1 - ESTRUTURAÇÃO DO SISTEMA
   Embora, o projeto Cyvis-1 incorpore diversos atributos visuais, assim como
   uma série de sofisticados recursos de visão (conforme discutido no Capítulo 5), seu
   primeiro protótipo é bastante limitado, baseando-se essencialmente na integração
   entre os atributos de cor e estéreo. A integração entre os atributos conforme
   idealizada no Cyvis-1, requer a colaboração em diversos níveis hierárquicos de
   processamento, além de permitir também que o processamento percorra o caminho
   de execução em ambos os sentidos ( top-down e botton-up) de forma a permitir a
   utilização de informações de alto nível. A integração entre os atributos é uma tarefa
   difícil e pouco explorada. Deste modo, o primeiro protótipo, embora apresente a
   execução em apenas um único sentido ( botton-up) e um limitado mecanismo de
   integração, que ocorre em apenas uma etapa hierárquica, constitui um importante
   passo para os estudos dos mecanismos de integração entre os atributos e,
   consequentemente, para o projeto Cyvis-1.
   O sistema cor/estéreo, cuja estrutura básica é mostrada pelo diagrama de
   blocos da Figura 8.1, é composto por seis módulos, ou subsistemas: aquisição de
   imagens, segmentação por cor, análise de formas, reconhecimento de objetos e
   controle geral. O sistema foi implementado com padrões distribuídos, utilizado de
   forma que cada um dos módulos pode ser alojado em uma máquina distinta. O
   CVMP é responsável pela conexão e troca de mensagens entre os módulos.
   307
   CAPÍTULO 8
   Cor
   Estéreo
   Aquisição
   Controle geral
   Base de dados
   dos modelos
   Análise de
   Reconhecimento
   formas
   de objetos
   Fig. - 8.1 - Sistema de integração entre cor e estéreo, segundo sua estrutura
PA modular [Moreira, 1999].
   8.2.1.1 - MÓDULO DE AQUISIÇÃO
   A aquisição de imagens é realizada através de duas câmeras digitais (CCD).
   As imagens são adquiridas em pares, com as câmeras posicionadas a uma
   distância conhecida, sem convergência, ou seja, os eixos de captura são paralelos.
   O módulo de aquisição é independente e autônomo, alojado em uma máquina que
   possui dispositivo para aquisição de imagens.
   Quanto ao seu funcionamento, o módulo fica aguardando mensagens de
   outros módulos, solicitando serviços. Toda vez que o módulo recebe uma
   solicitação, é realizada a aquisição das imagens, transmitidas para o módulo
   solicitante na forma de mapas de bits. Ao final do processo, o módulo envia uma
   mensagem indicando ao módulo solicitante que o serviço foi efetuado com êxito e
   volta ao estado de espera.
   8.2.1.2 - MÓDULO DE COR
   O módulo de cor é responsável pela segmentação de uma das imagens do
   par estéreo. A técnica utilizada é conhecida como mapa auto-organizável. Trata-se
   de uma técnica baseada em redes neurais, consistindo na segmentação das
   imagens através de regiões, formadas por agrupamentos de pixels. A técnica é
   descrita em detalhes por Moreira em sua tese de doutorado [Moreira, 1999]. No
   sistema as duas imagens (esquerda e direita do par estéreo) são utilizadas para o
   treinamento do mapa auto-organizável. Após a convergência da técnica, são
   308
   APLICAÇÕES PARALELAS EM VISÃO
   obtidas as classes identificadas, que segmentam a imagem em regiões. Com base
   nas regiões, são determinadas as fronteiras, gerando seu mapa de bordas. A
   segmentação ocorre em apenas uma das imagens, uma vez que as informações
   detectáveis nesse nível são irrelevantes para o módulo de estéreo.
   8.2.1.3 - ANÁLISE DE FORMAS
   A análise de formas é baseada na detecção das retas do mapa de bordas,
   uma vez que os objetos poliédricos podem ser modelados a partir das retas que
   constituem suas arestas. A detecção de retas é feita a partir da transformada de
   Hough, discutida na Seção 7.5. A partir dela, são encontradas as retas que passam
   sobre os pontos colineares da imagem. Conforme vimos nas Seções 7.5 e 7.5.1, na
   transformada de Hough as retas detectadas são representadas como picos no
   espaço de Hough. No entanto, os pontos colineares e ruídos na imagem geram um
   grande número picos, tornando praticamente impossível a obtenção somente das
   retas de interesse. Para solucionar este problema, foi introduzido o backmapping ou
   rastreamento, uma técnica complementar para solucionar esse problema.
   Através da combinação entre a transformada de Hough e do backmapping,
   o módulo de análise obtém as retas da imagem, na tentativa de localizar as arestas
   dos objetos. Entretanto, o módulo análise de formas necessita não apenas
   conhecer a equação das retas da imagem, mas também determinar seus
   segmentos, ou seja, a posição onde as retas começam e terminam. Para
   determinar os segmentos de retas, foi utilizada uma técnica proposta por Costa &
   Sandler [Costa & Sandler, 1993], a qual permitem obter os segmentos de reta
   mediante o resultado do backmapping, e eliminar as retas consecutivas e
   coincidentes. Assim é realizada a análise de formas, que consiste na determinação
   dos segmentos de retas contidos no mapa de bordas.
   8.2.1.4 - ESTÉREO
   O módulo de estéreo efetua o cálculo de profundidade para cada uma das
PA extremidades dos segmentos de retas determinados pelo módulo de análise de
   formas. O cálculo de profundidade é realizado a partir das disparidades localizadas
   entre os dois pares de imagem adquiridos pelo sistema. A disparidade é
   determinada a partir dos pontos conjugados ou de correspondência. Os pontos
   309
   CAPÍTULO 8
   conjugados são pares de coordenadas (uma coordenada para cada imagem do par
   estéreo) relacionadas ao mesmo ponto físico da cena na qual foi realizada a
   aquisição pelo par de câmeras [Shirai, 1987].
   Dentre os diversos métodos para determinar os pontos conjugados
   (correlação, diferenças quadráticas mínimas, transformadas de Gabor, entre outros
   [Theimer & Mallot, 1994] [Faugeras, 1996] [Qian, 1997]), foi adotado para a
   implementação do módulo de estéreo o método das janelas quadradas. Nessa
   abordagem, dado um ponto em uma imagem, é centrada uma janela quadrada com
   um tamanho determinado. A busca do ponto conjugado consiste na localização da
   janela correspondente, a outra imagem do par estéreo. A similaridade é
   determinada pelo conteúdo das janelas. Para solucionar algumas ambigüidades, é
   realizada a mudança sistemática do tamanho das janelas, conforme indicado por
   Shirai [Shirai, 1987]. A comparação entre as janelas é realizada apenas nas regiões
   determinadas pela linha epipolar, calculada através da geometria das câmeras,
   determina a região provável do ponto conjugado. A calibração das câmeras do
   sistema foi realizada mediante os procedimentos propostos por Tsai [Tsai, 1987].
   8.2.1.5 - RECONHECIMENTO DE OBJETOS
   O universo de objetos para qual o sistema foi proposto é constituído de 3
   entidades: cubo, tetraedro e prisma (ver Figura 8.2). Cada um dos objetos é
   construído em alumínio, apresentando dimensões conhecidas, onde cada face
   possui uma cor uniforme distinta, que permite a segmentação por região cromática.
   O sistema foi idealizado a fim de identificar os objetos tridimensionais, sob qualquer
   posição na cena, sendo tolerante a rotação e translação dos objetreconhecimento de
   espécies catalogadas. O inventário botânico é realizado essencialmente através
   dos herbários. Os herbários se caracterizam por uma coleção científica de
   exemplares de ramos férteis (galhos com folhas, podendo possuir flores ou frutos
   característicos), coletados na natureza, prensados, dessecados e montados sobre
PA papel cartão. Associados a cada exemplar existe uma ficha padronizada, contendo
   todas as informações sobre o espécime, com o rigor da taxonomia. Nos herbários
   podem ser armazenados grande quantidade de espécimes, que deverão ser
   alojadas em locais adequados à sua preservação, permitindo sua conservação por
   longo período de tempo (da ordem de séculos). Os exemplares devem ser
   arranjados segundo o critério botânico, a fim de auxiliar a localização e estudos
   [Peixoto & Barbosa, 1998].
   Deste modo, os herbários constituem a mais importante ferramenta de
   trabalho do botânico, através dos quais podem ser examinados e estudados,
   espécimes procedentes de diferentes locais e ecossistemas. Através de seu auxílio,
   o botânico pode comparar um exemplar na natureza com centenas de espécimes
   classificadas por especialistas e deste modo realizar sua identificação. Através da
   pesquisa de campo e da utilização de ferramentas como o herbário, é realizado o
   levantamento arbóreo de uma região, que consiste na especificação e na
   identificação das espécimes de árvores ali encontradas. O levantamento arbóreo é
   de importância vital para o estudo dos habitats e ecossistemas, assim como para a
   eventual descoberta de novas espécimes, auxiliando o desenvolvimento da
   pesquisa científica.
   8.4.1.1 - COLETA E TRATAMENTO DAS AMOSTRAS
   O levantamento arbóreo é uma árdua tarefa, na qual todas as fases devem
   ser realizadas através de trabalho manual. A primeira etapa do processo consiste
   na pesquisa de campo. Nessa fase é realizada a coleta dos exemplares que serão
   334
   APLICAÇÕES PARALELAS EM VISÃO
   identificados. Como exemplares, são coletados ramos férteis, ou seja, galhos com
   folhas e, caso estejam presentes flores e frutos. Coletado o material, esse deve ser
   preparado para que se conserve até a próxima etapa da pesquisa, que consiste na
   comparação e identificação desses espécimes com o material do herbário, uma vez
   que essas etapas são separadas por dias e as vezes até mesmo por meses
   [Fernandes, 1997] [Lorenzi, 1992].
   O material coletado, recebe um tratamento similar aquele executado para a
   formação do herbário, ou seja, os ramos são prensados e dessecados. Além da
   conservação, o tratamento também pode auxiliar na identificação do material, uma
   vez que este terá aspecto semelhante aos espécimes do herbário [Peixoto &
   Barbosa, 1998].
   8.4.1.2 - CLASSIFICAÇÃO ATRAVÉS DE HERBÁRIOS
   De posse do material coletado em campo, é realizada a identificação através
   do herbário. Nessa fase também o trabalho é exercido de forma manual. Caso o
   botânico tenha alguma pista a respeito da família ou da espécie do exemplar, a
   pesquisa é direcionada e a comparação é realizada com as pranchas previamente
   escolhidas para este fim. No entanto em muitas situações, especialmente se o
   botânico não for um profundo conhecedor de determinada espécie ou região, a
   busca deverá ser realizada através de comparações com um universo muito maior
   de pranchas.
   A comparação consiste em colocar o material coletado ao lado da prancha
   do herbário e realizar a identificação visual das semelhanças e diferenças entre
   ambas. Uma vez localizada a prancha que apresenta a maior semelhança com o
   espécime coletado, é realizada a identificação. Esse processo, além de trabalhoso
   e demorado, requer um vasto treinamento ao botânico, de forma a minimizar os
   erros decorrentes de falsas identificações.
PA 8.4.2 - OS HERBÁRIOS BRASILEIROS
   Os herbários são repositórios de material científico, contendo a
   documentação florística de um país. Suas informações constituem a fonte primária
   para a botânica, através das quais podem ser realizados trabalhos taxônomicos,
   evolutivos, ecológicos, biogeográficos, etnobotânicos e estudos de biodiversidade,
   sendo ainda uma importante ferramenta e fonte de dados para o planejamento do
   335
   CAPÍTULO 8
   desenvolvimento sustentável [Peixoto & Barbosa, 1998].
   Os países desenvolvidos possuem herbários praticamente completos,
   através dos quais são preparadas listas de espécies ameaçadas de extinção, de
   valor medicinal, ornamental, produtoras de frutos comestíveis e muitas outras.
   Entretanto, eles não contam com uma rica flora tropical e uma exuberante
   biodiversidade, como é a situação de alguns países em desenvolvimento, em
   especial o Brasil, que não tem feito o mesmo devido à falta de recursos,
   informações e pela complexidade da tarefa.
   Inúmeros estudos realizados sobre espécies brasileiras promissoras
   certificam o valor da flora nativa, sobre diferentes aspectos, e trazem à tona o
   quanto custa o desconhecimento do conjunto dessas espécies para a sociedade
   moderna. A falta de informações sobre as espécies nativas se dá,
   predominantemente, à diversidade e riqueza da flora, ao pequeno número de
   botânicos especializados que possam estudá-las e ao longo e trabalhoso processo
   de levantamento florístico. Esta situação torna-se mais crítica diante da rapidez com
   que está desaparecendo a vegetação natural e do longo período de treinamento
   exigido para formar um especialista em taxonomia.
   Estado
   Nº de Herbários Exemplares
   RJ
   11
   912.632
   SP
   16
   750.765
   RS
   15
   437.230
   PR
   8
   349.537
   PA
   3
   326.778
   DF
   4
   281.474
   MG
   11
   228.143
   BA
   7
PA 210.027
   AM
   3
   206.092
   PE
   6
   184.338
   SC
   4
   111.200
   PB
   2
   31.500
   CE
   4
   23.612
   GO
   1
   22.001
   ES
   3
   21.800
   MS
   4
   18.548
   AL
   2
   16.232
   MT
   1
   14.014
   PI
   1
   9.930
   AP
   1
   8.000
   AC
   2
   7.822
   SE
   1
   6.930
   RN
   2
   5.257
   MA
   1
   2.777
   Tabela 8.1 - Herbários brasileiros e números de exemplares [Peixoto &
PA Barbosa, 1998].
   336
   APLICAÇÕES PARALELAS EM VISÃO
   O Brasil conta com 113 herbários ativos, que guardam um acervo de
   4.187.154 espécimes vegetais, segundo a Sociedade Brasileira de Botânica (SBB)
   (1997) [Peixoto & Barbosa, 1998]. Embora em uma primeira instância esse número
   possa parecer significativo, ele reflete uma pequena fração da biodiversividade
   florística brasileira (sem considerar que muitas espécies se repetem em diferentes
   herbários). A Tabela 8.1 apresenta uma listagem contendo o número de herbários e
   as espécies catalogadas em cada estado brasileiro, e a Tabela 8.2 apresenta a lista
   dos herbários que mais detêm informações.
   Estado
   Sigla
   Instituição
   Exemplares
   RJ
   R
   Museu Nacional do Rio de Janeiro
   375.000
   RJ
   RB
   Jardim Botânico do Rio de Janeiro
   344.812
   SP
   SP
   Instituto de Botânica de São Paulo
   317.000
   PR
   MBM
   Museu Botânico Municipal de Curitiba
   255.000
   DF
   UB
   Universidade de Brasília
   208.000
   AM
   INPA
   Instituto de Pesquisas da Amazônia
   200.000
   PA
   IAN
   EMBRAPA, Amazônia Oriental
   164.000
   PA
   MG
   Museu Paraense Emílio Goeldi
   159.778
   SP
   SPF
   Universidade de São Paulo
PA 142.827
   RS
   RS
   Instituto Anchietano de Pesquisas
   120.000
   RS
   ICN
   Universidade Federal do Rio Grande do Sul
   118.000
   RS
   HAS
   Fundação Zoobotânica do Rio Grande do Sul
   108.300
   Tabela 8.2 - Os doze herbários brasileiros que mais detêm informações
   [Peixoto & Barbosa, 1998].
   8.4.3 - A PROPOSTA TREEVIS
   Levando em conta a importância do levantamento arbóreo e suas
   dificuldades, fomos motivados a idealizar um sistema cujo intuito é propiciar ao
   botânico taxonomista mais um recurso para auxiliar seu trabalho na identificação
   dos espécimes. Além da busca em herbários tradicionais ser uma tarefa bastante
   exaustiva, podemos citar alguns fatores que restringem sua utilização tais como: (i)
   Pequeno número de herbários, que em geral estão localizados em locais distantes
   do pesquisador, (ii) Dificuldade de replicação da base científica de modo a
   democratizar seu acesso, uma vez que os herbários são constituídos de
   exemplares retirados da natureza, (iii) Perda de informações essenciais durante o
   tratamento dos exemplares (cor e detalhes da textura) e (iv) longo treinamento na
   formação de especialistas realmente capazes de realizar a identificação.
   Esta proposta não visa a substituição dos herbários tradicionais, mas sim
   337
   CAPÍTULO 8
   adicionar mais um complemento ao conjunto de metodologias de identificação
   vegetal, permitindo acelerar o trabalho de reconhecimento (reconhecimento
   automático) e facilitar o acesso à informações, uma vez que os sistemas digitais
   são facilmente replicáveis, podendo ser distribuídos para diversas universidades,
   laboratórios e institutos de pesquisa.
   Dentro desta motivação surgiu a proposta do sistema TreeVis, cujo nome é
   derivado do inglês "Tree Vision System". Trata-se de um sistema capaz de
   armazenar, classificar e organizar dados científicos e realizar a identificação
   automática de espécies, funcionando como um herbário digital. Diferente dos
   herbários tradicionais, onde são colecionados ramos férteis, o TreeVis concentra
   nas folhas todo o sistema de informações e identificação dos exemplares.
   O processo de reconhecimento através das folhas é uma tarefa complicada
   e audaciosa, concretizando um verdadeiro desafio para um sistema de
   reconhecimento. Isso acontece devido à natureza dos vegetais. Embora conservem
   algumas características fundamentais, as folhas apresentam uma grande variação.
   Essas variações ocorrem dentro de um único indivíduo, onde a maturidade ou
   mesmo a formação das folhas, faz com que essas tenham grandes variações
   quanto ao tamanho, coloração, textura, formato, etc., e também entre indivíduos
   diferentes (da mesma espécie). Indivíduos diferentes de uma mesma espécie
   localizados nas mesmas regiões podem apresentar diferenças nas suas folhas
PA (como influência do solo) e, para dificultar ainda mais o processo, indivíduos de
   uma mesma espécie localizados em diferentes regiões ou ecossistemas, podem
   ainda conter folhas diferentes, refletindo o resultado de refinamento genético ou até
   mesmo mutações.
   Para vencer os desafios impostos pela complexa tarefa do reconhecimento
   de folhas, a proposta TreeVis está baseada em fundamentos que apresentam
   grande potencial para a solução do problema: (i) exploração sistemática das
   características das folhas através de um vasto número de atributos visuais, (i )
   sinergismo, (iii) análise estatística e (iv) metodologia de utilização.
   A exploração do maior número possível de informações (características) (i),
   fornece um contexto maior para a identificação. Devido ao grande universo de
   espécies e as grandes variações dentro de uma mesma classe, surge a
   necessidade de extrair grandes quantidades de informações, a fim de se conseguir
   dados suficientes para realizar uma classificação estatística. Esta abordagem, além
   de possuir motivação biológica, é também abordada em diversos sistemas
   338
   APLICAÇÕES PARALELAS EM VISÃO
   artificiais. O sistema de visão dos primatas por exemplo, associa diversos atributos,
   e através de sua combinação extrai uma incrível quantidade de características para
   realizar o reconhecimento. Encontramos também alguns sistemas de visão artificial
   com amplas bases de conhecimento que adotam essa estratégia para efetivar o
   reconhecimento de objetos, entre eles podemos citar a proposta Cyvis-1, bastante
   discutida nesta tese e o Seemore [Mel, 1997], sistema capaz de reconhecer um
   grande número de objetos bidimensionais, tridimensionais e flexíveis (cabo de
   telefone, tecido, etc.), fundamentalmente baseado na extração de um grande e
   variado número de características de diferentes atributos (cor, forma, textura,
   complexidade, etc.). Estreitamente ligado a essa estratégia encontramos o item (i ),
   onde podemos considerar que a combinação das características resulta em um
   sinergismo de atributos, onde a associação destas é muito mais rica do que a soma
   individual de cada parte.
   A análise estatística (iii) é um dos pontos fundamentais da proposta. Em
   primeiro lugar, através dela é realizada a classificação e consequentemente o
   reconhecimento. Em segundo lugar, é a abordagem estatística que ditará a
   metodologia de comparação e identificação. Por exemplo, através do bom senso
   estatístico, o sistema não processa o reconhecimento baseado em uma única folha
   (tanto no aprendizado quanto na busca), ao contrário disso são processadas
   diversas folhas (cerca de 10) de um mesmo espécime a fim de compensar suas
   grandes variações, convergindo para uma média.
   Finalmente é na metodologia de utilização (iv) ou seja nos procedimentos
   técnicos realizados pelo botânico que se encontra um outro ponto fundamental do
   sistema. A ele competirá a normalização da coleta de folhas, ou seja, as folhas
   deverão pertencer a uma média, não podendo ser coletados exemplares que
   contradigam a média do vegetal, tanto no tamanho, coloração ou forma. O botânico
   ainda deverá levar em conta questões como doenças ou outros aspectos que
   possam alterar as características das folhas do vegetal, e também se preocupar
   com a questão da maturidade, colhendo folhas sempre com maturidade média.
   8.4.4 - PROTÓTIPO TREEVIS
   Neste trabalho implementamos o primeiro protótipo do sistema TreeVis, no
   qual todos os métodos e técnicas utilizadas para a extração de características das
   amostras foram ajustados e configurados especificamente para a caracterização de
PA 339
   CAPÍTULO 8
   plantas arbóreas. O sistema foi implementado em Delphi para a plataforma
   Windows. Devido à grande quantidade de características extraídas das imagens,
   assim como pela resolução das imagens, o sistema consome considerável recurso
   computacional. Deste modo, ele foi implementado com recursos de paralelismo,
   através da utilização de CVMP, onde foi adotada a arquitetura de computação
   distribuída.
   A fim de avaliar, foram realizados experimentos com 59 espécies reais, das
   quais a maior parte é constituída de espécies de plantas arbóreas nativas da Mata
   Atlântica (reconhecida como a floresta mais ameaçada do planeta). Embora o
   resultado obtido tenha sido satisfatório, muito ainda deve ser feito para obter uma
   versão operacional, ou seja, que permita a utilização do TreeVis como uma
   ferramenta de trabalho para os botânicos.
   Nas próximas subseções iremos descrever o protótipo, abordar sua
   implementação paralela e apresentar alguns resultados obtidos.
   8.4.5 - DESCRIÇÃO DO SISTEMA TREEVIS
   O sistema TreeVis, conforme apresentado no diagrama em blocos da Figura
   8.14, é composto por seis módulos: Extração de características, Controle central,
   Treinamento e identificação, Análise estatística, Base de dados e Estrutura de
   amostragem.
   As informações são adquiridas pelo sistema através de um dispositivo de
   digitalização de imagens. Neste sistema foi adotado um "Scanner de mesa"
   comercial, que permite digitalizar imagens com até 9600 DPI (pontos por polegada
   " dot per inch"). Uma vez que as folhas possuem diferentes informações em cada
   um dos lados, o sistema necessita que sejam adquiridas as imagens referentes aos
   dois lados da folha, que podem ser a grosso modo definidos, como lado de sol
   (exposto a luz solar direta) e lado de sombra (lado oposto). Deste modo cada
   amido ao seu potencial de refletir a estrutura espacial da
   imagem. Embora, assim como a medida de entropia, a variância também seja
   determinada a partir da distribuição da freqüência dos níveis de cinza da imagem, a
   condição multi-escala engajada no tempo de decaimento faz com que seja
   incorporada a natureza da estrutura e complexidade espacial da medida.
   Uma outra medida importante, na tentativa de quantificar a complexidade de
   imagens, é a circularidade, determinada pela razão do quadrado do perímetro da
   forma por sua área. Deste modo, estima-se a circunferência como a forma mais
   simples, e por complexas as formas que apresentam irregularidade, especialmente
   a concavidade. Finalmente a dimensão fractal, calculada nesse experimento pelo
   método da salsichas de Minkowski (ver Seção 7.7), também se caracteriza como
   uma forma clássica para a quantificação da complexidade.
   8.3.4 - O EXPERIMENTO VIA WEB
   O experimento foi disponibilizado na Internet de modo que qualquer pessoa
   do planeta possa realizá-lo. A primeira página do experimento do ynergos contém
   as instruções básicas para a sua operação e um formulário solicitando os dados do
   326
   APLICAÇÕES PARALELAS EM VISÃO
   usuário (nome, e-mail, profissão e grau de instrução), assim como um botão
   prosseguir. Assim que o usuário pressiona o botão o experimento é inicializado,
   conforme vamos narrar. Cada imagem do experimento é apresentada na porção
   central da janela por um período fixo de tempo. Após o seu desaparecimento é
   exibida uma janela solicitando ao usuário uma nota de 0 a 10 (através de uma
   interface "combo box") para indicar o seu grau de complexidade (nenhuma
   informação sobre o conceito de complexidade é dada). Uma vez que todas as
   imagens tenham sido apresentadas e avaliadas pelo indivíduo, a página do
   experimento, que foi implementada em HTML e JavaScript, envia o resultado para
   um cgi-bin (Commom gateway interface) especial armazenado no servidor
   (experimento), que disponibiliza os dados do experimento para o ynergos. No
   mesmo instante, os dados do indivíduo, sua avaliação e a média de sua avaliação
   em relação aos outros experimentos é apresentada.
   8.3.5 - ALGORITMO GENÉTICO PARALELO - ANÁLISE E
   MODELAGEM DOS DADOS EXPERIMENTAIS
   Os dados coletados dos experimentos psicofísicos podem ser processados
   a qualquer momento pelo ynergos, a fim de se obter um modelo matemático-
   computacional da percepção humana da complexidade de imagens. Os resultados
   apresentados a seguir foram obtidos a partir do experimento psicofísico realizado
   por nove pessoas através da Internet. Para obter os coeficientes da combinação
   linear e logarítmica das características de complexidade extraídas das imagens
   (Subseção 8.3.3) correlacionadas à percepção humana, foi utilizada uma versão
PA distribuída do algoritmo genético [Goldberg, 1989] [Bruno et al., 2000], o qual
   comentaremos a seguir.
   A computação evolucionária, da qual se destaca o algoritmo genético, tem
   se tornado uma interessante alternativa para a otimização de problemas
   combinatórios e complexos. Os algoritmos genéticos codificam as soluções
   potenciais de um problema específico em uma estrutura de dados inspirada em
   cromossomos. A partir de regras de evolução genética inspiradas na natureza, tais
   como reprodução, mutação, crossover, adaptação e outras, é definido o melhor
   conjunto de parâmetros (indivíduos) que mais se adaptam (mais otimizados) a um
   determinado problema. Do ponto de vista computacional, o algoritmo genético é
   uma técnica custosa que, entretanto, apresenta um bom potencial de
   327
   CAPÍTULO 8
   implementação paralela. Sua inspiração se encontra na própria natureza, onde
   além dos indivíduos coexistirem em paralelo, ocorre o mesmo com diversos
   ambientes e nichos.
   A versão paralela do algoritmo genético foi implementada através de CVMP
   para plataforma distribuída. Devido à natureza do problema, foi adotada a
   estratégia de paralelismo processor farm. Conforme vimos no Capítulo 6, a
   estratégia processor farm, é amplamente utilizada em diversas situações e o CVMP
   possui um conjunto de ferramentas específicas para essa arquitetura, provendo sua
   programação de forma visual, simplificando bastante a sua implementação.
   Nesta concepção, o sistema é constituído de dois conjuntos de processos:
   Mestre e Escravo. O processo mestre, é responsável por coletar e redistribuir as
   populações durante a execução, além de gerar as populações iniciais e
   supervisionar os processos escravos. Já os processos escravos são responsáveis
   pelo processamento da evolução das populações. Na abordagem adotada, o
   mestre gera uma população através de parâmetros aleatórios, e a distribui para os
   processos escravos. No final de um determinado número pré-fixado de gerações
   (especificados por um parâmetro de controle), são selecionados os indivíduos mais
   adaptados, resultantes do processamento evolutivo de cada escravo e enviados
   para o mestre, que promove uma nova população baseada nesses indivíduos e
   redistribui para os escravos. Esse ciclo se mantém até que a convergência pré-
   estipulada seja atingida. A Figura 8.11 apresenta um diagrama ilustrativo sobre a
   estratégia básica de funcionamento do algoritmo genético paralelo utilizado. Nela
   temos o processo mestre e o conjunto de processos escravos. As tarefas que o
   mestre atribui aos escravos disponíveis são populações a serem evoluídas por um
   determinado número de gerações, o escravo retorna ao mestre um determinado
   número de indivíduos melhor adaptados.
   328
   APLICAÇÕES PARALELAS EM VISÃO
   Indivíduos
   melhor adaptados
   após n gerações
   Escravo n
   Mestre
   Escravo 1
   População total a
   ser evoluída
   Fig. - 8.11 - Diagrama ilustrativo da estratégia de paralelismo do algoritmo
PA genético distribuído com arquitetura CVMP processor farm .
   Na implementação do algoritmo genético foi gerada uma população inicial
   de 200 indivíduos, criados de forma aleatória e ordenados em ordem crescente
   mediante à sua adaptação ( fitness), dada pela distância euclidiana entre os
   parâmetros de complexidade definida pelos métodos matemáticos e o valor da
   função determinada pela análise humana. A cada geração, os 100 indivíduos com
   as melhores taxas de adaptação são submetidos ao cross-over e a mutação, a fim
   de produzir outros 100 indivíduos e compor a população total. Os 20 indivíduos com
   a menor adaptação, são também mantidos para garantir a diversidade. Maiores
   detalhes sobre o algoritmo utilizado no experimento podem ser obtidas em [Bruno
   et al., 2000].
   (a) (b)
   Fig. - 8.12 - Resultados da correlação do algoritmo genético para os modelos
   de complexidade utilizados. Referente a combinação linear (a) e logarítmica
   (b).
   329
   CAPÍTULO 8
   A Figura 8.12 apresenta os resultados do algoritmo genético mostrando o
   melhor ajuste das características dos modelos matemáticos utilizados em função da
   análise humana, onde a Figura 8.12a corresponde ao ajuste para o modelo de
   combinação linear (Equação 8.5) e a Figura 8.12b ao modelo logaritmo (Equação
   8.6). A taxa de adaptação foi normalizada no intervalo [-1;1]. Somente os
   coeficientes maiores do que 0,5 foram considerados no algoritmo genético de modo
   a reduzir o número de características do modelo final [Bruno et al., 2000].
   Uma vez definido os coeficientes válidos (maiores que 0,5 ou menores que -
   0,5), podemos analisar a otimização realizada pelo algoritmo genético e chegar ao
   modelo de características através da Figura 8.12. Dos 71 coeficientes extraídos
   originalmente (18 entropia, 18 tempo de decaimento, 18 circularidade e 17
   Minkowski), os modelos finais reduziram esse número para 22 (Figura 8.12a) e 8
   (Figura 8.12b), respectivamente para a combinação linear e logarítmica, o que
   indica que o modelo logarítmico demonstrou ser mais efetivo. Das 8 características
   resultantes do modelo, 4 são de entropia (3 positivas e uma negativa), 2 são de
   tempo de decaimento da variância (uma positiva e uma negativa) e 2 de Minkowski
   (uma positiva e uma negativa). Curiosamente, nenhum coeficiente de circularidade
   foi definido no modelo logarítmico, o que pode indicar uma predominância de
   textura maior que a forma na percepção de complexidade humana. O modelo
   obtido pode ser utilizado em análises de imagens e aplicações em visão
   computacional, onde são necessários obter medidas de complexidade aproximadas
   à percepção humana.
   8.3.6 - EFICIÊNCIA DA IMPLEMENTAÇÃO PARALELA
   Do ponto de vista do paralelismo e do CVMP, a implementação paralela do
   algoritmo genético possibilitou a comprovação da eficácia e dos benefícios da
   utilização do CVMP processor farm. Basicamente, encontramos cinco pontos que
   consolidaram a utilização do CVMP processor farm, demonstrados através da
   implementação do algoritmo genético paralelo: (i) simplicidade de utilização, (ii)
   estratégias de paralelismo prontas para uso, (i i) utilização genérica, (iv)
   balanceamento de carga automático e (v) alta performance.
   A Figura 8.13 apresenta três gráficos contendo o tempo de execução do
   algoritmo genético paralelo. Nos gráficos, cada um dos blocos representam as
   tarefas realizadas pelos processos escravos, que consistem em executar um
PA 330
   APLICAÇÕES PARALELAS EM VISÃO
   determinado número de gerações (8.13a e 8.13c - 20 gerações ; 8.13b - 50
   gerações). Em todos os exemplos, o sistema distribuído foi constituído de máquinas
   heterogêneas, com diferentes performances, o que coloca a prova seu
   balanceamento de carga. Nos gráficos (a) e (b) foram utilizadas quatro máquinas
   conectadas com rede ethernet 10 Mb/s. Em cada uma das máquinas foi executado
   um processo escravo, e na máquina mais veloz foi também incorporado o processo
   mestre, executado em concorrência através de multitarefa. No gráfico (c) foram
   utilizadas três máquinas conectadas através de fast ethernet 100 Mb/s. O tempo
   despendido com a troca de mensagens entre os processos é muito pequeno,
   comparado com o tempo de processamento de cada uma das tarefas, de modo
   que, a diferença de velocidade entre os sistemas de rede é praticamente
   desconsiderada.
   (a)
   (b)
   (c)
   Fig. - 8.13 - Gráficos apresentando o tempo de execução da implementação
   paralela do algoritmo genético.
   331
   CAPÍTULO 8
   A eficiência do balanceamento de cargas do sistema pode ser observada
   pela ausência de bolhas, demonstrando uma ótima utilização do hardware
   (eficiência), acarretando diretamente em boa performance. Embora a determinação
   precisa da performance do sistema seja dificultada devido à natureza aleatória,
   tanto na configuração inicial quanto na execução do algoritmo genético, ela pode
   ser estipulada de forma aproximada pela qualidade do balanceamento de cargas e
   pela baixa demanda computacional requerida pelas trocas de mensagens. Deste
   modo, se as máquinas utilizadas no sistema forem homogêneas, a taxa de
   desempenho vai estar muito próxima ao número de máquinas utilizadas.
   8.3.7 - GERAÇÃO AUTOMÁTICA DE RELATÓRIOS NA
   WEB
   Usualmente os experimentos conduzidos no ynergos produzem um grande
   conjunto de gráficos, dados numéricos e texto [Bruno et al., 1998] [Bruno et al.,
   2000]. Uma das funções do módulo Internet do ynergos é a produção de relatórios
   automáticos dos resultados obtidos nos experimentos, de modo a auxiliar a
   organização, a apresentação e visualização dos dados. Os resultados são gerados
   em HTML, possibilitando sua utilização em um grande número de aplicativos, assim
   como sua publicação direta na Internet.
   8.4 - TREEVIS - UM SISTEMA PARALELO DE VISÃO
   PARA ANÁLISE E RECONHECIMENTO ARBÓREO
   O levantamento de espécies arbóreas em florestas, além de ser um dos
   alicerces para o estudo e pesquisa científica em diversas áreas da ciência
   associadas à botânica, apresenta ainda importância vital para a manutenção e
   preservação ecológica, assim como para a economia florestal (cultivo,
   explorativismo, matéria prima para remédios, etc.). Sua importância se acentua nas
   florestas tropicais e equatoriais, que se caracterizam pela grande divergência de
   famílias e espécies de árvores, muitas das quais ainda não foram exploradas e se
   mantém objetos de pesquisa científica.
   Nesta seção será introduzida a proposta TreeVis, através da qual é proposto
PA um sistema para o reconhecimento automático de espécies arbóreas baseado na
   332
   APLICAÇÕES PARALELAS EM VISÃO
   análise sistemática de suas folhas. Além de prover o reconhecimento automático, o
   TreeVis, conta com um banco de dados, que armazena o modelo matemático do
   espécime e também sua descrição fotográfica, oferecendo uma alternativa aos
   herbários tradicionais. Também será descrito o primeiro protótipo do sistema
   TreeVis, implementado neste trabalho, o qual conta com uma arquitetura paralela
   para melhorar a performance do reconhecimento automático. A seção será
   finalizada com alguns dados experimentais de reconhecimento arbóreo de algumas
   espécies vegetais brasileiras (mata atlântica e cerrado) realizadas a partir do
   protótipo TreeVis.
   8.4.1 - LEVANTAMENTO ARBÓREO E OS HERBÁREOS
   A exploração desenfreada dos recursos naturais, a destruição dos habitats e
   a extinção de inúmeras espécies animais e vegetais, vem acontecendo nos últimos
   séculos sem a preocupação real da humanidade. Neste final de século entretanto,
   uma vez que estamos próximos de um ponto crítico, esses temas vem atraindo a
   atenção de diversos segmentos da sociedade, não sendo mais apenas um mero
   debate científico a respeito de um futuro distante. Toda essa atenção ao desgaste
   incontrolável da biosfera e a perda dos recursos genéticos nela presente, nos
   mostra que um dos grandes desafios de nosso tempo converge para o estudo e a
   compreensão da biodiversidade, para que além de conhecermos, possamos ainda
   resgatar, preservar e manejar alguns desses recursos, garantindo sua continuidade
   para o deleite das gerações futuras.
   As florestas tropicais e equatoriais são as regiões que apresentam a maior e
   mais exuberante diversidade biológica do planeta. Coincidentemente estão
   presentes em países emergentes, sem planos consistentes de preservação
   ecológica ou de levantamento sistemático da vegetação, distribuídos na América
   Latina, África e sudeste asiático. Dentre esses países podemos destacar o Brasil,
   que possui a flora arbórea mais diversificada do mundo, cuja falta de
   direcionamento técnico e conscientização ecológica na exploração dos recursos
   florestais vem acarretando danos irreparáveis, onde muitas espécies ainda
   desconhecidas ou pouco estudadas correm sério risco de desaparecer.
   As bases para o estudo da biodiversidade, sobretudo no reino vegetal,
   consistem na taxonomia e no inventário. A taxonomia vegetal é uma ciência que
   encontra um ponto fundamental em botânica, sendo responsável pela síntese,
   333
   CAPÍTULO 8
   organização, classificação, identificação e nomenclatura das plantas. É baseada
   fundamentalmente na Morfologia e na Anatomia, e recebe informações adicionais,
   enriquecendo seus processos de classificação, obtidas através do desenvolvimento
   de pesquisas em outras áreas, entre elas podemos destacar a Citologia, Fisiologia,
   Ecologia, Fitogeografia, Paleobotânica, Fitoquímica e a Genética. [Joly, 1993]
   [Stace, 1984] [Stuessy, 1990] [Lorenzi, 1992].
   Simultaneamente à classificação, surge a necessidade de realizar o
   inventário das espécies, através do qual é possível efetuar o ostra é representada através de um par de imagens. Além dessas informações,
   o sistema utiliza também uma imagem, adquirida através da ampliação de uma
   determinada região da folha, para a análise da textura de sua organização celular.
   Discutiremos sobre ela na Subseção 8.4.5.1.1. As imagens dos dois lados da folha,
   mais a imagem para análise de textura, constituem os dados de entrada do
   sistema, denominados de amostras. É denominada de Estrutura de amostragem, a
   amostra ou o conjunto de amostras a ser analisado.
   340
   APLICAÇÕES PARALELAS EM VISÃO
   Níveis de
   Cinza
   Cor
   Imagens
   Treinamento
   Forma
   Controle
   e
   Descrições
   Central
   Identificação
   Listas de
   Textura e
PA características
   Complexidade
   Histograma
   Base de Dados
   Análise
   Extração de características
   estatística
   Scanner
   Estrutura de
   amostragem
   Fig. - 8.14 - Diagrama em blocos apresentando os módulos que compõe o
   sistema TreeVis, e suas respectivas conexões.
   Nesta descrição não abordaremos da implementação paralela do sistema, a
   qual será discutida na Subseção 8.4.6, limitaremos por enquanto ao sistema na sua
   forma seqüencial. A partir da estrutura de amostras, pode ser solicitada uma
   análise, e deste modo o sistema inicia sua execução. O módulo Controle central
   envia as imagens que constituem cada uma das amostras da estrutura de
   amostragem para o módulo Extração de características. Este módulo é dividido em
   vários submódulos, cada um contendo uma família de métodos e técnicas de visão
   e processamento de imagens, responsáveis pela extração do conjunto de
   características da imagem (vetor de características).
   O sistema possibilita duas modalidades de identificação: Estática e
   dinâmica. Na identificação estática, o módulo Controle central aguarda até que
   todas as características sejam extraídas, e então as envia para o módulo
   Treinamento e Identificação, que através de busca e comparação com a base de
   dados realiza a identificação da amostra.
   A identificação dinâmica possibilita o reconhecimento da amostra em um
   tempo menor, aumentando a performance do sistema. Para essa modalidade o
   sistema tenta fazer o reconhecimento da amostra à medida em que é realizado o
   processamento e a extração das características. Uma vez que os métodos e as
   341
   CAPÍTULO 8
   técnicas de processamento de imagens e extração de características possuem
   tempo de processamento diferentes, à medida que os mais velozes (ex: área,
   histograma, etc.), extraem as características da imagem, estas são enviadas para o
   módulo de controle. O módulo de controle por sua vez, envia as característica
   parciais ao módulo Treinamento e identificação, que realiza uma busca no sistema
   de base de dados, obtendo uma lista das prováveis espécies, contendo a classe da
   espécie provável e o seu correspondente vetor de características. Esta lista é
   enviada para o módulo Análise estatística, o qual é baseado no cálculo da matriz de
   covariância, que permite determinar quais características apresentam as melhores
   discriminações entre as espécies da lista, podendo consequentemente classificá-las
   enquanto parte do módulo Extração de características executa o processamento.
   O sistema termina a execução quando finaliza a análise e processamento de
   cada uma das amostras da Estrutura de amostragem. Conforme comentamos
   anteriormente, a estrutura de amostragem pode conter uma ou mais amostras de
   uma mesma planta arbórea. A utilização de um maior número de amostras, faz com
   que o sistema possa se munir de recursos adicionais no processo de classificação,
   permitindo uma identificação mais acurada.
   Como resultado da identificação é apresentada ao usuário uma lista (com
PA cerca de 4 elementos) ordenada com as espécies mais prováveis. Selecionando o
   item da lista, são mostradas informações referentes à espécie, contendo as
   imagens de uma amostra (os dois lados da folha e a ampliação de análise de
   textura) e seus respectivos nomes popular, científico e família.
   O processo de treinamento do sistema consiste basicamente na inserção de
   novos espécimes à base de dados, sendo bastante similar ao do processo de
   identificação estática. Deve ser armazenado um grupo de amostras referente à
   espécie a ser inserida. Quanto maior o número de amostras, maior a chance de se
   obter um bom treinamento. É então solicitado ao sistema a inserção da espécie. O
   usuário deve preencher a ficha de identificação contendo o nome científico e a
   família da planta arbórea, assim como escolher uma amostra para caracterizá-la no
   processo de identificação (exibir ao usuário no resultado). Deste modo, como no
   processo de identificação, o módulo Controle central envia as imagens do primeiro
   elemento da Estrutura de amostragem para o módulo de Extração de
   características, o qual realiza o processamento e a extração das características,
   resultando em um vetor. O vetor de características é então enviado para o módulo
   Treinamento e identificação, que aguarda uma mensagem do módulo Controle
   342
   APLICAÇÕES PARALELAS EM VISÃO
   central, indicando que todas as amostras da Estrutura de amostragem foram
   processadas. Neste momento, o módulo Treinamento e identificação, realiza o
   cálculo da média dos vetores, e armazena-o no módulo Base de dados, juntamente
   com as informações sobre o espécime fornecidas pelo usuário.
   Tanto no treinamento quanto na identificação, a perícia técnica do usuário é
   fundamental, sendo o responsável pela determinação das folhas a serem
   amostradas. Lembrando mais uma vez, o material coletado para a amostragem
   deve refletir a característica média das folhas da planta arbórea, especialmente no
   que se refere à cor (maturidade), forma e dimensão. A qualidade do exemplar
   também é outro fator importante, uma vez que folhas com pragas, ou danificadas
   por insetos, vão descaraterizar o modelo obtido através do sistema TreeVis.
   Nas próximas subseções vamos descrever com maiores detalhes cada um
   dos módulos que compõe o sistema TreeVis.
   8.4.5.1 - ESTRUTURA DE AMOSTRAGEM
   O módulo Estrutura de amostragem é responsável pelo armazenamento das
   amostras a serem processadas. As amostras devem pertencer a uma mesma
   planta arbórea, ou ser provenientes de diferentes indivíduos da mesma espécie. O
   módulo funciona como uma estrutura de dados na forma de fila (FIFO - first in first
   out), disponibilizando as amostras para o módulo Controle central. O número de
   amostras necessárias para o funcionamento do sistema TreeVis é variável,
   podendo ir de uma única amostra até virtualmente quantas o usuário desejar
   utilizar. Diferentes amostras determinam uma média ao modelo das amostras,
   deste modo, quanto maior o número de amostras, maior a estimativa de que o
   modelo resultante vai estar mais próximo do modelo mais representativo da média
   das folhas desta espécie. Assim, a utilização de um número maior de amostras é
   fundamental para o bom treinamento de uma espécie.
   8.4.5.1.1 - Amostras
   As amostras são formadas por duas imagens principais e uma imagem
   adicional, que pode ou não ser utilizada no sistema. Uma vez que as folhas
   apresentam dois lados, com diferentes naturezas, fica bastante óbvio, que o
   sistema deve explorar essa característica. Portanto as imagens principais das
PA amostras são constituídas através da aquisição de cada um dos lados da folha
   (lado de sol e de sombra). O lado de sol é discriminado como lado A e o de sombra
   343
   CAPÍTULO 8
   de lado B.
   As imagens utilizadas no sistema são quadradas com lado de 512 pixels
   (potência de 2 (29 = 512)) para facilitar os métodos que utilizam a transformada
   rápida de Fourier - FFT. Esta dimensão foi escolhida por fornecer uma boa
   resolução. Experimentos realizados com resoluções menores, (128x128 e 256x256)
   não apresentaram resultados satisfatórios. Embora não tenhamos realizado testes
   detalhados, acreditamos que imagens maiores (ex: 1024x1024 ou 2048x2048)
   poderão apresentar melhores resultados, ficando como sugestão para
   experimentos e futuras versões do TreeVis. Cada imagem (lado A ou lado B) deve
   conter apenas uma folha, a qual deve estar orientada em 900, ou seja em posição
   vertical, com a extremidade da folha localizada na parte superior da imagem. A
   orientação é realizada a partir da nervura principal da folha, conforme mostra a
   Figura 8.15.
   Extremidade
   da folha
   Nervura principal
   Extremidade cortada
   do caule
   Fig. - 8.15 - Exemplo do alinhamento da imagem, na qual a nervura principal
   da folha deverá estar orientada na vertical.
   A aquisição das imagens de ambos os lados da folha é realizada com cerca
   de 200 DPI (pontos por polegada - dot per inch). No entanto na grande maioria dos
   casos, a imagem deve ser reduzida, a fim de que toda a folha caiba na imagem (ver
   Figura 8.15). O fator de redução é dado em porcentagem do tamanho original da
   imagem, e deve ser adicionado à amostra, para que com ele o sistema possa
   realizar os cálculos para compensar a redução.
   Além das imagens principais (os dois lados da folha), é realizada também a
   digitalização de uma terceira imagem, a qual denominamos imagem ampliada de
   textura, através da qual é realizada análise da organização (textura) celular. A
   Figura 8.16 mostra o procedimento de digitalização desta imagem. Com o lado de
   sol da folha, orientado no Scanner, é selecionada uma pequena janela quadrada de
   344
   APLICAÇÕES PARALELAS EM VISÃO
   0,341 polegadas de lado, a qual deve ser adquirida com uma resolução de 1500
   DPI, resultando em uma imagem de 512x512 pixels. A janela deve sempre ser
   posicionada na porção direita da folha, entre as nervuras.
   Fig. - 8.16 - Procedimento para aquisição da imagem ampliada de textura.
   Neste exemplo foi utilizada a folha da Hymenea courbaril (Jatobá).
   A Figura 8.17 mostra as imagens que compõe uma amostra completa, da
   Ormosia arborea (olho de cabra), apresentadas no ambiente gráfico do sistema
   TreeVis.
   Fig. - 8.17 - Amostra completa da Ormosia arborea (olho de cabra), no
   ambiente gráfico do sistema TreeVis. Da esquerda para a direita: lado A (sol),
   lado B (sombra) e imagem ampliada de textura.
   345
   CAPÍTULO 8
PA As amostras devem passar pelo processo de digitalização, o mais breve
   possível após sua coleta, a fim de não perderem suas propriedades vitais (cor e
   textura). As folhas devem ser lavadas e mantidas em água a fim de se manterem
   conservadas. É recomendado que algumas horas antes do processo de
   digitalização as folhas sejam ligeiramente prensadas, a fim de evitar que surjam
   dobras quando colocadas no Scanner.
   As amostras estão limitadas à folhas simples, tratando as plantas com folhas
   compostas ou palmadas da mesma forma, ou seja é considerado apenas um de
   seus elementos na constituição da amostra. As plantas com folhas compostas
   como o caso do Pau-Brasil ou palmadas como a Paineira, perdem importantes
   informações a respeito de sua composição, uma vez que o sistema considera
   apenas uma de suas componentes e despreza a sua estrutura. Uma sugestão para
   considerar essas estruturas é, nas futuras versões do sistema, incorporar essas
   informações, como parte integrante das amostras. Neste caso, usuário entraria com
   informações adicionais a respeito do espécime, indicando se a folha é simples,
   composta ou palmada, e no caso das palmadas, ainda poderia ser incorporado
   como característica de classificação o número médio de elementos que as
   compõem. Com base nestas informações o sistema poderia eliminar grande parte
   da base de dados, no processo de identificação, direcionado a pesquisa para as
   espécies pertencentes a estes grupos.
   8.4.5.2 - BASE DE DADOS
   No módulo Base de dados são armazenadas as informações referentes às
   amostras treinadas pelo TreeVis. Para cada amostra são armazenados os dados de
   identificação da espécie, fornecidos pelo usuário, contendo seu nome científico e
   vulgar, e a sua família. Uma amostra (lado A, lado B e ampliação de textura) é
   também armazenada, de forma a auxiliar o usuário na confirmação visual do
   veredicto providenciado pelo sistema. Além das informações fornecidas pelo
   usuário, é armazenado também o vetor das características extraídas pelo TreeVis,
   através do qual a espécie é modelada.
   8.4.5.3 - CONTROLE CENTRAL
   No módulo Controle central reside o coração do sistema. Nele é
   implementada a interface gráfica com o usuário (GUI), permitindo que o usuário
   346
   APLICAÇÕES PARALELAS EM VISÃO
   opere o sistema, efetue a identificação e treinamento das amostras, entre com a
   descrição das espécies (treinamento), compare o resultado visualmente, e também
   realize a visualização de algumas das técnicas e métodos de processamento de
   imagens e visão utilizadas no TreeVis. A Figura 8.18, exibe o ambiente gráfico com
   o usuário do sistema TreeVis, exemplificando alguns dos recursos de visualização
   das técnicas e métodos do TreeVis.
   Além de prover a interface gráfica com o usuário, a visualização científica e
   a operação do sistema, o módulo Controle central também controla, gerência e
   supervisiona todos os demais módulos.
   Fig. - 8.18 - Ambiente gráfico com o usuário do TreeVis. Exemplo de
   visualização de técnicas e métodos de processamento de imagens e visão.
   8.4.5.4 - EXTRAÇÃO DE CARACTERÍSTICAS
   Através do módulo Extração de características o TreeVis extrai o modelo de
   representação da amostra, que nada mais é do que um vetor de 165 elementos,
   contento todas as características determinadas pelo sistema. Este módulo é
   347
PA CAPÍTULO 8
   dividido em 5 submódulos: níveis de cinza, cor, forma, textura/complexidade e
   histograma. Os submódulos agrupam as técnicas e métodos utilizados para a
   extração das características, em função de sua natureza. O módulo Extração de
   características envia em tempo de execução do elemento do modelo de
   representação para o Controle central, possibilitando desta forma a operação do
   sistema em caráter de classificação dinâmica.
   8.4.5.4.1 - Níveis de Cinza
   Nesse módulo somente é processado o lado A da amostra, uma vez que o
   processamento aqui realizado leva somente em conta o formato da folha, a partir de
   sua binarização (que é o mesmo em ambos os lados). Dessa imagem são extraídas
   três características: área da folha, perímetro e circularidade (razão entre a área e o
   perímetro ao quadrado).
   8.4.5.4.2 - Cor
   O módulo cor é composto por dois conjuntos de características:
   cromaticidade e cromaticidade multiescala. No primeiro caso, é realizado o cálculo
   da cromaticidade para cada componente cromático (R, G e B) [Moreira, 1999]. Esse
   procedimento é realizado em ambos os lados da folha (lado A e B), uma vez que
   cada lado possui sua própria natureza cromática. As Equações 8.7, 8.8 e 8.9
   expressam o cálculo de cromaticidade para cada um dos componentes cromáticos
   da imagem, onde r, g e b é o valor do componente cromático de cada pixel, e n é o
   número de pontos pertencentes a folha. Devemos lembrar que somente são
   computados nesses cálculos os pixels pertencentes à folha.
   n
   ri
   +
   +
   i=
   r
   g
   b
   C( r
   i
   i
   i
   = 1
   )
   (8.7)
   n
   n
   gi
   +
   +
   i=
   r
   g
   b
   C( g
   i
   i
PA i
   = 1
   )
   (8.8)
   n
   348
   APLICAÇÕES PARALELAS EM VISÃO
   n
   bi
   +
   +
   i=
   r
   g
   b
   C b
   i
   i
   i
   ( = 1
   )
   (8.9)
   n
   Os cálculos para a cromaticidade multiescala são realizados da mesma
   maneira, sendo considerados os dois lados da imagem, que no entanto sofrem
   convoluções com Gaussianas de diferentes desvios padrão (5 desvios-padrão ao
   todo).
   8.4.5.4.3 - Forma
   O módulo forma analisa o contorno da folha (imagem binarizada) e também
   seu interior, através das nervuras. No primeiro caso, o sistema utiliza o algoritmo de
   extração de contorno [Cesar, 1997] (Figura 8.19b). Com base no modelo de
   contorno são calculadas 15 características, das quais, 3 consistem na energia de
   dobramento ( bending energy) multi-escala [Cesar, 1997] e as outras 12 nos
   descritores de Fourier 1D do contorno [Castleman, 1996] [Gonzalez & Woods,
   1993]. Uma vez que ambos os lados da folha possuem o mesmo contorno, somente
   é considerado o lado A.
   (a)
   (b)
   (c)
   Fig. - 8.19 - Visualização do cálculo de curvatura. Contorno da folha da
   Cariniana estrellensis (Jequitibá), obtida através da detecção de bordas da
   imagem binarizada. (b) Janela de controle, apresentando a projeção do
   contorno no eixo x, y e o gráfico de curvatura. (c) Projeção do gráfico de
   curvatura sobre o contorno (3D).
   A Figura 8.19 ilustra a visualização do cálculo de curvatura, onde a figura (a)
   349
   CAPÍTULO 8
   apresenta o contorno de uma folha, obtido através da detecção de borda (Sobel) da
   imagem binarizada, a figura (b) apresenta as projeções do contorno nos eixo x e y e
   o gráfico de curvatura e a figura (c) exibe a projeção do gráfico de curvatura de
PA forma perpendicular sobre o contorno (visualização 3D).
   Para a análise das nervuras é utilizada a transformada de Hough com
   backmapping, em ambos os lados da folha (lado A e lado B), uma vez que em
   determinadas espécies podem surgir diferenças entre as estruturas de cada lado. A
   nervura principal é desconsiderada no cálculo, que utiliza apenas as demais
   nervuras (ver Figura 8.20b). Através delas são obtidas 7 características, sendo que
   uma é referente ao ângulo de orientação das nervuras e as 6 restantes referentes
   ao número de retas obtidas, dentro de 6 dimensões pré-especificadas (definidas
   pelo sistema). A Figura 8.20 ilustra a imagem da folha segmentada exibindo seu
   contorno e nervuras (a) ,as nervuras consideradas na análise (b) e um exemplo
   mostrando o ângulo avaliado (c).
   (a) (b) (c)
   Fig. - 8.20 - Nervuras da folha, consideradas na transformada de Hough.
   Imagem segmentada (a), nervuras consideradas para a transformada (b) e
   referência do ângulo determinado pela análise (c).
   8.4.5.4.4 - Textura e complexidade
   No módulo Textura e complexidade são agrupados alguns métodos para
   medir a complexidade e a textura da folha, extraindo desse modo características.
   Como medidas de complexidade e de textura, o módulo utiliza a dimensão fractal
   (box counting), efetuada em cada um dos lados da folha, totalizando suas
   350
   APLICAÇÕES PARALELAS EM VISÃO
   características e a contagem de pontos de cruzamento por zero da transformada de
   Marr-Hildreth para 4 diferentes desvios-padrão (multi-escala) [Gonzalez & Woods,
   1993] [Marr,1982] [Parker, 1997], totalizando 5 características. Embora o módulo
   seja denominado Textura e complexidade, ele não é o único módulo a tratar deste
   atributo, uma vez que o módulo Histograma também apresenta medidas relativas
   que, devido à natureza dos métodos, foram agrupadas nele.
   Fig. - 8.21 - Visualização do domínio da freqüência (real) da imagem de
   ampliação de textura de 4 espécies diferentes, apresentando as diferenças
   que caracterizam os descritores.
   Dentre os submódulos de extração de características, Textura e
   complexidade é o único a utilizar a imagem ampliada de textura. Para analisar e
   extrair as características da imagem ampliada de textura, é utilizado os descritores
   da transformada de Fourier 2D da imagem [Gonzalez & Woods, 1993]. Os
   descritores utilizados são os radiais, e totalizam 15 características. A Figura 8.21
   apresenta a visualização do domínio (real) da freqüência de 4 espécies distintas de
   plantas arbóreas. Através delas podemos observar a variação na forma dos
   gráficos, a qual é descriminada pelos descritores, caracterizando o modelo de
   classificação por textura.
   351
   CAPÍTULO 8
   8.4.5.4.5 - Histograma
   Este módulo, embora extraia características relacionadas com a
   complexidade e a textura das folhas, recebe a denominação de Histograma, devido
   às técnicas utilizadas serem todas baseadas no histograma da imagem. Nele
   basicamente são realizadas dois tipos de medidas: cálculo do desvio-padrão da
   distribuição do histograma e cálculo da entropia do histograma [Gonzalez & Woods,
   1993]. Assim como no módulo Cor, somente são considerados os pixels
   pertencentes à folha para a elaboração do histograma. Uma vez que ambos os
PA lados da folha possuem diferentes textura, os dois são considerados pelo módulo.
   Fig. - 8.22 - Histogramas de folhas de 4 diferentes espécies, ilustrando a
   variação presente na distribuição dos histogramas.
   Os cálculos são realizados para níveis de cinza e para cada um dos
   componentes cromáticos (R, G e B). No primeiro caso, a imagem cromática da
   folha é convertida para níveis de cinza através da média dos componentes
   cromáticos. A partir dos níveis de cinza são computados 4 características para o
   desvio-padrão, das quais uma é realizada para a imagem padrão e as outras três
   para a imagem após sofrer convolução com Gaussianas de diferentes desvios-
   padrão (multi-escala). A mesma estratégia é realizada para o cálculo da entropia,
   onde também, são extraídas 4 características.
   352
   APLICAÇÕES PARALELAS EM VISÃO
   Cada um dos componentes cromáticos é considerado como um canal ou
   plano da imagem, sendo computados para cada um deles (R, G e B) as mesmas
   características obtidas na imagem de níveis de cinza. Deste modo, o número total
   de características extraídas pelo módulo é de 32 para cada lado da folha,
   totalizando 64.
   A Figura 8.22 ilustra a variação de histograma ocorrida entre 4 diferentes
   espécies de folhas. O histograma foi obtido através da imagem de níveis de cinza.
   8.4.5.5 - TREINAMENTO E IDENTIFICAÇÃO
   Tanto o treinamento quanto o reconhecimento são processos centrados no
   módulo Treinamento e identificação com base no vetor de características que,
   como vimos, é calculado através do módulo Extração de características.
   Para o módulo Treinamento e identificação o processo de treinamento
   consiste em calcular o vetor médio a partir do vetor de características de cada
   amostra processada. Para isso o módulo recebe o vetor de características do
   Controle central após a amostra ser processada pelo módulo de Extração de
   características. Ao final do processamento de todas as amostras, o módulo realiza
   a média dos vetores, obtendo o vetor de característica responsável pelo modelo da
   espécie. O vetor é armazenado juntamente com as informações de identificação da
   espécie adicionada ao sistema, na Base de dados.
   O reconhecimento pode ser efetuado de dois modos: dinâmico e estático. A
   identificação estática é realizada após serem extraídas as características das
   amostras. Compete ao módulo de treinamento e identificação realizar a
   comparação entre o modelo da amostra a ser classificada e os modelos
   armazenados na Base de dados. A comparação é realizada em duas etapas. A
   primeira seleciona uma lista de prováveis espécies, e na segunda etapa, esta lista é
   refinada. Na primeira etapa, apenas 63 das 165 características são consideradas. O
   modelo da primeira etapa de classificação é definido como um ponto num espaço
   de 63 dimensões. A lista de prováveis espécies é obtida através da distância
   euclidiana entre os dois modelos, sendo consideradas as espécies que
   apresentaram a menor distância ao modelo analisado (são inseridas na lista as
   espécies que possuem distância menor que o limiar estipulado pelo sistema). O
   refinamento da lista é realizado utilizando as outras 102 caraterísticas. É calculada
   a distância euclidiana (102 dimensões) entre os modelos da lista da primeira etapa,
   efetuando seu refinamento e obtendo deste modo a lista de identificação, que pode
   353
   CAPÍTULO 8
   possuir um ou mais elementos ordenados segundo a probabilidade de identificar o
PA modelo analisado.
   O processo de identificação dinâmica é uma tentativa de aumentar a
   performance do reconhecimento. Diferentemente do processo de reconhecimento
   estático, que aguarda até que todas as características sejam extraídas para iniciar a
   comparação, a identificação dinâmica, é um processo simultâneo à extração de
   características. Isto é permitido devido a comunicação entre os módulos Extração
   de características, Controle Central e Treinamento e identificação, que permitem que cada característica extraída seja enviada para o módulo de identificação. Com
   base nelas, o módulo realiza uma busca no banco de dados, e monta uma lista com
   que se enquadram no perfil do modelo incompleto. Esta lista é enviada então para o
   módulo Análise estatística, que retorna outra lista, indicando quais são as
   características mais importantes para classificar as espécies da lista que recebeu.
   Com base nessa informação o módulo solicita ao Controle central para que sejam
   priorizados métodos cujas características foram destacadas. O processo de
   identificação dinâmica finaliza quando as características extraídas, montarem um
   modelo que, mesmo incompleto, satisfaça as condições estabelecidas pelo sistema,
   determinando o reconhecimento.
   O processo de identificação dinâmica é um modo experimental de operação
   do TreeVis, que em certas situações consegue obter uma boa performance devido
   à limitação da extração de características, como por exemplo no caso das espécies
   com características marcantes, cuja identificação é realizada mesmo no modelo
   incompleto. Apresenta também situações onde não promove aumento de
   performance, como é o caso das espécies com características medianas, que não
   possibilitam uma boa identificação com modelos incompletos. A principal
   desvantagem na utilização do reconhecimento dinâmico está nos erros de
   identificação que o método acarreta. Assim, a identificação dinâmica deve ser
   considerada pelo menos a uma primeira instância, como uma alternativa de
   reconhecimento aberta ao estudo científico dentro do projeto TreeVis.
   8.4.5.6 - ANÁLISE ESTATÍSTICA
   O módulo Análise estatística tem a exclusiva finalidade de dar suporte ao
   módulo de treinamento e identificação, quando é realizado reconhecimento
   dinâmico. Basicamente sua função é determinar as características mais divergentes
   dentro de um conjunto de vetores de características, de modo a tornar possível a
   354
   APLICAÇÕES PARALELAS EM VISÃO
   classificação de modelos incompletos com razoável precisão.
   O principal mecanismo utilizado no módulo é o cálculo da matriz de
   covariância (Equação 8.10). Através da covariância, é possível diagnosticar o grau
   de similaridade entre as características dos modelos.
   1
   =
   x i
   ( ) x
   x i
   ( ) x
   (8.10)
   a b
   ,
   ( a
   a )( b
   b )
PA N
   Determinada a matriz de covariância, o módulo Análise estatística, procura
   pelos menores elementos da matriz, correlacionados com as características já
   extraídas pelo sistema, montando uma lista das características que possuem a
   maior chance de caracterizar o reconhecimento do modelo. O módulo conta
   também com uma tabela, indicando o tempo médio de duração para a extração das
   características. Com base na tabela e na lista de características, é elaborada uma
   nova lista, a qual é ordenada através da divergência da característica e de seu
   tempo de processamento, visando o aumento da performance no reconhecimento.
   8.4.6 - IMPLEMENTAÇÃO PARALELA
   Como ocorre usualmente em sistemas de visão, o TreeVis requer grande
   demanda computacional, possuindo portanto um elevado tempo de execução
   (Pentium II 400 MHz). A fim de melhorar a performance e consequentemente
   reduzir seu tempo de execução, foi realizada a implementação paralela do TreeVis,
   através de CVMP, possibilitando sua execução em sistemas distribuídos.
   Os módulos do sistema TreeVis possuem razoável autonomia e
   independência, permitindo a exploração de paralelismo. No entanto, o gargalo do
   sistema reside no módulo Extração de características, uma vez que concentra as
   diversas técnicas e métodos de processamento de imagem e visão, que são
   inúmeras vezes mais lentas que os processos localizados nos demais módulos.
   Deste modo, a estratégia de paralelismo adotada explorou a concorrência de seus
   submódulos.
   Foram incorporadas três estratégias de paralelismo ao sistema: (i)
   replicação dos módulos Extração de características, (i ) implementação paralela
   deste módulo e (iii) a combinação das duas estratégias anteriores.
   No primeiro caso a estratégia aproveita a necessidade do sistema a
   355
   CAPÍTULO 8
   múltiplas amostras. Assim, com a replicação dos módulos Extração de
   características, cada amostra é direcionada para um dos módulos, que as processa
   simultaneamente. A estratégia utilizada foi a fazenda de processadores, através da
   utilização do CVMP processor farm. Conforme mostrado na Figura 8.23, o sistema
   fica dividido entre mestre e escravos. Cada módulo escravo é constituído por um
   módulo de extração de características, ficando no módulo mestre todo o restante do
   sistema. O Controle central, principal unidade do mestre, fica incumbido de
   supervisionar, controlar e distribuir as tarefas (amostras) para os escravos. Essa
   estratégia possui como vantagem o balanceamento automático, podendo ser
   utilizado um conjunto de máquinas heterogêneas, sem a necessidade de ser
   realizado qualquer tipo de balanceamento de carga. A estratégia apresenta uma
   boa performance dependendo do número de amostras utilizadas, quanto maior o
   número destas melhor o resultado. Quando o número de amostras é
   consideravelmente maior que o número de processadores, a taxa de desempenho
   obtido se torna um fator próximo do número de unidades de processamento
   (escravos) do sistema, uma vez que o tempo gasto com o processamento é muito
   maior que o gasto na transferência dos dados.
   ESCRAVOS
   Imagens
   Níveis de
   Treinamento
   Cin
PA Ní zvaeis de
   e
   Descrições
   Cin
   Ní zvaeis de
   Níveis de
   Identificação
   Cinza
   Listas de
   Cor Cin
   Ní zvaeis de
   características
   Cor Cin
   Ní zvaeis de
   Cor Cinza
   Forma Cor
   Forma Cor
   Forma Cor
   Textura eForma
   Controle
   Base de Dados
   Complexida
   Textur de
   a Forma
   Central
   Análise
   Complexida
   Textur de
   a Forma
   estatística
   Complexida
   Textur de
   a
   Histogram
   Co a
   mplexida
   Textur de
   a
   Histogram
   Co a
   mplexida
   Textur de
   a
   Histogram
   Co a
   mplexidade
   Histograma
   Histograma
   Histograma
   Estrutura de
PA Extração de características
   Scanner
   amostragem
   MESTRE
   Fig. - 8.23 - TreeVis com a estratégia de paralelismo processor farm .
   No segundo caso, é explorado o paralelismo dentro do módulo, através de
   concorrência entre seus submódulos e também através da implementação paralela
   356
   APLICAÇÕES PARALELAS EM VISÃO
   dos métodos e técnicas (Capítulo 7). A exploração do paralelismo consiste na
   divisão do módulo Extração de características em partes, executando-as em
   concorrência. Devido à independência e autonomia de seus submódulos, a divisão
   do módulo de extração de características é uma tarefa simples. Contudo a
   dificuldade reside no balanceamento de cargas do sistema. Em sistemas
   homogêneos, as partes deverão possuir a mesma demanda computacional, ao
   passo que em sistemas heterogêneos, elas deverão possuir cargas proporcionais
   às máquinas em que serão executadas. Implementamos duas diferentes
   configurações dessa estratégia, uma dividindo o módulo em três partes e a outra
   em seis, ambas voltadas para sistemas distribuídos homogêneos (3 e 6 máquinas
   iguais).
   Níveis de
   Cinza
   Textura e
   Imagens
   Complexidade
   Treinamento
   e
   Descrições
   Identificação
   Listas de
   Histograma
   características
   níveis de cinza
   Controle
   Base de Dados
   Central
   Análise
   estatística
   Forma
   Estrutura de
   Cor
   Scanner
   amostragem
   Histograma
   Cor
   MESTRE
   Fig. - 8.24 - TreeVis - Exploração de paralelismo através da partição do
   módulo Extração de características em 3 partes, executadas simultaneamente
   em processadores diferentes.
   A Figura 8.24 contém um diagrama ilustrativo da versão na qual o módulo
PA de extração de características é dividido em 3 partes com performances
   aproximadamente equivalentes. Nesta abordagem, somente o submódulo
   responsável pelas medidas relativas a histogramas foi particionado, a fim de
   aproveitar as convoluções com a gaussiana (multi-escala) realizados no módulo de
   357
   CAPÍTULO 8
   Cor nos histogramas multi-escala cromáticos. Através desta configuração o TreeVis
   fica especificado para sistemas distribuídos constituídos de 3 máquinas
   homogêneas. Cada uma das máquinas deverá executar um dos fragmentos do
   módulo de extração de características. O módulo mestre, responsável pela
   supervisão e controle do sistema, é alojado (multitarefa) juntamente com o
   fragmento que agrupa os submódulos: Niveis de cinza, Textura e complexidade e
   histograma de níveis de cinza; uma vez que este possui o menor tempo de
   execução.
   Lado B
   Textura e
   Complexidade
   Lado A
   Níveis de
   Histograma
   Cinza
   níveis de cinza
   Textura e
   Imagens
   Ampl. textura
   Treinamento
   Complexidade
   e
   Descrições
   Identificação
   Listas de
   Histograma
   características
   níveis de cinza
   Lado A
   Forma
   Controle
   Base de Dados
   Central
   Análise
   estatística
   Lado B
   Forma
   Lado B
   Estrutura de
   Cor
   Scanner
   amostragem
   Histograma
   Cor
PA Lado A
   Cor
   Histograma
   Cor
   Fig. - 8.25 - TreeVis - Exploração de paralelismo através da partição do
   módulo Extração de características em 6 partes, executadas simultaneamente
   em processadores diferentes.
   Na Figura 8.25 é apresentada a versão do sistema para seis máquinas.
   Neste caso, cada uma das partes da fragmentação anterior (Figura 8.24) foi dividida
   em duas partes, correspondentes aos lados da amostra. Devido à sua natureza, o
   módulo de extração de características pode ser ainda dividido em muitos outros
   fragmentos, podendo até mesmo atingir níveis de paralelismo nos métodos e
   358
   APLICAÇÕES PARALELAS EM VISÃO
   técnicas de processamento de imagens e visão (como Hough por exemplo),
   possibilitando configurações para sistemas distribuídos com maior quantidade de
   máquinas. Neste trabalho à divisão do módulo foi realizada em até seis partes.
   A terceira estratégia (i i) de paralelismo consiste na combinação das
   estratégias processor farm (i) e fragmentação do módulo de extração de
   caraterísticas (ii). Nesse caso, o sistema possui as duas configurações, e
   dependendo do número de amostras utilizadas escolhe uma ou outra configuração
   para executar o sistema. Em sistema homogêneos, a primeira estratégia (i)
   apresenta uma performance melhor que a (ii), quando o número de amostras é
   múltiplo do número de processadores ou quando o número de amostras é grande e
   próximo ao múltiplo dos processadores. A segunda, entretanto, possui performance
   superior que a primeira, quando o número de amostras é menor que o número de
   processadores, ou quando o número de amostras é muito diferente do múltiplo do
   número de processadores.
   8.4.6.1 - RESULTADOS EXPERIMENTAIS
   Nesta subseção vamos apresentar duas séries de experimentos que
   comparam a performance das versões paralelas do TreeVis frente à sua versão
   seqüencial. Em todos os experimentos foram utilizados sistemas distribuídos
   homogêneos constituídos por máquinas AMD K6 II - 375 MHz conectadas via rede
   ethernet (padrão NE-2000) de 10 Mb/s. Na primeira série de experimentos foram
   utilizadas 3 máquinas e na segunda foi realizada a simulação de 6 máquinas. Cada
   série de experimentos contém duas experiências, uma voltada para a estratégia de
   paralelismo processor farm (i) e a outra para a estratégia (i ) (fragmentação do
   módulo de extração de características).
   Fig. - 8.26 - Gráfico do tempo de execução da versão paralela (processor
   farm ). Nove amostras foram processadas.
   359
   CAPÍTULO 8
   No primeiro experimento da primeira série foi realizado o reconhecimento de
   um espécime constituído por 9 amostras. O experimento consistiu na comparação
   entre a performance da versão paralela ( processor farm) frente a versão
   seqüencial. A Figura 8.26 apresenta os resultados obtidos no experimento, nela
   temos um gráfico do tempo de execução da versão paralela do sistema ( processor
   farm). Como pode ser observado, não ocorreram bolhas na execução e o tempo
   gasto com a transferência de dados foi praticamente desprezível, de modo que a
   taxa de desempenho ( speed-up) do sistema paralelo ficou próxima do número de
PA processadores (3).
   Na Figura 8.27 é mostrado o gráfico do tempo de execução da versão
   paralela do TreeVis (explorando o paralelismo do módulo de extração de
   características), comparada com sua versão seqüencial. Na Figura 8.27a temos o
   resultado do processamento de três amostras. Na máquina 1 foram executados os
   submódulos de cor e histograma cromático, além do mestre. Na máquina 2 o
   submódulo Forma e na máquina 3 os submódulos de níveis de cinza, textura e
   complexidade e, histograma de níveis de cinza. Na Figura 8.27b o tempo de
   execução seqüencial de uma amostra.
   (a)
   (b)
   Fig. - 8.27 - Gráficos do tempo de execução, comparando as versões paralela
   e seqüencial do TreeVis. (a) Execução de três amostras na versão paralela
   (fragmentação do módulo de extração de características). (b) Execução de
   uma amostra na versão seqüencial.
   Embora esta estratégia paralela apresente uma performance superior à
   versão seqüencial, obtendo uma máxima taxa de desempenho (Speed-up) de
   360
   APLICAÇÕES PARALELAS EM VISÃO
   aproximadamente 2,7, devido a seu balanceamento de carga, não tão equilibrado
   quanto na implementação anterior ( processor farm), apresentou uma performance
   menor. Devemos, entretanto, lembrar que para situações onde o número de
   amostras não é igual ao múltiplo do número de máquinas, surgem bolhas e a
   performance da implementação processor farm cai, fazendo com que a estratégia
   de exploração do módulo de extração de características apresente um desempenho
   superior, uma vez que não possui limitações quanto ao número de amostras.
   As Figuras 8.28 e 8.29 apresentam a segunda série de experimentos, na
   qual são utilizadas versões paralelas ( processor farm e fragmentação do módulo de
   extração de caraterísticas) configuradas para sistemas distribuídos compostos de
   seis máquinas. Seus resultados são proporcionais aos obtidos nos experimentos
   anteriores. Na versão processor farm, a taxa de desempenho ficou novamente
   muito próxima ao número de processadores utilizados (6). A versão seguinte,
   entretanto, apresentou uma pequena queda da taxa de desempenho,
   proporcionalmente ao experimento anterior (fig. 8.27), ficando em torno de 4,6. Isso
   se deve a um desequilíbrio no balanceamento de cargas do sistema, que no
   entanto pode ser melhorado através de uma nova configuração.
   Fig. - 8.28 - Gráfico do tempo de execução da versão paralela (processor farm )
   em sistema distribuído com 6 máquinas. Doze amostras foram processadas.
   361
   CAPÍTULO 8
   Fig. - 8.29 - Gráficos do tempo de execução, comparando as versões paralela
   e seqüencial do TreeVis. (a) Execução de três amostras na versão paralela
   (fragmentação do módulo de extração de características). (b) Execução de
   uma amostra na versão seqüencial.
   8.4.7 - RECONHECIMENTO DE PLANTAS ARBÓREAS
   A Tabela 8.3 apresenta a listagem das espécies utilizadas nos experimentos
   realizados com o TreeVis. Estas espécies caracterizam a flora brasileira, sendo
   nativas da mata atlântica (maior parte) e do cerrado. Além desta, utilizamos ainda,
   cerca de 30 espécies não catalogadas, contendo plantas ornamentais e frutíferas
   exóticas e nativas, a fim de somar 59 categorias na base de conhecimento do
PA sistema. Com bases nessas amostras, pudemos realizar experimentos para a
   condução do projeto (métodos, técnicas, características, etc.).
   A avaliação do sistema TreeVis é uma tarefa bastante difícil, uma vez que o
   processo de reconhecimento depende de um grande número de fatores (coleta dos
   dados, escolha da amostra, diferença entre indivíduos da mesma espécie, etc.).
   Embora não disponhamos do controle desses parâmetros, ficando como sugestão
   para trabalhos futuros, realizamos um experimento a fim de avaliar, mesmo que de
   maneira bastante aproximada, o desempenho do sistema no reconhecimento das
   espécies.
   362
   APLICAÇÕES PARALELAS EM VISÃO
   Família
   Denominação científica
   Denominação popular
   ANACARDIACEAE
   Schinus terebinthifolius Raddi
   Aroeira pimenteira
   ANACARDIACEAE
   Tapirira guianensis Aubl.
   Peito de pomba
   APOCYNACEAE
   Rauwolfia sellowii
   Casca d’anta
   BIGNONIACEAE
   Tabebuia impetiginosa (Mart.) Standl.
   Ipê roxo
   BIGNONIACEAE
   Tabebuia vellosoi (Tol.)
   Ipê amarelo
   BIGNONIACEAE
   Tabebuia roseo-alba (Ridl.) Sand.
   Ipê Branco
   BOMBACACEAE
   Pseudobombax grandiflorum Mart. & Zucc.
   Imbiruçú
   BOMBACACEAE
   Eriotheca candoleana
   Paina da mata
   BOMBACACEAE
   Chorisia speciosa (St. Hil.)
   Paineira
   BORAGINACEAE
   Patagonula americana L.
   Guaiuvira
   BORAGINACEAE
   Cordia sellowiana Cham.
   Chá de bugre
   BORAGINACEAE
   Cordia trichotoma (Vell.)
   Louro pardo
PA CECROPIACEAE
   Cecropia cineria
   Embaúba
   FABACEAE
   Platycianus regnelli Benth.
   Pau Pereira
   FABACEAE
   Miroxyon peruiferum (L.) Harms.
   Cabreúva
   LECYTHIDACEAE
   Cariniana estrellensis (Raddi) Kuntze
   Jequitibá
   LEGUMINOSAE
   Caesalpinia echinata L.
   Pau-brasil
   LEGUMINOSAE
   Hymenea courbaril L.
   Jatobá
   LEGUMINOSAE CAESALPINOIDEAE
   Bauhinia forficata (Link)
   Pata de Vaca
   LEGUMINOSAE-PAPILONOIDEAE
   Ormosia arborea (Vell.) Harms
   Olho de cabra
   MELASTOMACEAE
   Tibouchina pranulosa (Cogn.)
   Quaresmeira
   MELASTOMACEAE
   Tibouchina mutabilis (Cong.)
   Manacá da Serra
   MYRTACEAE
   Syzyngium jambolanum
   Jambolão
   MYRTACEAE
   Eugenia Uniflora (L)
   Pitanga
   MYRTACEAE
   Psidium cattleianum (Sabine)
   Araçá
   MYRTACEAE
   Psidium guajava (L.)
   Goiabeira
   MYRTACEAE
   Eugenia pyriformis (Camb.)
   Uvaia
   MYRTACEAE
   Myrciaria trunciflora (Berg)
   Jabuticabeira
   NYCTAGINACEAE
   Bougainvillea glabra (Choisy)
PA Primavera
   Tabela 8.3 - Espécies utilizadas no experimento.
   Conquanto o sistema necessita de várias amostras para efetuar um
   treinamento satisfatório, no experimento, realizamos o treinamento das espécies a
   partir de uma única amostra, a qual julgamos caracterizar a planta. Efetuado o
   treinamento das 59 espécies, realizamos o reconhecimento de 283 amostras.
   Assim como no treinamento, o reconhecimento também exige que diversas
   amostras sejam utilizadas para classificar uma espécie de forma satisfatória.
   Entretanto, visando colocar o sistema em um situação extrema, efetuamos o
   reconhecimento através de amostras constituídas por apenas uma folha. Dentre as
   283 amostras, foram identificas corretamente 226, sendo que o sistema cometeu 57
   erros no reconhecimento, estabelecendo uma margem de erro de
   aproximadamente 20%.
   363
   CAPÍTULO 8
   364
   CAPÍTULO
   9
   CONCLUSÃO
   "In my experience, the best creative work is never done when one is unhappy."
   Albert Einstein
   CAPÍTULO 9
   366
   CONCLUSÃO
   CAPÍTULO 9 – CONCLUSÃO
   9.1 – COMENTÁRIOS FINAIS E CONTRIBUIÇÕES
   Discutimos nesta tese uma série de aspectos relacionados ao paralelismo
   em visão natural e artificial. Uma vez que o paralelismo em visão artificial está
   diretamente relacionado à Computação Paralela, iniciamos a abordagem a partir de
   uma revisão dos conceitos fundamentais dessa área, tanto do ponto de vista da
   arquitetura (hardware) quanto da programação (software), com o intuito de fornecer
   aos leitores uma base substancial em Computação Paralela, permitindo uma
   melhor interação e compreensão aos assuntos tratados no decorrer da tese. Em
   visão natural, após realizarmos uma revisão de visão biológica, partimos para uma
   discussão sobre o sistema de visão dos primatas sob o ponto de vista do
   paralelismo, onde abordamos vários aspectos, dos quais podemos destacar: (i)
   modularidade do córtex visual, (ii) especialização funcional, (ii ) independência dos
   módulos e atributos, (iv) distribuição das informações ao longo do caminho visual,
   (v) independência e autonomia do caminho parvo e magno celular, (vi) arquitetura
   de paralelismo multiníveis, (vii) mapeamento das informações nas áreas corticais e
   (vi i) a integração dos sinais, módulos e atributos visuais.
   A integração entre o paralelismo em visão natural e artificial ocorre com a
   abordagem do projeto Cyvis-1. Fortemente inspirado na visão biológica, o Cyvis-1,
   apresenta diversas características baseadas no paralelismo dos sistemas de visão
   natural, que nos permitiu analisar, discutir e sugerir diversos aspectos do
   paralelismo natural que podem contribuir para a eficiência e o realismo dos
   sistemas de visão artificial. Entre os aspectos levantados e discutidos, podemos
   destacar: (i) modularidade, (i ) hierarquia, (i i) especialização funcional, (iv)
   cooperação entre subsistemas, (v) representação da informação em vários níveis
   de conhecimento, (vi) distribuição de informações em arquitetura paralela de visão,
PA (vi ) integração de atributos e módulos concorrentes, (vi i) granularidade de pacotes
   entre os níveis hierárquicos, (ix) supervisão e controle dos processos visuais, (x)
   processamento visual em tempo real, etc. Realizamos também uma série de
   comparações e análises críticas entre o projeto Cyvis-1 e outros sistemas de visão
   encontrados na literatura, que apresentam alguns aspectos semelhantes.
   367
   CAPÍTULO 9
   Neste trabalho verificamos que o paralelismo é inerente à visão natural,
   constituindo a base de sua arquitetura e podendo possibilitar uma série de
   benefícios aos sistemas de visão artificial. No entanto, constatamos que o
   paralelismo é pouco explorado em visão computacional, estando praticamente
   ausente se considerarmos sua importância, constituindo assim, uma lacuna no
   estudo da visão. Acreditamos que as razões para a ausência de paralelismo na
   visão artificial estão fundadas na própria Ciência da Computação, sendo esta o
   alicerce do estudo da visão artificial. Qualquer um que já tenha um dia desenvolvido
   e implementado um algoritmo paralelo, sabe das inúmeras dificuldades no
   desenvolvimento de software paralelo. A programação concorrente é uma tarefa
   árdua e complicada que, além de requerer um profundo conhecimento no assunto,
   exige um trabalho muito maior que o realizado nas soluções seqüenciais. Estas
   dificuldades são acentuadas pela escassez de ferramentas computacionais
?rtex visual através de simuladores neurológicos pode elucidar
   questões e apresentar novas abordagens para sistema paralelos de visão artificial.
   (ii ) Caracterização do paralelismo em visão: Os estudos e implementações de
   paralelismo em sistemas de visão artificial, realizados neste trabalho, podem ser
   aprimorados e estendidos a fim de se obter uma caracterização mais formal e
   genérica do paralelismo em visão artificial. Através da implementação e estudo de
   diversos sistemas de visão artificial, poderão ser estimadas estatísticas para o
   comportamento do fluxo de mensagem, dependência de dados e gargalos, ao longo
   da hierarquia do processamento visual.
   374
   CONCLUSÃO
   9.3.2 PROPOSTA CVMP:
   (i) Validar a versão CVMP multiprocessadores: Embora tenha sido implementado e
   discutido o componente CVMP para máquinas multiprocessadores, a sua validação
   foi realizada através de simulações, utilizando o mecanismo de multitarefa, ficando
   como uma tarefa para futuros desenvolvimentos do CVMP a sua avaliação e
   validação mais concreta em máquinas realmente multiprocessadas.
   (ii) Portar o CVMP para UNIX: Acreditamos que seria de grande importância portar
   a ferramenta CVMP para o sistema operacional UNIX, especialmente por este
   constituir uma plataforma particularmente utilizada no desenvolvimento de
   aplicações paralelas. Uma versão UNIX das ferramentas CVMP traria benefícios
   tanto para a proposta CVMP, através de sua divulgação, críticas e eventualmente
   contribuições do mundo UNIX, assim como para a própria comunidade UNIX, que
   possui como uma de suas principais deficiências a ausência de ferramentas que
   priorizem a interação homem-máquina e o manuseio amigável e intuitivo. A
   viabilização do CVMP para UNIX, se tornará possível e será justificada com o
   lançamento do ambiente de desenvolvimento Delphi para Linux, o Kylix, previsto
   para o segundo semestre de 2000.
   (ii ) Desenvolver o CVMP sobre plataformas PVM ou MPI: O CVMP pode ser
   desenvolvido para atuar sobre uma plataforma de troca de mensagens já
   estabelecida. Uma linha de pesquisa que deve ser considerada como continuidade
   deste trabalho é o desenvolvimento de versões CVMP sobre as plataformas PVM
   ou MPI. Uma vez que existe uma série de trabalhos científicos para essas
   plataformas, este desenvolvimento traria inúmeros benefícios para a proposta
   CVMP, ampliando seus recursos e possibilidades de desenvolvimento paralelo. Do
   mesmo modo, essa linha de pesquisa poderá proporcionar uma série de
   contribuições, levando para estas plataformas os benefícios CVMP
   (desenvolvimento
   visual,
   manuseio
   amigável,
   reutilização
   de
   código,
   desenvolvimento OOP, etc.).
   (iv) Novas arquiteturas: O CVMP pode ser considerado como uma camada extra de
   software sobre as primitivas de comunicação, que pode utilizar virtualmente
   qualquer mecanismo ou plataforma para troca de mensagens. Assim, uma
   interessante linha de pesquisa na qual pode ser utilizada essa proposta seria o
PA desenvolvimento de novas arquiteturas paralelas. Uma das dificuldades nesse tipo
   de projeto se encontra na base de plataformas de desenvolvimento de software.
   375
   CAPÍTULO 9
   Uma vez que as tradicionais plataformas de desenvolvimento paralelo necessitam
   " drivers" e bibliotecas específicas, o CVMP pode ser bastante promissor nesta área,
   uma vez que possui um código simples e enxuto, que pode ser facilmente adaptado
   a virtualmente qualquer mecanismo de comunicação. Um prova disto está no início
   de seu desenvolvimento. Antes de ser implementado para redes de computadores,
   o CVMP possuiu uma versão experimental que implementava máquinas paralelas
   através de comunicação com o porto paralelo (LPT, porta de impressora).
   (v) Encapsular outras estratégias de paralelismo: Um grande sucesso na proposta
   CVMP foi o encapsulamento da estratégia de paralelismo processor farm. Através
   deste componente, o desenvolvimento de aplicações paralelas baseadas nesta
   estratégia se tornou uma tarefa simples e objetiva, uma vez que o componente
   apresenta encapsulado todo o mecanismo envolvido nesta abordagem. No entanto,
   apenas uma estratégia de paralelismo foi encapsulada fazendo parte do conjunto
   de ferramentas CVMP, ficando como sugestão para futuros desenvolvimentos a
   incorporação de novos componentes que encapsulem outras abordagens de
   paralelismo.
   (vi) Desenvolver objetos para métodos de visão computacional e processamento de
   imagens: Uma das características da proposta CVMP é permitir a criação de
   componentes personalizados, que encapsulam métodos e técnicas. Embora
   tenham sido realizados estudos sobre alguns algoritmos de visão, apenas duas
   técnicas foram encapsuladas, gerando componentes prontos para utilização. De
   forma a auxiliar o desenvolvimento de aplicações paralelas, seria interessante a
   criação de diversos componentes com diferentes técnicas de processamento e
   visão computacional encapsuladas.
   (vi ) Aperfeiçoar o módulo de estatística: Uma das limitações das ferramentas de
   estatística apresentadas nesta tese, especialmente a versão em tempo real, está no
   seu condicionamento à máquina, ou seja, não foi desenvolvido uma versão da
   ferramenta que possibilita concentrar em um único módulo a análise de
   comportamento de todas as máquinas da rede. Embora esse tipo de abordagem
   possa acarretar uma sobre carga de mensagens na rede, diversas situações
   justificam sua utilização.
   376
   CONCLUSÃO
   9.3.3 - APLICAÇÕES PARALELAS REAIS EM VISÃO
   ARTIFICIAL
   9.3.3.1 - PROJETO CYVIS-1
   (i) Incorporação de novos atributos visuais: No protótipo desenvolvido no grupo,
   apenas duas modalidades visuais foram consideradas. A proposta do Cyvis-1,
   entretanto, é baseada na integração de diversos atributos visuais. Portanto, novas
   pesquisas deverão ser realizadas, especialmente na estrutura de comunicação e
   representação de informações, a fim de permitir que atributos adicionais sejam
   acrescentados no sistema.
   (ii) Reestruturação do sistema priorizando a performance: Embora o paralelismo
   tenha sido utilizado no sistema enfocando os estudos de integração de atributos
   visuais, representação de dados e trabalho corporativo, sua reestruturação visando
   ampliar a performance e independência de dados entre os módulos seria bastante
PA interessante, uma vez que este é um dos principais objetivos da Computação
   Paralela.
   (ii ) Inserção de novas estratégias de comunicação e fluxo inverso de dados: O
   projeto Cyvis-1 prevê várias etapas de comunicação realizadas entre os atributos
   visuais em diferentes níveis hierárquicos do processamento, assim como o fluxo de
   informações nos dois sentidos ("top-down" e "botton-up"). Pesquisas deverão ser
   realizadas a fim de incorporar tais características ao sistema.
   9.3.3.2 - PROPOSTA TREEVIS
   (i) Avaliação do protótipo (identificação das plantas arbóreas): A avaliação do
   protótipo TreeVis, realizada nesta tese, foi bastante sucinta. Apresentamos apenas
   um resultado para uma situação extrema do sistema (pior situação), que embora
   tenha mostrado bons resultados, não relatou com a devida determinação científica
   sua validação. Pretendemos realizar novos experimentos a fim de determinar de
   maneira mais acurada as características do protótipo, contendo resultados para as
   situações extremas e para as situações onde o sistema se apresente mais
   promissor (maior quantidade de amostras por espécie) e também, se possível, com
   um número maior de espécies arbóreas.
   377
   CAPÍTULO 9
   (ii) Realização de estudo abrangente da natureza e diversidade morfológica das
   folhas: Para implementar o primeiro protótipo do TreeVis, adotamos algumas
   metodologias para a extração de características, que embora tenham sido
   escolhidas experimentalmente através de análises em alguns tipos de folhas, a
   pesquisa realizada não foi suficientemente abrangente e acurada da forma exigida
   pelo problema. Para a continuidade da proposta TreeVis seria necessária, uma
   vasta e abrangente investigação sobre as características morfológicas das folhas
   de plantas arbóreas, de modo a definir de maneira mais precisa quais as
   metodologias e medidas se adequam melhor ao processo de classificação das
   espécies. Devido à divergência das espécies, acreditamos que deverão ser
   acrescidas muitas técnicas de processamento e visão, a fim de obter bons
   resultados em bases com centenas ou milhares de espécies.
   (ii ) Desenvolvimento de novos protótipos, dando continuidade a proposta: O
   reconhecimento automático de plantas arbóreas é um problema que está longe de
   ser resolvido na sua íntegra. O protótipo apresentado nesta tese contém apenas os
   primeiros passos para uma solução. Muito trabalho e pesquisa ainda são
   necessários, sugerindo numerosos outros protótipos para consolidar uma
   ferramenta consistente e definitiva para que o TreeVis possa vir a ser utilizado
   como um herbário digital.
   (iv) Adaptação e extensão do sistema para outros problemas em ciência teórica e
   aplicada: Embora voltado para a botânica, o ambiente e as estruturas de
   paralelismo desenvolvidas no protótipo TreeVis podem ser adaptadas e estendidas
   para outros problemas em ciência teórica e aplicada incluindo, por exemplo,
   mineração de dados em engenharia biomolecular (genética).
   378
   BIBLIOGRAFIA
   BIBLIOGRAFIA
   [Almasi & Gottlieb, 1994] ALMASI, G. S.; GOTTLIEB, A. Highly Paral el Computing.
   2.ed. California, The Benjamin/cummings Publishing, 1994.
   [Amorin et al.,1988] AMORIN, C. L.; BARBOSA, V. C.; FERNANDES, E. S. T. Uma
   introdução à computação paralela e distribuída. VI Escola de
PA Computação, Campinas, UNICAMP, 1988.
   [Andrews & Schneider, 1983] ANDREWS, G. R.; SCHNEIDER, F. B. Concepts and
   Notations for Concurrent Processing. ACM Computing Surveys, v.15
   pp3-43, 1983.
   [Atkin, 1987] ATKIN, P. Performance Maximization. Technical note 17, Inmos Ltd.,
   Bristol, 1987.
   [Baber et al., 1993] BABER, C. ; HOYES, T. ; STANTON, N. A. Comparison of
   GUIs and CUIs: appropriate ranges of actions and the ease of use.
   Displays, v14, n4, pp207-215, 1993.
   [Bal ard & Brown, 1982] BALLARD, D. H ; BROWN, C. M. Computer Vision.
   Prentice-Hall, 1982.
   [Barlow & Mollom, 1982] BARLOW, H. B. ; MOLLON, J. D. The Senses, Cambridge
   University Press, 1982.
   [Bem-Ari, 1990] BEM-ARI, M. Principles of Concurrent and Distributed
   Programming. New York, Prentice Hall, 1990.
   [Benchmark] http://webopedia.internet.com/TERM/b/benchmark.html
   [Bennett, 1997] BENNETT, G. Designing TCP/IP Internetworks. John Wiley &
   Sons, 1997.
   [Besag, 1986] Besag, J. On the statistical analysis of dirty pictures. J. Roy.
   Statist.Soc. B, 48(3):259-302, 1986.
   [Biswas et al., 1998] BISWAS, M. K. ; GHOSE, T. ; GUHA, S. ; BISWAS, K. K.
   Fractal dimension estimation for texture images: A parallel approach.
   Pattern Recognition Letters, 19(1998) pp.309-313, 1998.
   [Blasdel, 1986] BLASDEL, G. Differential imaging of ocular dominance and
   orientation selectivity in monkey striate cortex. Nature, 321:579-585,
   1986.
   [Bogni & Marrone, 1991] BOGNI, C. J.; MARRONE, L. Arquitectura de
   379
   BIBLIOGRAFIA
   Computadoras. Rio de Janeiro, V Escola Brasileiro - Argentina de
   Informática, 1991.
   [Bonhoeffer & Grinvald, 1991] BONHOEFFER, T. ; GRINVALD, A. Iso-orientation
   domains in cat visual cortex are arranged in pinwheel-like patterns.
   Nature, 353: 429-431, 1991.
   [Bonner, 1995] BONNER, P. Programação Visual: Promessa/Realidade Windows
   Computing, v. 2, n.1, p.64-6, 68, 70, 72, 74-5, 1995.
   [Braham, 1996] BRAHAM, R. Toward an artificial eye, IEEE Spectrum, p.20-29,
   May 1996.
   [Braitenberg & Braitenberg, 1979] BRAITENBERG, V ; BRAITENBERG, C.
   Geometry of orientation columns in the visual cortex. Biological
   Cybernetics, 33:179-186. 1979.
   [Brawer, 1989] BRAWER, S. Introduction to Paral el Programming. San Diego, CA
   (USA), Academic Press, 1989.
   [Breton, 1991] BRETON, Philippe História da Informática São Paulo, Ed. UNESP,
   1991
   [Brigham, 1988] BRIGHAM, E. O. The Fast Fourier Transform and its Applications.
   Prentice Hall, 1988.
   [Broca, 1861] BROCA, P. P. Perte de la parole, ramol isement chronique et
   destructuion partielle du lobe antérieure gauche du cerveau. Bull. Soc.
   Anthropol, v. 2, pp. 235-238.
PA [Bruce & Green, 1990] BRUCE, V. ; GREEN, P. Visual perception: physiology,
   psychology and ecology 2ed. London, Lawrence Erlbaum Associates,
   1990.
   [Bruno & Costa, 1996] BRUNO, O. M. ; COSTA, L da F. Towards Cost-Effective
   and Versatile Real-Time Vision Based on a Distributed System of
   Personal Computers. IEEE Proceedings - II Workshop on Cybernetic
   Vision. São Carlos, Brasil, 1996.
   [Bruno & Costa, 1997] BRUNO, O. M.; COSTA, L. da F. Versatile Real-Time Vision
   Based on a Distributed System of Personal Computers. Proceedings -
   Third IEEE International Conference on Engineering of Complex
   Computer Systems. Como, Itália, 1997.
   [Bruno & Costa, 2000] BRUNO, O. M.; COSTA, L. da F. Effective Image
   Segmentation with Flexible ICM-Based Markov Random Fields in a
   Distributed Systems of Personal Computers. Real-Time Imaging, artigo
   380
   BIBLIOGRAFIA
   submetido e aceito, aguardando publicação.
   [Bruno et al., 1998] BRUNO, O. M., CESAR Jr., R.M., CONSULARO, L.A., and
   COSTA, L. F. Automatic feature selection for biological shape
   classification in ynergos. Proceedings 1998 International Symposium on
   Computer Graphics, Image Processing and Vision, Rio de Janeiro, RJ,
   IEEE Computer Society Press, pp 363-370, 1998.
   [Bruno et al., 2000] BRUNO, O. M., CESAR Jr., R.M., CONSULARO, L.A., and
   COSTA, L. F. ynergos - Synergetic Vision Research. Real Time Journal,
   artigo submetido e aceito, aguardando publicação.
   [Bruno, 1995] BRUNO, O. M. Sistema Automatizado de Medidas TSC em
   Plataforma GUI Dissertação de Mestrado, IFSC – USP, 1995.
   [Bruno, 1999] BRUNO, O. M. Exame de qualificação, IFSC-USP, 1999.
   [Calvert, 1997] CALVERT, C. Borland C++ Builder unleashed. Sams, 1997.
   [Calvert, 1999] CALVERT, C. Delphi 4 unleashed. Sams, 1999.
   [Cantoni & Lombardi, 1999] CANTONI, V. ; LOMBARDI, L. Visual attention in
   artificial systems. Proceedings 1999 I International Seminar on
   Bioelectronic Interfaces and III Workshop on Cybernetic Vision,
   Campinas, Brazil, 1999.
   [Cantù,1995] CANTÙ, M. Mastering Delphi Sybex, 1995
   [Caserta et al., 1995] CASERTA, F. ; ELDRED, W. D. ;FERNANDEZ, E. ;
   HAUSMAN, R. E. ; STANFORD, L. R. ; BULDEREV, S. V. ;
   SCHWARZER, S. ; STANLEY, H. E. Determination of fractal dimension of
   physiological y characterized neurons in two and three dimensions.
   Journal of Neuroscience Methods. 56, pp. 133-144, 1995.
   [Castleman, 1996] CASTLEMAN, K.R. Digital Image Processing, Prentice-Hal ,
   Englewood Cliffs, NJ, 1996.
   [Cesar & Costa, 1998] CESAR Jr., R.M. and COSTA, L. F. Neural cel classification
   by wavelets and multiscale curvature, Biological Cybernetics, v.79, n.4,
   pp.347-360, 1998.
   [Cesar, 1997] CESAR Jr., R. M. Análise Multi-escala de formas bidimensionais.
   Tese de doutorado, IFSC - USP, 1997.
   [Chappel , 1998] CHAPPELL, L. A. Novel 's Guide to Lan/Wan Analysis : Ipx/Spx.
   Novell Press, 1998.
   [Chel appa & Jain, 1993] CHELLAPPA, R. ; JAIN, A, (eds.). Markov Random Fields.
PA Academic Press, 1993.
   381
   BIBLIOGRAFIA
   [Chu & George, 1999] CHU, E. ; GEORGE, A. Inside the FFT Black Box: Serial and
   Parallel Fast Fourier Transform Algorithms. CRC Press LLC, 1999.
   [Clark, 1986] CLARK, N. N. Three Techniques for Implementing Digital Fractal
   Analysis of Particle Shape .Powder Technology. 46, 1986.
   [Codenoti & Leoncini, 1994] CODENOTI, Bruno ; LEONCINI, Mauro.. Introducing to
   Paral el Processing. New York, Addison-Wesley, 1994.
   [Coelho, 1   amigáveis e intuitivas, baseadas na interação homem-máquina, para o
   desenvolvimento de aplicações paralelas.
   Além do perfil científico e tecnológico no projeto Cyvis-1, devemos levar em
   conta o trabalho humano envolvido sob o ponto de vista do desenvolvimento e
   implementação. Estando o Cyvis-1 fortemente inspirado nos benefícios do
   paralelismo em visão, surge à tona as dificuldades da programação concorrente.
   Uma vez que o Cyvis-1 é um projeto complexo, modular e de longa duração, que
   abrange diferentes especializações em visão (atributos visuais) e portanto possui
   vários pesquisadores envolvidos, surgem também as questões da manutenção e
   reutilização de código e da integração e cooperação entre os pesquisadores. Um
   dos principais objetivos deste trabalho foi apresentar as soluções para estes
   problemas e assim propor uma plataforma de desenvolvimento para o projeto
   Cyvis-1.
   A fim de atender as necessidades de paralelismo do Cyvis-1 e dos demais
   projetos de nosso grupo (Cybernetic Vision Research Group), introduzimos uma
   nova plataforma de desenvolvimento de programação concorrente denominada
   CVMP (Cybernetic Vision Message Passage). Baseado em programação orientada
   a objetos, interface homem-máquina, engenharia de software e programação visual,
   o CVMP é uma proposta para facilitar e simplificar o desenvolvimento de programas
   paralelos, seja através de sistemas distribuídos ou máquinas multiprocessadores.
   Através do CVMP, qualquer programador com um conhecimento reduzido em
   Computação Paralela pode desenvolver com facilidade suas próprias aplicações
   368
   CONCLUSÃO
   paralelas. Além da facilidade de utilização, o CVMP também apresenta recursos
   para a reutilização de código, permitindo que as estruturas e algoritmos possam ser
   reaproveitados, agilizando o desenvolvimento de sistemas.
   Dentre os componentes que compõem o CVMP, o CVMP processor farm,
   em especial, ilustra as possibilidades de reutilização de código, facilidade e
   simplicidade no desenvolvimento de aplicações paralelas. Este componente possui
PA encapsulados todos os recursos necessários para o desenvolvimento de uma
   aplicação paralela baseada na estratégia processor farm, permitindo que o
   programador desenvolva um programa concorrente de forma visual.
   Diferente da programação seqüencial, na programação concorrente é
   necessário ao programador analisar a execução do programa, de modo a localizar
   os gargalos do sistema e efetuar o balanceamento de cargas, permitindo ampliar a
   sua performance e eficiência. Uma grande limitação dos ambientes de
   desenvolvimento paralelo está na falta de suporte para tais análises, tornando-as
   uma tarefa árdua e difícil a ser realizada pelo programador. A fim de suprir essas
   limitações e auxiliar o programador nas análises estatísticas dos programas
   concorrentes, o CVMP apresenta ferramentas de análise estatística, que permitem
   o monitoramento e a análise dos programas em duas diferentes modalidades:
   dados analisados após o término dos processos ou em tempo de execução.
   O CVMP foi desenvolvido para ser utilizado na plataforma Delphi/C++
   Builder (Windows NT/9X), aproveitando os recursos computacionais destes
   ambientes de desenvolvimento (OOP, programação visual, etc.), e permitindo que
   os programadores utilizem as linguagens e os ambientes seqüenciais a que estão
   familiarizados no desenvolvimento das aplicações paralelas. Entretanto, graças a
   sua concepção, o CVMP se comporta como uma camada adicional de software,
   que gerencia as primitivas de comunicação do sistemas operacional, podendo,
   deste modo, atuar em sistemas distribuídos ou multiprocessadores (memória
   compartilhada). Devido a essa característica, o CVMP pode ser desenvolvido de
   modo a utilizar sistemas de troca de mensagens já existentes, tais como o PVM ou
   MPI, permitindo um desenvolvimento simples, amigável, e os benefícios da OOP
   (programação visual, reutilização de código, etc.).
   Outra característica do CVMP, devido a sua versatilidade, é a possibilidade
   de fornecer a base para o desenvolvimento de novas arquiteturas paralelas. Uma
   vez que o CVMP apresenta um código simples e enxuto (componente CVMP básico
   com cerca de 980 linhas) e pode ser baseado em qualquer mecanismo de
   369
   CAPÍTULO 9
   comunicação, ele pode ser utilizado como plataforma de desenvolvimento de
   software para novas arquiteturas. Um bom exemplo para essa aplicação, seriam as
   arquiteturas baseadas em interface SCSI [Henry et al., 1998] [Mattson & Henry,
   1998] [Phillips, 1998] que, por estarem em desenvolvimento, podem não apresentar
   dispositivos de comunicação prontos para utilizarem por exemplo ferramentas
   convencionais de desenvolvimento paralelo (MPI, PVM, etc.). Uma vez que o
   CVMP pode ser facilmente adaptado a qualquer mecanismo de comunicação, ele
   pode fornecer a base para o desenvolvimento para novas arquiteturas paralelas.
   No decorrer do trabalho, observamos que os problemas que afligiam o
   desenvolvimento do Cyvis-1 não estavam apenas limitados ao seu universo, mas
   sim poderiam preencher de certo modo a lacuna do paralelismo em visão, e
   também de diversas outras áreas científicas que demandam soluções paralelas.
   Deste modo, a proposta CVMP não apenas cumpriu seus objetivos iniciais como
   também possibilitou um vasto campo de utilização, abrindo inúmeras perspectivas
   para esta proposta. Voltaremos a este assunto na seção 9.3, na qual são discutidos
   seus desenvolvimentos futuros.
   Uma vez definida a proposta de paralelismo, um dos objetivos foi avaliar,
   analisar e validar o CVMP, nos aspectos de funcionalidade, performance e
   utilização. Esse objetivo foi satisfeito através de uma série de implementações de
PA algoritmos de visão computacional e de processamento de imagens. Foram
   implementados diversos algoritmos clássicos na área, tais como operadores locais,
   transformada de Hough, transformada de Fourier e outros. Em cada um dos casos
   foi discutida a arquitetura e abordagem paralela, assim como analisada a
   performance e eficiência da versão paralela dos algoritmos frente à seqüencial. Os
   algoritmos foram analisados através dos módulos de estatística do CVMP, os quais
   permitiram um estudo sobre seu comportamento, eficiência e performance, gerando
   resultados que validaram a proposta e demonstraram sua performance e potencial
   para desenvolvimento de aplicações paralelas. Dentro dessa análise foi ainda
   introduzida uma nova técnica de paralelismo para um novo algoritmo de
   segmentação de imagens baseado em campos aleatórios de Markov [Bruno &
   Costa, 2000].
   Finalizando o trabalho, foram apresentadas 3 aplicações reais de visão
   artificial que utilizam diferentes conceitos de paralelismo. Tais aplicações não
   apenas concluem a validação da ferramenta de desenvolvimento paralelo
   desenvolvida no decorrer deste doutorado, como também demonstram diferentes
   370
   CONCLUSÃO
   vantagens na utilização de paralelismo em sistemas de visão, tais como: aumento
   de performance, integração entre atributos visuais, modularidade, independência
   modular e integração entre pesquisadores. Duas dessas aplicações foram
   desenvolvidas em conjunto com outros membros do grupo de Visão Cibernética,
   assim permitindo avaliarmos o paralelismo e o CVMP como integradores de
   trabalho. A integração entre pesquisadores ocorre devido à natureza do
   paralelismo, que exige uma estrutura modular e independente e que propicia o
   trabalho cooperativo. Quanto ao CVMP, a possibilidade de utilizá-lo em projetos
   cooperativos reais foi de grande valia para comprovar sua simplicidade de utilização
   (manuseio amigável), facilidade, interação homem-máquina, integrar pesquisadores
   em trabalhos paralelos cooperativos e reutilização de código. Deste modo, os
   ótimos resultados obtidos com o CVMP na implementação destas 3 aplicações foi
   uma convincente maneira de demonstrar que os objetivos da proposta foram
   satisfeitos.
   Todas as 3 aplicações discutidas nesta tese são inéditas, constituindo por si
   só contribuições originais. A primeira delas contém uma proposta para a integração
   de atributos visuais (cor e estéreo) dentro do projeto Cyvis-1, a partir do
   paralelismo. Desenvolvida por Jander Moreira e Alan Salvany Felinto, em
   colaboração com autor, o sistema foi implementado em CVMP, tendo como
   finalidade a identificação de objetos poliédricos cromáticos através da integração
   entre os atributos visuais cor e estéreo. Aqui foi apresentado o primeiro protótipo do
   sistema Cyvis-1, e diferente das outras duas aplicações, o paralelismo é visto como
   um agente de integração, uma vez que a implementação não objetiva a
   performance de processamento. Além da integração dos atributos visuais, a
   aplicação ilustrou também o paralelismo como fonte de modularização e
   consequentemente como base de apoio para o trabalho cooperativo.
   Na segunda aplicação foi implementado um experimento no projeto
   ynergos. Desenvolvido em colaboração com Luís Augusto Consularo e Roberto
   Cesar Marcondes Jr. [Bruno et al., 2000], a aplicação constitui um experimento para
   um modelo de complexidade baseado na percepção humana. Através de um
   experimento psicofísico, são coletados dados que refletem a percepção de
   complexidade humana. O modelo é baseado em 4 técnicas de medidas de
PA complexidade: (i) Entropia dos níveis de cinza, (ii) Tempo de decaimento multi-
   escala da variância da distribuição dos níveis de cinza da imagem (variância do
   histograma), (i i) circularidade e (iv) dimensão fractal por salsichas de Minkowski.
   371
   CAPÍTULO 9
   Com base nos dados do experimento psicofísico, as técnicas são otimizadas
   através de um algoritmo genético paralelo, implementado através do CVMP
   processor farm. Neste experimento, o paralelismo foi utilizado para aumentar a
   performance do processo de otimização realizado pelo algoritmo genético. A
   performance da implementação paralela foi bastante satisfatória, apresentando uma
   taxa de desempenho próxima ao número de processadores utilizados.
   Na terceira aplicação foi introduzida uma proposta do autor, de um sistema
   de visão paralela para o reconhecimento automático de plantas arbóreas. A fim de
   desenvolvermos uma aplicação real para visão paralela, procuramos identificar um
   problema de relevância, onde pudéssemos contribuir para sua solução. Em
   botânica, é de extrema importância o estudo da biodiversidade, sendo assim é vital
   o levantamento arbóreo das florestas tropicais, uma vez que estas apresentam a
   maior biodiversidade do planeta. Foi introduzida nesta tese a proposta de um
   sistema, que fornece aos botânicos uma ferramenta complementar aos tradicionais
   herbários. Intitulado TreeVis, o sistema de visão em questão extrai uma série de
   atributos de folhas de plantas arbóreas e, através de classificador estatístico,
   procura identificar o espécime, funcionando como um herbário automático. O
   sistema é baseado em uma arquitetura paralela, utilizada para aumentar o
   desempenho dos processos de treinamento e reconhecimento. Através de uma
   heurística especial, tomada a partir do número de amostras a ser processada, o
   sistema escolhe qual estratégia de paralelismo realiza a tarefa com a melhor
   performance. Os resultados obtidos comprovaram mais uma vez o potencial do
   CVMP no fornecimento das bases computacionais para o desenvolvimento de
   paralelismo, mesmo em situações complexas.
   9.2 - SÍNTESE DAS PRINCIPAIS CONTRIBUIÇÕES
   Embora inter-relacionados, os assuntos abordados nesta tese podem ser
   divididos em três modalidades, relacionadas da seguinte forma: (i) discussão do
   paralelismo em visão natural e artificial; (ii) proposta CVMP e (iii) aplicações
   paralelas reais em visão artificial. Seguindo essa divisão, foi montada a tabela 9.1,
   que apresenta a síntese das principais contribuições de cada modalidade.
   372
   CONCLUSÃO
   ABORDAGEM
   CONTRIBUIÇÕES
   • Revisão bibliográfica crítica e abrangente de computação paralela.
   • Discussão do sistema de visão cortical dos primatas sob o ponto de
   vista do paralelismo.
   Discussão do
   • Levantamento das principais questões, adotadas no sistema de visão
   paralelismo em visão
   dos primatas, que podem aperfeiçoar os sistemas de visão artificial.
   natural e artificial
   • Levantamento de sistemas de visão e comparação com o Cyvis-1.
   • Discussão das abordagens de paralelismo no projeto Cyvis-1
   • Levantamento das possíveis contribuições fornecidas pelo
PA paralelismo em visão artificial.
   • Proposta de um conjunto de ferramentas para o desenvolvimento de
   aplicações paralelas, com base na simplicidade de utilização
   (manuseio amigável), facilidade, programação visual e reutilização de
   código - CVMP (Cybernetic Vision Message Passage).
   • Desenvolvimento, implementação e validação da proposta CVMP.
   Proposta CVMP
   • Ferramentas para a análise estatística de programas concorrentes.
   • Implementação e avaliação do desempenho de diversos algoritmos
   de visão e processamento de imagens.
   • Técnica de paralelismo para um novo algoritmo de segmentação de
   imagens baseado em campos aleatórios de Markov.
   • Estrutura de paralelismo para a integração de atributos visuais
   (estéreo e cor) no projeto Cyvis-1, em colaboração com os colegas
   Jander Moreira e Alan Salvany Felinto.
   • Experimento para extrair um modelo de complexidade baseado na
   percepção humana, através da Internet, com abordagem paralela.
   Desenvolvido em colaboração com Luis Augusto Consularo e Roberto
   Aplicações paralelas
   Cesar Marcondes Junior [Bruno et al., 2000].
   reais em visão artificial • TreeVis - Proposta e implementação de um sistema para o
   reconhecimento automático de plantas arbóreas (herbário digital).
   • Arquitetura de paralelismo com heurística seletiva, para diagnosticar
   automaticamente a melhor performance de atuação (projeto TreeVis).
   • Demonstração do paralelismo como base para estruturação e
   modularização de sistemas de visão, de forma a contribuir com o
   trabalho cooperativo entre pesquisadores da área.
   Tabela 9.1 - Síntese das principais contribuições desta tese.
   373
   CAPÍTULO 9
   9.3 - PESQUISAS FUTURAS
   Uma das características dos trabalhos multidisciplinares está na diversidade
   de direções que eles motivam, possibilitando perspectivas tanto para sua
   continuidade quanto para o surgimento de novas linhas de pesquisa. Como seria de
   se esperar, as contribuições desta tese proporcionam diversos caminhos para
   estudos futuros, complementações do trabalho e novas linhas de pesquisa. Vamos
   fazer algumas sugestões para a continuidade deste trabalho, obedecendo a divisão
   modular apresentada na seção anterior: (i) estudos de paralelismo em visão natural
   e artificial; (ii) proposta CVMP e (iii) aplicações paralelas reais em visão artificial.
   Estaremos tecendo um breve comentário em cada um dos itens das subseções
   seguintes.
   9.3.1 - ESTUDOS DE PARALELISMO EM VISÃO NATURAL
   E ARTIFICIAL
   (i) Acompanhar o desenvolvimento da neurociência: O córtex visual ainda é muito
   pouco compreendido, tornando sua pesquisa uma área fértil e produtiva, da qual
   provêm com freqüência considerada, novos modelos, teorias e descobertas. Deste
   modo, o estudo do paralelismo em visão é uma tarefa contínua, que exige o
   acompanhamento constante do desenvolvimento da neurociência e áreas
   relacionadas.
   (ii) Experimentos em modelos corticais artificiais: Modelos corticais artificiais
PA contribuem para a compreensão dos mecanismos corticais. O estudo do
   paralelismo no c?998] COELHO, R. C. Síntese, modelagem e simulação de estruturas
   neurais morfologicamente realísticas. Tese de doutorado, IFSC - USP,
   1998.
   [Consularo & Costa, 1998] CONSULARO, L. A. ; COSTA, L. da F. MATCOM
   Integrates MATLAB Resources Into Standalone Applications. Computers
   in Physics, v12 n5 p460, 1998.
   [Consularo et al., 1999] CONSULARO, L. A. ; CESAR JR, R. M. ; COSTA, L. da F.
   ynergos and its application to contour segmentation. Proceedings 1999 I
   International Seminar on Bioelectronic Interfaces and III Workshop on
   Cybernetic Vision, Campinas, Brazil, 1999.
   [Costa & Sandler, 1993] COSTA, L. da F. ; SANDLER, M. B. Effective detection of
   digital bar segments with Hough transform. CVGIP: Gr. Models Imge
   Process: v.55, n.3, pp.180-191, 1993.
   [Costa & Slaets, 1991] COSTA, L. da F. ; SLAETS, J. F. W. On the efficiency of
   parallel pipelined architectures, IEEE Transactions on Signal Processing,
   39(9):2086-2089, 1991.
   [Costa & Velte, 1999] COSTA, L. F. and VELTE, T. Automatic characterization and
   classification of ganglion cells from the salamander retina, Journal of
   Comparative Neurology, v.404, n.1, pp.33-51, 1999
   [Costa et al., 1994] COSTA, L. da F. ; RODA, V. O. ; KÖBERLE, R. A biological y-
   inspired system for visual pattern recognition. Proceedings - IEEE
   International Symposium on Industrial Electronics, Santiago, Chile, 1994.
   [Costa, 1996] COSTA, L. da F. Novas perspectivas em neuromorfologia e
   neuromodelagem, Tese de livre-docência, IFSC - USP, 1996.
   [Cox, 1986] COX, Brad J. Object-Oriented Programming – AN Evolutionary
   Approach. New York, Addison-Wesley, 1986.
   [Darwin, 1859] DARWIN, C. R. On the Origin of Species by Means of Natural
   Selection - The Preservation of Favored Races in the Struggle for Life,
   London, 1859 (disponível em http://www.literature.org/authors/darwin-
   382
   BIBLIOGRAFIA
   charles/the-origin-of-the-species/index.html).
   [Deatz, 1997] DEATZ, G. Sharing memory. Delphi Informant, v.3, n.11, 1997.
   [Dowling, 1992] DOWLING, J. E. Neurons and networks - An introduction to
   neurocience. The Belknap Press of Harvard University Press, 1992.
   [Duda & Hart, 1972] DUDA, R. O. ; HART, P. E. Use of the Hough transformation to
   detect lines and curves in pictures. Comunications of the ACM, v.15, n.1,
   pp11-15, 1972.
   [Duda & Hart, 1973] DUDA, R. O. ; HART, P. E. Pattern classification and scene
   analysis. John Wiley and Sons, Inc., New York, 1973.
   [Dumas, 1995] DUMAS, A. Programando winsock. Axcel Books, 1995.
PA [Duncan, 1990] DUNCAN, R. A Survey of Paral el Computer Architectures.
   Computer IEEE, v23, n 2, p 5-16, 1990.
   [Etter, 1995] ETTER, D. M. Introduction to MATLAB for engineers and scientists.
   Prentice-Hall, 1995.
   [Faber et al., 1987] FABER, V ; LUBECK, O. M. ; WHITE, A. B. Jr. Comments on
   the paper “Paral el efficiency can be greater than unity”, Paral el
   Computing, 4:209-210, 1987.
   [Falconer, 1990] FALCONER, K. Fractal Geometry-Mathematical Foundations and
   Applications. John Wiley & Sons, 1990.
   [Faugeras, 1996] FAUGERA, O. Three-dimensional computer vision: a geometric
   viewpoint. MIT Press, 2nd ed. 1996.
   [Fernades et al., 1993] FERNANDES, Edil S. T.; AMORIN, Cláudio, L. de
   Arquiteturas Paralelas Avançadas. Embalse, VI Escuela Brasileño –
   Argentina de Informática, 1993.
   [Fernades, 1997] FERNANDES, I. Taxonomia e fitogeografia de Cyatheaceae e
   Dicksoniaceae nas Regiões Sul e Sudeste do Brasil. Tese de doutorado,
   IB (Instituto de Botanica) USP, 1997.
   [Flynn, 1966] FLYNN, M. J., Very High Speed Computing Systems Proc.IEEE Vol
   54, p 1901-9, 1966
   [Flynn, 1972] FLYNN, M. J. Some Computer Organizations and Their Effectiveness.
   IEEE Trans. Comput. C-21 p948-60, 1972
   [Foster, 1995] FOSTER, I. Designing and Building Paral el Program – Concepts and
   Tools for Paral el Software Engineering. New York, Addison-Wesley,
   1995.
   [Fritsch & Hitzig, 1870] Fritsch, G. ; Hitzig, E. Uber die elektriche erregbakeit des
   383
   BIBLIOGRAFIA
   grosshirns. Arch. F. Anat. Physiol. U. Wiss. Med., v.37, pp. 300-332.
   [Gazzaniga, 1998] GAZZANIGA, m. S. The split brain revisited Scientific American
   v. 279, n. 1, p 34-39, July, 1998.
   [Gehani, 1988] GEHANI, N. Ed. ; MCGETTRICK, A. Ed. Concurrent Programming.
   Wokingham, England, Addison-Wesley, 1988.
   [Geist et al., 1996] GEIST, BEGUELIN, DONGARRA, et al. PVM: Paral el Virtual
   Machine, A User's Guide and Tutorial for Paral el Computing, MIT Press,
   1996.
   [Geman & Geman, 1984] GEMAN, S. ; GEMAN, D. Stochastic relaxation, Gibbs
   distributions, and the Bayesian restoration of images. IEEE Transactions
   on Pattern Analysis and Machine Intel igence, vol. PAMI-6, n.6, november
   1984.
   [Gerig & Klein, 1986] GERIG, G. & KLEIN, F. Fast contour identification through
   efficient Hough transform and simplified interpretation strategy. In: Proc.
   8th Int. Conference on Pattern Recognition, vol. 1, pp. 498-500, Paris,
   France, October 27-31, 1986.
   [Gimarc & Milutinovic, 1987] GIMARC, C. E.; MILUTINOVIC, V. M. A survey of
   RISC processors and computers in the mid-1980s. IEEE Computer, 20(9),
   p59-69, Sep. 1987.
   [GNOME] www.gnome.org
   [Goldberg, 1989] GOLDBERG, D. E. Genetic algorithms in search, optimization, and
   machine learning, Addison-Wesley, 1989.
   [Goldstein, 1989] GOLDSTEIN, E. B. Sensation and Perception. Wadsworth
PA Publish Company, 1989.
   [Goldstine, 1993] GOLDSTINE. Herman H. The Computer from Pascal to Von
   Neumann. Princeton, Princeton University Press, 1993.
   [Gomes et al., 1999] GOMES, C. ; BUNKS C. ; CHANCELIER, J. ; STEER, S. ;
   NIKOUKHAH, R. Engineering and scientific computing with Scilab.
   Springer Verlag, 1999.
   [Gonçalves, 1999] GONÇALVES, S. E. Reconhecimento Visual Atencional. Tese
   de doutorado, COPPE, UFRJ, 1999.
   [Gonzalez & Woods, 1993] GONZALEZ, R. C. ; WOODS, R. E. Digital Image
   Processing. Addison-Wesley, 1993.
   [Gregory, 1987] GREGORY, S. Paral el Logic Programming in PARLOG, Addison-
   Wesley, 1987.
   384
   BIBLIOGRAFIA
   [Grimes, 1997] GRIMES, R. Professional DCOM programming. Wrox Press, 1997.
   [Guil & Zapata, 1997] GUIL, N.; ZAPATA, E. L. Fast Hough transform on
   multiprocessors: A branch and bound approach. Journal of Paral el and
   Distributed Computing, 45(1):82-89, August 1997.
   45(1):82-89, 25 August 1997. [BibTeX entry]
   [Hayes, 1990] HAYES, Frank From TTY to VUI. Byte, p205-211, Ap. 1990.
   [Henry et al., 1998] HENRY, G. ; FAY, P. ; COLE, B. ; MATTSON, T. G. The
   performance of the Intel TFLOPS supercomputer.
   http://developer.intel.com/technology/itj/q11998/articles/art_2.htm , 1998.
   [Hockney & Jesshope, 1988] HOCKNEY, R. W.; JESSHOPE, C. R. Paral el
   Computers 2. Philadelphia, IOP, 1988
   [Hodges, 1992] HODGES, Andrew Alan Turing: The Enigma London, Vintage,
   1992.
   [Hough, 1959] HOUGH, P. V .C. Machine Analysis of Bubble Chamber Pictures.
   International
   Conference
   on
   High
   Energy
   Accelerators
   and
   Instrumentation, CERN, 1959.
   [Hubel & Wiesel, 1977] Functional architecture of macaque monkey visual cortex.
   Ferrier Lecture, Proc. R. Soc. Lond. B. 198:1-59.
   [Hubel et al., 1977] HUBEL, D. H.; WIESEL, T. N.; STRYKER, M. P. Orientation
   columns in macaque monkey visual cortex demonstrated by the 2-
   deoxyglucose autoradiograph technique. Science, 269:328-330.
   [Hubel, 1995] HUBEL, D. H. Eye, brain and vision Scientific American Library,
   1995.
   [Hudak, 1989] HUDAK, P. Functional Programming Languages, ACM Computing
   Surveys, v. 21, pp359-411, 1989.
   [Hundert, 1995] HUNDERT, E. M. Lessons from an optical il usion: On nature and
   nurture, knowledge and values. Harvard University Press, 1995.
   [Hurson et al., 1993] HURSON, A. R. ; PAKZAD, S. H. ; CHENG, J. Object-
   Oriented Database Management Systems: Evolution and Performance
   Issues, Computer, v.26, n. 2, p. 48-60, 1993.
PA [Hwang et al., 1984] HWANG, Kai; BRIGGS, Fayé A. Computer Architecture and
   Paral el Processing. New York, McGraw-Hil , 1984.
   [Inmos, 1988] INMOS Limited. Transputer Reference Manual. New York, Prentice
   Hall, 1988.
   [Inmos, 1988b] INMOS Limited. Occam2 Programming Manual, Prentice Hal , 1988.
   385
   BIBLIOGRAFIA
   [Inmos, 1989] Transputer Applications Notebook - Architecture and Software.
   Inmos, 1989.
   [Joly, 1993 JOLY, A. B. Botânica - Introdução à taxonomia vegetal. Companhia
   Editora Nacional, 11 edição, 1993.
   [Julesz, 1995] JULESZ, B. Dialogues on perception. The MIT Press, 1995.
   [Kaye, 1989] KAYE, B. H. Image Analysis Techniques for Characterizing Fractal
   Structures. from The Fractal Approach to Heterogeneous Chemistry (D.
   Avnir, editor). John Wiley & Sons Ltd., 1989.
   [Kaye, 1994] KAYE, B. H. A Random Walk Through Fractal Dimensions: 2nd Edition.
   New York, VCH Publishers, 1994.
   [Kindermann and Snel , 1980] KINDERMANN, R. ; SNELL, J. L. Markov random
   fields and their applications. Contemporary Mathematics, American
   Mathematical Society, 1980.
   [Konopka, 1997] Konopka, R. Developing custom Delphi 3 components.
   Scottsdale, Arizona (USA), The Coriolis Group, 1997.
   [Kosslyn, 1996] KOSSLYN, S. M. Image and Brain: The resolution of the imagery
   debate. The MIT Press, 1996.
   [Kovács, 1996] KOVÁCS, Z. L. Redes neurais artificiais: Fundamentos e
   aplicações. São Paulo, Edição Acadêmica, 1996.
   [Kovács, 1997] KOVÁCS, Z. L. O cérebro e a sua mente: Uma introdução à
   neurociência computacional. São Paulo, Edição Acadêmica, 1997.
   [Krishnamurthy, 1989] KRISHNAMURTHY, E. V. Paral el Processing: Principles
   and practice. Sydney, Addison-Wesley, 1989.
   [Kung et al., 1987] KUNG, S. Y. et al. Wavefront Array Processors – Concept to
   Implemention. Computer IEEE, 20(7), p18-33, Jun. 1987.
   [Kylix] http://www.borland.com/about/press/2000/kylixkickstart.html , Abril, 2000.
   [Leventhal, 1988] LEVENTHAL, Lance Lance Leventhal’s 80386 Programming
   Guide Toronto, Bantam Book, 1988.
   [Levine & Shefner, 1991] LEVINE, M. W. ; SHEFNER, J. M. Fundamentals of
   sensation and perception. Brooks/Cole Publishing, 1991.
   [Levine, 1985] LEVINE, M. D. Vision in man and machine. N. York, McGraw-Hil ,
   1985.
   [Li, 1995] LI, S. Z. Markov random field modeling in computer vision. Springer-
   Verlag, 1995.
   [Livingstone & Hubel, 1988] LIVINGSTONE, M. ; HUBEL, D. Segregation of form,
   386
   BIBLIOGRAFIA
   color, movement and depht: anatomy, physiology and perception.
   Science, v.240 p.740-749, 6 May 1988.
   [Lorenzi, 1992] LORENZI, H. Árvores brasileiras: Manual de identificação e cultivo
   de plantas arbóreas nativas do Brasil. Editora Plantarum, 1992.
   [Machado, 1993] MACHADO, A. B. M. Neuroanatomia funcional. 2.ed. São Paulo,
   Atheneu, 1993.
PA [Mandelbrot, 1977] MANDELBROT, B. B. Fractals: Form, Chance and Dimension.
   W. H. Freeman and Company, 1977.
   [Mandelbrot, 1983] MANDELBROT, B. B. The fractal geometry of nature. W. H.
   Freeman and Company, 1983.
   [Marr, 1982] MARR, D. Vision - A computational investigation into the human
   representation and processing of visual information. New York, W. H.
   Freeman and Company, 1982.
   [Mattson & Henry, 1998] MATTSON, T. G. ; HENRY, G. An overview of the Intel
   TFLOPS supercomputer.
   http://developer.intel.com/technology/itj/q11998/articles/art_1.htm , 1998.
   [McCulloch & Pitts, 1943] MCCULLOCH, W. ; PITTS, W. A logical calculus of the
   ideas immanent in nervous activity. Bulletin of Mathematical Biophysics,
   1943.
   [Mel, 1997] MEL, B. W. SEEMORE: Combining color, shape, and texture
   histogramming in a neurally inspired approach to visual object recognition.
   Neural Computation, v.9 pp.777-804, 1997.
   [Morante et al., 1999] MORANTE, S. ; ROSSI, G. ; SALINA, G. A paral el fast
   Fourier transform. International Journal of Modern Physics C, Vol. 10, No.
   5, pp. 781-805, 1999.
   [Moreira et al., 1999] MOREIRA, J. ; FELINTO, A. S. ; COSTA, L. F. Cyvis-1:
   Integration of Color and Stereo. International Workshop on Synthetic-
   Natural Hybrid Coding on 3D imaging. Santorini, Greece, September 15-
   17, 1999.
   [Moreira, 1999] MOREIRA, J. Uma proposta de estruturação e integração de
   processamento de cores em sistemas artificiais de visão. Tese de
   doutorado, IFSC - USP, 1999.
   [Mullender et al., 1990] MULLENDER, S. J.; ROSSUM, G.; TANENBAUM, A. S.;
   RENESSE, R.; STAVEREN, H. Amoeba: A Distributed Operating System
   for the 1990s. IEEE Computer, vol. 23, pp. 44-53, May 1990.
   387
   BIBLIOGRAFIA
   [Naiditch, 1995] NAIDITCH, D. Rendezvous with Ada 95, John Wiley & Sons, 1995.
   [Nazif & Levine, 1984] NAZIF, A. M. ; LEVINE, M. D. Low level image
   segmentation: An expert system. IEEE Transactions on Pattern Analysis
   and Machine Intelligence. V.PAMI-6, n.5, September, 1984.
   [Nelson, 1989] NELSON, M. LZW data compression. Dr. Dobb's Journal, October
   1989.
   [Oppenheim & Schafer, 1975] OPPENHEIM, A.V. ; SCHAFER, R.W. Digital Signal
   Processing, Prentice Hall, 1975.
   [Pacheco, 1997] PACHECO, Peter. Paral el Programming with MPI, Morgan
   Kaufmann, 1997.
   [Parker, 1997] PARKER, J. R. Algorithms for Image Processing and Computer
   Vision. John Wiley & Sons, 1997.
   [Peddie, 1992] PEDDIE, Jon Graphical User Interfaces and Graphic Standards.
   New York, McGraw Hil , 1992.
   [Peitgen & Saupe, 1988] PEITGEN, H. O. ; SAUPE, D. The science of fractal
   images. Springer-Verlag, New York, 1988.
   [Peixoto & Barbosa, 1998] PEIXOTO, A. L. ; BARBOSA, M. R. V. Os herbários
   brasileiros e a flora nacional: Desafios para o século 21. Sistemas de
   informação sobre biodiversidade/biotecnologia para o desenvolvimento
PA sustentável, 1998. - http://www.bdt.org.br/oea/sib/
   [Penrose, 1989] PENROSE, R. The emperor's new mind: Concerning computers,
   minds, and the laws of physics. Oxford University Press, 1989.
   [Petzold & Yao, 1996] PETZOLD, C. ; YAO P. Programming Windows 95.
   Redmond, Microsoft Press, 1996
   [Pfister, 1995] PFISTER, G. F. In Search of Clusters, New York, Prentice Hal , 1995.
   [Phil ips, 1998] PHILLIPS, B. Have storage area networks coming out of age? IEEE
   Computer, p10-12, July, 1998.
   [Poggio & Weinshal , 1993] POGGIO, T. ; WEINSHALL, D. The MIT vision
   machine: Progress in the integration of vision modules. In: CHELLAPA,
   R. ; JAIN, A. Markov random fields: Theory and application. Academic
   Press, Boston, 1993.
   [Poggio et al., 1985] Poggio, T. ; Torre, T. ; Koch, C. Computational vision and
   regularization theory. Nature, 317:314-319, 1985.
   [Pratt, 1984] PRATT, T. W. Programming Languages – Design and Implementation,
   New York, Prentice Hall, 1984.
   388
   BIBLIOGRAFIA
   [Preece et al., 1994] PREECE, J. ; ROGERS, Y. ; SHARP, H. ; BENYON, D.
   Human-Computer interaction. Addison-Wesley, 1994.
   [Pressman, 1988] PRESSMAN, R. Software Engineering. New York, McGraw Hil ,
   1988.
   [PVM]
   Paral el
   Virtual
   Machine
   -
   Home-Page.
   http://www.epm.ornl.gov/pvm/pvm_home.html
   [Qian, 1997]Qian, N. Physiological computation of binocular disparity . Vision Res.,
   37(13):1811-1827, 1997
   [Quinn, 1987] QUINN, M. J. Designing efficient algorithms for paral el computers.
   [Richter, 1995] RICHTER, J. Advanced Windows. Microsoft Press, 1995.
   [Rol s et al., 1994] ROLLS, E. T ; TOVEÈ, M. J. ; PURCELL, D. G. ; STEWART A.
   L. ; AZZOPARDI, P. The responses of neurons in the temporal cortex of
   primates and face identification and detection. Experimental Brain
   Research, n. 101, p473-484, 1994.
   [Rosenberry et al., 1992] ROSENBERRY, W.; KENNEY, D.; FISHER, G.
   Understanding DCE. Sebastopol, O’Reilly, 1992.
   [Ryan, 1992] RYAN, B. Built for speed Byte, p123-129, Feb. 1992.
   [Schalkoff, 1989] SCHALKOFF, R. F. Digital image processing and computer
   vision. John Wiley and Sons, 1989.
   [Schmidt, 1980] SCHMIDT, R. F. Fisiologia Sensorial. EDUSP, 1980.
   [Shapley & Perry 1986] SHAPLEY, R. ; PERRY, V. Cat and monkey retinal
   ganglion cel s and their visual functional roles. Trends in Neuroscience, v9
   p.229-235, 1986.
   [Shirai, 1987] SHIRAI, Y. Three-dimensional computer vision. Springer-Verlag,
   1987.
   [Smith et al., 1996] SMITH, T. G. ; LANGE, G. D. ; MARKS, W. B. Fractal Methods
   and results in cellular morphology - dimensions, lacunarity and
PA multifractals. Journal of Neuroscience Methods. 69, pp.123-136, 1996
   [Snow, 1992] SNOW, C. R. Concurrent Programming. Cambridge, Cambridge
   University Press, 1992.
   [Sobel, 1970] SOBEL, I. E. Camera models and machine perception. Ph.D. Thesis,
   Stanford University, 1970.
   [Spufford & Uglow, 1997] SPUFFORD, F. ; UGLOW, J. Cultural Babbage –
   Technology, Time and Invention London, Faber and Faber, 1997.
   [Stace, 1984] STACE, C. A. Plant Taxonomy and Biosystematics, London, Edward
   389
   BIBLIOGRAFIA
   Arnold, 1984.
   [Stanley, 1986] STANLEY, H. E. Form: An introduction to self-similarity and fractal
   behavior, in: STANLEY, H. E. ; OSTROWSKY, N. On Growth and form -
   Fractal and non-fractal patterns in physics. Martinus Nijhoff Publishers,
   Dordrecht, The Netherlands, p. 21-53, 1986.
   [Stuessy, 1990] STUESSY, T. F. Plant Taxonomy (The systematic Evaluation of
   Comparative data). New York, Columbia University Press, 1990.
   [Tabak, 1990] TABAK, Daniel RISC systems Taunton, Research Studies Press,
   1990.
   [Tanenbaum, 1989] TANENBAUM, Andrew S. Computer Networks. Englewood
   Cliffs, Prentice-Hall, 1989.
   [Tanenbaum, 1990] TANENBAUM, Andrew S. Structured Computer Organization.
   Upper Saddle River, Prentice-Hall, 1990.
   [Tanenbaum, 1992] TANENBAUM, Andrew S. Modern Operating Systems.
   Englewood Cliffs, Prentice-Hall, 1992.
   [Tanenbaum, 1995] TANENBAUM, Andrew S. Distributed Operating Systems.
   Englewood Cliffs, Prentice-Hall, 1995.
   [Thazhuthaveetil & Shah, 1991] THAZHUTHAVEETIL, M.J. ; A.V. SHAH Parallel
   Hough transform algorithm performance. Image and Vision Computing,
   volume 9 (1991), number 2, pp. 88-92, 1991.
   [Theimer & Mallot, 1994] THEIMER, W. M., MALLOT, H. A. Phase-based binocular
   vergence control and depth reconstruction using active vision. CVGIP:
   Image Understanding. 60(3):343-358. November 1994.
   [Tovée, 1996] TOVÉE, M. J. An introduction to the visual system. Cambridge
   University Press, 1996.
   [Tricot, 1995] TRICOT, C. Curves and Fractal Dimensions. Springer-Verlag, Paris,
   1995.
   [Tsai, 1987] TSAI, R. A versatile camera calibration technique for high accuracy 3D
   machine vision metrology using off-the-shelf TV and lenses. IEEE Journal
   of Robotics and Automation, 3(4):323-344, August 1987
   [Unger, 1958] UNGER, S. H. A computer oriented towards spatial problems.
   Proceedings Inst. Radio Engineering, USA, 1958.
   [Voorhees & Poggio, 1988] VOORHESS, H. ; POGGIO, T. Computing texture
   boundaries from images. Nature, v.333 p364-367, 1988.
   [Wilder, 1993] WILDER, F. A guide to the TCP/IP protocol suite. Artech House,
   390
   BIBLIOGRAFIA
   1993.
   [Wil iams, 1994] WILLIAMS, A. OLE 2.0 and DDE distil ed: A programmer's crash
   course. Addison-Wesley, 1994.
PA [Zeki & Shipp, 1988] ZEKI, S. ; SHIPP, S. The functional logic of cortical
   connections, Nature, v.355, p311-317, September 1988.
   [Zeki, 1993] ZEKI, S. A vision of the brain. Blackwel Science, 1993.
   [Zuffo, 1978] ZUFFO, J. A. Fundamentos da arquitetura e organização dos
   microprocessadores. São Paulo, Edit. Edgard Blücher, 1978.
   391
   290 14457
